<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"augf.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1. tensorflows tensorflow 数据流图 用于数值计算单开源软件库 Nodes : 数学操作 &gt; 特别地，有数据输入和数据输出的节点， 或者是读取、写入持久变量的终点 &gt; persistent edges: 多维数据数组， tensor &gt; 根据不同的计算, 张, 即数据的大小可变size 特征 - 高度的灵活性，可自己写C++ - 可以在CPU,">
<meta property="og:type" content="article">
<meta property="og:title" content="deep learning study">
<meta property="og:url" content="https://augf.github.io/2019/09/10/deep-learning-study/index.html">
<meta property="og:site_name" content="Life&#39;s Notes">
<meta property="og:description" content="1. tensorflows tensorflow 数据流图 用于数值计算单开源软件库 Nodes : 数学操作 &gt; 特别地，有数据输入和数据输出的节点， 或者是读取、写入持久变量的终点 &gt; persistent edges: 多维数据数组， tensor &gt; 根据不同的计算, 张, 即数据的大小可变size 特征 - 高度的灵活性，可自己写C++ - 可以在CPU,">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-09-10T12:56:16.000Z">
<meta property="article:modified_time" content="2021-05-27T01:05:35.000Z">
<meta property="article:author" content="Yun-Pan Wang">
<meta property="article:tag" content="deeplearning">
<meta property="article:tag" content="tools">
<meta property="article:tag" content="numpy">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://augf.github.io/2019/09/10/deep-learning-study/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>deep learning study | Life's Notes</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Life's Notes</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">岁月数载，愿不负韶华</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://augf.github.io/2019/09/10/deep-learning-study/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          deep learning study
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-10 20:56:16" itemprop="dateCreated datePublished" datetime="2019-09-10T20:56:16+08:00">2019-09-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/" itemprop="url" rel="index"><span itemprop="name">tools</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>13k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>11 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="tensorflows">1. tensorflows</h2>
<p>tensorflow 数据流图 用于数值计算单开源软件库</p>
<p>Nodes : 数学操作 &gt; 特别地，有数据输入和数据输出的节点，
或者是读取、写入持久变量的终点 &gt; persistent</p>
<p>edges: 多维数据数组， tensor &gt; 根据不同的计算, 张,
即数据的大小可变size</p>
<p>特征 - 高度的灵活性，可自己写C++ - 可以在CPU, GPU, Docker等，
Portablilty 可移植性 - 科研和产品 - 自动求微分 &gt;
只需要添加数据和目标函数，可以自动计算相关的微分导数 - 多语言支持 -
支持线程、队列、异步操作的支持，可以自由第将TensorFlow中的计算元素分配到不同的设备中</p>
<span id="more"></span>
<h3 id="什么是tensorflow">1.1 什么是tensorflow</h3>
<p>能够在几行代码之内构建模型，能够在几十或几百个机器的簇是哪个进行训练，从而用该模型进行非常低的延迟预测</p>
<p>模型会以图的形式展现出来，可以推迟或删除不必要的操作，甚至重用部分结果，还可以很轻松地实现的一个过程叫做反向传播。
基于所见的样本以及计算的误差。来更新模型中的链接强度，这整个过程就是反向传播</p>
<p>因为模型表现为操作图而不是代码，因此会自动地计算以及应用这些迭代更新。</p>
<p>可以用一行代码声明，我想这部分图在这里运行，另一部分分布式运行在不同的机器上。</p>
<p>注重数学的在GPU上运行，与此同时，数据输入的代码在CPU运行。专门的硬件TPU</p>
<p>tensorflow可以在ios安卓、甚至树莓派等设备上加载。</p>
<p>TensorBoard可视化哦工具</p>
<h3 id="tensorflow可以做什么">1.2 tensorflow可以做什么</h3>
<p>谷歌在多种应用上应用了tensorflow</p>
<h3 id="tensorflow入门指南">1.3 tensorflow入门指南</h3>
<ul>
<li><p>边: Tensor &gt; 把所所有都看作张量 &gt; 属性 - 数据类型
tf.float32, tf.complex32 ? 怎么表示, tf.int32, tf.string, tf.bool - 形状
list: [1,2,3,4] &gt; 操作 - 获取阶 tf_tensor1_ndim = tf.rank(tf_tensor1)
- 切片 tensor[:,1] ?是否是引用 - 返回numpy数组 tf.eval(tensor) &gt;
分类</p>
<ul>
<li>每次运行都一样
<ul>
<li>1维 tf.constant(tf.type)</li>
</ul></li>
<li>每次运行都不一样 &gt; 占位input_node = tf.placeholder(tf.int32) +
输入 sees.run( , feed_dict={input_node: 2})</li>
<li>每次运行中都发生变化，比如模型中的参数 &gt; 如果设置变量
<ul>
<li>tf_var = tf.get_variable(name, shape=, initializer=tf.costant())
<ul>
<li>name唯一标志，不可重复，下文可直接使用？一般两个名字一样？ &gt;
理解: name主要有两个用法：1.保存时可以直接使用变量保存 2.
tensorboard时用来使用 &gt; why?
因为这里name实际上是tensorflow中自己存储的命名空间，而py文件中的名字是python中的命名空间，所以当脚本运行终止后将不复存在</li>
<li>shape:[1,2], []表示标量</li>
<li>initializer: 默认值 arry-like &gt;
如果默认所有变量都使用默认值启动，那么tf.global_variables_initializer()
&gt; 当发生变化时，判断是否合理
<ul>
<li>取值
<ul>
<li>tf.constant</li>
<li>tf.zeros_initializer, tf.glorot_uniform_initializer</li>
</ul></li>
</ul></li>
<li>变量检查 assign_node = tf.assign(tf_var, default_node) default_node
= tf.constan(arr) 为true表示成功</li>
<li>运行时靠什么启动? sess.run(assign_node), sess.run(tf.var)</li>
</ul></li>
<li>tf_var = tf.Variable(initializer=arr_like_list, tf.type, name=,
traninable=Fals.e, collections=[]) collections表示可能的类型 &gt; 获取值
sess.run(tf_var.initializer) sess.run(tf_var)</li>
<li>进阶：考虑作用域问题，将问题转换为作用域问题 &gt;
用途主要在RNN循环神经网络的构建中会使用到 with
tf.variable_scope(scope_name, reuse=False): v1 = get_variable('x', [1])
&gt; 技巧： 把每个层看作一个单元 scope_name为str, 直接进行改变名称即可;
当指定reuse=True时，可以进行变量复用</li>
</ul></li>
</ul></li>
<li><p>节点： operation</p></li>
<li><p>架构</p>
<ul>
<li>sess = tf.Session()
<ul>
<li>sess.run(args)
<ul>
<li>args(0): list(nodes) 需要输出的节点</li>
<li>feed_dict={} : 为前面tf.placeholder(tf.int32)占位的数据输入数据</li>
</ul></li>
</ul></li>
<li>机器学习过程
<ul>
<li>设计抽象模型
<ul>
<li>构建网络结构 x= tf.placeholder y=tf.placeholder m=tf.var
b=tf.var</li>
<li>模型表达式 y_guess = mx + b</li>
<li>损失定义 loss = tf.square(y-y_guess)</li>
<li>指定梯度下降方法 optimizer =
tf.train.GradientDescentOptimizer(lambda): 学习率</li>
<li>train_op = optimizer.minimize(loss) 训练模型</li>
</ul></li>
<li>开始训练
<ul>
<li>loss, _ = sess.run([loss, train_op], feed_dict={input_placehold: ,
output_placehold: }) &gt; _占位, 表示train_op. &gt;
这样直接完成一轮训练？并没有说迭代终止条件啊！！！ &gt;
input_placeholder应该是支持数组的吧？
还有应该默认就把var看作模型的参数，每次梯度下降进行更新吧？每个变量tf.Variable.init()中有可选方法，
traninable来选择是否使用到Optimizer,
不过这应该是不会在模型中使用到吧</li>
</ul></li>
<li>debug
<ul>
<li>print_sum_node = tf.Print(node1,list(nodes)) //
表示自己想要的node</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="其它">1.4 其它</h3>
<p>tensorflow使用数据流图将计算表示为独立的指令之间的依赖关系，这可生成低级别的编程模型。
首先定义低级别的编程模型，在改模型中，首先定义数据流图，然后创建tensorflow会话。</p>
<p>why？ 数据流图 &gt;
数据流是一种用于并行计算的常用模型。tf.matmul操作对应于单个节点 -
并行处理。通过使用明确的边缘来表示操作之间的依赖关系 -
分布式执行。通过使用明确的边缘来表示操作之间流动的值，可以将程序划分到不同机器的多种平台
- 编译.
XLA编译器可以使用数据流图中的信息生成更快的代码，例如将相邻的操作融合到一起
- 可移植性。不依赖与模型的代码表示法</p>
<p>tf.Graph结构 -
图结构：图的节点和边缘，表示各个操作组合在一起的方式，但不规定它们的使用方式
- tf.Operation: 节点. - tf.Variable(0) - tf.matul(x,y) -
tf.constant(42,0) - tf.train.Optimizer.minmize():
执行的最后，该操作在执行时将返回一个tf.Operation.
该操作在运行时将这些梯度用到一组变量上。 &gt;
一般地，直到拥有表示整个计算（例如梯度下降法的一步）的tf.Tensor或tf.Operation,才使用Session计算
- 图集合: 在图中存储了元数据集合的通用机制。 &gt; 如Variable,
collections, 分全局变量和可训练变量</p>
<p>？如何保存整个图，保存整个图的关键就在于保存节点和边，所以在tensorflow中就是如何保留节点和边。
即Tensor, Operation &gt; 不保留Operation,
每个Tensor都有自己的名称。特别地是，在保存时，Tensor命名为"生成它的操作：索引"？？？,
是否有name</p>
<ul>
<li><p>将操作放置到不同的设备</p>
<ul>
<li>设备规范：<code>/job:&lt;JOB-NAME&gt;/task:&lt;TASK-INDEX&gt;/device:&lt;DEVICE_TYPE&gt;:&lt;DEVICE_INDEX&gt;</code>
&gt; 其中device_type即决定CPU还是GPU</li>
<li>并行化？
<ul>
<li>这里的并行化从编程的角度的感觉就是指定每个device安排哪些工作而已。
&gt; ? 总的操作应该是合起来看的吧？
<ul>
<li>任务并行 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">with tf.device(&quot;/job:ps/task:0&quot;):</span><br><span class="line">    weights_2 = tf.Variable(tf.truncated_normal[]) </span><br><span class="line">with tf.device(&quot;/job:ps/task:1&quot;):</span><br><span class="line">    weights_1 = </span><br></pre></td></tr></table></figure></li>
<li>数据并行 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with tf.device(tf.train.replica_device_setter(ps_task=3)):</span><br><span class="line">    w_0 = tf.Varible  // task:0</span><br><span class="line">    b_0 = tf.Varible  // task:1</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>类张量对象</p>
<ul>
<li>tf.Tensor</li>
<li>tf.Varible</li>
<li>numpy.ndarray</li>
<li>list</li>
<li>标量Python数据类型 &gt;
注意！在写代码时最好将所有的类张量都转换为tf.Tensor.
否则，每次使用时都会创建新的Tensor, 会爆内存</li>
</ul></li>
<li><p>会话 tf.Session &gt; 推荐 <code>with tf.Session() as sess:
#..</code> &gt; 会话是拥有物理资源如GPU和网络连接的 &gt;
tf.train.MonitoredTrainingSession或tf.estimatorEstimator?
将会自动创建和管理Session</p>
<ul>
<li>tf.Session.init三个参数
<ul>
<li>target: 默认将使用本地机器中的设备，也可以指定棋子。</li>
<li>graph: 会默认捆绑到当前的图</li>
<li>config: 配置设备、机器以及优化</li>
</ul></li>
<li>tf.Session.run(): 执行动作，会强调需要执行哪些子图.
在执行最终节点之前，务必注意需要将所有的变量的初始化操作完成
<ul>
<li>fetches: list, 指定必须要执行哪些操作</li>
<li>feed_dict: dict为图的元素赋予值</li>
<li>options</li>
<li>run_metadate</li>
</ul></li>
</ul></li>
<li><p>直观展示图</p>
<ul>
<li>tf.summary.FileWriter(save_path, sess.graph): 在with tf.Session() as
sess之后，即将图已经建好之后 &gt; 发现一个事情？
sess.run在写代码时，感觉到一个点就是，每个点是单独算的。然后进行梯度更新的，然后图神经网络是这样没有问题的，但是一般的算法也是这样搞的吗？</li>
</ul></li>
<li><p>保存和恢复</p>
<ul>
<li>变量保存 saver = tf.train.Saver(), saver.save(sess, "model.ckpt");
tf.reset_default_graph() saver.restore(sess, "model.ckpt") &gt;
注意这里的保存方式就是之前讨论的保存方式。然后还有一点就是默认会保存全部的变量
checkpoint file &gt; 特殊定制化： saver.save(var_name, var)</li>
<li>模型保存 tf.saved_model.simple_save</li>
</ul></li>
<li><p>debug 待扩展</p></li>
<li><p>性能</p>
<ul>
<li>输入流水线 &gt;
输入流水线会从一个位置提取数据，对数据进行转换，然后将数据加载到加速器上进行处理。
&gt; https://zhuanlan.zhihu.com/p/43356309
推荐大数据100MB以上使用tf.data,小数据集使用feed_dict
<ul>
<li>create <code>.tfrecords</code> file, 思路即通过迭代器来做</li>
<li>read '.rfrecords` as input, 整个过程使用迭代器来完成</li>
</ul></li>
<li>RNN: 动态和静态的RNN, 会将内存从GPU切换到CPU</li>
<li>针对CPU预处理: 配置线程数或者编译器版本mkg ### 1.5 tensorboard
tensor神经网络可视化 &gt; 有多个可视化的点
https://zhuanlan.zhihu.com/p/36946874</li>
</ul></li>
</ul>
<h3 id="keras-高级接口">1.6 keras 高级接口</h3>
<p>训练神经网络中最基础的三个概念： 1. epoch:
使用训练集的全部数据对模型进行一次完整训练，成为一代训练 2. batch:
使用训练集中的一小部分样本对模型权重进行一次反向传播的参数更新，这一小部分样本称为一批数据
3. Iteration:
使用一个Batch数据对模型进行一次参数更新的过程，称为一次训练</p>
<p>tf.keras高阶API - 方便使用 - 模块化和可组合 - 易于扩展</p>
<p>包括特定功能 - Eager Execution - tf.data - Estimator</p>
<p>序列模型：这里说的就是搭积木的意思，即自己一层一层地建立神经网络的连接
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mode = tf.keras.Sequential()  </span><br><span class="line">// 线性模型，这里，那么后面的Dense中的参数64是怎么是定的</span><br><span class="line">mode.add(layers.Dense(64, activation=&quot;relu&quot;))</span><br><span class="line">mode.add(layers.Dense(64, activation=&quot;relu))</span><br></pre></td></tr></table></figure></p>
<p>tf.keras.layer - activation:
设置层的激活函数。此参数由内置函数的名称指定 "relu", tf.relu -
kernel_initializer 和bias_initializer:
创建层权重（核和偏差）的初始化方案。默认"Glorot uniform" -
kernel_regularizer和biar_regularizer:
应用层权重的正则化方案，例如L1或L2正则化</p>
<p>keras文档</p>
<blockquote>
<p>https://blog.csdn.net/sinat_26917383/article/details/72857454</p>
</blockquote>
<p>具体思路： Dense这里不过表示深度学习中某一层的全连接层而已</p>
<p>https://blog.csdn.net/sinat_26917383/article/details/72857454
https://tensorflow.org/guide/keras</p>
<p>下一步，探讨需要什么环境？</p>
<p>RNN是涉及到具体的链接层的。这里的层是进行抽象的，keras tf.Dense():
应该是没有参数定义实际上应该怎么运算？
也就是说对于图神经网络的结构只能用tensorflow底层接口来做。</p>
<h4 id="一个完整的pipeline">1) 一个完整的pipeline</h4>
<ol type="1">
<li>构建简单的模型
<ul>
<li>序列模型
<ul>
<li>两种初始化方法
<ul>
<li>model = Sequential() model.add(layer)</li>
<li>model = Sequential([layer1, layer2, ..])</li>
</ul></li>
</ul></li>
<li>配置层 &gt;
layer即配置层的含义，在这里可以指多个层。对于深度神经网络而言，dropout的实现不过就是在需要的地方加上一层dropout
<ul>
<li>Dense配置的东西
https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense &gt;
Dense(32, input_shape(16, )) # input array of shape (<em>, 16); output
arrays of shape (</em>, 32) 一般*为batch_size的大小
<ul>
<li>units: dimensionality of the output space</li>
<li>activation: 激活函数</li>
<li>user_bias: boolean, 是否使用bias向量 ???
意思是输入是向量，而不是矩阵？？</li>
<li>initializer: kernel, bias</li>
<li>regularize: kernel, bias</li>
<li>constraint: kernel, bias</li>
</ul></li>
<li>关于layer的配置,</li>
</ul></li>
</ul></li>
<li>训练和评估
<ul>
<li>model.compile()
<ul>
<li>optimizer: tf.train.AdamOptimizer, tf.train.RMSPropOptimizerm
tf.GradientDescentOptimizer</li>
<li>loss, 在优化期间最小化的函数，常见均方误差mse,,
categorical_crossentropy binary_crossentropy</li>
<li>metrics, 用于监控训练，字符串或者可调用对象, 比如准确率</li>
</ul></li>
<li>mode.fit()
<ul>
<li>data</li>
<li>labels</li>
<li>epochs: 总共运行几次训练</li>
<li>batch_size: 一次训练使用多少个样本</li>
<li>validation_split: 0~1, 交叉验证集占训练集的比例</li>
<li>validation_data = (val_data, val_labels)), 与上面的二选其1进行 &gt;
该命令执行后直接会运行</li>
</ul></li>
<li>model.evaluate(data, labels, batch_size=32)
对未知数据集和预测结果进行评价 // 每个batch_size为一个评价单元</li>
<li>model.predict(data, batch_size) 模型预测</li>
</ul></li>
</ol>
<h4 id="构建高级模型">2）构建高级模型</h4>
<h5 id="函数式api">函数式API</h5>
<ul>
<li>多输入</li>
<li>多输出</li>
<li>具有共享层(同一层被调用多次)</li>
<li>具有非序列数据流的模型（剩余连接）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">inputs = tf.keras.Input(shape=(32,))  # Returns a placeholder tensor</span><br><span class="line"></span><br><span class="line"># A layer instance is callable on a tensor, and returns a tensor.</span><br><span class="line">x = layers.Dense(64, activation=&#x27;relu&#x27;)(inputs)</span><br><span class="line">x = layers.Dense(64, activation=&#x27;relu&#x27;)(x)</span><br><span class="line">predictions = layers.Dense(10, activation=&#x27;softmax&#x27;)(x)</span><br><span class="line"></span><br><span class="line">model = tf.keras.Model(inputs=inputs, outputs=predictions)</span><br><span class="line"></span><br><span class="line"># The compile step specifies the training configuration.</span><br><span class="line">model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),</span><br><span class="line">              loss=&#x27;categorical_crossentropy&#x27;,</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br><span class="line"></span><br><span class="line"># Trains for 5 epochs</span><br><span class="line">model.fit(data, labels, batch_size=32, epochs=5)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用了函数式编程接口，tensor为输入变量，返回结果也为tensor</p>
</blockquote>
<h5 id="模型子类化">模型子类化</h5>
<blockquote>
<p>通过对tf.keras.Model进行子类化并定义自己的前向传播来构建完全可自定义的模型。在__init__中创建层并将它们设置为类实例的属性。在call方法中定义前向传播
通过继承keras中已有Model,
还是根据本身已有的数据，还是调用原本的功能，不过会进行添加一些新功能</p>
</blockquote>
<h5 id="自定义层">自定义层</h5>
<p>tf.keras.layer.Layer进行子类化并实现以下方法自定义层
只需要实现以下接口 - build: 创建层的权重 add_weight方法添加权重 &gt;
shape = tf.TensorShape() self.kernel = self.add_weight() super(MyLayer,
self).builf(input_shape) - call: 定义前向传播 &gt; return
tf.matmul(inputs, self.kernel) - compute_output_shape:
指定在给出形状的情况下如何计算层的输出相撞 &gt; shape =
tf.TensorShape(input_shape).as_list() &gt; shape[-1]=self.output_dim
return tf.TensorShape(shape) - 或者，实现get_config方法序列化层,
from_config; 因为需要涉及到存储 &gt; base_config = super(MyLayer,
self).get_config() &gt; base_config['output_dim']=self.output_dim &gt;
return base_conofig &gt; <span class="citation"
data-cites="classmethod">@classmethod</span> &gt; def from_config(cls,
config): return cls(**config)</p>
<p>？？ python 如何进行继承，是方法抽象吗？ 还有抽象方法呢？ <span
class="citation" data-cites="关键字">@关键字</span> 全局变量呢</p>
<h2 id="pandas">2. pandas</h2>
<p>https://www.pypandas.cn/</p>
<p>pandas: 处理表格和混杂数据 numpy: 处理统一的数值数据 scipy:
数值计算工具 分析库：scikit-learn 和 statsmodels 数据化可视库:
matplotlib</p>
<ul>
<li>数据结构
<ul>
<li>Series:
类型与一维数组的对象，它有一组数据（各种numpy数据类型）以及一组一直相关的数据标签即索引组成。
&gt;
索引可以为字符串，在使用numpy函数或者类似num朋友的运算，如布尔型数组的过滤、标量乘法、应用数学等都会保留索引值的链接
&gt; np.exp(Series), 即可以直接传入series &gt;
Series可以看作是一个定长的<strong>有序</strong>字典，因为它是索引值到数据值的一个映射,
索引是key, 可以用in
<ul>
<li>init初始化: 深复制
<ul>
<li>dict: ser1 = pd.Series(dict)</li>
<li>list: ser2 = pd.Series(list1, index=list2)</li>
<li>array: ser2 = pd.Series(arr1, index=list1)</li>
</ul></li>
<li>index： list('abcdef') // 超级简单的方法
<ul>
<li>index本身就是属性, RangeIndex, Index两种</li>
<li>ser2.index=list3 // 直接修改</li>
</ul></li>
</ul></li>
<li>DataFrame &gt;
表格性的数据结构，它包含一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame即有行索引，也有列索引。
&gt; 可以看作是由Series组成的字典，共用同一索引 &gt;
Dataframe中的数据是以一个或多个二维快存放的。
虽然是二维结构保存数据的，但可以很轻松地表示为更高维度的数据
<ul>
<li>属性
<ul>
<li>df1.index.name / df1.columns.name</li>
<li>df1.values</li>
<li>df1.index: 不可改变，切片也不可改变；为不可变对象; Index类型,
因为是序列，所以允许重复元素 &gt; 一些操作
<ul>
<li>append, difference, intersection, union, sin, delete, drop,
insert(i, ) isunique, unique</li>
</ul></li>
</ul></li>
<li>init
<ul>
<li>dict: df1 = pd.DataFrame(dict): dict.key是等长的list,
将key映射为列名；列顺序未被指定 &gt; 注意元组会被当成一个值</li>
<li>2d_arr: df1 = pd.DataFrame(2d_arr, columns=list1, index=list2) //
注意columns是指定列名， 并且指定了列顺序; index指定行名</li>
</ul></li>
<li>索引： 一旦给定就确定下来，不会发生任何改变
<ul>
<li>Series: df1[column_name], df.column_name</li>
<li>Value: df1[column_name][index_name]</li>
<li>Object行, df1.loc[index_name]<br />
</li>
</ul></li>
<li>添加、修改 &gt; 按照类型赋值
<ul>
<li>按索引的方式添加，添加等于修改
<ul>
<li>df1[column_name] = Series: 不够的值，没有的值会赋np.NaN</li>
<li>df1.loc[index_name]=list1: 必须匹配，否则报错</li>
<li>df1[colume_name][index_name]=1</li>
</ul></li>
</ul></li>
<li>删除
<ul>
<li>删除列 del df1[column_name]</li>
<li>删除全部 del df1</li>
<li>批量删除 drop
<ul>
<li>df1.drop(colums_list)</li>
<li>df1.drop(index_list)</li>
<li>df1.drop(list1, axis): 按默认来，0为x轴</li>
</ul></li>
</ul></li>
<li>取切片的都属于浅复制, 即改变任何一个的元素都会引起另一个的改变。
&gt; 注意这里是末端包含式切片 &gt; 特别地,
当删除frame中的serie时，新的serie还存在, 为变化之前的值 &gt; <code>ser1
= pd1['value'],   pd1['value'][2]=1, del
dp1['value'];  ser1仍存在</code>
<ul>
<li>杂项
<ul>
<li>范围 pd1[columnN: columnM]: 因为是序列数据，所以直接取范围;
可用int</li>
<li>特定项 pd1[[column1, colum3, colum4]]， Series可用int做,
默认从0开始</li>
<li>obj[cond]</li>
</ul></li>
<li>通法
<ul>
<li>pd1.loc[val, val2] 标签</li>
<li>pd1.iloc[i, j] 整数</li>
</ul></li>
</ul></li>
<li>特殊值处理
<ul>
<li>空值 "" isnull()</li>
<li>缺失值 nan或naT isna()</li>
<li>两种手段
<ul>
<li>删除对应行和列： df.dropna()</li>
<li>填充 df.dropna() // 细粒度地填充, inplace=True在原来上操作</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>基本功能
<ul>
<li>重新索引
<ul>
<li>row ser1.reindex(new_index, method="ffill") // 使用前向值进行填充;
fill_value: 替代缺失值; limit最大填充量</li>
<li>columns pd.reindex(columns=new_columns)</li>
</ul></li>
<li>算术运算和数据对齐 &gt; 必须行名，列名相同才好使 &gt;
非对齐使用nan填充
<ul>
<li>会用到吗？
<ul>
<li>add, radd: r表示reverse版本，即将两个操作数的位置交换</li>
<li>sub, rsub</li>
<li>div, rdiv</li>
<li>floordiv, rfloordiv</li>
<li>mul, rmul</li>
<li>pow, rpow</li>
</ul></li>
</ul></li>
<li>DateFrame和Series: 广播运算，对每一行都做</li>
<li>pd1.apply(func, args=): 特别好用 +
lambda表达式，作用在每个元素级别</li>
<li>排序和排名
<ul>
<li>sort by index: pd.sort_index(axis=0)</li>
<li>sort by value
<ul>
<li>ser1.sort_value() //nan在尾部</li>
<li>pd1.sort_value(by=[col1,col2])</li>
</ul></li>
<li>rank obj.rank(ascending=false, axis= , method= )
<ul>
<li>method: 相同排名的处理问题; first 按索引的第一个; max, 最大; min;
average</li>
</ul></li>
</ul></li>
<li>汇总和计算描述统计-&gt;基于列的Series
<ul>
<li>df.sum(axis=, skipna=)</li>
<li>df.idxmax() 索引位置 max() 索引值</li>
<li>df.cumsum() &gt; count, mean, std, min, max</li>
</ul></li>
<li>唯一值，值计算及成员资格
<ul>
<li>ser1.unique()</li>
<li>ser1.value_counts() // 计算重复出现的值</li>
<li>ser1.isin(ser2)</li>
<li>ser1.match(ser2) 对齐数据, 比较返回真假值</li>
</ul></li>
</ul></li>
<li>数据加载、存储和文件格式
<ul>
<li>读写
<ul>
<li>read_csv( seq=',')</li>
<li>read_table(seq=')</li>
</ul></li>
<li>处理
<ul>
<li>索引</li>
<li>类型推断和数据转换</li>
<li>日期解析</li>
<li>迭代</li>
<li>不规整数据问题</li>
</ul></li>
</ul></li>
</ul>
<h2 id="matplotlib">4. matplotlib</h2>
<p>matplotlib 更详细的内容
https://www.matplotlib.org.cn/api/overview/index.html</p>
<ul>
<li>基本API入门 <code>import matplotlib.pyplot as plt</code> &gt;
只要返回对象是figure的，就会在jupyter中产生图 &gt;
在py文件中，则是使用plt.show()产生图
<ul>
<li>多个子图
<ul>
<li>fig = plt.figure()
<ul>
<li>ax1 = fig.add_subplot(2,2,1) //(length, width, rank) rank从1开始
&gt; 此时ax1 就可用作 plt</li>
</ul></li>
<li>fig, axs = plt.subplots(2,3) &gt; axs[0,1]获取子图
<ul>
<li>plt.subplots(args) 参数
<ul>
<li>nrows, ncols</li>
<li>sharex, sharey 是否共享x，y轴</li>
<li>subplot_kw 各subplot的关键字字典</li>
</ul></li>
<li>fig.subplots_adjust(wspace=0.3, hspace=0.5) &gt;
这里可以直接使用plt, 因为matplotlib会自动引用新添加的子组件的对象
<ul>
<li>wspace, hspace, 图与图之间的间隙中宽度为子图的多少倍,
即一般为0.3之类, 为百分比</li>
</ul></li>
</ul></li>
</ul></li>
<li>图的类型
<ul>
<li>plot(x[,y]) 折线图，x默认索引</li>
<li>hist(y) 条形图，x默认索引</li>
<li>scatter(x,y) 散点图</li>
</ul></li>
<li>操作图
<ul>
<li>调整子图周围的间距 wspace, hspace</li>
<li>plot(args) 参数
<ul>
<li>fmt_str "{marker}{line}{color}" 或者
<code>[color][marker][line]</code>
<ul>
<li>marker
<ul>
<li><code>.</code>: point</li>
<li><code>o</code>: 实心circle</li>
<li><code>v</code>, <code>^</code>, <code>&gt;</code>,
<code>&lt;</code>: 各个方位的实心三角形</li>
<li>1, 2, 3, 4: 箭头，下、上、左、右</li>
<li>|,_: vline, hline</li>
<li>s: square; *: start; D: diamond,; p: 多边形; +,x</li>
</ul></li>
<li>linestyle
<ul>
<li><code>-</code>: 实线</li>
<li><code>--</code>:虚线</li>
<li><code>-.</code>: 非规整虚线</li>
<li><code>:</code>: 小点小点的线</li>
</ul></li>
<li>color
<ul>
<li>b: blue, g:green, r:red, c:cyan, y:yellow, k:black, w:white</li>
</ul></li>
</ul></li>
<li>lable: 设置图标说明</li>
<li>drawstyle: 点到点的其它路径画法</li>
<li>xlim, yli: x,y的界限</li>
<li>grid: 网格线是否打开</li>
</ul></li>
<li>set方式设置参数 &gt; plt.set(dict) 全局设置 &gt; plt.legend()
用于增加图裂
<ul>
<li>设置刻度标签，为刻度赋予自己的意义 &gt; tricks =
ax.set_xtricks([0,250,500,750,1000]); &gt; labels =
ax.set_xticklabels(list('abcdf'))</li>
<li>图的标题 title &gt; ax.set_titile("")</li>
<li>图的x轴lable &gt; ax.set_xlabel()</li>
<li>图解，标注某个点 &gt; ax.annotate(label, xy=(x,y))</li>
<li>保存文件 &gt; plt.savefig(".png")</li>
</ul></li>
</ul></li>
<li>全局配置，字体什么的 plt.rc(); pandas本身ser.plot(),
df.plot()就可以进行绘图</li>
</ul></li>
<li>应用
<ul>
<li>画等高线图
<ol type="1">
<li>取特定个点 np.linspace(start, end, number), np.arange(start, end,
step)</li>
<li>画网格 xx, yy=np.meshgrid(x,y) xx表示n个x轴的数据
yy表示m个y轴的数据</li>
<li>plt.contour(x,y,f(x,y)) // 绘制等高线</li>
</ol></li>
<li>动画animate
<ul>
<li>animation.FuncAnimation(fig=fig, func=animate, init_func=,
frames=length, interval=60ms频率, blit=True是否更新所有的点) &gt;
line.set_data([],[]) point.set_data([],[])
<ul>
<li>def animation(i): line.set_ydata((np.sin(x+i/100)))</li>
</ul></li>
</ul></li>
</ul></li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/deeplearning/" rel="tag"># deeplearning</a>
              <a href="/tags/tools/" rel="tag"># tools</a>
              <a href="/tags/numpy/" rel="tag"># numpy</a>
              <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/09/10/ipython-personnal-reference/" rel="prev" title="ipython personnal reference">
      <i class="fa fa-chevron-left"></i> ipython personnal reference
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/09/11/gnn-semi-gnn-relization-progress/" rel="next" title="semi-gnn, relization progress">
      semi-gnn, relization progress <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
      <div class="tabs tabs-comment">
        <ul class="nav-tabs">
            <li class="tab"><a href="#comment-gitalk">gitalk</a></li>
            <li class="tab"><a href="#comment-livere">livere</a></li>
        </ul>
        <div class="tab-content">
            <div class="tab-pane gitalk" id="comment-gitalk">
              <div class="comments" id="gitalk-container"></div>
            </div>
            <div class="tab-pane livere" id="comment-livere">
              
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC80NjU1Mi8yMzA2Mg=="></div>
  </div>
  
            </div>
        </div>
      </div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#tensorflows"><span class="nav-number">1.</span> <span class="nav-text">1. tensorflows</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFtensorflow"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 什么是tensorflow</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tensorflow%E5%8F%AF%E4%BB%A5%E5%81%9A%E4%BB%80%E4%B9%88"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 tensorflow可以做什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tensorflow%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 tensorflow入门指南</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E5%AE%83"><span class="nav-number">1.4.</span> <span class="nav-text">1.4 其它</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#keras-%E9%AB%98%E7%BA%A7%E6%8E%A5%E5%8F%A3"><span class="nav-number">1.5.</span> <span class="nav-text">1.6 keras 高级接口</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84pipeline"><span class="nav-number">1.5.1.</span> <span class="nav-text">1) 一个完整的pipeline</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA%E9%AB%98%E7%BA%A7%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.5.2.</span> <span class="nav-text">2）构建高级模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%87%BD%E6%95%B0%E5%BC%8Fapi"><span class="nav-number">1.5.2.1.</span> <span class="nav-text">函数式API</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%AD%90%E7%B1%BB%E5%8C%96"><span class="nav-number">1.5.2.2.</span> <span class="nav-text">模型子类化</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82"><span class="nav-number">1.5.2.3.</span> <span class="nav-text">自定义层</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pandas"><span class="nav-number">2.</span> <span class="nav-text">2. pandas</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#matplotlib"><span class="nav-number">3.</span> <span class="nav-text">4. matplotlib</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yun-Pan Wang"
      src="/images/default-avatar.png">
  <p class="site-author-name" itemprop="name">Yun-Pan Wang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">115</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">69</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/AugF" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;AugF" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wangyp@smail.nju.edu.cn" title="E-Mail → mailto:wangyp@smail.nju.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/Joswxe" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;Joswxe" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.google.com/" title="https:&#x2F;&#x2F;www.google.com" rel="noopener" target="_blank">Google</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://cn.bing.com/" title="https:&#x2F;&#x2F;cn.bing.com" rel="noopener" target="_blank">Bing</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.baidu.com/" title="https:&#x2F;&#x2F;www.baidu.com" rel="noopener" target="_blank">Baidu</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">[object Object]</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">466k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">7:04</span>
</div>!

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '9552a863f697c06e137f',
      clientSecret: '65716dc606be017204585b55c9858ede23eae0b9',
      repo        : 'augf.github.io',
      owner       : 'AugF',
      admin       : ['AugF'],
      id          : 'a56b01a4e699abcdda4cd55a230a79d4',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

</body>
</html>
