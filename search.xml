<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2022/hello-world-1939fef88a09/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a
href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a
href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new post <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>About me</title>
    <url>/2019/About-me-b2883e66631a/</url>
    <content><![CDATA[<p>一个正在行进中的人</p>
]]></content>
  </entry>
  <entry>
    <title>GraphSampling Directions</title>
    <url>/2020/GraphSampling-Directions-9c9446de6884/</url>
    <content><![CDATA[<p>未来的方向：</p>
<ol type="1">
<li>采样算法的选择： 精度高 有理论保证 按照自己的想法做</li>
</ol>
<ul>
<li>Sampling加速
<ul>
<li>选取特定的Sample算法</li>
<li>单机多卡</li>
<li></li>
<li>CPU内存放不下数据集</li>
</ul></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>C-SAW论文阅读</title>
    <url>/2020/C-SAW%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-316f3c062f95/</url>
    <content><![CDATA[<h1
id="c-saw-a-framework-for-graph-sampling-and-random-walk-on-gpus">C-SAW:
A Framework for Graph Sampling and Random Walk on GPUs</h1>
<h2 id="摘要">摘要</h2>
<p>表示学习是机器学习的一个基本任务，自动地从图数据中学习到特征，而不是通过手动选择。代表算法有DeepWalk,
node2vec和GrpahSAGE.</p>
<p>这些算法首先从输入图中采样出子图。采样是一个很困难的任务，它需要并行地独立地采样出每个子图。</p>
<p>现有的图预处理，数据挖掘和表示学习系统都没有有效地实现并行化采样。减低了表示学习的end-to-end的表现</p>
<p>本文中，我们提出了NextDoor，首个设计到GPUs上的图采样方法。同时，介绍了一种高阶API</p>
<h2 id="introduction">Introduction</h2>
<p>表示学习的目标是学习数据的特征</p>
<p>当运行random walks,
NEXTDOOR相比于KnightKing提高了696倍；相比于GraphSAGE's
sampler增加了1300倍</p>
<p>主要贡献： 1. A new transit-parallel机制 2. NEXTDOOR's API 3.
NEXTDOOR's system, 利用transit-parallellism, 负载均衡和缓存 4.
Performance evaluation</p>
<h2 id="背景和动机">背景和动机</h2>
]]></content>
  </entry>
  <entry>
    <title>TOEFL word details</title>
    <url>/2019/TOEFL-word-details-706dbe9b044c/</url>
    <content><![CDATA[<h1 id="总课程">总课程</h1>
<h2 id="词汇">2. 词汇</h2>
<p>按规则出牌</p>
<h3 id="词缀">2.2 词缀</h3>
<h4 id="前缀">2.2.1 前缀</h4>
<p><img data-src="vlcsnap-2019-05-13-15h48m17s024.png" /></p>
<img data-src="/2019/TOEFL-word-details-706dbe9b044c/vlcsnap-2019-05-13-15h48m17s024.png" class="" title="this is an image">
<ul>
<li>时间 ex,pre,pro/re 前/后</li>
<li>位置
<ul>
<li>inter/out 里/外</li>
<li>over,super/sub 上/下</li>
<li>trans 变化 transformer</li>
<li>under</li>
</ul></li>
<li>数量
<ul>
<li>uni 1</li>
<li>bi, di(divide),twi(two,twi-light黎明，暮光之城), du(?) 2</li>
<li>centil 100</li>
<li>milli 1000</li>
<li>mono 单一</li>
<li>multi 多</li>
</ul></li>
<li>程度
<ul>
<li>super, over, under ,hyper, well</li>
</ul></li>
<li>方式
<ul>
<li>auto 自动的</li>
<li>co 合作 cooperate, cooperation</li>
<li>mal 坏的</li>
<li>mis 错的</li>
<li>self 自己</li>
</ul></li>
<li>态度
<ul>
<li>anti</li>
<li>counter n. 反击，对立面 counter strike cs游戏</li>
<li>pro 支持</li>
</ul></li>
</ul>
<h4 id="后缀">2.2.2 后缀</h4>
<p><img data-src="vlcsnap-2019-05-13-16h27m44s962.png" /></p>
<ol type="1">
<li>动词</li>
</ol>
<blockquote>
<p>-ate create</p>
<p>-ish fish finish identify watch harden realize surprise</p>
</blockquote>
<ol start="2" type="1">
<li>名词</li>
</ol>
<blockquote>
<p>-ant servant pedant挂坠</p>
<p>-ary anniversary</p>
<p>-let 小的东西 toilet</p>
</blockquote>
<h3 id="换词方法">换词方法</h3>
<p>过去的英语体系对现在英语产生了影响</p>
<p><img data-src="vlcsnap-2019-05-13-16h46m21s713.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-16h48m28s450.png" /></p>
<blockquote>
<p>wrack, wreck 残骸</p>
<ol type="1">
<li>时间越靠后，越靠后出现</li>
<li>任意的字母都可以滑动， bat bet bit bot but ?</li>
</ol>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-16h50m57s819.png" /></p>
<blockquote>
<p>check cheque 支票，组织</p>
<p>发音重点</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-16h53m54s165.png" /></p>
<h3 id="不按规则出牌的">不按规则出牌的</h3>
<p><img data-src="vlcsnap-2019-05-13-16h55m02s009.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-16h56m31s884.png" /></p>
<p>gossip : sip 闲聊</p>
<p>camouflage 伪装</p>
<p>sanguine 乐观的，满怀希望的，面色红润的</p>
<p>abracadabra 咒语 bra, brag吹牛</p>
<h3 id="不可拆单词">不可拆单词</h3>
<h4 id="section"><img data-src="vlcsnap-2019-05-13-17h02m33s624.png" /></h4>
<p>nicotine 尼古丁 oratorio 宗教中的歌唱曲 maverick 与众不同的人 utopian
乌托邦 meander 蜿蜒，曲折</p>
<p>sihouette 法国财政部部长， 吝啬，短期任职</p>
<p>serendipitous 偶然的</p>
<p><img data-src="vlcsnap-2019-05-13-17h10m11s134.png" /></p>
<p>latte 有奶的</p>
<p>instant 速溶咖啡</p>
<p><img data-src="vlcsnap-2019-05-13-17h10m57s878.png" /></p>
<p>Narcissus</p>
<p>Nemesis</p>
<p><img data-src="vlcsnap-2019-05-13-17h11m38s291.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-17h12m02s367.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-17h12m25s522.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-17h12m57s834.png" /></p>
<blockquote>
<p>parachute 降落伞</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-17h14m35s244.png" /></p>
<h3 id="记单词的过程">记单词的过程</h3>
<p><img data-src="vlcsnap-2019-05-13-17h17m39s853.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-17h17m53s620.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-17h18m52s967.png" /></p>
<h2 id="学科词汇">3. 学科词汇</h2>
<h3 id="学术词根">3.1 学术词根</h3>
<p><img data-src="vlcsnap-2019-05-13-17h22m50s335.png" /></p>
<blockquote>
<p>conscience 良知</p>
<p>prescience 预知</p>
<p>pseudoscience 伪科学</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-17h26m27s978.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-17h32m58s743.png" /></p>
<blockquote>
<p>ego 自私，自理， ecology eco表示house</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-17h36m14s246.png" /></p>
<blockquote>
<p>nomy</p>
<ol type="1">
<li>物资--规则，学科 agronomy, astronmy</li>
<li>管理、法律 autonomy autonomous</li>
</ol>
</blockquote>
<ul>
<li>背词怎么背？
<ul>
<li>两方面共同记忆</li>
</ul></li>
</ul>
<p><img data-src="vlcsnap-2019-05-13-17h38m42s444.png" /></p>
<p>ics表示学科</p>
<p><img data-src="vlcsnap-2019-05-13-17h40m08s812.png" /></p>
<h3 id="数学类词根">3.2 数学类词根</h3>
<p><img data-src="vlcsnap-2019-05-13-17h41m43s405.png" /></p>
<p>mathematics 注意e不发音</p>
<p><img data-src="vlcsnap-2019-05-13-17h42m40s927.png" /></p>
<p>人名，记汉语拼音</p>
<p>algebra 代数</p>
<p>arithmetic ars/art + metrica(to measure)</p>
<p>algorithm 算术法则</p>
<p><img data-src="vlcsnap-2019-05-13-17h46m56s700.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-17h49m15s187.png" /></p>
<blockquote>
<p>equilibrium 平衡状态</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-17h51m37s590.png" /></p>
<blockquote>
<p>parity 公平, nonpareil无与伦比的， parable 可以修理的</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-17h52m02s047.png" /></p>
<blockquote>
<p>numerable 可数的</p>
<p>innumerable 不可数的</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-17h53m41s866.png" /></p>
<p>link, correlation,connection</p>
<h3 id="物理类词根">3.3 物理类词根</h3>
<h4 id="力">3.3.1 力</h4>
<p><img data-src="vlcsnap-2019-05-13-17h55m39s911.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-18h00m24s168.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-18h02m50s129.png" /></p>
<blockquote>
<p>cradle-to-grave 从生到死</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-18h03m19s383.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-18h04m36s183.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-18h05m15s210.png" /></p>
<blockquote>
<p>B motto 格言， motif 主题</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-18h07m41s292.png" /></p>
<h4 id="热学类词根">3.3.2 热学类词根</h4>
<p><img data-src="vlcsnap-2019-05-13-18h11m43s637.png" /></p>
<blockquote>
<p>isotherm 等温线</p>
<p>endothermic 里面， 吸热的，恒温动物</p>
<p>exothermic 发热的</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-18h14m10s300.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-18h16m27s803.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-18h17m29s861.png" /></p>
<blockquote>
<p>per- 全， -esece 散</p>
</blockquote>
<p><img data-src="QQ截图20190513182006.png" /></p>
<h4 id="声学类词汇">3.3.3 声学类词汇</h4>
<p><img data-src="vlcsnap-2019-05-13-18h20m59s556.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-18h22m09s724.png" /></p>
<blockquote>
<p>-ferous 带有什么的</p>
</blockquote>
<p><img data-src="vlcsnap-2019-05-13-18h24m31s074.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-18h25m35s306.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-19h30m51s888.png" /></p>
<p><img data-src="vlcsnap-2019-05-13-19h32m16s890.png" /></p>
<blockquote>
<p>eu 好的，优秀的； caco 不好</p>
</blockquote>
<ul>
<li>plod 砰地一声 diligently and dull 勤奋的，迟钝的 plaudit 喝彩，赞美
<ul>
<li>大声，拟声词 &gt; applaud</li>
<li>plod 沉重的脚步，沉重的走，辛勤工作 &gt; explode 外爆
implode内爆</li>
</ul></li>
<li>verber = beat, vibrate wipe, wag &gt; reverberate 反响 vervain
马鞭草</li>
<li>echo 回声 = sound &gt; anechoic 没有回声的</li>
</ul>
<h4 id="光学类词根">3.3.4 光学类词根</h4>
<ul>
<li><p>lumin=light &lt;- lumen 光通量单位. 启发，充满，单指光 &gt;
illuminate 阐明 luminary 只是渊博的人 // ary 后缀 luminous
发光的，明亮的 luminosity 发光度 luminescent 发光度 unilluminating
unenlightening 无启发性的，没有作用的</p></li>
<li><p>lustr, luc=light, lustrum古罗马驱魔意识 lust 欲望 desire,
wish,longing 光亮的，明亮的 &gt; lustre(luster) 光彩 lustrous 有光泽的
lackluster无光泽的 illustrate 说明!! illustrious 杰出的 //il
表示什么意思 elusive 难懂的，逃避的 //? lucent 光亮的 lucid 清晰的
elucidate 阐明，说明!! translucent 半透明的 noctilucent 夜间发光的 lusty
健壮的，精力旺盛的</p></li>
</ul>
<p>leuk -&gt; light luc, lust, lustr, lumin</p>
<ul>
<li><p>light &gt; lighter 点火者，打火机 lightproof 防光的 enlighten
启发 twilight 微明的，黎明 != delight 高兴，不是一个词源 delicious,
delicate</p></li>
<li><p>radi = ray 光线 radius 散射的感觉 &gt; radio 无线电 radioactive
放射的 radiant 发光的 irradiate 照射</p>
<ul>
<li>root, 树根也是发射的感觉 &gt; radical 根本的，激进的 radicle 跟
article //cle? eradicate 根除 radix 根，基数</li>
</ul></li>
<li><p>cand=white, glow 来自于candle蜡烛 kindle发光 &gt; candle candela
烛光 candid 坦率的 candescent 白热的 incandescent 白热的//in加强
incendiary 纵火犯 incense: make angry让你发光，让你生气; sweet-smelling
substance 香味剂</p></li>
<li><p>flect, flex=bend 弯曲 &gt; reflect 反射, 沉思 //往回弯 reflection
relective refraction 折射 frac=break deflect turn aside偏转 inflect
使弯曲 deflex turned abruptly downward 使向下弯曲 inflex 使弯曲 vs
inflexible不可以弯曲的!!! flexible可以弯曲的 //!!</p></li>
<li><p>sol=sun只有一个太阳</p>
<ul>
<li>阳光 &gt; solor 太阳的 solarize 晒，曝光 parasol 阳伞 solarium
日光浴 insolate暴晒 solace 安慰 // 阳光 console 慰藉 // 大家一起用阳光
obsolete 过时的 //ob过去</li>
<li>孤独 sole 单独的，唯一的 solitary 孤独的 soliloquy 独白//loqu=speak
solo 独奏曲 insolence //in 傲慢，无礼 desolate 荒凉的 desolation
荒废</li>
</ul></li>
<li><p>sight=vision 眼光 &gt; sightly attractive 养眼的 long-sighted
远视眼的 farsighted: to see a great distance, good
judgment,sagacious睿智的，有远见的，有洞察力的 insight 洞察力 oversight
失误</p></li>
<li><p>splend=be right,shine,gleam, glisten辉煌，闪耀 &gt; splendid
辉煌的，闪耀的 splendor 光彩，壮丽 resplendent 辉煌的</p></li>
<li><p>vis, vid=to see, to know, wise眼光看到的 &gt; visible 看得见的
vision 实例 visionary 幻想的 visual 视觉的 visualize 形象化 advise
advisory previse 预知 revise 修改 supervise 监督//super在上面 evident
显然的，正确的 invidious 嫉妒的 //in一直盯着看 envy (envious) 嫉妒的
provide 提供 provident 有远见的 providence 远见 providential 幸运的
Providence普鲁维登斯 providential fate:good
guided,forethought,precaution visage 想象; television电视 envisage
正视，想象</p></li>
<li><p>vis,vid =separate 看得清的，可以区分的 &gt; divide 划分 dividend
被除数，股息 devise 设计，发明</p></li>
<li><p>opt, opto=sight eye oqw opt,opto &gt; optic 光的 optometrist
验光师 synopsis摘要，大纲 optics 光学 optometer 视力计 opthalmologist
眼科专家 #### 3.3.5 电学类词根</p></li>
</ul>
<p><img data-src="vlcsnap-2019-05-21-22h52m56s543.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h11m46s139.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h12m16s668.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h12m45s009.png" /></p>
<h3 id="化学类词根">3.4 化学类词根</h3>
<p><img data-src="vlcsnap-2019-06-05-08h14m16s044.png" /></p>
<h4 id="组成性质">3.4.1 组成性质</h4>
<p><img data-src="vlcsnap-2019-06-05-08h14m49s967.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h17m05s962.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h19m38s673.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h21m50s219.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h22m48s624.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h23m53s885.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h26m09s645.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h27m03s914.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h27m44s115.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h29m11s367.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h32m12s073.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h33m01s737.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h33m41s614.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h35m33s534.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h35m20s050.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h36m41s627.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h37m16s956.png" /></p>
<h4 id="结构">3.4.2 结构</h4>
<p><img data-src="vlcsnap-2019-06-05-08h40m01s912.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h40m55s882.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h41m36s333.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h42m32s841.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h42m58s764.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h43m57s100.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h45m23s272.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h45m37s979.png" /></p>
<h4 id="变化规律">3.4.3 变化规律</h4>
<p><img data-src="vlcsnap-2019-06-05-08h47m34s632.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h49m27s739.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h50m11s429.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h51m18s580.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h52m01s163.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h52m31s298.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h54m00s376.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h54m24s462.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h54m53s509.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h55m37s867.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h56m27s111.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h57m14s042.png" /></p>
<p><img data-src="vlcsnap-2019-06-05-08h57m14s042-1559696280619.png" /></p>
<h3 id="天文学词根">3.5 天文学词根</h3>
<p><img data-src="vlcsnap-2019-06-08-20h45m20s879.png" /></p>
<p>cata 灾难</p>
<p><img data-src="vlcsnap-2019-06-08-20h47m07s936.png" /></p>
<p><img data-src="vlcsnap-2019-06-08-20h51m58s307.png" /></p>
<p><img data-src="vlcsnap-2019-06-08-20h53m57s963.png" /></p>
<p><img data-src="vlcsnap-2019-06-08-20h54m48s060.png" /></p>
<p>purge 清洗，洗涤</p>
<p>purity 纯净</p>
<p><img data-src="vlcsnap-2019-06-10-16h20m18s576.png" /></p>
<p><img data-src="vlcsnap-2019-06-10-16h21m15s342.png" /></p>
<h3 id="地质地理类词根">3.6 地质地理类词根</h3>
<h4 id="希娜神话相关">3.6.1 希娜神话相关</h4>
<ol type="1">
<li>大地女神Gaea geo,ge</li>
</ol>
<ul>
<li>earth, land; soil, world &gt; geology
地质学：板块运动，岩石化学机理，数理基础；本质 geological 地质学的 &gt;
geography 地理学: 文科，地理表层；表面的 geophysics 地球物理学
geochemistry 地球化学</li>
</ul>
<ol start="2" type="1">
<li><p>父亲 混沌 chaos cosmo 表示秩序 cosmos 宇宙 &gt; 空虚中产生，
有大地女神，爱神，地狱神，黑夜神，黑暗神</p></li>
<li><p>长子兼丈夫 Uranus 天王星， 天父 &gt;
没有男神相助下，生出了天空，然后再结合饿到</p></li>
</ol>
<ul>
<li>Titans 巨神族 6 men 6 women &gt; titanic: having great magnitude,
force or power
<ul>
<li>带头：时间之神 Cronus （Chronos??） chron 慢性的， 加入h &gt;
chronic 慢性的 chronology 年代学</li>
</ul></li>
<li>Cyclopes 独目众神 3人 &gt; cynosure 注意的焦点，小熊星座，北极星
lope 大步慢跑 elope 私奔</li>
<li>Giants 巨人众神族 100只手 100个脑袋 3人</li>
</ul>
<ol start="4" type="1">
<li>Gaea + Cronus
<ul>
<li>Furies 复仇女神 &gt; fury
<ul>
<li>Nemesis</li>
</ul></li>
<li>Typhon: 100个头， 海上信号器：大喇叭 typhoon 台风</li>
<li>Zeus</li>
</ul></li>
</ol>
<h4 id="词根">3.6.2 词根</h4>
<ol type="1">
<li><p>terr</p>
<ul>
<li>piece of earth, ground and land; ters; to dry, opposed to sea; &gt;
terrain 地形 terrace 梯田 terrritory 领土，版图 Mediterranean 地中海 //
中间 subterranean 地下的 terra firma
陆地（威尼斯人统治的意大利领土）</li>
<li>tres, to treamble 抖 &gt; terrible 害怕 terrify 恐吓 terrific
极好的，激动地都 terrorist 恐怖份子</li>
</ul></li>
<li><p>inter = in + terr 埋葬 &gt; disinter=dis + inter 挖掘 &gt;
extraterritoriality: &gt;&gt; exemption from the application or
jurisdiction of local law or tribunals.</p></li>
<li><p>tele: far/distant &gt; telegraph 电报 telephone 电话 telemeter
测距计 telescope scope看得远，望远镜</p></li>
</ol>
<p>Geology Earth Science</p>
<ol start="4" type="1">
<li>地质学
<ul>
<li>Tectonic/Structures 大构造</li>
<li>Lithology 岩石学</li>
<li>Paleontology // pale部分， onto?生物， 古生物学</li>
<li>Remote Sensing 遥感，卫星</li>
<li>Mineralogy 矿物学</li>
</ul></li>
<li>Tectonic/Strutures 寒武纪时代，生命大爆发</li>
</ol>
<p>Ordovician 寒武纪 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Animals with hard-shells appeared in great numbers for the first time during Cambrian. The continents were flooded by the shallow seas. The supercontinent of Gondwana冈瓦纳大陆 had just formed and was located near the South Pole.</span><br><span class="line">During the Ordovician ancient oceans separated the barren continents of Laurentia, Baltica, Siberia and Gondwana. The end of the Ordovician was one of the coldest times in Earth history. Ice coverd much of the southern region of Gondwana.</span><br></pre></td></tr></table></figure></p>
<p>Jurassic 侏罗纪 晚侏罗纪</p>
<p>Convergent boundary 收敛型板块边界 converge thrust(推) compress
mountain 陆上：range</p>
<p>Divergent boundaries 离散型边界 split extend mountain 海里:ridge</p>
<p>Transform boundaries 走滑型边界 strike-slip compression-shear 压减型,
不是水平的力，所以有力的分解 strike打 slip滑</p>
<p>分界质 - 塑性介质，如果橡皮泥， fold - 刚性介质，三角板 fault
断层</p>
<ul>
<li>小的层面碰撞, crack, rift &gt; rif分开的意思 river. 东非大裂谷
rift</li>
</ul>
<ol start="6" type="1">
<li><p>地质灾害 cataclysm &gt; cata down &lt;= caco clysm&lt;- klyzein
&lt;- to wash</p>
<ul>
<li>kakos="bad,evil"-&gt;down 希腊语前缀，直接引入英语 cacophony
刺耳的声音 cacography 拼写错误，书法很差 catalog 下降的原木 目录
catastrophe 大灾祸，不幸</li>
<li>kallo=beauty -&gt; call &gt; calligraphy 书法</li>
<li>常见的地质灾害
<ul>
<li>earthquake // quake 震动的感觉， 地震本身</li>
<li>seismology 人工地震, 比如鞭炮，炸弹 &lt;- seismic &lt;- shake
地震学</li>
<li>magnitude 地震级别，提高一级，实际提高30倍</li>
<li>epicenter 地震中心 epi=upon, among (e~u, i~on)</li>
<li>tsunaml 海啸 tsu=harbor nami=waves 日语源</li>
<li>Tidal潮汐 wave 海啸</li>
</ul></li>
<li>The Power of Nature
<ul>
<li>typhoon 台风</li>
<li>sandstorm 沙尘暴</li>
<li>flood 洪水</li>
<li>earthquake 地震</li>
<li>tornade 飓风 torn=turn</li>
<li>snowstorm 暴雪</li>
<li>landslide 滑坡</li>
<li>cyclone 龙卷风</li>
<li>hailstorm hail 冰雹 hailform</li>
<li>valcano 火山</li>
<li>hurricane 飓风</li>
<li>tsunami 海啸</li>
<li>drought 干旱 dry</li>
<li>lightning/thunder 闪电/雷</li>
<li>mud-rock flow 泥石流 mud+rock+flow</li>
</ul></li>
<li>picture
<ul>
<li>台风，根据左旋还是右旋来判断是上升期还是下降期</li>
<li>沙尘暴，沿着风的切线方向走</li>
</ul></li>
</ul></li>
<li><p>岩石学</p>
<ul>
<li>igneous rock 火成岩, 喷火形成的岩石 &gt; ign 希腊语 &lt;- fire,
scarifice fire ignite 点燃; ignitable可以着火的 ignition 点火装置
<ul>
<li>granite 花岗岩 谷物和颗粒 &gt; granite &lt;- grain -&gt; granulate
使成粒状</li>
<li>geyser 天然热喷泉 gush喷出</li>
<li>火山爆发相关
<ul>
<li>Vulcan 火神<br />
&gt; valcano-eruption rupt破 e=out Boliing rock erupts from the crater;
the lava flows slowly down the mountain.</li>
<li>magma chamber 岩浆</li>
<li>crater 火山口 //cra-&gt;kera=to mix bowl for mixing wine with
water</li>
<li>lava 熔岩 // lav 冲洗</li>
<li>ash cloud/ volcanic ash 冲上去的东西 火山灰</li>
</ul></li>
<li>火山分类
<ul>
<li>active volcano 活火山</li>
<li>dormant volcano // dorm=to sleep dormitory /..ory表示场所 寝室</li>
<li>extinct volcano 死火山</li>
</ul></li>
</ul></li>
<li>sedimentary rock 沉积岩 &gt; shale 页岩 limestone 石灰岩 碳酸钙</li>
<li>metamorphic rock 变质岩 &gt; marble
大理石，石灰岩经过高温高压作用下的结果</li>
</ul></li>
<li><p>古生物学 &gt; fossil 化石 New Concept 4 Lesson 1</p></li>
<li><p>Remote Sensing</p></li>
<li><p>Mineralogy 矿物学 &gt; 孔雀石，金刚石 ore 矿物 quartz 石英
aluminum 铝</p></li>
<li><p>Earth's sphere structure</p>
<ul>
<li>内部圈层 interior sphere/ 外部圈层 outer sphere &gt; The Earth
environment is composed of the interacting subsystems of air(大气),
water（水）, living things（生物）,earth's crust地壳, mantle地幔 and
core地核.
<ul>
<li>atmosphere // atmo大气 大气圈</li>
<li>hydrosphere // hydro水 水圈</li>
<li>biosphere //bio 生命 生物圈</li>
<li>crust</li>
<li>matle</li>
<li>outer core/ inner core</li>
</ul></li>
</ul></li>
<li><p>地质作用</p>
<ul>
<li>external process
<ul>
<li>weathering 风化</li>
<li>erosion 侵蚀</li>
<li>sendimentation 沉积 sand=&gt;send</li>
</ul></li>
<li>internal process
<ul>
<li>metamorphic 变质，变形作用 //mor形状 &gt; meta 1. int he midst of ,
along with , after 2. changed, altered 3. higher, beyond, behind</li>
<li>magmatic 岩浆作用</li>
<li>deformation 变形破坏作用 //forma ### 3.7 生物类词根</li>
</ul></li>
</ul></li>
</ol>
<p><img data-src="vlcsnap-2019-06-10-16h22m27s594.png" /></p>
<p>vi- li- 活的</p>
<p>bo 植物学</p>
<p><img data-src="vlcsnap-2019-06-10-16h26m30s023.png" /></p>
<p><img data-src="vlcsnap-2019-06-10-16h27m32s579.png" /></p>
<p><img data-src="vlcsnap-2019-06-10-16h29m08s025.png" /></p>
<p><img data-src="vlcsnap-2019-06-10-16h30m08s492.png" /></p>
<h3 id="历史类词根">3.8 历史类词根</h3>
<p>when, where, who, what</p>
<blockquote>
<p>历史研究的是什么时候，谁在哪里做了一件事</p>
</blockquote>
<ul>
<li>chron: 表示时间， Cronus时间之神</li>
</ul>
<p>chronic 慢性的 chronicle编年史</p>
<p>synchronize 同步，同时的</p>
<p>c和ch可以替换</p>
<ul>
<li><p>annual，ann,eon=year 表示时间</p>
<p>annual每年的 anniversary周年 biannual 每年两次 annuity养老金</p></li>
<li><p>loc = location 表示地点</p>
<p>locate, locomotion, dislocate 使混乱</p></li>
<li><p>stat, stit,stitut = set up</p>
<p><img data-src="vlcsnap-2019-06-21-18h12m10s352.png" /></p>
<p><img data-src="vlcsnap-2019-06-21-18h13m34s539.png" /></p></li>
<li><p>表示写的词根</p>
<blockquote>
<ul>
<li>graph, gram=write, draw, scratch, picturesque独特的</li>
</ul>
<p>photography</p>
<p>telegraphy 电报 topography top地点-&gt;地形 geography</p>
<p>autography auto表示自己 亲笔署名、手稿</p>
<p>monography 争论</p>
<p>lexicograph = lect graphy 词典编著</p>
<p>steno=narrow +graphy 速记</p>
<p>dict书 + graphy 助听器</p>
<p>demo 人民，人物 + ~ 人口统计学</p>
<p>epi 外面 +~ 铭文</p>
<p>calli 好 书写</p>
<p>typo 刷 印刷术</p>
<p>bibli书目 数目摘要</p>
<ul>
<li>gram 写， smal weight课</li>
</ul>
<p><img data-src="vlcsnap-2019-06-21-18h23m40s312.png" /></p>
</blockquote></li>
<li><p>其他类词根</p>
<blockquote>
<p>vict, vinc 克服，战胜 fight</p>
<p>victory 胜利 convict 定罪 conviction</p>
<p>evict 驱逐expel eviction</p>
<p>invincible 不能征服的，无敌的</p>
<p>convince 使确信</p>
<p>convincing</p>
</blockquote>
<blockquote>
<p>vol,volv,volt = roll, turn, twist</p>
<p>voluble 有才的 volubility 健谈</p>
<p>revolution 革命 revolve 旋转</p>
<p>evolve 进展 evolution</p>
<p>involve 限于 involvement</p>
<p>convolve 盘旋</p>
<p>volume 旋转， 卷，册</p>
<p>voluminous 多产的</p>
</blockquote></li>
</ul>
<h3 id="政治学类词根">3.9 政治学类词根</h3>
<ul>
<li>arch = ruler, chief,government</li>
</ul>
<blockquote>
<p>archy 拱形的， architect 建筑 architecture 建筑学 anarchy 无政府状态
anarchic 无政府的 monarch 君王 mon 单一</p>
<p>archives 档案 patriarch 父权制 matriarch 母权统治</p>
<p>tect=texture;build;do;pie up</p>
</blockquote>
<ul>
<li>democracy</li>
</ul>
<blockquote>
<p>demos n. 古希腊人民 people</p>
<p>epidemic 流行的 pandemic 大范围的 endemic 地方的 demagogue 煽动者</p>
<p>demography 人口统计学</p>
<p>cracy = rule , crat=ruler</p>
<p>democracy -&gt; democrat 民主</p>
<p>autocracy-&gt; autocrat 独立</p>
<p>bureaucracy 官僚</p>
<p>pluto 钱 cracy 财阀政治</p>
<p>theocracy 神</p>
<p>mono单一 独裁</p>
<p>mob 暴民</p>
</blockquote>
<ul>
<li>population</li>
</ul>
<blockquote>
<p>popul,publ=people</p>
<p>populous 人口稠密的 popularize 普及 depopulate 减少人口 copulation
交尾，交配</p>
<p>public publish publication publicity 出版</p>
</blockquote>
<ul>
<li>fus, fug = flee ,run away</li>
</ul>
<blockquote>
<p>refugee 难民 fugitive 逃亡的 refuge 避难所</p>
<p>fugacious 转瞬即是的</p>
<p>centrifugal 离心的</p>
<p>insectifuge 驱虫剂</p>
<p>subterfuge 托词</p>
<p>lucifuge 避光</p>
</blockquote>
<ul>
<li>fun=pour 流、泻</li>
</ul>
<blockquote>
<p>refuse -&gt; refusal</p>
<p>confuse -&gt; confusion 困惑</p>
<p>diffuse -&gt; diffusion 扩散</p>
<p>effuse -&gt; effusion 流出</p>
<p>infuse -&gt; infusion 灌输</p>
<p>profuse -&gt; profusion 丰富</p>
<p>suffuse 充满 transfuse 注入 refute 驳斥</p>
</blockquote>
<ul>
<li>mind- mon, monit; warn,advis</li>
</ul>
<blockquote>
<p>monument 让你思考的人 monitor monition admoish ad=together</p>
<p>premonish 预先警告 summon 号召 summon 传票</p>
</blockquote>
<ul>
<li>community muni,mun=public</li>
</ul>
<blockquote>
<p>community service 志愿者 communal 公共的 communize 公有化</p>
<p>municipal 市政的 municipality 市政当局 immunity 免疫</p>
<p>communicate =communicative 沟通</p>
<p>munificent genorosity and liborality 宽宏大量的，慷慨的</p>
</blockquote>
<ul>
<li>polis 古希腊城邦</li>
</ul>
<blockquote>
<p>polis,polic,polit=govern,state,city</p>
<p>police, policy, politics politician 政治学的</p>
<p>cosmpolis 国际化都市</p>
<p>metropolis 计划</p>
<p>mother + pols : 首都</p>
<p>metro 地铁 法语</p>
<p>underground</p>
<p>subway</p>
</blockquote>
<ul>
<li>range</li>
</ul>
<blockquote>
<p>arrange arrangement rearragne disarrange 打乱 misarrange 安排错误
derange 使错乱，使发狂</p>
<p>range &lt;- rank ring</p>
<p>conserve 节约使用、保护某物 conserve
strength/health/energy/water/resources</p>
<p>preserve 保持原样，但保护时，比conserve正式</p>
<p>reserve 保存，留存</p>
</blockquote>
<ul>
<li>sequ, sent- follow</li>
</ul>
<blockquote>
<p>second-&gt;sec-&gt;sequu</p>
<p>sequence次序 consequence结果 subsequence顺序 sequential连续的
sequacious盲从的 obsequious奉承的 consecutive连续的 consecution连贯</p>
<p>sue 跟随，恐告 consue 继而发生 pursue 追赶</p>
<p>prosecute to follow till the end,perform执行</p>
<p>persecute 迫害</p>
</blockquote>
<ul>
<li>urb=city</li>
</ul>
<blockquote>
<p>urban urbane优雅的 exurban城市外面 suburb 郊区 suburbanite
郊区人民</p>
</blockquote>
<h3 id="人类学词根">3.10 人类学词根</h3>
<h4 id="男女相关">男女相关</h4>
<ul>
<li><p>anthrop 人</p>
<blockquote>
<p>anthr &lt;- andry &lt;- man</p>
<p>op &lt;- optic &lt;- eye,face</p>
<p>polyandry</p>
<p>polygamy</p>
<p>polygyny</p>
<p>gamy, ginny &lt;- queen</p>
<p><img data-src="vlcsnap-2019-06-21-20h33m54s596.png" /></p>
</blockquote></li>
<li><p>gyn, gynec, gamy = queen, woman</p>
<blockquote>
<p><img data-src="vlcsnap-2019-06-21-20h34m48s586.png" /></p>
</blockquote></li>
<li><p>patri &lt;- father</p>
<blockquote>
<p><img data-src="vlcsnap-2019-06-21-20h38m12s959.png" /></p>
</blockquote>
<blockquote>
<p>patriarch patriarchy patron patronize patronage patriot</p>
<p>patriotism patrilineal society expatriate banish,exile</p>
</blockquote></li>
<li><p>matri, matr- mother</p>
<blockquote>
<p><img data-src="vlcsnap-2019-06-21-20h40m15s745.png" /></p>
</blockquote>
<blockquote>
<p>matrix 子宫</p>
</blockquote></li>
</ul>
<h4 id="情感">情感</h4>
<ul>
<li><p>love</p>
<blockquote>
<p><img data-src="vlcsnap-2019-06-21-20h42m54s826.png" /></p>
<p>希腊，罗马</p>
<p>amateur 业余爱好者</p>
<p>amicable 和善的 amiable 亲切的</p>
<p>amity 友好</p>
<p>Eros 丘比特的小名 = the good of love. rose 代表爱情</p>
<p>erosion erotic 腐蚀的 corrsion</p>
</blockquote></li>
<li><p>phil, philo = love</p>
<blockquote>
<p><img data-src="vlcsnap-2019-06-21-20h53m01s124.png" /></p>
<p>philology 爱哲学</p>
</blockquote>
<p><img data-src="vlcsnap-2019-06-21-20h55m38s313.png" /></p>
<p><img data-src="vlcsnap-2019-06-21-21h14m21s009.png" /></p></li>
<li><p>path=suffering, feeling, illness, disease</p>
<p><img data-src="vlcsnap-2019-06-24-16h30m35s385.png" /></p>
<blockquote>
<p>又痛苦又激情， 耶稣为人类受难的感情</p>
<p>pathetic 悲惨的</p>
<p>antipathy 反感，延误</p>
<p>apathy 冷漠</p>
<p>apthetic 冷漠的，缺乏兴趣的，无动于衷的</p>
<p>sympathy sym=same, 同情心</p>
<p>path logy</p>
<p>psy cho poth 精神</p>
</blockquote></li>
<li><p>soph=debate 善辫, wise</p>
<p><img data-src="vlcsnap-2019-06-24-16h37m16s340.png" /></p></li>
<li><p>phobia 恐惧， 以ia结尾的可以表示病</p>
<p><img data-src="vlcsnap-2019-06-24-16h38m54s427.png" /></p>
<blockquote>
<p>phobia, acrophobia, hydrophobia, sinophobe sino中国;
任何单词加上phob, 就是恐惧的意思。</p>
</blockquote></li>
</ul>
<h4 id="行为">行为</h4>
<ol type="1">
<li>flu=flow, 作名词“流感”</li>
</ol>
<p><img data-src="vlcsnap-2019-06-24-16h43m48s872.png" /></p>
<p>fluency, effluent, influence, influenza, fluid, fluidity, flux,
infulx</p>
<p>fluctuate, mellifuous, confluence, superfluous 过，多余的, affluent,
effluvium</p>
<p>refluent</p>
<ol start="3" type="1">
<li>sect, seg = divide, piece, cut</li>
</ol>
<p><img data-src="vlcsnap-2019-06-24-16h46m24s020.png" /></p>
<p>segment a,b; intersect, bisect, vivisect : vivi活的</p>
<p>dissect解剖， transect 横截</p>
<blockquote>
<p>为什么可以替换，因为发音特别相似，ct和g发音相似</p>
</blockquote>
<ol start="4" type="1">
<li>gen,gener,genit,birth,produce,create, beget,race,kind</li>
</ol>
<p><img data-src="vlcsnap-2019-06-24-16h53m39s450.png" /></p>
<p>genus, genetic,general,generate,generation,regenerate,degenerate.</p>
<p>genius, ingenuous, ingenious 我，机灵的。 generous</p>
<p><img data-src="vlcsnap-2019-06-24-17h01m42s500.png" /></p>
<p>homo(相同的)geneous, hetero(不同的)geneous genre</p>
<p>indigenous, indigence gentle, genteel, engende, progeny</p>
<p>indi = in, within gence=egere be in need,want</p>
<ol start="5" type="1">
<li>gress=step,go</li>
</ol>
<p><img data-src="vlcsnap-2019-06-24-17h07m02s793.png" /></p>
<p>gress, grad</p>
<ol start="6" type="1">
<li>soci=social</li>
</ol>
<p><img data-src="vlcsnap-2019-06-24-17h08m58s877.png" /></p>
<ol start="7" type="1">
<li>migr-&gt;move</li>
</ol>
<p><img data-src="vlcsnap-2019-06-24-17h10m16s091.png" /></p>
<p>hemikrania &lt;- hemi+kranion half+skull</p>
<ol start="8" type="1">
<li>orig,ori---rise</li>
</ol>
<p><img data-src="vlcsnap-2019-06-24-17h12m17s060.png" /></p>
<p><img data-src="vlcsnap-2019-06-24-17h13m12s472.png" /></p>
<p><img data-src="vlcsnap-2019-06-24-17h14m24s632.png" /></p>
<p><img data-src="vlcsnap-2019-06-24-17h15m20s709.png" /></p>
<p><img data-src="vlcsnap-2019-06-24-17h16m58s812.png" /></p>
<p><img data-src="vlcsnap-2019-06-24-17h18m00s176.png" /></p>
<p><img data-src="vlcsnap-2019-06-24-17h18m04s599.png" /></p>
<p>manu =hand, mainfacture , mainfest,</p>
<p><img data-src="vlcsnap-2019-06-24-17h19m35s895.png" /></p>
<p><img data-src="vlcsnap-2019-06-24-17h20m36s820.png" /></p>
<p>impasse 僵局</p>
<p><img data-src="vlcsnap-2019-06-24-17h21m31s883.png" /></p>
<p><img data-src="vlcsnap-2019-06-24-17h24m33s615.png" /></p>
<h3 id="文化类词根">3.11 文化类词根</h3>
<ul>
<li>creed,cred = believe,trust</li>
</ul>
<p>credit 信任，信用卡，电影片头字幕</p>
<p>credible 可信的</p>
<p>creditable 可靠的</p>
<blockquote>
<p>able 能够的</p>
</blockquote>
<p>accredit 信任, a表示强调</p>
<p>credence 信任</p>
<p>credential 证明书</p>
<p>credo 信条</p>
<p>discredit 怀疑</p>
<p>credulous 轻信的</p>
<p>quack doctors charming money out of the pockets of credulous
health-hungry citizens.</p>
<blockquote>
<p>charm 骗别人</p>
</blockquote>
<p><img data-src="vlcsnap-2019-06-28-12h50m52s843.png" /></p>
<ul>
<li>fid = trust, faith</li>
</ul>
<p>confident 自信的</p>
<p>self-confident</p>
<p>confidant 心腹知己</p>
<blockquote>
<p>ant 表示人</p>
</blockquote>
<p>confidential 机密的，秘密的</p>
<p>diffident 缺乏自信的</p>
<p>confide 信任</p>
<p>fidelity 忠实</p>
<p>infidel 不心焦的</p>
<p>perfidy 背叛 perfidious 背信弃义的</p>
<blockquote>
<p>per全部，贬义</p>
</blockquote>
<p>affidavit 宣誓书</p>
<p>fiduciary 信任的</p>
<ul>
<li>liber=free</li>
</ul>
<p>noble, generous people</p>
<p>liber(l狮子+ i我+ ber高贵)</p>
<p>liberty = people 人 liberal arts 文科</p>
<p>liberty people 扩大 man男性特征</p>
<p>intellectual enlargement mechanical</p>
<p>liberty 自由</p>
<blockquote>
<p>ty名词后缀</p>
</blockquote>
<p>liberal liberate illiberal libertine</p>
<p><img data-src="vlcsnap-2019-06-28-12h59m09s027.png" /></p>
<blockquote>
<p>girl 中世纪统称男性，词义缩小， 女性；</p>
<p>bird 特指一种鸟，词义扩大，广义鸟</p>
</blockquote>
<ul>
<li>ment = mind， 元音互换，把e换为了i，所以就这样</li>
</ul>
<p>mental 精神的 mentality 智力 mention comment com=together</p>
<p>commentate 评论，解说 demented 发狂的，精神错乱的</p>
<p>remind amentia 智力缺陷</p>
<ul>
<li>nov= new,yound,recent,shape,unusual</li>
</ul>
<p>novel 小说</p>
<p>novelty 新奇</p>
<p>nova 新星</p>
<p>novation 更新</p>
<p>novice 新手</p>
<p>innovate innovation 内在的革新</p>
<blockquote>
<p>in 让你变新</p>
</blockquote>
<p>renovate 反省</p>
<p><img data-src="vlcsnap-2019-06-28-13h06m54s217.png" /></p>
<ul>
<li>prais,preci = praise, value. price字母顺序不变，意思不变</li>
</ul>
<p>appraise 评价 appraisal 评价，骨架</p>
<p>precious 宝贵的</p>
<p>appreciate 赏识，涨价</p>
<p>appreciative 欣赏的</p>
<p>appreciable 可感知的，可评价的</p>
<p>depreciate 变低，轻视</p>
<ul>
<li>duc, duct=lead, bring</li>
</ul>
<p>duck 公爵，手，拳头</p>
<blockquote>
<p>Duck University. Knowledge and Faith 贵族学习，引导</p>
</blockquote>
<p>to pull, drag</p>
<blockquote>
<p>因为首先作为贵族，具有权力。然后leader，然后引申为pull,drag.
最后引申为a kind of animal</p>
</blockquote>
<p><img data-src="vlcsnap-2019-06-28-13h11m38s882.png" /></p>
<p>duct这里主要是作为引导的意思。</p>
<p>duct 管道</p>
<p>ductile 展开的</p>
<p>aqueduct 导水管</p>
<blockquote>
<p>aque 水</p>
</blockquote>
<p>educate 教育</p>
<p>educe 唤起</p>
<blockquote>
<p>e=out</p>
</blockquote>
<p>abduc 绑架</p>
<blockquote>
<p>ab不好的方向</p>
</blockquote>
<p>deduce 推论</p>
<blockquote>
<p>向下</p>
</blockquote>
<p>induce 劝诱</p>
<blockquote>
<p>加强</p>
</blockquote>
<p>induct 引导</p>
<p>introduce 介绍</p>
<blockquote>
<p>intro开始</p>
</blockquote>
<p>produce 产生</p>
<blockquote>
<p>pro向前</p>
</blockquote>
<p>product 生产</p>
<p>productivity 生产力</p>
<p>reduce 减少</p>
<blockquote>
<p>re 往回</p>
</blockquote>
<p>conduct 引导 con=together</p>
<p>conductor 领导，经理</p>
<p>seduce se分开 诱使</p>
<p>traduce tra横着 诽谤</p>
<p>vioduct vio路 高架桥</p>
<p>ventiduct vent 过去?， 通风管道</p>
<ul>
<li>art=skill, joint,trick!!!</li>
</ul>
<p>article 文章， 物品，项目，条款，清楚说出</p>
<blockquote>
<p>art+ cle 变成名词， article表示任何有技巧的东西。</p>
</blockquote>
<p>artless 朴实的</p>
<p>artful 狡猾的</p>
<p>artistry 艺术技巧</p>
<p>artificial 人造的</p>
<blockquote>
<p>人做出来的技巧</p>
</blockquote>
<p>artisan</p>
<p>artifact fact=do 做艺术</p>
<p><img data-src="vlcsnap-2019-06-28-13h30m32s576.png" /></p>
<ul>
<li>lingu=language</li>
</ul>
<p>lingu = language l和d互换 tongue 舌头 dingua lingua</p>
<p>linguist 语言学家 linguistics 语言学</p>
<p>bilingual , unilingual,</p>
<p><img data-src="vlcsnap-2019-06-28-13h34m17s854.png" /></p>
<h3 id="法学类词根">3.12法学类词根</h3>
<ol type="1">
<li><p>leg, legis = law &gt; legal 法律的 legality illegal 违反的
illegitimate 私生的 legislate 立法 legislation n. 立法 legislature
立法机构 privilege 特权 pri在前面 &gt; lect log. privi(privita)+leg(law)
&gt; delegate 代表 &gt; relegate 驱逐 banish 委托，丢弃</p>
<p>本身来源于log-&gt;lect, 学科, 从学科中选择出来的东西</p></li>
<li><p>jur, juris=law, swear &gt; just 公平，公正； 公正，法律引申 &gt;
jury 陪审团 &gt; injury 伤害 injurious 有害的 perjury 伪证 per: away,
entirely jurisdiction 权限 GRE conjure together+swear 祈求 abjure
放弃宣誓 adjure 郑重选址</p></li>
<li><p>dict, dic=say, speak, point out , show, teach &gt; dictate 口述
dictator 独裁者 说这个话的人 diction 用词 dictionary 字典 ary名词后缀
vocabulary dictum 格言 benediction 祝福 malediction 诅咒 male坏
contradict 驳斥 反 contradictory 反驳的 jurisdiction 权限 juris
公平，说公平 predict 预测 pre在前面 addict 上瘾 ad=toward 一直
predicament 困境 pre在前面说出来的话 indict 起诉 in加强 abdicate 放弃
ab否定前缀，不的意思 predicate 断言<br />
dedicate 献身 de向里面给 indicate 暗示 in加强 edict 法令，公告
e=out</p></li>
</ol>
<blockquote>
<p>dictatorship 独裁政治 indite 写，创作 in 下来 vindicate win赢的, 平反
vindictive(vin&lt;-win) verdict ver 真实的 裁决 valediction 告别
val&lt;- be well, 说好话 farewell 再见 valiant 勇敢的</p>
</blockquote>
<ol start="4" type="1">
<li><p>jur,jurth=law, swear; dic, dict=say, speak =&gt; judg,
judic=judge &gt; judgment 判断 judicial 司法的，公正的 adjudge 宣判
ad=toword judiciary 司法的，审判的 adjudicate 审判，裁定 prejudice 偏见
prejudge 预先判断</p></li>
<li><p>cern, cert, cret=separate, sure 分开 sift/sieve; perceive,
comprehend 一种感知 crisis: 危机 concern 关注 discern 识别 cern
可以分开，即识别 discernible 可辨别的 dis=away certainty 确定
可以被分开的东西，即确定 certificate 证书，
直接用的是上面的引申义，即确定 certitude 确信 discretion 判断力 discrete
分立的, e被t给分立了 disceet 谨慎的 secret 秘密 secrete
隐藏，即秘密用来隐藏的</p></li>
<li><p>fin = end, boudary, limit 边界，线，最终引申为钱，
因为钱可以解决任何事情 &gt; fine 精巧的，罚金，变细-&gt;
通过钱就可以结束 finance 财政， 付罚金后就免罪或对伤者补偿了，结束了
finish 结束 finale 结局 finality 结尾，最终 confine 限制 define 定义
finite 游侠的 infinite 无限的 infinitesimal 吴强小的 affinity
亲密的关系（能进入范围内的）af强调，进入这个边界即亲密</p></li>
<li><p>fort
原义为剑身上最坚硬的部分，-&gt;最强的,优点,强音（弦乐器的F音） &gt;
force 力量 forceful 有力量的 enforce 强迫，执行 en reinforce 加强，增援
fortress 要塞 fort墙堡 fortify 加强 foritude 坚韧 effort 努力 comfort
舒适 com=together discomfort 不适</p></li>
<li><p>her, hes=stick, cling &gt; adhere 粘附，坚持 ad=toward 某种去向
adhere to 对什么的坚持 adherence 忠诚 adhesive 粘性的 cohere 粘着
co=together coherent 粘在一起的，连贯的 inherent 内在的，与生聚来的
hesitate 犹豫 ? 抓住，不是很果断的 hesitation 犹豫</p></li>
<li><p>hibit=hold, possess &lt;- habit 来自于习惯。 一直习惯的东西即拥有
&gt; exhibit 展出，陈列 ex + hold 拥有的向外，即展出，陈列 exhibition
展览会，显示 n. inhibit 抑制，约束 in在里面， hibit inhibition 抑制
uninhibited 放荡不羁的, 不受抑制的 prohibit 禁止，阻止 向前拥有
prohibition 阻止 prohibitive 禁止的</p></li>
<li><p>odin=order &gt; ordinal 顺序的，依次的 ordinary 平常的 ordinary
平常 ordinance 法令，布告 inordinate 紊乱的 in 没有顺序的,
in有时表示否定 extraordinary 非常的，特别的 extra 特别的 coordinate
同等的，调整，整理 ordain 规定，颁布 subordinate 次要的，附属的 adorn
装饰 ornate 装饰的，华丽的 disorder 扰乱 coordinate
同等的，调整，整理</p></li>
<li><p>prov,prob = test front &lt;- pro v,b可以替换 &gt; probable 可能的
可以测试 probe 探针，侦查 可以测试 probability 可能性 probity 正直
随便怎么测试 approve 赞成，通过 可以加强测试 probation 查验，鉴定<br />
approval 赞成 probative 检验的 disapporval 不赞成 reprobate 责难 re,
再次测试，re从某种意义上是具有否定意义的 disprove 反驳 reprove
责备</p></li>
<li><p>strict, strain, string=tighten structl stretch 收敛 &gt;
绷紧的意思，凡是有str都可以看作有这种意思</p></li>
</ol>
<blockquote>
<p>strict stricture 责难 在精神上的 constrict 压缩 constriction
stringency 严格，紧绷 stringent 严厉的 constringe 使收缩 strain 疲劳 //
换掉了a字母和i字母，所谓的元音替换意思不变 constrain 抑制，拘束
constraint 抑制 overstain 过度紧张 restrain 反复地拉，阻止 restrict 限制
restraint 克制 // constraint 直接加t变为名词</p>
</blockquote>
<p>The Motion Picture Association of America - G General - M Middle - R
Restricted 色情，暴力 - X 严加限制级，来自于罗马数字10</p>
<ol start="13" type="1">
<li>sur=sure 确定 &gt; sur=sure &lt;- secure &lt;-
se(sed)+cure(care)</li>
</ol>
<blockquote>
<p>assure 保证，使确信 // a, 有种使动的感觉 reassure 使安心 surety
担保，保证 insurance 保险 assurance 确信 censure 责难 //
cen集中，大家一块来 assuredly 确实地，确信的</p>
</blockquote>
<ol start="14" type="1">
<li><p>term=limit, end, boundary &gt; terminal 终点站 terminate
终止，结束 termination 终止 terminer 判决，终止 terminus 终点，界标
terminology 术语学 // 范围内的东西，边界 determine 决定 // de? 去的感觉
determined 坚决的 interminable 无限的 // inter在什么里面，不终结的？？
exterminate 消除 // ex=out</p></li>
<li><p>treat=handle &gt; tract
物理中有讲过，可以拉的意思，所以为处理</p></li>
</ol>
<blockquote>
<p>treaty 条约 treatment 对待，处理 maltreat 虐待 // mal表示坏的 retreat
撤退 // re=back, 往回对待 entreat 祈求 // en=to entreaty 祈求 treatise
论文 // -ise名词后缀</p>
</blockquote>
<h3 id="校园生活类词根">3.13 校园生活类词根</h3>
<ol type="1">
<li>act = to do, to drive &gt; g=ct -&gt; ag,act=to act, to drive</li>
</ol>
<blockquote>
<p>active, activity, activate, inactivity actual真实的 actualize
实现，实施 exact 精确的 ex+act, force out, demanding, right interact //
在里面动， 相互的 react 起反应 // enact 颁布 //en=do transact 交易，办理
// trans变化 + change counteract 中和 // count 反, act=to do agenda:
things to be done agile 敏捷的 // ag=to do, ile名词后缀 agitate
agitating 煽动 agent 机构，试剂, agency coagent 合作者，帮手</p>
</blockquote>
<ol start="2" type="1">
<li><p>alter, altern = other = o(al=beyond) + t(h)er = to change &gt;
alter , alterable可以改变的, alteration alternate 轮流，记忆 alternative
选择性的， 可供选择的选项 // ive结尾的名词， detective alien 外来的 The
night sounds grew louder</p></li>
<li><p>don, dot=give &gt; donate 捐赠 donor 捐赠 condone 宽恕 //
给你一些权力 antidote 解毒药 condition 条件 tradition 习惯 edit 编辑
editorial 编辑（人） extradite 引渡 extradition 引渡 pardon 原谅 //
pardon? 有什么问题吗 par,per-through, thoroughly anecdote = an+ex+dote =
not + out + give = secret to private stories rendition 表演，演唱，翻译
// render=re+der=give back, yield, present,deliver</p></li>
<li><p>cre,creates=grow, make &gt; create procreate procreative
有生育能力的，生产的 // pro=pre 向前 increase increment 增加 // in
里面增加 decrease decrement 减少 // de 不增加 recreate // re 再次产生
娱乐，消遣 concrete 具体的，（引申为具体的名词）混泥土 crescent
新月形的，逐渐增加的 // cre像月亮的 decrescent 逐渐减少的</p></li>
<li><p>mir=look, laugh, wonder &gt; mir=look, laugh, wonder&lt;-
s(mile)</p></li>
</ol>
<blockquote>
<p>miracle 奇迹 // wondered miraculous 神奇的 mirror mirage
海市蜃楼，幻想 mirth 收集，高兴 admire admiration 钦佩</p>
</blockquote>
<ol start="6" type="1">
<li><p>not(e)=obeserve, mark=know &gt; notable 著名的，值得注意的 notice
通知，布告 notify 通报 notion 概念，想法，一件 denote 附录 denotation
指示</p></li>
<li><p>nounce, nunci=speak, shout &gt; nounce, nunci=speak,shout //
un-&gt;ou announce // 说出来 announcement announcer enunciate 阐明 //
en=out annunciate 通告 pronounce 宣告 pronounced 明确的，显著的 renounce
= give up 断绝关系 // out denounce = accuse 谴责 // back</p></li>
<li><p>pend, pens=hang 挂坠 &gt; pendant 垂饰 pending 悬而未决的
inpending 迫近的 perpendicular 垂直的 depend 依赖 dependent 依靠的
dependant // ! n. 侍从，食客 independent 独立的 suspend -&gt; suspense
-&gt; suspension老的时候赖以生存的东西 append 增加 appendage appendix
附录</p></li>
<li><p>pend, pens, pond = (s)pend; to pull, stretch, weight, expend &gt;
expend -&gt; expenditure 支出 pension 养老金 compensate 偿还, 补偿
recompense 报偿 dispense 分配 dispensable 可有可无的 dispensary
诊所，花钱的地方 pensive 问题进行延展 沉思的 perpend 向前延展 仔细考虑
ponder 思考 ponderance 平展 ponderous 笨重的 // 胖的要死 propensity
热身</p></li>
<li><p>pli, ple, plen, plet=to be full, fill; p ly-&gt; ply &gt; plenary
plen多 完全的，绝对的 plenty 丰富、大量 plentitude 充分 complement
补足物 // com 一块 supplement 补充 // sup 下 implement 工具，实现 //
im=in 往里面 deplete 耗尽 // de=not replenish 补充 replete 充满的 //
accomplish 达到 // ac补充</p></li>
<li><p>pli, ple, ply=fold; pl-it-&gt;pli 来自于辫子 &gt; ply:
不断地做，折叠，层 eg1: The market traders noisily ply their wares. eg2:
three ply recycled paper complicate // 一起折 复杂 complication //
并发症， 有多种名词化的方式，各自有什么选择的余地 tion, ity, cacy, ary,
or, er explicate 说明 // ex=out explicable explicit 清楚的，直率的
implicit 含蓄的 // im=in implicate 暗示，牵连 replicate 复制 replica
复制品 pliable 易弯的 supplicant 恳求者 // sup向下的 accompice 帮凶 //
ac强调 complicity 同谋 //
注意末尾为ity和ation是不一样的，是否变形也不一样？？ duplicity
狡猾，奸诈</p></li>
<li><p>plex=fold &gt; complex 复杂的 duplex 两倍的，双重的 composed of
two parts du=duo=two complextion 肤色，局面 e.g. The American complexion
visibly darkened in the 1980s. perplex 困惑 // per=total perplexed
困惑的</p></li>
</ol>
<h4 id="section-1">3.13.8</h4>
<ol type="1">
<li>port
<ul>
<li>carry &gt; import 进口 export 出口 support 支持 transport //
trans=ver 交通 purport v. 标榜 n. 主旨大意</li>
<li>take &gt; protable 轻便的 portage 搬运 porter 守门人 comport
表现，水果盘 comportment 举止，行为 disport 向四面八方带 玩耍 deport 1.
驱逐 deportation 2. 举止 deportment sym. comportment apportion 分配
portfolio 投资组合，部长职务 // port=take</li>
</ul></li>
<li>press &gt; pressure express 往外面压 表达，快速的 expression
高速公路 compress 压缩 compressible compression // ible, able 可以什么的
depress 沮丧 depressed depression impress 盖印 oppress // 加强
压迫，压抑 repress 再压 抑制，镇压 suppress -&gt; suppression 镇压</li>
<li>pute=to think, pruno梅干？，修剪 变体得到pute &gt; compute 计算
computable computer // +r也可以变成名词 dispute // 向四面八方不停地想
dis=away disputable disputatious 争论 impute
//im有种强加于某人身上的感觉 指责。归因于 repute 再次想 名气 reputation
名誉，名声 disrepute 坏名声 // dis=坏</li>
<li>quest, quer, quir, quis=seek,search &gt; quest 请求 question query
询问，怀疑 inquest 审讯（不能将自己的想法强加于人） inquire(enquire
变体) 询问 inquiry 调查，质询 acquire -&gt; acquired -&gt; acquistive
-&gt; acquirement 获得 require 要求，命令 request 要求 requisite
必备的，必需品 prerequisite 先决条件 conquer 克服，展示 conquest
克服，战胜 disquisition 专题论文, 对一个问题的寻求</li>
<li>scend,scent, scens=climb &gt; ascend 攀登，上升 //cend?? descend
下降 descent 降下，出生，猛攻 condescent 屈尊，谦逊 to yield
deferentially transcend 超越，胜过 descendant 子孙，后代 // de向下
ant表示人</li>
<li>sid=sit &gt; reside 居住 residence 住处 residue 残余 preside
在前面坐, 主持 president 主题 presidium 主席团 subside // 用于保证生活的
补贴金 subsidiary 下沉 subsidy 辅助的 dissidence 意见不同 dissident
唱反调者 consider 考虑 considerate 体贴的 insidious 隐藏轨迹的 assiduous
勤奋的 sedate 镇静 sedulous 坚韧不拔的 supersede 取代 // sup在上面坐
sedentary 久坐的</li>
</ol>
<h4 id="section-2">3.13.9</h4>
<p>stand - st, sta &gt; stable 稳定的 obstacle 障碍 - stant, stat, stan
&gt; instant 立即的 instantaneous 瞬间的 stature 雕像 status 身份
stationery 文具，信纸 stationary 固定的 state 描述，国家 - sist &gt;
assit 协助 desist 终止 exist 存在 insist 坚持 // 短期坚持 persist 坚持
// per, 全部的，时间较长 resist 抵抗 // re再一次，反</p>
<ol type="1">
<li><p>st,sta = stand &gt; stable 稳定的 stabilty stabilization 稳定性
obstacle 障碍 stamina 体力，耐力 steadfast 坚定的 homestead
家园，田产</p></li>
<li><p>stant, sta,stan &gt; instant 立即的 instance 情况 instantaneous
瞬间的 state stateliness 威严，庄重 statement stationary 固定的
stationery 文具，信纸 statue 雕像 status 身份，地位 statute 法令，条例
constant 衡量，不变的 substance 物质 substantial 坚固的，真实的
substantive 独立存在的 distant 远的 distance 距离 equidistance 等距离
circumstance 情况，环境 // 绕着圈站 estate 房地产，财产 static 静态的
statistics 统计学 obstinate 顽固的 obstinacy 固执 // ob反<br />
stagnant 停滞的，迟钝的 withstand 抵挡，经受住 apostate 变节者，背叛者
// ap=off, 远离 apostasy 脱党，背叛</p></li>
<li><p>sist=stand &gt; assist assistant 助手 //!, 注意是a assitance 援助
consist 一致 consistence 连贯 desist 终止 exist existence 存在 insist
insistence 坚持 persist persisitence 坚持 resist resistance 反抗 //
注意名词是a irresistible 不可抵抗的 subsist 坚持下去，存在</p></li>
</ol>
<h4 id="similsimulsemblspectsspicspir">3.13.10
simil,simul,sembl,spects,spic,spir</h4>
<ol type="1">
<li><p>simil, simul, sembl=alike, same //
只是将same对应的原因位置的单词进行了替换，如此而已 &gt; similar 相似的
similarity simile 明喻 similitude 相似 dissimilar 不同的 assimilate 吸收
// as强调 facsimile 募写，传真 // fac=do verisimilar 好像真实的 simulate
simulation 模拟 simultaneous 同时发生的 simulaneity 同时的 semblance
外表 resemble 相似 assemble 组装 dissemble 掩饰</p></li>
<li><p>spect, spic</p>
<ul>
<li>look, see,scope &gt; expect 期待 aspect 面貌，外表 inspect 检查
respect 尊敬 respectable 可敬的 //-able sb 值得被 respectful 尊重人的
//-ful sb是一个 sb.的人 respective 分别的，各自的<br />
prospect 期望 prospective 预期的 prospectus 间接 retrospect 回顾
retrospective 回顾的 suspect 怀疑 // 往下面看 suspicion 怀疑 suspicious
可疑的 specious 华而不实的 // 看得好的 spectate 观看 spectator 观众
spectacular 壮观的 speculate 推测，思索，投机 auspice 吉兆 auspicious
幸运的 awi(bird)+spec aviary conspicuous 显著的 despise 轻视 despicable
可鄙的 perspective 透视法 perspicacious 具有洞察力的 circumspect 慎重的
// cascade 小瀑布 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Olympics Rehearsal</span><br><span class="line">Fireworks cascade above the Olympic National Stadium in Beijing, July 16, 2008. The Olympic National Stadium is known as the &quot;Bird&#x27;s Nest&quot;. Red is an auspicious color in China, associated with protection and prosperity.</span><br></pre></td></tr></table></figure></li>
<li>kind &gt; special // 具体某个种类后 specialize 专门研究 // ize动词化
speciality 特性 // ity specific 特别的 specification 规范，说明书
species 种类 specimen 范例，样本 consepcific 同种的</li>
</ul></li>
<li><p>spir=breathe, spit-&gt; spirit=soul, courage, vigor, breath &gt;
spirit spirited 有精神的 spiritual dispirit aspire 热望 aspiring 积极的
aspiration 渴望 conspire conspiracy 阴谋 expire expiration 期满 //
信用卡上 inspire inspiration 灵感 perspire 出汗 respire respiration 呼吸
transpire // trans=vert 蒸发</p></li>
</ol>
<h4 id="sum-tain-ten-tin-turb">3.13.11 sum, tain, ten, tin, turb</h4>
<ol type="1">
<li><p>sum</p>
<ul>
<li>total super &gt; sum 总和 summary 概要。摘要 summation 总和，合计
summit 顶点 summon 号召，召唤 summa corn laude 享有最高荣誉 super with
laude</li>
<li>to take up 占据 &gt; exempt exempt(sum) 不再占据，豁免 sumptuous
奢侈的 // ous的感觉，一种程度加多的感觉，添加一种程度 sumptuary
禁止奢侈的 //-ary !!!! assume 假定，承担 // 加强占据 assumption
假定，假设 consume // 一块占据，消费 consumer 消费者 // 有e直接加r
resume 恢复，重新占用 presume 假定 presumption 假定</li>
</ul></li>
<li><p>tag, tac(t), tig, ting = tangent, touch &gt; tactual 触觉的
tactility 触感 attach 联系 attached attachment contact 联系 contagion
传染 // tagi- contagious 传染性的 // i contiguous 毗邻的，接近的 //
tigu- contingent 视具体情况而定的 contingency 可能性 intact
完整的，未动过的 // 在里面 tactics 战术，策略 tangible 可触摸的
intangible 感觉不到的</p></li>
<li><p>tain, ten, tin=tangent -&gt; hold &gt; attain 达到 attainment
attainable maintain // main手，用手握住 maintence 保持 sustain 支撑
sustenance // sus在下面 tenable 可坚持的 tenacity 坚韧的 untenable
站不住脚的 content 满意的 // 一起hold discontent 不满的 pertinent 有关的
impertinent 无关的，鲁莽的 tenant 顾客 tenancy 租赁 tenure 任期 detain
拘留 pertain 适合。，属于 countenance 面容，表情 retain 保持 retention
记忆力 abstinence away from hold 放弃，禁绝</p></li>
<li><p>tend, tent, tens=stretch &gt; tend 趋势 tendency 倾向 trend 倾向
attend 参加 attendant 服务员 attentive 留心的 extend 延展 extensive
广阔的 intense 强烈的 intension 紧张的 intensify 加强，强化 //ify 动词
pretend 在前面拉，假装的 假装 pretension 借口，自负 pretentious
自命不凡的 distend 扩大 //dis=away contend 斗争</p></li>
<li><p>tom=cut &gt; atom 不能切 原子 tome 卷，册 epitome 摘要 epitomize
摘要 anatomy 解剖 // ana &lt;- animal anthropotomy 人体解剖 // anthro
人</p></li>
<li><p>turb=stir 搅拌的; turb=stir &lt;- turb = turmoil 乱 &gt; disturb
扰乱 disturbance 扰乱 turbulence 骚乱，紊乱 turbulent 狂暴的 turbid
浑浊的 turbine 涡轮 perturb 使烦恼 // per 全都 perturbative
不安的</p></li>
<li><p>us, ut=use &gt; usage 使用 utilize 利用 usual 通常的 -&gt;
unusual abuse // ab=not, 滥用 abusive disabuse 纠正 misuse 误用 utilize
利用 utility 有用 utilitarian 功利的 //-ian utensil 器具 usurp 篡夺
usu(use) + rp(rape) 使用强权</p></li>
<li><p>ven, vent=come; venue=a place for event -&gt; come &gt; advent
来临，出现 adventure 冒险 adventurous 冒险的 //去e加ous adventurer
冒险家 venture 冒险，投机 venturesome 冒险的 convene 召集，集合
convention 打会，协定 conventionality 常规，老套 event 时间 eventful
eventual 最后的 eventuality 可能性的 invent //快来 发明 inventive 创造的
convene 召集 convenience 方便 revenue 收入 avenue 大街 // 用来走路的大街
contravene // contra 反 违反 convenant 契约 intervene 干涉 // inter
在里面 inventory 详细目录，存货清单</p></li>
<li><p>vail,val</p>
<ul>
<li>valid: be of use &gt; avail 有助 eg; My daughter did not avail
herself of my advice. avail of = take advantage of available invalid
病人 invalidate 使..无效</li>
<li>strong &gt; prevail 盛行 prevailing 流行的 prevalence 流行 valor
英勇 valiant 勇敢的</li>
<li>value &gt; valuable 有价值的 evaluate 评价 devaluate 贬值 undervalue
低估 equivalence 等值 equivalent 相等的 invaluable 无价的 indispensable
不可缺少的</li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>english</category>
        <category>TOEFL</category>
        <category>word</category>
      </categories>
      <tags>
        <tag>english</tag>
        <tag>TOEFL</tag>
        <tag>word</tag>
      </tags>
  </entry>
  <entry>
    <title>TOEFL listening</title>
    <url>/2019/TOEFL-listening-b27330092a01/</url>
    <content><![CDATA[<h1 id="概述">1. 概述</h1>
<p>书籍推荐： 林强新托福听力真经之TPO超详解析 ## 1.1 考试 1. 题型 30： 1
conversation + 2 lecturers 2*30 英语加试 1+2</p>
<ol start="2" type="1">
<li><p>时间 20 mins听力+10 mins做题(5+6+6=17) &gt; 30s 一题,
计时！</p></li>
<li><p>具体的题 要点:</p></li>
</ol>
<ul>
<li>名词专业化，学术化 stack 书架</li>
<li>一词多义</li>
</ul>
<p>5 mins 文章 题未知！！ 答题，next，题不可逆！！</p>
<ol start="4" type="1">
<li>内容</li>
</ol>
<ul>
<li>对话
<ul>
<li>office hours 多 老师！</li>
<li>service encounters 遭遇 多</li>
<li>students interaction 0.1比例 !!! &gt; 女尊男悲， ！女</li>
</ul></li>
<li>讲座
<ul>
<li>独白，互动，问答出题</li>
<li>kinds
<ul>
<li>Arts</li>
<li>Life Science &gt; 动物</li>
<li>Physical Science 自然科学！</li>
<li>Social Science</li>
</ul></li>
<li>main domins
<ul>
<li>Mosaics 马赛克，镶嵌</li>
<li>Ceramics陶瓷</li>
<li>Physioloy of sensory organs 感知器官生命机能</li>
<li>Food foraging 觅食</li>
<li>Astronomy and cosmology 天文学，物理学</li>
<li>Particle physics 粒子物理</li>
<li>Seismology 地震学</li>
<li>Optics 光学</li>
</ul></li>
</ul></li>
<li>考试题型</li>
</ul>
<ol type="1">
<li>Basic comprehension
<ul>
<li>Gist question 主旨题</li>
<li>Detail</li>
</ul></li>
<li>Pragmatic understanding
<ul>
<li>Purpose ! &gt; 不要过度推断 tpo27, 直接！！</li>
<li>Attitude</li>
</ul></li>
<li>Connecting information
<ul>
<li>Organization ! &gt;
不要过度推断，记住细节问体现了什么，落实到组织上</li>
<li>Inference</li>
</ul></li>
</ol>
<p>做题原则！！</p>
<h2 id="分以上">1.2 23分以上</h2>
<ol type="1">
<li>六大误区：</li>
</ol>
<ul>
<li>词汇量大，分就高</li>
<li>tpo刷2次</li>
<li>真实题难</li>
<li>笔记</li>
<li>走神</li>
<li>多练难</li>
</ul>
<ol start="2" type="1">
<li>词汇 5000 80+ 6500 90+ 8000 100+ 13000 110+</li>
</ol>
<p>0.7 基础 0.2 专业 0.1 超托福, 放弃！</p>
<p>基础词汇1s反映不过来，不合格，听不准</p>
<p>语速 190~210 单词反映力 1. revolvtion? 天文学? v. 中乱 2. deceive
欺骗 3. not seriously? 未必，否定 4. incoperate 吸收，纳入,合作 5. suite
! sw:t 套房，套件</p>
<p>怎么背? 1. 重复！多次 2. 时差, 练抢答 &gt; 记录? 3. 音差, 跟读</p>
<blockquote>
<p>出声，快速抢答; 早晚40min tpo提高的手段 每道题做到很好,
难度没有绝对之分</p>
</blockquote>
<p>tpo哪三个学科出现频率最高？ &gt; 生物，艺术，天文宇宙</p>
<p>背书的专业词汇</p>
<p>记笔记 &gt; 听，优先值是是否听懂!</p>
<p>2h录音，分开，一次不超过40min</p>
<h2 id="听力推荐">1.3 听力推荐</h2>
<ol type="1">
<li>Step by Step 3000: 2或4 &gt; 题材多，题型多，口音多； 细节把握</li>
<li>Listen to this 经典 !!! &gt; 题材多，题型多，练英音</li>
<li>新概念2（语法）， 3（词汇） &gt; 方便自学</li>
<li>空中英语教室，中级别 泛听</li>
</ol>
<p>听写吗? &gt; 只注意局部，而忘记了整体 &gt; 没有用！</p>
<p>为什么第一遍听不懂，第二遍可以？ &gt; 精听不够，没办法梳理大意</p>
<p>tpo听力词汇，词频词汇！ &gt; 精准备考</p>
<p>语法不好怎么办？ &gt; 无敌英语高中语法 1~63, 1~128</p>
<p>校园生活 &gt; That's why I chose Yale? !
https://www.youtube.com/watch?v=tGn3-RW8Ajk</p>
<ul>
<li>debate： a serious discussion of a subject in which many people take
part &gt; Education is the current focus of public debate.</li>
<li>matriculate: to be formally admited to study at a university or
college &gt; where to matriculate</li>
<li>hail
<ul>
<li><ol start="22" type="a">
<li>(formal) to call someone in order to attract their attention &gt;
shall we hail a taxi</li>
</ol></li>
<li><ol start="14" type="a">
<li>small, hard balls of ice that fall from the sky like rain. &gt; a
hail of bullets</li>
</ol></li>
</ul></li>
<li>quintessential: being the most typical example or most important
part of something. &gt; Sheep's milk cheese is the quintessential
Corsican cheese.</li>
<li>residential reside
<ol type="1">
<li>a residential road, area. has only private houses, not ofices and
factories.</li>
<li>a residential job, position,course, etc, is one for which you live
at the same place where you work or study</li>
<li>relating to where you live or have lived. &gt; It was not safe to
locate the chemicals factory in a residential area.</li>
</ol></li>
<li>liberal ~ arts 文科
<ol type="1">
<li>society: respecting and allowing many different types or beliefs or
behaviour &gt; a liberal society.</li>
<li>politics: believing in or allowing more personal freedom and
deveplopment towards a fairer sharing of wealth and power within
society</li>
<li>generous: giving or given in generous way</li>
<li>not exact: without attention to or interest in detail</li>
</ol></li>
<li>thrive: to grow, to develop, or be successful 好的，成长的趋势 &gt;
she seems to thrive on stress</li>
<li>thread
<ul>
<li>fibre: (a length of )a very thin fibre线 &gt; losse threads</li>
<li>connection: main thinking way</li>
<li><ol start="22" type="a">
<li>put something long and thin such as string or through a narraow ole
or into a small space 穿线， 除毛</li>
</ol></li>
</ul></li>
<li>Shakespeare Studies and Pre-Med<br />
</li>
<li>common ground 共同点</li>
<li>grill: 烤架，烧烤店</li>
<li>fill: v. 填充，充满; n. 需要的量</li>
<li>buttery: n. 饮食店; 涂了黄油的土豆</li>
<li>right down to: 就连...也包括在内</li>
<li>work out: 锻炼身体</li>
<li>below: 在较低处，在什么之下，小于</li>
<li>rehearsal: 排练，彩排</li>
<li>hone: 使...变锋利；磨炼 hone the skill</li>
<li>chill: to become cold 冷却，使变冷</li>
<li>dorms 宿舍</li>
<li>suite 套房</li>
<li>sheets 床单</li>
<li>couch 沙发，以某种方式表达</li>
<li>lava熔岩 lamp灯</li>
<li>awhile=for a short time. &gt; stay awhile</li>
<li>master
<ul>
<li><ol start="14" type="a">
<li>主人; 船长; 大师; 杰出画家; 男中学教师; 少爷： 原版</li>
</ol></li>
<li><ol start="22" type="a">
<li>精通，掌握</li>
</ol></li>
<li><ol type="a">
<li>技术娴熟的</li>
</ol></li>
</ul></li>
<li>dean
<ul>
<li><ol start="14" type="a">
<li>系主任；元老；牧师</li>
</ol></li>
</ul></li>
<li>suffice足够 to be enough</li>
<li>Broadway （纽约）百老汇剧场，音乐剧</li>
<li>subsidize: to pay part of the cost of something</li>
<li>harmonize: 为什么配和声，使协调</li>
<li>cheer for 欢呼，喝彩；鼓舞，振奋</li>
<li>prevail v. 占优势，流行，盛行 &gt; 7.09</li>
</ul>
<p>天文学 &gt; Journey to the Edge of the Universe, 2遍 !
https://www.voicetube.com/videos/17931 多做TPO, 关键在细抠</p>
<h2 id="精听">2.1 精听</h2>
<ol type="1">
<li>听+做题</li>
<li>努力听清，逐句，保留不会的地方</li>
<li>对照文本，搞懂一切</li>
<li>复听</li>
<li>对照文本，看忙去</li>
<li>听读训练</li>
</ol>
<p>注意！ 3天之后请复听！ &gt; it' mounthful: something is hard to
explain. TPO!!!</p>
<p>注意不要忽略简单的俗语，要真正弄懂一句话 TPO23 C2: And my students.
they bring so much insight to the table that it's easy to forget who the
professor is. &gt; 注意这里table是引申为上课的教室的意思</p>
<p>能看懂却不能有画面感的句子！！</p>
<p>lec1: 2.5h~3h. 200h足够</p>
<h2 id="语音现象">2.2 语音现象</h2>
<p>it so produce offers again? 1. but sometimes the produce we offer is
organically grown. &gt; produce ? organically grown? &gt; produce, n.
stress pronuncation, 农产品 &gt;
记单词时要认真地记住各种常见单词的含义</p>
<p>content, 由发音 去记单词</p>
<p>todo: 变词音，变词性，变词义的单词</p>
<p>lecture by next summer 2. Ok, I'm going to begin this lecture by
giving you your next assignment. &gt; by giving ????
从单词的具体的音去反应，从句子的结构去反应 &gt; giving you your
反应不过来 &gt; ! p + k + 元 = b/d/g
因为有元音，所以需要把气息给收住</p>
<p>it's my issue to see esos i think 3. It's meant to show a sense of
isolation I think. &gt; 语速, 看句子， meant ? &gt; a sense of
辅元音连读未听出来 &gt; of 弱化， 弱化的本质实际上就是嘴型变小 &gt;
美音和英音， 美音meant !!!!</p>
]]></content>
      <categories>
        <category>english</category>
        <category>TOEFL</category>
        <category>listening</category>
      </categories>
      <tags>
        <tag>english</tag>
        <tag>TOEFL</tag>
        <tag>listening</tag>
      </tags>
  </entry>
  <entry>
    <title>TOEFL word</title>
    <url>/2019/TOEFL-word-d079bf0f3ef9/</url>
    <content><![CDATA[<h2 id="词汇发音">1. 词汇发音</h2>
<p>如何发重音 https://zhuanlan.zhihu.com/p/48251386</p>
<h2 id="词汇记忆">2. 词汇记忆</h2>
<h3 id="问题">2.1. 问题</h3>
<p>单词记忆的频率问题 单词记忆的手段问题： 1. 单词书：不符合大脑记忆方式
2. 英语教材： 单一的媒介</p>
<p>单词记忆的心理问题：广为流传的50%，60%理论，信心</p>
<h3 id="解决办法">2.2. 解决办法</h3>
<p>物质层面 精神层面 &gt;
一开始造词时，词语的意思往往都是物质层面的意思。所以需要我们进行扩展，引申和联想到精神层面的意思去
例子: constraction</p>
<p>频率——战术：多量多次记忆，等差数列记忆法 单词什么时候复习？
隔等差数列的天数后进行复习（0,1,3,4,5) 字典：韦式字典 参考书选定一本</p>
<p>战术——重复+一次性记忆特征足够明显的单词+多媒体爆炸</p>
<blockquote>
<p>di=not, away digress 物质上离开； 精神上涣散 词根记忆法 典故法：
narcissus 自恋，水仙话 分类法，词以类记</p>
</blockquote>
<h2 id="单词分类">3. 单词分类</h2>
<blockquote>
<p>必须认识到单词具有以下几种情况： 1.
可拆分单词，很容易地可以通过词根、词缀来判断出单词的意思 2.
不可拆分单词，很难拆分，按照死记硬背的方法</p>
</blockquote>
<h2 id="按规则出牌--词根">4. 按规则出牌- 词根</h2>
<h3 id="学术生活类">4.1 学术生活类</h3>
<ul>
<li>例子
<ul>
<li>meter
<ul>
<li>measure: 测量 &gt; optometer; //opt表示光 视力计 optometrist 验光师
//ist表示人 dromometer // dromo速度 速度计 odometer // odo距离,里程
里程表 telemeter // tele距离 测距计 densimeter 密度集 altimeter // alt
&lt;- tall(词源法) 高度计 thermometer // ther温度 温度计
？？？中间o是干什么的？元音起到的作用：元音连字符，为了使单词读起来是连贯的；可有可无
barometer //baro阻止 气压计</li>
<li>dimension 尺度 &gt; kilometer // kil=mil 千; 千米 hectometer 百米
100 // hect=cent decameter 十米 //deca
Decemeber十二月，农历每年3月为第一个月 decimeter 分米 // deci centimeter
厘米 1/100 century millimeter // 毫米 million</li>
<li>geometry 几何学 &gt; 几何学引入测量 perimeter // re=repeat,back;
di,dis=no,away,apart; per=thoroughly,贬义（为后面的词根产生贬义色彩）;
全部测量 周长 diameter // dia穿过去 直径 dialog 对话 /di'amter/</li>
</ul></li>
<li>bar 物质层面——杆，精神层面——阻止，阻拦 &gt; baritone // tone声音
男中音 barrister //er表示对应的人，阻止坏事情发生的人 律师，诉讼律师
embarrassed 尴尬的</li>
</ul></li>
<li>学术类词根
<ul>
<li>sci=to know
<ul>
<li>sci = to know: conscious // con+sci 有意识的 deliberate, intentional
&gt; subconscious 潜意识的 nescient 无知的 // ne-no omniscient 博识的 //
omn=over 全部知道</li>
<li>science = knowledge: conscientious //有良心和道德的 diligently 1.
sense of moral goodness; 2. meticulous, careful; &gt; conscience 良心
prescience 预知 pseudoscience 伪科学 // pseudo 假的，错误的</li>
</ul></li>
<li>log=Greek word"logos"
<ul>
<li>word/speech-&gt; logue &gt; eulogy //eu优 说好话 赞词 monologue 独白
neologism // neu new新 新语</li>
<li>reason/idea-&gt; logic &gt; anthropology // anthr人 人类学 sociology
社会学 geneology基因学 theology // the神， 神学 psychology //psy心理
心理学 chronology 年代学 physiology // phy身体的 生理学 histology 组织学
neurolog y 神经学 embryology 胚胎学</li>
</ul></li>
<li>nomy &gt; economy - eco: house, dwelling, place, habitation:
village, villa, weik -&gt; eko -&gt; eco //w不发音，两个元音去掉 &gt;
ego egocentric 以自我为中心 egoist 自私自利的人 // ego 自己 ecosysytem,
ecology //eco 房子 - nomy: numismatics(coin, currency 货币，现金) //
matics表示学科 numi 表示货币 &gt; sanctioned by custom, usage and law;
managed; 规则，传统，法律，管理，一个学科的知识 a field of knowledge -
物质层面 具体： 规则，学科 &gt; agronomy 农学 // agriculture 农业 agr
表示农业 astronomy 天文学 // astr star - 精神层面 抽象： 管理，法律 &gt;
autonomy 自治 // auto ? 自动的，也可以引申为自己的 autonomous a. &gt;
任何词的记忆需要记住两个意思 abstract 摘要， 抽象 absent
缺席的，心不在焉的 surprise 突袭， 吃惊<br />
dismiss 解散，不屑一顾 construction 构造， 主观解释 susceptible
易感染的， 易影响的</li>
<li>ics : logic 学科 &gt; physics物理学 metaphysics形而上学
dynamics动力学 eugenics优生学 linguistics语言学 aeronautics航空学
optics光学 phonetics语音学 politics政治学 statistics统计学
aesthetics美学 homiletics同性恋学 didactics教学法学 pediatrics小儿科学
athletics竞技学 genetics遗传学 logistics物流学（logic 逻辑学）
dietetics营养学 mechanics力学</li>
</ul></li>
<li>数学
<ul>
<li>简介
<ul>
<li>mathematics //注意这里的e不发音 &gt;
读音时可以考虑不发音啊，还有直接通过汉语拼音来读不也是一样的吗</li>
</ul></li>
<li>algebra代数学（等式右边的东西可以移动到左边去，等式性质不变）,
arithmetric // ars/art+metrica(to measure) &gt; artithmetric 算数
algebra + arithmetric = algrorithm</li>
<li>meter</li>
<li>equ: equal, even相等的，偶数 balance &gt; adequate //ad加强+equ
充分的，充足的 equate // ate使等于 equal equation //等式 equator赤道
equivalent// equ + val=value 等价的 equilibrium 平衡状态 inequity
//不平等的 equine 似马的，马的 equitation 骑术 equivocate
支吾///equ+voc=voice<br />
equanimity 沉着，镇静 // equ+animal(活的东西) 稳定的活的东西</li>
<li>par： equal, even pair&lt;-paar 变成词根去掉多余的音节 &gt; parity
平价，相等 imparity // im否定，进入，加强 不平等 compare 比较 comparison
// ! 注意是ison 比较 nonpareil // 不平的，无法匹及的，无与伦比的 parable
可以比较的 reparable 可以修理的</li>
<li>numer=number &gt; numerable 很多的，可数的 innumerable
很多的，不可数的 numerous 很多的，注意ous跟able修饰词的方法不同
enumerate //e=out, 列举，枚举 <code>Numerous studies have shown that
there is a correlation between career and financial sucess and powerful
precise vocabulary.</code></li>
</ul></li>
<li>物理
<ul>
<li>力
<ul>
<li>tract !!! 拉力=draw &gt; traction 牵引力 tractor 拖拉机 tractable
可以拉的，(精神)可管教的 attract // a表示强调，后面词根首字母双写 吸引
abstract （物质）摘要，抽象 contract // con+tract一块拉，合约，缩短
detract // de=down divert=转向(物质）； diminish=减少，贬损（精神）
distracted // dis: 低级别单词no, 高级别单词away; divert=分散，转移
(物质) puzzle=困惑（精神） extract 要求，拔出 protract 延长 retract
取消，缩回 subtract 减少</li>
<li>grav, griev=to dig, heavy; carve雕刻 c-&gt;g //
词源，所以也可以表示沉重的，坟墓等意思 &gt; gravity 重力 gravitate 加重
aggravate 使严重 grave重 grief 痛苦 grievous 痛苦的 aggrieve 使痛苦
grievance 不平，委屈 grave 1. 沉重的；阴沉的 2. 坟墓 3. 雕刻
cradle-to-grave cradle摇篮，人出生的 一生一世，时间长久 gravid(pregnant)
怀孕的 -&gt;gravida 孕妇</li>
<li>pel, puls=drive, push, shake, swing &gt; expel 驱逐 impel 推进
dispel 消散 repel 击退 propel 推进，驱使 compel 强迫 appellant
上诉的，上诉人 //a+pp ant人 expulse 开出 impulse 冲动 repulse
拒绝，反驳，击退 complusion 强迫 propulsion 推进 pulse 脉搏，脉冲
pulsate 有规律的跳动</li>
<li>mob move; disorderly part of the population,rabble乌合之众 &gt;
mobile 可移动的 automobile 汽车//bile弱化 demobilize 复员</li>
<li>mot
<ul>
<li>move &gt; motion 运动 locomotion 移动 motive 动机 motivation 动机
remote 遥远 commotion 骚动，暴乱 // con+mot一块动 promote 促进，促销
demote 降级，降职 emotion 感情//e=out momentum 动力，要素 moment
瞬间，片刻的</li>
<li>a witty saying //witty 诙谐的 &gt; motto 格言 motif 主题</li>
</ul></li>
<li>celer=quick, speed, swift c=k, kel=to drive,set in swift
motion(gallop) kelt凯尔特人，狂热的战争爱好者 &gt; celerity 速度
accelerate 加速 decelerate</li>
</ul></li>
<li>热
<ul>
<li>therm=heat, ghwerm, warm &gt; thermal thrmos 热水瓶 thermometer
温度计 diathermal //dia穿过 透热的 isotherm //iso相同 等温线 endothermic
吸热的，恒温动物 exothermic 放热的</li>
<li>calori=heat &gt; calorie 卡路里 calorify 加热 calorifacient 发热的
caldron 大锅 coddles 溺爱 scald 烫伤 //s对意思影响不大,slow chafe 恼火
nonchalance 冷淡</li>
<li>frig,friger=cold &gt; frigid 冷的，冷淡的 refrigerator 冰箱
refrigerate 让...变冷的 refrigerant 制冷的，冷却剂 frost 霜，冻</li>
<li>ferv!! = boil 沸、热 &lt;- brew -&gt; frew -&gt;ferv &gt; fervid
(sym: impassioned) 热心的 perfervid 非常热心的 fervent 炽热的 fervor
热情 fervescent:growing hot defervesce 退热 effervesce 冒泡，兴奋</li>
<li>zeal： ardor &gt; zeal 热情，热心 zealous热心的 zealot 狂热者
jealous 嫉妒的，质疑的</li>
</ul></li>
<li>声
<ul>
<li>son=sound &gt; sonic 音速的 supersonic 超音速的 sony 索尼 dissonance
不和谐 // 有着不的声音 consonance 调和 resonance 回声 sonata 奏鸣去
sonnet 十四行</li>
<li>voc, vok!! = call, voice &gt; vocal(vocalist) 有声的（声乐家）
vocation （vacation假期）/ avocation 职业，号召/副业 vocabulary 词汇
vociferous 大声叫的，喊叫的 //ferous带有什么的 advocate advocator 提倡
// ad=to, voc=voice convoke convocation召集 revoke 废除，取消 revocable
irrevocable evoke 唤起 vouch担保，证明 equivoke 双关语 wordplay
equivocate 使模糊，欺骗lie invoke(request)--invocatory provoke
激怒，煽动 provocative 煽动的</li>
<li>audi,audit=hear &gt; audit 审计，旁听 audible 听得见的 audience
听众的 audition 试听，听</li>
<li>tone=sound tongue tungue &gt; monotonous 单调的，无音调的 baritone
男中音 tenet:a principle ,belief,or doctrine generally, hold to be
true原则</li>
<li>phony=fame 名词后缀，常用来形容声音怎么样 &gt; euphony
悦耳之声//eu好的 cacophony caco: kakos bad,evil symphony</li>
<li>plod 砰地一声 大声，喝彩 &gt; applaud explode implode
沉重的脚步</li>
<li>verber=beat,vibrate振动，wipe擦，wag摇 &gt; reverberatem
vervain</li>
<li>echo=sound &gt; anechoic 没有回声的</li>
</ul></li>
<li>光
<ul>
<li>lumin=light lumen光通量单位 启发，单指光 &gt; illuminate 阐明,
luminary 知识渊博的人, luminous 发光的 luminosity发光度
luminescent发光度</li>
<li>lustr,luc=light lust:desire,wish,longing &gt; lustre 光彩 lustrous
lackluster illustrate 说明 illustrious 接触的 lucid清晰 elucidate 阐明
translucent 半透明的</li>
<li>light &gt; lighter lightproof enlighten twilight</li>
<li>radi=ray, radius-&gt; root &gt; radio, radioactive radiat; radical,
radicle, radix</li>
<li>cand=white, glow 烛光 &gt; candle, candid candescent incendiary
incense</li>
<li>flect,flex=bend弯曲 &gt; reflect, reflract \frac=break; deflex</li>
<li>sol=sun, sole &gt; solor太阳的 solarize 晒 solace 安慰 console;
sole, solitary 孤独的</li>
<li>sight=vision &gt; sightly=attractive long-sighted insight
oversight</li>
<li>splend=be right,shine, gleam, glisten &gt; splendid, splendor</li>
<li>vis,vid=to see, to know, wise; separate &gt; visible vision
visualize supervise envy provide; divide, dividend devise</li>
<li>opt,opto=sight eye oqw &gt; optic, optometrist synopsis optics</li>
</ul></li>
<li>电
<ul>
<li>electro=electric, electricity &gt; electron, hydroelectric
electrocution<br />
-on表示微粒, neutron 中子 photon 光子 proton 质子 radion 放射微粒</li>
<li>tele=distant &gt; telephone, telegraph, telescope, telemeter</li>
<li>Z 闪电 快 &gt; zigzag zag zenith天顶 zephyr西风 zipppy qucikly,
strikingly fresh,lively zip=move rapidly, 拉链 zombie omb 降起物 tomb
坟墓 bomb 炸弹 comb 梳子 womb梳子</li>
</ul></li>
</ul></li>
<li>化学
<ul>
<li>组成性质
<ul>
<li>pos, posit = put, pause ??? &gt; pose position purpose positive
opposite composite复合 composure沉着 discompose分解
<ul>
<li>down-de depose: 1. dethrone; 2. put down, deposit沉积 3.
testify</li>
<li>apart-dis dispose: 1. put in place放置 2. give a tendency,being
leaning倚 toward</li>
<li>apposite ap+pos 一再； 特别地</li>
<li>repose: 1.repose 安置，依靠; 2. repose(pause) 休息，睡眠</li>
</ul></li>
<li>pon,pound=put, pause ? &gt; component 成分 compound 混合物 opponent
对手 propone 提议 propone 提议</li>
<li>part, port=part &gt; particle 例子 partisan partisanship biparisan
divide portion apportion proportion disproportion depart department
apartment partner partial</li>
<li>mini &gt; minimal , minimum, minister部长 administer管理 minion
minor</li>
<li>micro &gt; microsoft microscope microbiology microfilm</li>
<li>macro 宏观 &gt; macroword macroclimate macroscale</li>
<li>acid, acri, acu, acrid = sour, sharp 急剧的，尖头 &gt; acid,
acidity, acidulous 带酸味的，尖刻的 acidify subacid acrid, acrimony
acerbic</li>
<li>ac: acid =angle 尖 ? &gt; acute严重的 acuity敏锐 acumen acme
acupuncture acrophobia acronym acrobat</li>
<li>oxy, oxi=氧 &gt; paroxysm oxy-ac=sharp oxygen sharp, generate,
acidic dioxide di-2 dilemma diplomat diplomacy dia-穿过 diagonal
diabetes egg- 蛋， 刺激</li>
<li>sal = salt &gt; salty 咸的 salify 使成盐 saline 含盐的 \ -line
salinity 含盐量 salad 色拉，用盐做的食品 saltern 盐田<br />
salary 工资 salient 显著的 ? insul 岛屿 = in + sal insul, isol,
isl=island, sole insular</li>
<li>tox=poison &gt; toxin 毒素 toxic 有毒的 toxication中毒
toxicology毒物学 intoxicate醉人 intoxicant 醉人的 detoxify 解毒
toxophily 射箭</li>
</ul></li>
<li>结构
<ul>
<li>struct= to build, pile堆, assemble to spread, to stretch out,
strew散播 &gt; structure destructible construct destruct毁坏 reconstruct
instruct 交道 obstruct 妨碍 instrument 工具 substructure 下部结构
supstructure 上部结构</li>
<li>mod=mode, manner, measure &gt; modest 谦虚 modern 现代化 modify修改
commode 梳妆台<br />
acommodate: 1. provide 2. make fit 3. give consideration to</li>
<li>form=shape &gt; formal 形式上的 formalism 形式主义 //ism什么主义的
formality 礼仪，理解 formation形成，构成 formala 公式 formalate
用公式表达 confom 符合 deform 变形 inform通知 twiformed 有两种形式的
reform 改革 transform 转变 perform 表现</li>
<li>cruc, crus, crux=cross 十字形，交叉 &gt; crucial 关键的 crux
难点，关键（十字路口-&gt; 关键)<br />
excruciate 拷打 cruise 巡航，徘徊 crucify 钉在十字架上，折磨 crusade
改革运动</li>
</ul></li>
<li>变化规律
<ul>
<li>norm=rule, norm &gt; norm 标准 normal 正常的 abnormal 异常的
enormous 巨大的 subnormal 低于正常的 transnormal 超出一般的
normalization 标准化 formalism 形式主义 formality 礼仪，礼节</li>
<li>solve 宏观变化
<ul>
<li>solu, solv, solute=loosen, disperse分散, dissipate消散 &gt; so=sed,
separate=apart solu lu=lose absolute 绝对的 absolutism absolve 免除
absolution赦免 exculpate 赦免 solvable 可以解决 solvent
溶剂，有偿付能力的 solvency 溶解力，偿付能力</li>
</ul></li>
<li>lut, lav, luv &gt; dilute - di divide, separate &lt;- bi - lute
lut,lav,luv=lave洗澡? - wave - wash &gt; dilute 稀释 dilution lavish
浪费的，奢侈的，滥用 lavatory 厕所，浴室</li>
<li>rupt=break, rupture &gt; abrupt 猝 erupt corrupt interrupt 大段
bankrupt 银行破产 disrupt 破坏 irrupt 冲入</li>
<li>spers=scatter散开 sparse稀少的 &gt; disperse 分散 asperse
散布坏的东西 intersperse 点缀，散布</li>
<li>lect,lig-- 微观变换 lect,lig=chosse, gather lect =log &gt; elect
collect select intelligence 智力 neglect 忽视 recollect 回想 legible
清晰的，易读的 eligible 合格的 elegant 优雅的 elite 精华，精英</li>
<li>brev, bridge=make short &gt; abreviate 缩写 brief=summary abridge
删节，精简</li>
<li>vers, vert=turn-over 周转 versus &gt; adverse 不利的 adversity 灾难
averse 反对的 aversion厌恶 avert 转移 obverse 正面，正面的 versatile
多才多艺的 version convert 变换 controvert:deny the truth of something
invert 倒置，点到 revert还原 diverse 多种</li>
</ul></li>
</ul></li>
<li>天文
<ul>
<li>astro, aster=star &gt; astronomy astrospace astronaut cosmonaut
tailonaut astrophysics disaster灾难 disastrous catastrophe灾难
<ul>
<li>solor system
<ul>
<li>Mercury 水星 商神、辩神、狡猾神、其他神的信史</li>
<li>Venus 金星 美与爱神</li>
<li>Earth 地球 土神</li>
<li>Mars 火星 战神</li>
<li>Jupiter 木星 主神</li>
<li>Saturn 土星 农业神</li>
<li>Uranus 天王星 最早神</li>
<li>Nepture 海王星 海神</li>
<li>Pluto 冥王星 地府之神</li>
</ul></li>
</ul></li>
<li>aer,aero,aeri=air, i/e互换 &gt; aerate 通气 aerology 气象学 aerial
天线 aerosphere大气 aerospace 航天</li>
<li>stell=star 星星 &gt; stellar 恒星 interstellar 星际穿越 constellate
星座</li>
<li>atory: observatory 表示场所或者地点 &gt; laboratory conservatory
lavatory purge 清洗，洗涤 purity 纯净 emulsion 乳化 promulgate
发布，公布</li>
</ul></li>
<li>地质地理
<ul>
<li>Chaos-&gt;Gaea-+&gt;Uranus-&gt;Titans(Cronus,chron慢性的
chronic),Cyclopes(cynosure, lope),Giants -+Chronos-&gt;
Furies(Fury),Typhon, Zeus</li>
<li>terr
<ul>
<li>piece of earth, ground and land;ters;to dry,opposed to sed; &gt;
terrain 地形 terrace 梯田 territory 淋雨</li>
<li>tres, to treamble 抖 &gt; terrible, terrify, terrific, terriorist
&gt; inter=in+terr; disinter=dis+inter挖掘</li>
</ul></li>
<li>tele: far/distant &gt; telegraph, telephone, telemeter,
telescope</li>
<li>kinds
<ul>
<li>Tectonic/Structures
<ul>
<li>Ordovician寒武纪， Jurassic 侏罗纪</li>
<li>Convergent boundary/ Divergent boundary/ Transform boundary</li>
<li>fold; fault; crack, rift;</li>
<li>cataclysm &gt; cata = kakos: bad,down; kailo=beauty,call; &gt;
cacophony, cacography, catalog, catastrophe, calligraphy
<ul>
<li>earthquake &gt; seismology,&lt;- seismic=shake, magnitude,
epicenter(epi=upon,among) Tidal wave tsunaml</li>
<li>typhoon</li>
<li>sandstorm</li>
<li>flood</li>
<li>tornade torn=trun</li>
<li>snowstorm</li>
<li>landslide</li>
<li>cyclone</li>
<li>hailstorm hail</li>
<li>valcano</li>
<li>hurricane</li>
<li>tsunami</li>
<li>drought</li>
<li>lightning/thunder</li>
<li>mud-rock flow</li>
</ul></li>
</ul></li>
<li>Lithology 岩石学
<ul>
<li>igneous rock: ign希腊语 fire, scarifice fire &gt; ignite, ignitable,
ignition grainite 花岗岩 &lt;- grain 谷物 geyser 喷泉 gush 喷出
<ul>
<li>components
<ul>
<li>Valcan 火神, valcano-eruption</li>
<li>magma chamber 岩浆</li>
<li>crater 火山口</li>
<li>lava 熔岩</li>
<li>ash cloud/ volcanic ash 火山灰</li>
</ul></li>
<li>kinds
<ul>
<li>active volcano</li>
<li>dormant volcano // dorm=to sleep dormitory</li>
<li>extinct volcano</li>
</ul></li>
</ul></li>
<li>sedimentary rock 沉积岩 shale 页岩</li>
<li>metamorphic rock 变质岩 marble 大理石</li>
</ul></li>
<li>Palenotology： fossil</li>
<li>Remote Sensing</li>
<li>Mineralogy 矿物学 ore, quartz, aluminum</li>
</ul></li>
<li>Earth's sphere structure
<ul>
<li>outer sphere
<ul>
<li>atmosphere air</li>
<li>hydrosphere water</li>
<li>biosphere living things</li>
</ul></li>
<li>interior sphere
<ul>
<li>crust 地壳</li>
<li>matle 地幔</li>
<li>outer core/ inner core</li>
</ul></li>
</ul></li>
<li>地质作用
<ul>
<li>external process: weathering风化, erosion侵蚀,
sendimentation&lt;-sand风化</li>
<li>internal process: metamorphic变质变形 mor; magmatic岩浆作用;
deformation 变形破坏作用</li>
</ul></li>
</ul></li>
<li>生物
<ul>
<li>biology bio-life bi-对称的，两条腿，两条胳膊 &gt; biology biosphere
biochemistry agrobiology biocide vi- li- 活的 bo 植物学</li>
<li>herb &gt; herbivorous 食草的 vor=to eat herbaceous 草本植物的</li>
<li>Flora 花神 flor, flour=flower, florid 如花的 &gt; floral 有花的
flora 植物群 fauna 动物群 floret 小花 flourish 繁荣兴旺 effloresce 开花
defloration 摘花，玷污 noctiflorous 夜间开花的</li>
<li>grain 粮食 acre亩 land c=g agr,agri,agro=field, land &gt; agrarian
荼毒的 agriculture 农业，农学 agronomy 农艺学</li>
</ul></li>
</ul>
<h3 id="社会科学类-leg-script">4.3 社会科学类 leg, script</h3>
<ul>
<li>例子
<ul>
<li>leg 物理层面——腿，精神层面——法律 &gt; legal 合法的 illegal //
i表示否定+双鞋 legislate // 使合法 illegitimate 违法的，私生的 relegate
降级，流放 //repeat, back! delegate 代表 //de:down</li>
<li>script 写 &gt; manuscript 手稿 //man男人，手 scripture 经文，原件 //
ture名词后缀 ascribe 归功于 // a强调 inscribe 记下 circumscribe 限制 //
circum圈 conscribe 强行征召 // con=together describe 描写 prescribe
规定，开药 //pre=before n. prescription 药方 subscribe 捐款，订阅
transcribe 抄写，转录 // transcript 成绩单</li>
</ul></li>
<li>历史
<ul>
<li>when, where, who, what 历史研究的是什么时候，谁在哪里做了一件事</li>
<li>chron 表示时间 Cronus 时间之神 &gt; chronic 慢性的 Cronus 时间之神
synchronize 同步，同时的</li>
<li>annual, ann, eon=year 表示时间 &gt; annual 每年的 anniversary 周年
biannual 每年两次 annuity 养老金</li>
<li>loc = location 表示地点 &gt; locate, locomotion ,dislocate
使混乱</li>
<li>stat, stit, stitut=set up,place &gt; stature (物)身材，身高
(精神)精神高度 statute 法令，条例 constitute 注册呢个，建成 constitution
宪法，章程 reconstitute 重新组成 institute 创立，学院，规定 substitute
替代 restitute 偿还 destitute 贫困，频繁 prostitute 妓女 superstition
迷信</li>
<li>grap=write, draw,scratch, picture &gt; photography telegraph电报
topography地形 geography autography monigraphy 争论 lexicography=lect
graphy 词典编著 stenography //steno narrow 速记 dictgraphy 助听器
demography 人口统计学 epigraphy 铭文 calligraphy 书法 bibligraphy
参考书目</li>
<li>gram=write letter of the alphabet small weight 克 &gt; program 项目
grammer 语法 diagram 图表，图解 epigram 格言，警句</li>
<li>vict,vinc 克服，战胜 fight &gt; victory 胜利 convict 定罪 conviction
evict 驱逐 expel eviction invincible 不能征服的，无敌的 convince 使确信
convincing</li>
<li>vol, volv, volt = roll, turn, twist &gt; voluble 有才的 volubility
健谈 revolution 革命 revolve 旋转 evolve 进展 evolution involve 限于
involvement convolve 盘旋 volume 旋转，卷，册 voluminous 多产的</li>
</ul></li>
<li>政治
<ul>
<li>arch=ruler, chief首席,government &gt; archy 拱形的 architect 建筑
architecture 建筑学 anarchy 无政府状态 anarchic 无政府的 monarch 君王 //
mona单一 archives 档案 patriarch 父权制 matriarch 母权统治</li>
<li>tect=texture;build,do,pie up ?</li>
<li>democracy
<ul>
<li>demos n. 古希腊人民 people &gt; epidemic 流行的 pandemic 大范围的
endemic 地方的 demagogue 煽动者 demography 统计学家</li>
<li>cracy=rule, crat=ruler &gt; democracy democrat 民主 autocracy
autocrat 民主 bureacucarcy 官僚 plutocracy 财阀政治 theocracy 神学
monocarcy 独裁政治 mobcracy 暴政</li>
</ul></li>
<li>popul, publ=people &gt; population populous 人口稠密的 popularize
普及 depopulate 减少人口 copulation 交配 public publish publication
publicity 出版</li>
<li>fus, fug=flee, run away ? 使...逃离的感觉 &gt; refugee 难民 fugitive
逃亡的 refuge 避难所 centrifugal 离心的 fugacious 转瞬即是 insectifuge
驱虫剂 subterfuge 托词 lucifuge 避光</li>
<li>fun=pour 流，泻 &gt; refuse refusal confuse confusion diffuse
diffusion 扩散 effuse effusion 流出 infuse infusion 灌输 profuse
profusion 丰富 suffuse 充满 transfuse 注入 refute 驳斥</li>
<li>mon, monit=mind; warn, advice; &gt; monument 让你思考的人 monitor
monition admoish //ad=together premonish 预先警告 summon 号召 summon
传票</li>
<li>muni, mun=public &gt; community service 志愿者 communal 公共的
communize 公邮话 municipal 市政的 municipality 市政当局 immunity 免疫
communicate = communicative 沟通 munificent genorosity and liborality
宽宏大量的，慷慨的</li>
<li>polis 古希腊城邦, polic, polit=govern ,state, city &gt; police
policy politics politician 政治学的 cosmpolis 国际化都市 metropolis 计划
metro 地铁 underground subway</li>
<li>range? rank ring &gt; arrange arrangement rearrange disarragne
misarrange 安排错误 derange 使错乱</li>
<li>serve &gt; conserve 节约使用，保护某物 strength/
health/energy/water/resources preserve 保护原样，比conserve正式 reserve
保存，留存</li>
<li>sequ, sent =follow &gt; second-&gt;sec-&gt; sequ sequence 次序
consequence 结果 subsequence 顺序 sequential 连续的 sequacious 盲从的
obsequious 奉承的 consecutive 连续的 consecution 连贯</li>
<li>sue 跟随，恐告 &gt; consue 继而发生 pursue 追赶 prosecute =to follow
till the end; perform 实行，起诉</li>
<li>urb=city &gt; urban urbane 优雅的 exuraban 城市外面 suburb 郊区
suburbanite 郊区人民</li>
</ul></li>
<li>人类学
<ul>
<li>男女相关
<ul>
<li>anthrop human anthr,andry,man &gt; op optic eye,face polyandry
一夫多妻的 polygamy 一夫多妻制 polygyny 一夫多妻制 anthropology 人类学
paleoanthropology 古人类学 anthropophagus 人体解剖学 anthroposociology
人类社会学</li>
<li>gyn, gynec, gamy =queen, woman &gt; gynecology 妇科医生 gynarchy
女人政治 androgyny 半男半女 monogyny 一妻制 monandry 一夫制 monogamy
一夫一妻制 misogynist 厌恶女人的人 philogynist 喜爱女人的人</li>
<li>patri=father &gt; patriarch 家长，创办者 patriot 爱国者 patriarchy
家长同志 patriotism 爱国心 patron 赞助人 patrilineal society 父系社会
patronize 资助 expatriate 外籍 banish放逐 exile 流亡 patronge 保护</li>
<li>matri, matr-= mother &gt; maternal 母亲的 matriarch 女家长
matriarchy 女家长制 metropolis 首都 matrix 子宫，矩阵 matron
主妇，老妇人</li>
</ul></li>
<li>情感
<ul>
<li>amor,amot,am=love &gt; amour 恋爱的， 情人的，奸情 amatory 恋爱的
amorous 多情的 paramour 情妇，情夫 amateur 业余爱好者 amicable 和善的
amiable 亲切的</li>
<li>phil, philo=love (ph-v, vilo-love) &gt; philanthropy 慈善事业
philology 与文学 zoophilous 爱护动物的 philosophy 哲学 philo+soph
philately 集邮 phil爱+a无+tel(tax)税 bibliophilist 书籍收藏学家
neophilia 具有强烈好奇感的，喜欢新奇的</li>
<li>differt kinds of love
<ul>
<li>eros: sexual love 男女 欲望</li>
<li>phileo: have affection for 友谊 友谊</li>
<li>stergo：love of parents and children or a ruler and his subjects
有责任的爱 偏爱</li>
<li>agapao：have regard for 大爱，最高境界的爱 尊敬</li>
</ul></li>
<li>ster=duty(l) &gt; strong, stiff, rigid, strict, serere,little stern
严厉的，苛刻的 thorn(st~th) 荆棘、刺、戳 sterile 贫瘠的（少） starve
饿死 strand 困境 starch 淀粉，古板的 stark(ch~k) 刻板的，十足的 torpor
迟钝[(s)ter 刻板的] stare 盯着看，凝视 strut 大步快走</li>
<li>path=suffering, feeling, illness, disease
表示又痛苦又激情，耶稣为人类受难的感情 &gt; pathetic 悲惨的 antipathy
反感，厌恶 apathy 冷漠 apathetic 冷漠的，缺乏兴趣的，无动于衷的 sympathy
同情、同情心 pathology 病理学 psychopath 精神病患者</li>
<li>soph=debate 善辫，wise 古代人们认为善辫的人是智者 &gt; sophist
诡辩这 sophism 诡辩 sophisticate 世故的，世故，复杂，精巧 sophisticated
诡辩的，久经世故的 philosophy 哲学 sophomore 大学二年级学生 wise
more</li>
<li>phob, phobia=run, fear恐惧，以ia结尾的可以表示病 &gt; phobia 恐惧症
acrophobia 恐高症(acro=angle) hydrophobia 恐水症狂犬症 sinophobe
厌恶中国的人</li>
</ul></li>
<li>行为
<ul>
<li>flu=flow 流感 &gt; fluency 流利 fluctuate 波动 effluent 流出的，污水
mellifluous 流畅的 influence 影响 confluence 汇合 influenza 流行性感冒
superfluous 多余的、过量的 fluid 流动性，流动的 affluent 丰富的 fluidity
流动性 effluvium 臭气 flux 变迁,融化，通量 refluent 回流，退潮 influx
流入</li>
<li>sect,seg=divide, piece,cut &gt; section 部分 insect 昆虫 segment
段，分割 intersect 交叉 bisect 切成两半 vivisect 活体解剖 dissect
解剖，把...切成碎片 transect 横截</li>
<li>gen,gener, genit, birth,produce, create,beget,race,kind &gt; genus
种，类，属 eugenics 优生学 genetic 遗传的 genuine 真实的，诚恳的
sincere, authentic general 一般的 genius 天才，天赋 generate 产生
ingenuous 产自内心的，坦白的，正直的 generation 产生，一代人 ingenious
机灵，创造性的 regenerate 新生，革新 generous 慷慨的，大方的 degenerate
退化的 homogeneous 均匀的 genial 亲切的 heterogeneous 异质的 indigenous
本土的 genre 类型、流派 indigence 贫乏 pathogeny 生病、病原 gentle
温和的，文雅的 congential 天赋的 genteel 绅士风度的 primogenitor
始祖、祖先 engende 产生、造成 progeny 后裔</li>
<li>gress=step,go &gt; aggress 攻击，侵犯 aggressive 好斗的 digress 离题
digression 离题 congress 大会，国会 progress 前进 egress 出口 ingress
入口 retrogress 退步 trangress 违反，犯罪</li>
<li>soci=social &gt; society 社会 socialism 社会主义 sociality
社会性、社交 socialite 社会精英 socialist 社会主义者 asocial
自私、缺乏社交的 sociology 社会学 consociate 使结合、联盟 associate 联系
dissociate 分离 association 联想、结交 sociopath
反社会者，不喜欢社交的人 sociable 好交际的，友善的</li>
<li>migr -- *mei = to change, go and move -- mutable &gt; migrant
候鸟，移居者 migrate 使移动 migratory 迁移的，流浪的 emigrate
移居（出境） immigrate 移居（入境） transmigrate 移居，宗教之轮回
migraine 偏头痛</li>
<li>ori,orig = rise, begin &gt; orient 东方的 origo 起点 oriental
东方的，东方人 originate 引发，发明 occident 西方的（cid） aboriginal
土著居民 orientation 方向 abortion 堕胎，流产 disorient 使失去方向
abortive 夭折 origin 起源 original 最初的</li>
<li>karaoke 卡拉ok &gt; kara head; room,empty oke orchestra</li>
<li>orchestra 管弦乐队 &gt; or(ori:rise,begin) ches(box) tra(denoting
place)</li>
<li>cur,curs,cour, cours=run kelt=kers to run? &gt; cursory 草率的
concur 同时发生 cursive 草书的 current 水流 incur 招惹 currency 流通
occur 发生，出现 curriculum 课程 occurrence 出现，事件 recur 复发，重现
recurrent 再发生的，周期性发生的 excurse 远足，短程旅行 excursive
离题的，散漫的 course 路线，过程，急行 courser 猎人，猎狗<br />
precursor 先驱 recourse 求助 scour 冲洗，快走，腹泻 succour 救援者
coarse 粗糙的</li>
<li>man, manu=hand, strength, power over &gt; manual 手册，指南 manacle
手铐 manicure 修指甲 manage 管理 manuscript 手稿 manufacture 制造，加工
maintain 维持，维修，供养 mandate 指令，要求 maneuver 操纵 manifest
表明，显然的 // fest=打击 struck,seized manumit 解放，释放 manipulate
操纵，控制 pul=plenary poly man=power over 权力无限的</li>
<li>pass,pat=1.feeling(suffering,enduring) 2.通过 &gt; passion 激情
impassion 激动 passive 被动的 impassive 冷漠的 compassion 同情，怜悯
patience 耐心 compatible 协调的，一致的 compatibility 兼容性; passage
通过 passenger 乘客 passport 护照 impasse 僵局 surpass 超越 trespass
侵入，过失(terr=land,earth) compass 罗盘 encompass 包围，环绕</li>
<li>sens,sent=sense,feeling agreement &gt; sense 感觉 sensible 可感知的
sensibility敏感性 sensitive 敏感的 sensory 感觉的 sentiment 情感
sentimental 不理智的 nonsense 胡说 assent 赞成，同意(~ascend 上升)
consent 同意 consentient 同意的 consensus 意见一致的 dissent 不同意
resent 怨恨 present 陈述</li>
<li>tim=fear &gt; timid 胆小的 timidity 胆怯 timorous 胆小的 intimidate
胁迫 intimidation meticulous 细心的 meticu+tim 小心翼翼的，一丝不苟的
methodical method 有条不紊的</li>
</ul></li>
</ul></li>
<li>文化
<ul>
<li>creed, cred=believe,trust &gt; credit credible可信的
creditable可靠的 accredit 信任 credential 证明书 credo 信条 discredit
怀疑 credulous 轻信的 (charm骗人)</li>
<li>fid=trust, faith &gt; confident self-confident confidant 心腹知己
confidential 机密的 diffdent 缺乏自信的 confide 信任 fidelity忠实
infidel 不心焦的 perfidy 背叛 perfidious 背信弃义的 affidavit 宣誓书
fiduciary 信任的</li>
<li>liber=free noble高贵的 generous people; l+i+ber &gt; liberty 自由
liberal arts 文科 intellectual知识分子 enlargement放大 liberal 自由的
liberate 解放，释放 libertine 放荡不羁者(自由过度)</li>
<li>ment=mind &gt; mental 精神的 mentality 智力 mention comment
commentate 评论，解说 demented 发狂的，精神错乱的 remind amentia
智力缺陷</li>
<li>nov=new,yound,recent, shape,unuaual &gt; novel 小说 novelty 新奇
nova 新星 novation 更新 novice 新手 innovate 革新 innovation 内在的革新
renovate renovation 翻新</li>
<li>prais,preci=praise,value,price &gt; appraise 评价 appraisal
评论，骨架 precious 宝贵的 appreciate 赏识，涨价 appreciative 欣赏的
appreciable 可感知的，可评价的 depreciate 变低，轻视(duc,
duct=lead,bring)</li>
<li>duc, duct=to pull, drag; lead, bring 领导，引起
<ul>
<li>duck 公爵，手，拳头 &gt; duct 管道 ductile 展开的 aqueduct 导水管
educate 教育 educe 唤起 abduc 绑架 deduce 推论 induce 劝诱 induct 引导
introduce 介绍 produce 产生 product productivity 生产力 reduce 减少
conduct 引导 conductor 领导，经理 seduce 分开 traduce 横着，诽谤 vioduct
高架桥</li>
</ul></li>
<li>art=skill, joint, trick &gt; article 文章，物品，项目 //cle变成名词
artless朴实的 artful 狡猾的 artistry 艺术技巧 artificial 人造的,假的
artisan 技工 artifact 人造物品 (fact=do)</li>
<li>lingu=language &gt; linguist 语言学家 linguistics 语言学 bilingual
说两种语言的 unilingual 一种语言的 multilingual 多种语言的
sublingual舌下的</li>
</ul></li>
<li>法学
<ul>
<li>leg, legis=law &gt; legal 法律 illegal 违法的 legislate 立法
legislation 立法 legislature 立法机构 privilege 特权 delegate 代表
relegate 驱逐 banish 委托，丢弃</li>
<li>jur,juris=law, swear
<ul>
<li>just 公平，工作 &gt; jury 陪审团 injury 伤害 injurious 有害的
perjury 伪证 conjure 祈求 abjure 放弃宣誓 adjure 郑重宣誓</li>
</ul></li>
<li>dict, dic = say, speak, point out, show, teach &gt; dictate 口述
dictionary 字典 vocabulary contradict 反驳 perdict 预测 addict 上瘾
perdicament 困境 indict 起诉 abdicate 放弃 predicate 断言 dedicate 献身
edict 法令 indite 写，创作</li>
<li>jurg,judic=judge &gt; judgment 判断 judicial 司法的，公正的 adjudge
宣判 judiciary 司法的，审判的 adjudicate 审判，裁定 prejudice 偏见</li>
<li>cern,cert, cret=separate,sure分开 &gt;
sift/sieve:perceive,comprehend 一种感知 crisis 危机 concern 关注 discern
识别 discernible 可识别的 certainty 确定 certificate 证书 certitude 确信
discrete 分立的 secret 秘密</li>
<li>fin=end,boudary,limit &gt; fine 精巧的， 罚款 finance finish finale
finality finite 有限的 infinite 无限的 affinity 亲密的关系</li>
<li>fort 原义指剑上最坚硬的部分，最强的，优点 &gt; force forceful
enforce 强迫 reinforce 加强 fortify 加强 foritude坚韧 effort 努力
comfort 舒适 discomfort 不适</li>
<li>her, hers=stick,cling &gt; adhere 粘附，坚持 adherence 忠诚 adhesive
粘性的 cohere 粘着 coherent 粘在一起的 inherent 内在的 hesitate 犹豫
hesitaion</li>
<li>hibit=hold,possess habit &gt; exhibit 展出，陈列 exhibition 展览会
inhibit 抑制 prohibiit 禁止</li>
<li>odin=order<br />
&gt; ordinal 顺序的 ordinary 平常的 ordinance 法令 extraordinary
非常的，特别的 coordinate 同等的，调整 ordain 规定 ornate 装饰的
disorder 扰乱</li>
<li>prov,prob=test front &gt; provbable 可能的 probe 侦查 probability
approve 赞成 probation 查验，坚定 approval 赞成 disprove 反驳 reprove
责备</li>
<li>strict, strain, string=tighten, stretch &gt; strict stricture 责难
constrict 压缩 stringency 严格，紧绷 constringe 使收缩 strain 疲劳
constrain 抑制，拘束 constraint 抑制 overstain 过度紧张 restrain
反复地拉，组织 restrict 限制 restraint 可知</li>
<li>sur=sure &gt; secure assure 保证 reassure 使安心 surety 担保，保证
insurance 保险 assurance 却行 censure 责难 assuredly 确信地</li>
<li>term=limit, end, boundary &gt; terminal 终点站 terminate termination
终止 terminier 判决 terminology 术语学 determine 决定 determined 坚决的
interminable 无限的 exterminate 消除</li>
<li>treat=handle &gt; treaty 条约 treatment 对待，处理 maltreat 虐待
retreat 撤退 entreat 祈求 treatise 论文</li>
</ul></li>
</ul>
<h3 id="校园生活类">4.2 校园生活类</h3>
<ul>
<li>例子
<ul>
<li>pute: think &gt; compute dispute // dis=away分开想，争论 impute 归罪
repute 名气</li>
<li>vis, vid: see &gt; visible envious // 一直盯着看 羡慕</li>
</ul></li>
<li>实际
<ul>
<li>act,ag = to do, to drive &gt; active, actual, react</li>
<li>alter, altern=other=to change &gt; alternate</li>
<li>don, dot=give &gt; donate, donor, condition</li>
<li>cre, creates=grow, make &gt; create, increase, decrease,
concrete</li>
<li>mir=look,laugh,wonder &gt; miracle, mirror</li>
<li>not(e)=observer,mark=know &gt; notice, notify, denote,
denotation</li>
<li>nounce, nunci=speak, shout &gt; anounce, annunciate, denounce</li>
<li>pend, pens=hang &gt; pendant, pending, inpending, depend</li>
<li>pend, pens, pond = (s)pend, to pull,stretch, weight, expend &gt;
expend, pension</li>
<li>pli,ple,plen,plet=to full, fill; &gt; plenary, plenty,
supplement</li>
<li>pli,ple,ply=fold &gt; complicate, explicate, implicit, implicate,
replicate</li>
<li>plex=fold &gt; complex, duplex, complextion</li>
<li>port=carry,take &gt; import, export, support, portable, portage,
disport</li>
<li>press &gt; pressure, express, oppress</li>
<li>pute=to think,pruno &gt; compute, dispute, impute, repute</li>
<li>quest,quer,quir,quis=seek,search &gt; quest, question, inquest,
inquire, inquiry, acquire, require, request, conquer</li>
<li>scend, scent, scens=climb &gt; ascend, descend, condescent</li>
<li>sid=sit &gt; reside, residue, preside, subside, subsidy</li>
<li>st, sta, stant, stat, stan, sist=stand &gt; stable, obstacle,
stature, instant, stationary, assist, assistant, consist, exist, insist,
persist, subsist</li>
<li>simil, simul, sembl=alike, same &gt; similar, simile, similitude,
assimilate, simulate, semblance, resemble, assemble</li>
<li>spect, spic=look, see, scope;kind &gt; expect, aspect,inspect,
respect, prospect, spectate,auspicious; special, speciality, species,
consepcific</li>
<li>spir=breathe, spit-&gt;spirit=soul, courage, vigor, breath &gt;
spirit, spiritual, aspire, expire, respire</li>
<li>sum=total,super;to make up &gt; summary, summit; assume, consumer,
resume, exempt;</li>
<li>tag, tac(t), tig, ting=tangent, touch &gt; tactual, attach, contact,
contagion, intact, tangible</li>
<li>tain, ten, tin=tangent, hold &gt; attain, maintain, tenable,
tenacity, content, discontent,tenant, detain, pertain, retain</li>
<li>tend, tent, tens=stretch &gt; tend, tendency, trend, distend,
contend</li>
<li>tom=cut &gt; atom, tome, epitome</li>
<li>turb=stir; &gt; disturb, turbulence, perturb</li>
<li>us,ut=use &gt; usage, utilize, usual, abuse, disabuse, utilize,
usurp</li>
<li>ven, vent=come; venue=a place for event-&gt;come &gt; advent,
adventure, venture, convene, event, reveneue, avenue</li>
<li>vail, val=valid:be of use;strong;value &gt; avail, invaild, prevail,
prevalence, valor, valuable, evaluate</li>
</ul></li>
</ul>
<h2 id="按规则出牌--词缀">5. 按规则出牌- 词缀</h2>
<blockquote>
<p>词缀不能表示单词的实际意义</p>
</blockquote>
<ul>
<li>前缀：方向、强度
<ul>
<li>时间
<ul>
<li>前：
<ul>
<li>ex expect在前面 期望</li>
<li>pre presend</li>
<li>pro process</li>
</ul></li>
<li>后： re=back</li>
</ul></li>
<li>位置
<ul>
<li>inter 里面 internal</li>
<li>out 外面 outlet</li>
<li>over 上面 overlook</li>
<li>sub 下面 subscribe</li>
<li>super 上面 superior</li>
<li>trans 变化位置 transform 变形 transfer</li>
<li>under 在什么下面 undertake</li>
</ul></li>
<li>数量
<ul>
<li>uni 1 uniform unique独一无二的</li>
<li>bi(bicycle), di(divide划分，本身对称), twi(two, twice,twin,
twilight黎明, i和o发生变化，即元音发生替换), du(发音的问题？
duet二重唱，决斗) 2</li>
<li>centi 100 century</li>
<li>milli 1000 million millimeter</li>
<li>mono 单一 Monday monopoly</li>
<li>multi 多 multiply</li>
</ul></li>
<li>程度
<ul>
<li>super 超级，过分 superman</li>
<li>over overestimate 高估</li>
<li>under 未达到 underestimate</li>
<li>hyper 过分 hypertension 高血压</li>
<li>well 好地， 受过好的教育 well-educated</li>
</ul></li>
<li>方式
<ul>
<li>auto 自动 automatic</li>
<li>co 合作 cooperate, cooperation</li>
<li>mal 坏的, maltreat 虐待<br />
</li>
<li>mis 错的 mistake错误 // 注意错的事情不一定是坏的</li>
<li>self 自己的 selfish selfless</li>
</ul></li>
<li>态度
<ul>
<li>anti 反对 antibody 抗体 antibiotic抗生素</li>
<li>counter n. 反击，对立面; counter strike cs游戏 counterpart</li>
<li>pro 支持 propose</li>
</ul></li>
<li>否定
<ul>
<li>ab abuse abnormal</li>
<li>an anticipate?</li>
<li>de decline</li>
<li>in individual 个人的</li>
<li>non nonsense 废话</li>
<li>under underestimate低估</li>
</ul></li>
</ul></li>
<li>后缀：状态、词性
<ul>
<li>动词
<ul>
<li>ate: create</li>
<li>ish: finish fish</li>
<li>ify satisify classify</li>
<li>ch watch reach</li>
<li>en strengthen weaken</li>
<li>ize realize</li>
<li>ise surprise</li>
</ul></li>
<li>名词
<ul>
<li>or actor</li>
<li>ee employee 雇员</li>
<li>ess actress</li>
<li>an/ian historian 历史学家</li>
<li>ance balance 平衡</li>
<li>ant //!!!!, servant 服务员, pedant 挂坠</li>
<li>ity creativity 创造力，创造性</li>
<li>th width</li>
<li>ary //!!!, anniversary 周年庆</li>
<li>um mum 妈妈 lum 烟囱</li>
<li>age usage 使用</li>
<li>let //!!!,小的东西 toilet</li>
<li>try entry, country, chemistry</li>
<li>ness sadness vividness 抽象形式的单词</li>
<li>al offical arrival proposal terminal</li>
<li>ese Japanese Chinese</li>
<li>hood 时期 childhood neighborhood brotherhood likelihood
adulthood</li>
<li>ics physics academics athletics classics economics</li>
<li>ion function motion action education</li>
<li>ism 什么主义，什么论 Dadaism criticism sadism radicalism
激进主义</li>
<li>ist 什么主义者，从事...的专家 socialist scientist physicist
notionist</li>
<li>ment development, implement工具, movement 动作 agreement 统一
management管理</li>
<li>ship 表示某种特定关系 friendship relationship fellowship
schoarship奖学金</li>
</ul></li>
<li>形容词
<ul>
<li>al normal formal eventual actual</li>
<li>tle little settle battle ???</li>
<li>tive relative active informative selective creative</li>
<li>id candid 坦白的 avid 渴望的 afraid 害怕的 acid 酸的</li>
<li>que clique 团？</li>
<li>ous 拥有充满的意思 delicious envious anxious desirous ambiguous</li>
<li>less =without worthless没有价值的 jobless fearless homeless</li>
<li>able 能.., 可以..., 值得..., reliable drinkable eatable movable</li>
<li>free carefree无忧不虑的</li>
<li>ful colorful beautiful wonderful</li>
<li>ic energetic, ehthusiastic fantastic scientific classic
historic</li>
<li>like 像.. childlike, fishilike</li>
<li>some awesome 令人敬佩的 adventuresome 冒险的 battlesome 好斗的</li>
<li>y noisy lively lovely timely及时的 manly 男子气概的 friendly 友好的
lowly 备件的 monthly 每月的</li>
</ul></li>
<li>副词
<ul>
<li>ward backward 反向地 forward向前地 frontward朝前地</li>
<li>ly slowly carelessly carefully quickly manly</li>
<li>wise likewise同样地 otherwise否则 cockwise 顺时针地</li>
</ul></li>
</ul></li>
</ul>
<p>单词的形成过程就是搭积木的过程，那么 meter -&gt; metrical -&gt;
symmetrical对称的 -&gt; asymmetrical不对称的 为什么要去掉e？
名词或者英文缩略与规则</p>
<h2 id="按规则出牌词源">6. 按规则出牌——词源</h2>
<blockquote>
<p>什么时候用？当按照常见方法无法分析出所包含的词根词缀时，此时就考虑使用这种方法来探究它原本对应的是什么</p>
</blockquote>
<p>顺序问题</p>
<p>承认两个原则： - 所有的单词都可以通过一个最简单的单词得到 -
某些其他体系的英语会对现代的英语产生影响，这是无法排除的</p>
<p>词源法，主要用于那些隐藏较深的词汇，无法一眼识别出来 dingy
肮脏的，褪色的 -&gt; dung 大便 dinghy 小船 trough 水槽</p>
<p>古英语到现代英语， 复杂词汇到简单词汇, 常用的三种换词方法 ### 6.1.
元音字母替换，单词含义不变或细微变化 a, e, i, o, u, y 降序,连续 &gt;
谁更重要，谁在前面（古英语） &gt; 元音可以连续下进行替换 wrack, wreck
残骸 bat, bet, bit, bot, but</p>
<h3 id="辅音字母替换单词含义不变或细微变化">6.2.
辅音字母替换，单词含义不变或细微变化</h3>
<blockquote>
<p>组内进行替换，单词含义不变 - h,c,k,g,q,qu</p>
</blockquote>
<pre><code>&gt; 发音相近   check cheque 机票和组织</code></pre>
<ul>
<li>b,p,ph,f,v &gt; fracture, break 破裂</li>
<li>f,t</li>
<li>s,t,d</li>
<li>m,n,r,l,y,j,g</li>
<li>z,j,d &gt; day, journal 每天</li>
<li>u,v,w &gt; went开口 vent出去</li>
</ul>
<h3 id="英文字母的位置与谐音变化单词含义不变或细微变化">6.3.
英文字母的位置与谐音变化，单词含义不变或细微变化</h3>
<ul>
<li>位置变化 &gt; star , astr astronaut 宇航员 alt &lt;- tall</li>
<li>谐音变化* &gt; OIC, Oh, I see!</li>
</ul>
<h2 id="不按规则出牌">7. 不按规则出牌</h2>
<p>谐音法，联想记忆法，拼音法，拆分法</p>
<h2 id="不可拆">8. 不可拆</h2>
<p>文化背景法， 典故法，分类法， 形近意近归纳法，例句法，诵读法</p>
]]></content>
      <categories>
        <category>english</category>
        <category>TOEFL</category>
        <category>word</category>
      </categories>
      <tags>
        <tag>english</tag>
        <tag>TOEFL</tag>
        <tag>word</tag>
      </tags>
  </entry>
  <entry>
    <title>TOEFL word overview</title>
    <url>/2019/TOEFL-word-overview-395610c497f2/</url>
    <content><![CDATA[<h1 id="词缀">词缀</h1>
<p>五星级词缀 - im,in: 否定，进入，加强 - dis: 低级别 no, 高级别 away;
apart - ad: to， toward - re: back - a+p: 强调，一再 - mis: bad -
phi：good - homo 相同的 hetero不同的 - suc= sub 下 - se 分开，诱使 =
seduce - uni 单一的 - per aeay, entirely</p>
<p>前缀 - 时间： ex,pre,pro re=back - 位置 inter/out over,super/sub
trans under - 数量 uni bi centi milli mono multi - 程度 super over under
hyper well - 方式 auto co mal mis self - 态度 anti counter pro - 否定
ab, an, de, in, non, under</p>
<p>后缀 - v: ate, ish, ify, ch, en, ize, ise - n: or, ee, ess, an/ian,
ance, ant, ity, th, ary, um, age, let, ness, al, ese, hood, ics, ion,
ism, ist, ment, ship - a al, tle, tive, id, que, ous, less, able, free,
ful, ic, like, some, y</p>
<h1 id="其他">其他</h1>
<p>换词方法 1. 元音字母 2. 辅音字母组 - h,c,k,g,q,qu - b,p,ph,f,v - f,t
- s,t,d - m,n,r,l,y,j,g - z,j,d - u,v,w</p>
<h1 id="词根">词根</h1>
<h2 id="总览">总览</h2>
<ol type="1">
<li><p>学术： sci, science, log, eco, nomy, ics</p></li>
<li><p>数学 meter, equ, part, numer</p></li>
<li><p>物理</p>
<ul>
<li>力 tract, grav, griev, pel,plus, mob, mot, celer</li>
<li>热 therm, calori, frig,friger, ferv, zeal</li>
<li>声 son, voc, vok, audi,audit, tone, phony, plod, verber, echo</li>
<li>光 lumin, lustr,lusc, lust,radi,cand, flect,flex, sol, sight,splend,
vis,vid</li>
<li>电 electro,tele, z</li>
</ul></li>
<li><p>化学: pos,posit,pon,pound,part,
port,mini,micro,macro,acid,acri,acu,acrid,ac,dia,sal
tox,struct,mod,form,cruc,crus,curx,norm,
solu,solv,solute,di,lut,lav,lux,rupt,spers,
lect,brev,bridge,vers,vert</p></li>
<li><p>天文: astro,aster,aer,aero,aeri,stell,atory</p></li>
<li><p>地质地理: terr,tele,cata,caco,call,ign</p></li>
<li><p>生物: bio,vi,li,herb,flor,flour,agr,agri,agro</p></li>
<li><p>历史: chron,
annual,ann,eon,loc,stat,stit,stiut,grap,gram,vict,vinc,vol,volv,volt</p></li>
<li><p>政治:
arch,tect,dem,cracy,crat,popul,publ,fus,fug,fun,mon,monit,polis,polic,polit,range,
serve,sequ,sent,sue,urb</p></li>
<li><p>人类学:
anthrop,anthr,andry,gyn,gynec,gamy,patri,matri,matr,amor,amot,am,phil,philo,ster,
path,soph,phob,phobia,flu,sect,seg,gen,gener,genit,gress,soci,migr,ori,orig,kara,oke,cur,
curs,cour,cours,man,manu,pass,pat,sens,sent,tim</p></li>
<li><p>文化:
creed,cred,fid,liber,ment,nov,prais,preci,duc,duct,art,lingu</p></li>
<li><p>法学:
leg,legis,jur,juris,dict,dic,jurg,judic,cern,cert,cret,fin,fort,her,hers,hibit,odin,
prov,prob,strict,strain,string,sur,term,treat</p></li>
</ol>
<p>校园生活类:
act,ag,alter,altern,don,dot,cre,creaters,mir,not,nounce,nunci,pend,pens,pli,ple,plen,
plet,plex,port,press,pute,quest,quer,quir,quis,scend,scent,scens,sid,st,sta,stant,stat,sist,
simil,simul,sembl,spir,sum,tag,tact,tig,ting,tain,ten,tin,tend,tent,tens,tom,turb,us,ut,ven,
vent,vail,val</p>
<h2 id="细节">细节</h2>
<p>人文科学 1. 学术 - sci: to know; conscious - science=knowledge:
conscientious - log=word/speech logue monologue - log=reason/idea logic
anthropology - eco=house,dwelling,place economy ego=self egecentric -
nomy=rule, subject(agronomy astronomy); management, rule(autonomy) -
ics=logic 学科 physcis dynamics 2. 数学 - algebra 代数 - meter: 1.
measure (optometrist, telemeter); 2. dimension (kilometer) 3. gemotry
(diameter) - equ=equal, even adequate 充分的 inequilty - par=equal, pair
parity 平价 compare - numer=number numerable 很多的，可数的 enumerate 3.
物理 - 力 - tract=draw abstract traction extract - grav, griev=to dig,
heavy; gravity aggravate - pel,puls=drive, push, shake,swing expel
compel - mob=move,乌合之众 mobile autombile - mot=1.move(motion, motive)
2. a witty saying (motto) - celer=quick,speed celerity accelerate - 热 -
therm=heat, warm thermal diatheraml isotherm - calori=heat calorie
calorify<br />
- frig,friger=cold frigid 冷的 refrigerator 冰箱 - ferv=boil perfervid
fervent - zeal=ardor zealous jealous - 声 - son=sound sonic resonance -
voc,vok=call,voice vocal evoke - audi, audit=hear audit audience -
tone=sound monotonous 单调的 - phony euphony 悦耳之声 symphony - plod
applaud explode - verber=beat, vibrate reverberatem - echo=sound
anechoic - 光 - lumin=light illuminate luminosity - lustr,luc=light
lust:desire,wish,longing lustre illustrate - light lighter enlighten -
radi=ray,root radio, radical ,radix - cand=white candle, candid - flect,
flex=bend reflect - sol=1. sun (solor solace console) 2. solo (sole,
solitary) - sight=vision sightly - splend=be right,shine splendid -
vis,vid=to see, to know,wise (visible envy provide); separate (divide) -
opt,opto=sight optic - 电 - electro=electric electron - tele=distant
telephone - Z=fast zigzag 4. 化学 - pos,posit=1.put
(pose,composite);2.pause (repose, 休息) - pon,pound=put,pause componet
compound - part, port=part particle depart - mini minimal, minimum -
micro microsoft - macro macroword - acid,acri,acu,acrid=sour, sharp
acid, acerbic - ac=acid,angle acute acuity - dia=across diagonal -
sal=salt salty salify saline salary - tox=posion toxic toxicology -
struct=to build, pile ,assemble structure construct - mod=mode, manner,
measure modest modern - form=shape formal conform - cruc,crus,curx=cross
十字形，交叉，关键 crucial crux cruise - norm=rule, norm norm normal -
solu, solv,solute=loosen,disperse 分解 solvable solvent - di=divide,
separate - lut,lav,lux=wash lavish 浪费的 lavatory 厕所，浴室 -
rupt=break, rupture abrupt interrupt bankrupt - spers=scatter 少年凯
disperse 分散 intersperse - lect, lig=choose,gather elect collect select
- brev, bridge=make short abreviate brief - vers,vert=turn-over adverse
adversity averse 反对 convert 5. 天文 - astro, aster=star astronomy
cosmonaut - aer,aero, aeri=air aerate tongqi aerosphere - stell=star
stellar interstellar - atory=场所 laboratory lavatory<br />
6. 地质地理 - terr=1.piece of earth,ground and land(terrain);2. to
treamble抖 terrible terrific - tele=far/distant telegraph -
cata,caco=kakos,bad,down catalog catastrophe cacophony -
call=kailo,beauty,call; calligraphy - ign=fire, scarifice ignite
ignitable 7. 生物 - bio=life biology biosphere - vi=li=live - herb
herbivorous herbaceous - flor,flour=flower,florid floral flora - agr,
agri,agro=field, land agrarian, agriculture 社会科学 1. 历史 -
chron=time Cronus chronic synchronize - annual,ann,eon=year annual
anniversary - loc=location locate locomotion - stat, stit, stiut=set
up,place stature statute constitute - grap=write,draw, scratch, picture
photography telegraph - gram=write program grammer diagram - vict,
vinc=克服，fight victory convict<br />
- vol,volv,volt=roll,turn,twist voluble 有才的 revolution revolve
involve 2. 政治 - arch=ruler,chief,government archy architect
architecture archives - tect=texture,build,do - dem=people epidemic
pandemic endemic - cracy=rule, crat=ruler democracy democrat -
popul,publ=people population populous popularize - fus,fug=flee,run away
refugee refuge - fun=pour refuse confuse infuse -
mon,monit=mind,warn,advice summon monition - muni,mun=public community
communal - polis,polic,polit=govern,state,city police policy politics -
range=rank,ring arrange rearrange - serve conserve preserve -
sequ,sent=follow sequence consequence sequential - sue=follow consue
pursue - urb=city urban suburb 3. 人类学 - anthrop=human anthropology -
anthr,andry=man polyandry - gyn,gynec,gamy=queen,woman gynecology
monogyny - patri=father patriarch patriot - matri,matr=mother maternal
matriarch - amor,amot,am=love amour amatory amateur - phil,philo=love
philantropy phiology<br />
- ster=duty stern sterile stare - path=suffering,feeling,illness,disease
pathetic apathy - soph=debate,wise sophist sophisticate -
phob,phobia=run,fear phobia acrophobia - flu=flow fluency fluctuate
effluent influence - sect,seg=divide, piece, cut section insect -
gen,gener,genit=birth,produce,create genus gennerate - gress=step,go
aggress progress ingress - soci=social society asocial - migr = to
change,go and move migrant migrate - ori,orig=rise, begin orient origo
originate - karaoke kara=head,room,empty oke=orchestra - cur,curs,
cours, cour=run cursory incur currency - man,manu=hand,strength,power
over manual manicure manage -
pass,pat=1.feeling,suffering,enduring(passion impassion passive) 2.
通过(passage, passenger, passport) - sens,sent=sense,feeling agreement
sense sensible consent - tim=fear timid meticulous 4. 文化 -
creed,cred=believe,trust credit credible creditable - fid=trust, faith
confident confide - liber=free,noble liberty intellectual liberal -
ment=mind mental mentality mention - nov=new, yound,recent, shape novel
novlty innovate - prais,preci=praise, value,price appraise precious -
duc,duct = to pull, drag;lead,bring ductile educate product -
art=skill,joint,trick artful artistry artifact - lingu=language
linguistics 5. 法学 - leg,legis=law legal illegal legislate -
jur,juris=law, swear jury injury - dict,dic=say,speak, point out dictate
addict - jurg,judic=judge judgment judicial - cern, cert, cret=separate
concern discern discrete - fin=end, boundary,limit fine finite -
fort=force enforce - her,hers=stick, cling adhere hesitate -
hibit=hold,posses habit exhibit exhibition - odin=order ordinal
coordinate - prov,prob=test front probe disprove -
strict,strain,string=tighted strict stricture constrict - sur=sure
secure assure - term=limit,end, boundary terminal determine -
treat=handle treaty treatment maltreat 校园生活类 - act,ag=to do, to
drive active actual - alter, altern=to change alternate - don,dot=give
donate,donor - cre,creaters=grow,make create increase -
mir=look,laugh,wonder miracle,mirror - not(e)=observer,mark=know notice
notify denote - nounce,nunci=speak,shout anounce denounce -
pend,pens=hang pendant pending - pli,ple,plen,plet=to full,fill plenty
supplement - plex=fold complex duplex - port=carry,take import export -
press pressure express - pute=to think,pruno compute dispute -
quest,quer,quir,quis=seek,search quest inquest acquire -
scend,scent,scens=climb ascend descend - sid=sit reside residue preside
- st,sta,stant,stat, sist=stand stable obstacle assist - simil,
simul,sembl=alike,same similar simile assimilate semblance -
spir=breathe, spit soul,courge,vigor,breath spirit expire -
sum=1.total,super(summary); 2. to make up(resume) -
tag,tact,tig,ting=tangent,touch tactual contact - tain,ten,tin=hold
attain maintain - tend,tent,tens=stretch tend tendency trend contend -
tom=cut atom tome epitome - turb=stir disturb turbulence perturb -
us,ut=use usage utilize usual - ven,vent=come advent venture convene -
vail,val=valid,be of use; strong,value avail valuable evaluate</p>
]]></content>
      <categories>
        <category>english</category>
        <category>TOEFL</category>
        <category>word</category>
      </categories>
      <tags>
        <tag>TOEFL</tag>
        <tag>word</tag>
      </tags>
  </entry>
  <entry>
    <title>The Minto Pyramid Princlple</title>
    <url>/2019/The-Minto-Pyramid-Princlple-f2d0ed39c855/</url>
    <content><![CDATA[<p>金字塔结构</p>
<p>金字塔结构是什么？</p>
<p>金字塔有什么用？ 为什么？</p>
<p>想想一种场景，让我们记住一组东西。即输入，我们要如何记住呢？
人类的直觉就是将这些内容进行归纳分组。 &gt;
一次记忆一般超不过7个思想，4,5个即可</p>
<p>然后输出的时候，分层可以让人的记忆内容变少。</p>
<p>比如一组东西。 这里有3类物品。</p>
<p>自上而下，先传达结论。 任何其他顺序都可能造成无解。</p>
<p>人大脑的本质，没在接受一个东西时。如果不理解，就会有疑问，比如跟前面有什么联系。
&gt;
人的思维能力都是有限的，一部分思维能力用于识别和解毒读到的词语，一部分用于找出思想之间的关系，剩下的则要用于理解文中所表述的思想的含义。</p>
<p>一般来说，调查的问题是零散的，所以需要我们自下而上地思考，总结概括。
先将词分组，再抽取组与组之间的共性，从而抽取出主旨思想，单一思想。</p>
<p>金字塔结构有三种关系： 1.
纵向：文章中任一层次的思想必须是其下一层次思想的概括 2.
横向：每组的思想必须属于同一逻辑范畴 3.
横向：每组中的思想必须按照逻辑顺序组织。 - 演绎归纳 - 因果关系（时间） -
评论（空间） - 类别（程度）</p>
<p>金字塔每层的含义 1. 主题 2. 关键句 3. 较具体的思想（新的思想）</p>
<p>学习三个点： 1. 学什么 2. 知其然 3. 用其法</p>
<p>算法题的步骤： 1. 要求 2. 设计原则 3. 模型 4. 具体设计 5.
关于设计的验证</p>
]]></content>
  </entry>
  <entry>
    <title>基础算法</title>
    <url>/2019/algorithm-acwing-basic-77364f848063/</url>
    <content><![CDATA[<p>[toc]</p>
<h3 id="十大排序算法">十大排序算法</h3>
<h4 id="算法分类">算法分类</h4>
<p>十种常见排序算法可以分为两大类： 1.
比较类排序：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn),
所以又称为非线性时间比较类排序 2.
非比较类排序：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，所以称为线性时间非比较类排序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void quick_sort(int q[], int l, int r)&#123;</span><br><span class="line">    if(l&gt;=r) return;  // 注意边界条件不可少</span><br><span class="line"></span><br><span class="line">    int x=q[l], i=l-1, j=r+1; // 或q[(1+r)/2], q[r]</span><br><span class="line">    // 这里赋初值是为了后面对称的情况</span><br><span class="line">    while(i&lt;j) &#123;</span><br><span class="line">        do i++; while(q[i]&lt;x);</span><br><span class="line">        do j--; while(q[i]&gt;x);</span><br><span class="line">        if(i&lt;j) swap(q[i],q[j]); // 注意这里要加一个判断</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    quick_sort(q, l, j);  // </span><br><span class="line">    quick_sort(q, j+1, r);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="归并">2. 归并</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">const int N=1e6+10;</span><br><span class="line">int n;</span><br><span class="line">int q[N], tmp[N];</span><br><span class="line"></span><br><span class="line">void merge_sort(int q[],int l, int r)&#123;</span><br><span class="line">    if(l&gt;=r) return;</span><br><span class="line">    int mid=l+r&gt;&gt;1;</span><br><span class="line">    merge(q, l, mid);</span><br><span class="line">    merge(q, mid+1,r);</span><br><span class="line"></span><br><span class="line">    int k=0, i=l, j=mid+1;</span><br><span class="line">    while(i&lt;=mid&amp;&amp;j&lt;=r)&#123;</span><br><span class="line">        if(q[i]&lt;q[j]) tmp[k++]=q[i++];</span><br><span class="line">        else tmp[k++]=q[j++];</span><br><span class="line">    &#125;</span><br><span class="line">    while(i&lt;=mid) tmp[k++]=q[i++];</span><br><span class="line">    while(j&lt;=r) tmp[k++]=q[j++];</span><br><span class="line"></span><br><span class="line">    for(i=l,j=0;i&lt;=r;i++,j++) q[i]=tmp[j];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">    scanf(&quot;%d&quot;,&amp;n);</span><br><span class="line">    for(int i=0;i&lt;n;i++) scanf(&quot;%d&quot;,&amp;q[i]);</span><br><span class="line">    merge_sort(q,0,n-1);</span><br><span class="line">    for(int i=0;i&lt;n;i++) printf(&quot;%d&quot;, q[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="二分">3. 二分</h3>
<h4 id="整数二分">整数二分</h4>
<p>// 整数二分，有单调性一定可以二分；但是没有单调性也可以二分 //
在区间上定义上某种性质，将区间分为两部分，左边满足某种性质，右边不满足某种性质；二分法可以用来寻找不满足性质和满足性质的边界
？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int bsearch_1(int l,int r)&#123;</span><br><span class="line">    while(l&lt;r)&#123;</span><br><span class="line">        int mid=l+r&gt;&gt;1; // 下取整</span><br><span class="line">        if(check(mid)) r=mid; // [l,mid]</span><br><span class="line">        else l=mid+1;</span><br><span class="line">    &#125;</span><br><span class="line">    return l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int bsearch_2(int l, int r)&#123;</span><br><span class="line">    while(l&lt;r)&#123;</span><br><span class="line">        int mid=l+r+1&gt;&gt;1;</span><br><span class="line">        if(check(mid)) l=mid;</span><br><span class="line">        else r=mid-1;</span><br><span class="line">    &#125;</span><br><span class="line">    return l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">如何判断死循环</span><br><span class="line">mid=l=r时，是否陷入死循环</span><br></pre></td></tr></table></figure>
<p>整数二分的问题一定可以用这个模板来解决。
每次二分，能找到一个答案的区间；当区间的长度是1时，即是解</p>
<p>二分能够包含解，然后用边界可以推出解。 &gt;
二分的退出条件一定是i=j吗？，这里知道快排的退出条件并不是l=r
对！！！！，二分一定能找到解，退出是i一定等于j</p>
<blockquote>
<p>性质的寻找， 如果a[mid] &lt; x,
怎么办？实际上就是看目标的数在a[mid]与x之间，比如靠近x最大的数，
此时l=mid; 如果是找x相等的左边界，在a[mid] 在a[mid] &gt; x, 比如 ???
有点模糊</p>
</blockquote>
<h4 id="浮点数二分simple">浮点数二分simple</h4>
<blockquote>
<p>这里就不用+1，-1 求平方根</p>
</blockquote>
<blockquote>
<p>这里务必注意左右范围的选取问题。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">int main()&#123;</span><br><span class="line">    double x;</span><br><span class="line">    cin&gt;&gt;x;</span><br><span class="line"></span><br><span class="line">    double l=0, r=x; // r=max(1,x);</span><br><span class="line">    while(r-l&gt;1e-8)&#123;  // 这里比要求的有效数字多2</span><br><span class="line">    // 这里用迭代次数来停止也可以，比如100，即除以2^100.</span><br><span class="line">        double mid=(1+r)/2;</span><br><span class="line">        if(mid*mid &gt;= x) r=mid;</span><br><span class="line">        else l=mid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    printf(&quot;%lf\n&quot;,l); </span><br><span class="line">    // 这里l或者r</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="高精度">4. 高精度</h3>
<p>A+B： len(A)=1e6 A-B: A*a 1e6 a-10000 A/a</p>
<p>存储，倒序存储 在末位加上一位，下标为0的存个位。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A+B</span><br><span class="line">int a[N],b[N],sum[N];</span><br><span class="line">int cnt=0;</span><br><span class="line">for(int i=0,j=0;i&lt;n&amp;&amp;j&lt;m;i++,j++)&#123;</span><br><span class="line">    sum[i]=(a[i]+b[j]+cnt)%10;</span><br><span class="line">    cnt=(a[i]+b[j]+cnt)&gt;10?1:0;</span><br><span class="line">&#125;</span><br><span class="line">if(cnt) a[n+1]=1;</span><br><span class="line"></span><br><span class="line">A-B</span><br><span class="line">len(A)&gt;=len(B)</span><br></pre></td></tr></table></figure></p>
<p>如果A，B可能取正或负，那么一定可以转化为绝对值进行相加或者相减！</p>
<p>高精度减法 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">t=(t + A[i])/b;</span><br><span class="line">c.push_back(t%10);  //?</span><br><span class="line">t=A[i]%b;</span><br><span class="line"></span><br><span class="line">for (int i=A.size()-1;i&gt;=0;i--)</span><br><span class="line">t=10t+A[i];</span><br><span class="line">if((t/b)) c.push_back(t/b);  </span><br><span class="line">t %= b;</span><br><span class="line">t</span><br></pre></td></tr></table></figure></p>
<h3 id="前缀和和差分">5. 前缀和和差分</h3>
<ul>
<li>前缀和 a1, a2, a3,..., an S0, S1, S2,..., Sn a_{i}= S_{i}- S_{i-1}
S0=0; 当S0=0时，特别好定义边界。 前缀和 Si = Si-S0.</li>
</ul>
<p>因此，可以很容易地求片段和。 &gt;
很厉害！可以统一了，不用预处理了</p>
<blockquote>
<p>scanf比cin快一倍 ios::sync_with_stdio(false);
cin和标准输入输出不同步，提高cin读取速度；不能使用scanf</p>
</blockquote>
<p>区间和 区域和 (x1,y1), (x2,y2) Sx2y2-Sx1y2-Sx1y1+Sx1y1</p>
<ul>
<li>差分 前缀和的逆运算 &gt; 作用：可以在O(n)时间内B-&gt;A 区间[1,r]+c
&gt; b[l]+c, b[r+1]-c</li>
</ul>
<h3 id="双指针算法">6. 双指针算法</h3>
<p>两类： 一个数组两个指针；两个数组同时处理。 代码框架
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(i=0,j=0;i&lt;n;i++)&#123;</span><br><span class="line">    while(j&lt;i &amp;&amp; check(i,j)) j++;</span><br><span class="line">    res=max(res, j-i+1);</span><br><span class="line">    // 每道题的具体逻辑</span><br><span class="line">&#125;</span><br><span class="line">O(n+m) </span><br><span class="line">这里i和j具有单调性，i和j只向一个方向发展。</span><br></pre></td></tr></table></figure></p>
<p>核心思想 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int i=0;i&lt;n;i++)</span><br><span class="line">    for(int j=0;j&lt;n;j++)</span><br><span class="line">        O(n^2)</span><br></pre></td></tr></table></figure> 将上面朴素算法优化到O(n), 运用了某种性质</p>
<p>维护两个窗口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ad daa</span><br><span class="line">ad</span><br><span class="line">daa</span><br><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;string.h&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">    char str[100];</span><br><span class="line">    gets(str);</span><br><span class="line">    int n=strlen(str);</span><br><span class="line">    </span><br><span class="line">    for(int i=0;i&lt;n;i++)&#123;</span><br><span class="line">        int j=i;</span><br><span class="line">        while(j&lt;n &amp;&amp; str[j]!=&#x27; &#x27;) j++; // i,j-1具体单词</span><br><span class="line">        for(int k=i;k&lt;j;k++)&#123;</span><br><span class="line">            cout&lt;&lt;str[k];</span><br><span class="line">        &#125;</span><br><span class="line">        cout&lt;&lt;endl;</span><br><span class="line">        i=j;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 枚举起点和终点</span><br><span class="line">// 每个指针的位置都有意义</span><br><span class="line"> for(int i=0;i&lt;n;i++)</span><br><span class="line">    for(int j=0;j&lt;n;j++)</span><br><span class="line">        if(check(i,j))&#123;</span><br><span class="line">            res=max(res,i-j+1);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">// 双指针算法 O(n)</span><br><span class="line">for(i=0,j=0;i&lt;n;i++)&#123;</span><br><span class="line">    while(j&lt;i &amp;&amp; check(i,j)) j++;</span><br><span class="line">    res=max(res, j-i+1);</span><br><span class="line">    // 每道题的具体逻辑</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>特殊情况的举例</p>
<blockquote>
<p>数组元素的目标和为什么限制为一个解，因为如果是多个解时。对于 <code>1
1 1 1 1, 1 1 1 1 , 2</code>本身就要O(n*m),算法必然为O(n^2)的。 ???? ###
7. 位运算</p>
</blockquote>
<p>从个位开始算,(11111)_2 &gt; 先把第k位移到最后一位 &gt; n&gt;&gt;k
&amp; 1 看一下n的第k位是几？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int k=3;k&gt;=0;k--)</span><br><span class="line">    cout&lt;&lt;(n&gt;&gt;k&amp;1)&lt;&lt;endl;</span><br></pre></td></tr></table></figure>
<p>lowbit(x): 返回x的最后一位1 x&amp;(~x+1)= x&amp;-x</p>
<h3 id="离散化整数的离散化">8. 离散化，整数的离散化</h3>
<p>10^9 稀疏的值域，映射到从0开始的自然数 10^5
注意这里映射的话的思想实际上就是按照个数索引来映射的感觉。</p>
<p>a-&gt;b &gt; 1. a[]可能中有重复元素： 去重 &gt; 2.
如何算出a[i]离散化后的值：a是有序的，二分</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vector&lt;int&gt; alls;</span><br><span class="line">sort(alls.begin(), alls.end());</span><br><span class="line">alls.erase(unique(alls.begin(), alls.end()),alls.end()) // 去重</span><br><span class="line">&gt; ?这里unique返回的就是改变后的alls, 且alls后面的重复的元素都放在最后部分</span><br><span class="line"></span><br><span class="line">// 二分求出x对应的离散</span><br><span class="line">int find(int x)&#123; // 找第一个大于等于x的位置</span><br><span class="line">    int l=0, r=all.size()-1;</span><br><span class="line">    while(l&lt;r)&#123;</span><br><span class="line">        int mid=l+r&gt;&gt;1;</span><br><span class="line">        if(x&lt;=all[mid]) r=mid;</span><br><span class="line">        else l=mid+1;</span><br><span class="line">    &#125;</span><br><span class="line">    return r+1; // 这里是否加1都无所谓，这里从1开始映射；1,2,3,4,..,n</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意，一般的离散化的目标就是所有会用到的坐标 区间和 n+2m(l,r)</p>
<h3 id="合并区间">9. 合并区间</h3>
<ol type="1">
<li>按区间做变短排序</li>
<li>总共有三种情况 <code>ri&lt;ri+1, ri+1&lt;ri, ri&lt;li+1</code>
一般是贪心，优先对左右端点进行排序</li>
</ol>
<h3 id="其他">其他</h3>
<p>java输入输出比较慢</p>
<p>编译语言和即时编译 小数据 javascript,python快 大数据 go,c,c++快
javascript&gt;python&gt;go=C++&gt;java</p>
<h4 id="错误类型">错误类型</h4>
<ul>
<li><p>Segmentation Fault 基本情况是否没有考虑 数组是否越界
没有输入</p></li>
<li><p>Time Limit Exceeded<br />
输入输出可能都存在着问题</p></li>
</ul>
<p>关键：把自己想的算法能够实现出来</p>
]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm acwing data-struture</title>
    <url>/2019/algorithm-acwing-data-struture-95ca5642476a/</url>
    <content><![CDATA[<p>数据结构</p>
<h1 id="链表与邻接表">1. 链表与邻接表</h1>
<p>strut Node{ int val; Node *next; }; //不讲！</p>
<p>new Node(); // 动态在堆中申请非常慢！ &gt; 可以在初始化时弄多个。</p>
<blockquote>
<p>数组模拟单链表</p>
</blockquote>
<ul>
<li><p>单链表： 邻接表（存储图和树） e[N], ne[N]下标,head, idx &gt;
有个问题，删除后空闲节点不好回收；一般来说不需要管删除的点，浪费即浪费，只是想快，不用考虑内存泄露的方法。
&gt; 写工程时，才需要考虑多久 &gt; 单链表只能向后看，向前只能从头遍历。
O(1)时间插入，O(n)时间; 尾插法O(1), 记录一下即可
注意从0开始存储内容，所以remove和add都是k-1，还要特别注意remove
head;</p></li>
<li><p>双链表： 优化某些问题 e[N],l[N],r[N],0表示头，1表示尾 init:
r[0]=1,l[1]=0, idx=2; 注意不需要连起来
务必注意，从2开始存储元素，所以remove和add都需要映射为k-1+2=k+1</p></li>
</ul>
<p>struct Node{ int e,l,r; }nodes[N]; remove
<code>nodes[nodes[k].l].r=nodes[k].r</code> &gt; 不推荐 # 2. 栈与队列
栈： tt,0 队列：hh,tt &gt; 边界看个人习惯，0或-1</p>
<h1 id="单调栈">3. 单调栈</h1>
<blockquote>
<p>给定一个序列，求一个数左离它最近小于它的数 暴力做法费时
善于发现数据的性质
时间复杂度：每个元素进站一次和最多出站一次，所以算法复杂度为O(n);</p>
</blockquote>
<h1 id="单调队列">4. 单调队列</h1>
<blockquote>
<p>求滑动窗口中的最大值和最小值， 凡是能抽象出来。
一个严格单调队列的最小值就是其头和尾。
队列的大小不会超过滑动窗口的大小！！！</p>
</blockquote>
<blockquote>
<p>单调栈和单调队列的做法都是通过暴力分析，然后用栈和队列来模拟，并且去掉没有用的元素。然后再剩余的元素有没有单调性，有的话就可以考虑栈和队列。
栈是最近最小，队列是全局最小。然后因为单调还可以用二分法来进行查找。</p>
</blockquote>
<p>多重背包也可以用滑动窗口来优化，因为滑动窗口可以做</p>
<p>对队列的研究，什么时候入队，什么时候出队？</p>
<p>！！！这里队列里居然存的是下标，天啦一下子就避免了情况的讨论。 &gt;
存下标会很容易来判断什么时候进行元素弹出</p>
<blockquote>
<p>在实际做的时候，会开O_2和O_3优化，此时速度就与stl相差没多少了
但是在做算法题时，拿数组模拟的队列和栈比stl快。
比赛方是不会开优化的！</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">const int N=1e6+10;</span><br><span class="line"></span><br><span class="line">int q[N];</span><br><span class="line">int a[N];</span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">    int n,k;</span><br><span class="line">    scanf(&quot;%d %d&quot;,&amp;n,&amp;k);</span><br><span class="line">    for(int i=0; i&lt;n;i++) scanf(&quot;%d&quot;,&amp;a[i]);</span><br><span class="line">    int hh=0,tt=-1;</span><br><span class="line">    for(int i=0;i&lt;n;i++)&#123;</span><br><span class="line">        // 判断对头是否划出了窗口</span><br><span class="line">        if(hh&lt;=tt &amp;&amp; i-k+1 &gt; q[hh]) hh++;</span><br><span class="line">        while(hh&lt;=tt &amp;&amp; a[q[tt]]&gt;=a[i]) tt--; //</span><br><span class="line">        printf(&quot;hh: %d, tt: %d\n&quot;,hh,tt);</span><br><span class="line">        </span><br><span class="line">        q[++tt]=i; // 注意这里模拟的不是实际的物理位置. !!因为hh&gt;tt,当前元素没找出来，注意</span><br><span class="line">        if(i&gt;=k-1) printf(&quot;---%d \n&quot;,a[q[hh]]);</span><br><span class="line">        </span><br><span class="line">        for(int j=hh;j&lt;=tt;j++) printf(&quot;%d &quot;,a[q[j]]);</span><br><span class="line">        puts(&quot;&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="kmp">5. KMP</h1>
<blockquote>
<p>S字符串,P模板串 从1开始</p>
</blockquote>
<p>暴力 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">i:1..n</span><br><span class="line">j:2..m</span><br></pre></td></tr></table></figure></p>
<p>优化：一直向取的距离足够大 &gt; 最少移动距离，最大后缀</p>
<p>next[i]=j: 以i为终点的，所能匹配的最长距离.
关键！一定要理解透，这里比如next[1]=0,表示第一个节点没有匹配的内容。
&gt; 务必注意是当前！ p[1,j]=p[i-j+1,i]</p>
<p>i,j为S和P的指针。 所以在i失配的话。 &gt;
模板串移动的是最长的，所以从模板串的角度来看是最优的！</p>
<blockquote>
<p>算法时间复杂度是O(n)的，再快不可能有更快的了！</p>
</blockquote>
<blockquote>
<p>j最多加m次，j大于0， while循环最多减m次。所以时间复杂度为2m。</p>
</blockquote>
<p>注意比较的对象：s[M],p[N] # 6. Trie树
高效存储和查找字符串及其次数的数据结构
将字符串拆分为各个字母，组合成一个多叉树。 &gt; 相比于kmp，利用了前缀
&gt; 如：abcdef, root-&gt;a-&gt;b-&gt;c-&gt;d-&gt;e-&gt;f-&gt;$ &gt;
对于串树，一般只包含大写或小写字母！一定有限制</p>
<p>son[N][26],cnt[N],idx 理解：trie树内部每个节点占用一个idx,
idx的取值范围为0-N
son[idx][1]指向关联的下个节点，cnt[idx]以此idx为结尾的单词的个数。</p>
<p>所以不可能有son[1][2]和son[1][3],不对有的，这里是指针</p>
<h1 id="并查集">7. 并查集</h1>
<ul>
<li>将两个集合合并</li>
<li>询问两个元素是否在一个集合中 BF: belong[x],
判断两个元素是否在一个集合belong[x]==belong[y];合并需要将一个集合中的所有元素改为另一个
并查集在近乎O(1)的时间内快速支持两个操作。</li>
</ul>
<blockquote>
<p>原理：用树来做，树根的编号就是整个集合的编号。每个节点存储它的父节点，p[x]表示x的父节点
问题1. 如何判断树根，if(p[x]==x): 特殊情况的处理 问题2.
如何求x的集合编号：while(p[x]!=x) x=p[x]; 时间复杂度
问题3，如何合并两个集合： p[x]是x的集合，p[y]是y的集合，则p[x]=y;</p>
</blockquote>
<p>路径压缩优化：当找到根节点时，把路径上的所有节点都指向根节点. O(1)
&gt;
这里也可以应用一个简单的启发式策略——按秩合并。该方法使用秩来表示树高度的上界，在合并时，总是将具有较小秩的树根指向具有较大秩的树根。简单的说，就是总是将比较矮的树作为子树，添加到较高的树中。为了保存秩，需要额外使用一个与
uset 同长度的数组，并将所有元素都初始化为
0。这样找祖先会减少递归迭代的次数，最坏只有logN次。 暂时这里不采用！</p>
<p>代码核心最关键的就是find()函数！！！</p>
<blockquote>
<p>集合合并的所有问题都可以用
看题目中哪些操作可以优化，考虑什么时候用什么数据结构；操作有什么特点，最小值，堆。
区间和啊， 区间数组，树状数组，线段树！！ 有序链表，平衡树，set来做</p>
</blockquote>
<h1 id="堆">8. 堆</h1>
<p>如何手写一个堆？stl - 插入一个数 - 求集合中的最小值 - 删除最小值</p>
<p>扩展 - 删除任意一个元素 - 修改任意一个元素</p>
<blockquote>
<p>stl中的堆就是优先队列！！priorityqueue 小根堆
从1开始编号，2i表示左孩子节点，2i+1表示右孩子节点 基本操作 down(x){} //
往下移，跟孩子中最小的进行交换。说明最上面的数变大了所以要往下沉，那么是否无法交换了就说明没有必要往下移动了。
up(x){} // 往上移，只需要与根节点进行比较</p>
</blockquote>
<p>变小往上走，变大往下走</p>
<p>数据结构 heap,size</p>
<ul>
<li>插入一个数： heap[++size]=x,up(size)</li>
<li>求最小值： heap[1]</li>
<li>删除最后一个元素: heap[1]=heap[size], size--,down(1);</li>
<li>删除任意一个元素： heap[k]=heap[size],
down(k),up(k)(只执行一个);</li>
<li>修改任意一个元素: heap[k]=x,down(k),up(k) 完全二叉树。</li>
</ul>
<blockquote>
<p>堆排序，把数列建成一个堆，每次把堆顶元素输出</p>
</blockquote>
<ul>
<li>如何建堆？ &gt; 一个一个将数进行插入 nlogn. &gt; O(n),
从n/2开始down到1. n/4+ 2<em>n/8+3</em>n/16 +...=O(n) &gt;
从下往上down可以保证每个儿子都是好的</li>
</ul>
<p>模拟堆， 删除第k个插入的点 &gt; ph[j]=k
第j个插入的点在堆中对应第k个元素 &gt; hp[k]=j
堆中第k个元素对应第j个插入的点 需要存储映射</p>
<h1 id="哈希表">9. 哈希表</h1>
<h2 id="简介">9.1 简介</h2>
<ul>
<li>存储结构 开放寻址法、拉链法</li>
<li>字符串哈希方式</li>
</ul>
<blockquote>
<p>N: 1e5 ,1e6 把值域大的数映射到值域比较小的数 1.
哈希函数，模的数为质数，距离2的整数幂远，数学证明了冲突概率是最小的 2.
冲突 cstring: memset</p>
</blockquote>
<blockquote>
<p>感觉上</p>
</blockquote>
<blockquote>
<p>注意，哈希表能使实际求的时候时间复杂度变低，但是并不意味着空间大小会变小</p>
</blockquote>
<h3 id="方法">9.2 方法</h3>
<h4 id="开放寻址法厕所找坑位法">9.2.1 开放寻址法（厕所找坑位法）</h4>
<p>查找、删除、添加
如果都满了的话find会陷入死循环，但是经验上来说会用2,-3倍的空间大小。
INT_MAX=0x3f3f3f3f; memset()按字节，不能处理vector，
strcopy()遇到<code>\0</code>就结束。 &gt; 哈希表时间复杂度都是O(1)，
用到哈希表O(n). &gt;
不需要sort一遍，如果sort就会从O(n)-&gt;O(nlogn)，变慢</p>
<blockquote>
<p>对比前面的离散化的思想，不过离散化区间和那道题实际上运用了前缀和来做。
#### 9.2.3 字符串哈希方式
对比与KMP，用于查找模板串是否存在，不一定要用KMP算法。</p>
</blockquote>
<p>字符串前缀哈希 h[1]="A" h[2]="ABC" &gt; h[n]:
表示前n个字符串的哈希值； h[0]=0;</p>
<h5 id="问题">问题：</h5>
<ol type="1">
<li>如何定义某个前缀的哈希值？把字符串转化为数字！
把字符串看作是P进制的数（Godel编码） 如"ABCD", 注意需要保证唯一性！！！
对应十进制的数：1<em>p^3 + 2</em>p^2 + 3<em>p^1 + 4</em>p^0</li>
<li>这个数会很大，进行取模, 这里Q会远小于数值: mod Q</li>
</ol>
<p>结果将任何一个字符串映射为了0 ~ Q-1.</p>
<p>注意！ 不能把某一位的字母映射为0, 需要映射为从1开始的数。
假定人品足够好，不考虑冲突；经验值是p取131或13331, Q取2^64,unsigned long
long,
所以就不需要取模了，任意一个数都会自动溢出，在绝大概率保证不会出现冲突。</p>
<p>好处： 可以求出字符串所有子串的哈希值：所以就可以用来作字符串的查找
字符串：[l,r]的哈希值h[r]-h[l-1]*p[r-l+1] &gt;
把所有的看成数位，所以每个数段都有其哈希值。那么，因为最高位当做零位就意味着位数一定？？不需要！！！
因此就可以在线性时间内求出每一段的哈希值。</p>
<p>讨论预处理， h(i)=h(i-1)+str(i); &gt;
因为这里h()相当于取Q的模，所以h就是没有操作 ##### 想想
这里就是超级牛逼的，比KMP还厉害很多！ 问某两端是否完全相同</p>
<p>这里感觉上利用了前缀和的思想以及其他，将字符串通过Godel编码（数的进制的方式），映射为数。
因为每一个前缀都是唯一的，所以必然就前缀唯一 ？？
那怎么知道这多个前缀是否是某一特定的字符串的呢？还有怎么插入数据的？</p>
<p>等下这里完全就没有了哈希的概念！！，它是制定了规则。不是前缀树，需要插入一系列字符串进行查找某个字符串是否存在。
就是根据规则，进行计算数就行了，就比较某个区间的计算出来的结果是否相同</p>
<p>但是，预处理的话，一位是对应着多种结果啊，这些是要事先计算出来吗？</p>
<h5 id="作用">作用</h5>
<p>快速比较两个字符串是否相等。 O(n), O(1)</p>
<p>可解的题： 搜索哈希，直接搜 兔子 回文串 后缀数组 二维哈希</p>
<p>KMP可以用来求循环节。</p>
<h1 id="stl初步">10. STL初步</h1>
<p>vector, string ,queue, priority_queue, stack, dequeue,
set,map,multiset,multimap unordered_set, .... //
c++中实现的哈希表？？？？ bitset 状态压缩</p>
<p>vector 变长数组，倍增思想。 string substr(),
c_str()//对应char数组指针 queue 队列 push， front, pop priorityqueue,
堆，优先队列，push, top(),pop() stack, push, top, pop() dequeue双端队列,
支持随机访问； set,map, 基于平衡树（红黑树）来实现的，动态维护有序序列
unordered, 基于哈希表来实现的 &gt; 需要添加对应的头文件</p>
<p>bitset, 压位 List</p>
<p>set: find() O(n) C++ vector基本用法</p>
<h2 id="vector">vector</h2>
<p>vector<int> a(10,n); size() // O(1) empty() //返回 clear() 特有
系统为某一个进程分配空间时，所需时间与空间大小无关，与申请次数有关。
所以1000和1000次1不一样 倍增的思想</p>
<p>申请一个数组长度n=10^6, 一共要申请logN次，额外copy次数平均为1 front()
back() push_back() pop_back() begin() end() [] a.end()=a[size]
迭代器可以看成是指针 a&lt;b, 支持比较运算，基于字典序</p>
<h2 id="pair">pair</h2>
<p>pair&lt;int,int&gt; p; p.first(), p.second();
支持比较预算，按字典序，以first为第一关键字，second为第二关键字
p=make_pair(10,"yxc") C++11: p={20,"abd"} &gt; 某个东西有两种属性 &gt;
三种不同的属性pair&lt;int, pair&lt;int,int&gt;&gt;</p>
<blockquote>
<p>pair vs struct, 比一般的结构体 string可以用作栈 ## string size()
length() empty(), clear() a+="def", a+='c'; a.substr(0,2) 起始地址，长度
a.c_str()</p>
</blockquote>
<h2 id="queue">queue</h2>
<p>size(), empty(), 没有clear()函数q=queue<int>(); push(), front(),
back(), pop()</p>
<h2 id="priority_queue默认大根堆">priority_queue默认大根堆</h2>
<p>push() 插入一个元素 top() 返回堆顶元素 pop() 弹出堆顶元素
无clear元素</p>
<p>如何使用小根堆？ 插入时使用负数
priority_queue&lt;int,vector<int>,greater<int>&gt; heap; //
定义小根堆</p>
<h2 id="栈">栈</h2>
<p>push, top,pop,size, empty</p>
<h2 id="deque">deque</h2>
<p>效率非常低 size(), empty(), clear() front()/back()
push_back()/pop_back() push_front()/pop_front() begin()/end() [] ##
set/multiset,map/multimap size() empty() clear() O(1) set/multiset
O(logN) insert() 插入一个数 find() 查找一个数 count() 返回某一个数的个数
begin()/end() ++, --返回前驱和后继 O(logN) erase() (1)
输入是一个数，删除所有x, O(k+logn) (2) 输入是一个迭代器, 删除这个迭代器
lower_bound()/upper_bound() !!!! lower_bound()
返回大于等于x的最小的数的迭代器 upper_bound()
返回大于x的最小的数的迭代器，不存在返回end() map/multimap insert()
插入的是一个pair erase() 输入的参数是pair或迭代器 find() []
时间复杂度是O(logN)?? &gt; map&lt;string,int&gt; a; a["yxc"]=1
lower_bound(), upper_bound() &gt; 支持排序</p>
<p>unordered_set,unordered_map,unordered_multiset, unordered_multimap
和上面类似，增删改查的时间复杂度均为O(1)
但是不支持lower_bound()/upper_bound(), 迭代器的++,-- &gt;
凡是排序的都不支持</p>
<p>bitset() &gt; 1024 bool, 1024B=1KB; 用字节来存 1024/8=128 &gt;
什么时候用？ 比如10000*10000 bool, 10^8 B, 100MB, 空间限制是64MB
biset&lt;10000&gt; s; //这里10000指的是个数 ~s取反， &amp;, |, ^
&gt;&gt;, &lt;&lt; ==, != [] 某位 count() 返回有多少个1 any/none()
any()判断至少有一个1 none()判断是否全为0 set() 把所有位置为1 set(k,v)
将第k位变为v reset() 把所有为变为0 flip() 把所有位取反 flip(k)
把第k位取反</p>
<h2 id="注意">注意</h2>
<p>scanf读char时有空格和回车不能处理，读字符串可以进行过滤</p>
<p>比较序列中两个元素的某个关系的最值，如果该关系是双方等价的，那么可以不用存储该元素的数组
先插入再查询可以避免处理空，只是多一个时间复杂度</p>
<p>每次做题前把思路想清楚！！</p>
<p>思考回溯法，在循环前加入语句和循环后加入语句的区别有什么呢</p>
<p>模运算很有意思！！</p>
<p>路径的距离来做</p>
<p>if (a &amp;&amp; b), 注意是b不等于0时为真</p>
<p>segment flase: N常数空间开辟不对，或者循环溢出等等 ## 课后题 ###
最大异或数</p>
<blockquote>
<p>发现这里的思路跟我自己想的还是有很大差别，比如说我的想法就是直接分析题。怎么得到一组数中所有的最大的异或数。
这里的做法就是O(n<sup>3)-&gt;O(n</sup>2) 记住一定要从暴力解开始出发
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Trie树来做</span><br><span class="line">int res=0;</span><br><span class="line"></span><br><span class="line">// a1,a5;a5,a1; 规定小于数</span><br><span class="line">for(int i=0;i&lt;n;i++)&#123; // 枚举第一个数</span><br><span class="line">    for(int j=0;j&lt;r;j++)&#123;  // 试图找最大的数</span><br><span class="line">        max=res(max,ai^aj);</span><br><span class="line">    &#125; // 枚举第二个数</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">首先考虑如何寻找最大的异或数。 </span><br><span class="line">首先找第30位是0的数</span><br><span class="line">倒序找数</span><br></pre></td></tr></table></figure>
注意这里M的取值是看实际情况中Trie树中最多有多少个节点，所以要看多种情况来做。
每个叶节点代表一个集合，表示所有能往下走的数。</p>
</blockquote>
<blockquote>
<p>与一开始想法不同的点是，倒序排序的，把所有树给撑满，自己的想法这点出问题了
举例子</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">res= res*2+u;</span><br><span class="line">res +=1&lt;&lt;i;</span><br><span class="line"></span><br><span class="line">res=1101 -&gt; 11011  二进制乘法的感觉</span><br></pre></td></tr></table></figure>
<h3 id="食物链">食物链</h3>
<blockquote>
<p>首先应该分析题，发现题中种类关系是如此少，以至于所有关系放在一个类中即可</p>
</blockquote>
<blockquote>
<p>哇，居然从路的路径长度入手来看，nb。
由距离进行定义，使用模的关系！！厉害，看每个人和领袖之间的距离关系
所以说，构造的时候实际上使用的增加最小长度的路径</p>
</blockquote>
<blockquote>
<p>三类，吃、被吃、同类</p>
</blockquote>
<p>算法 &gt; 初始化，每个节点都是根节点，所以初始化为0</p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>acwing</category>
        <category>basic</category>
        <category>data-struture</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>acwing</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm acwing dp</title>
    <url>/2019/algorithm-acwing-dp-9d33371c6027/</url>
    <content><![CDATA[<p>转换为背包问题 线性DP, 区间DP, 计数类DP， 数位统计DP, 状态 压缩DP,
树形DP, 记忆化搜索</p>
<ol type="1">
<li>01背包 N, V vi, wi &gt; 每件物品仅用一次</li>
</ol>
<p>总体积一定的时候求最大价值</p>
<ol start="2" type="1">
<li><p>完全背包问题 每件物品有无限个</p></li>
<li><p>多重背包问题 每个物品有si个 优化</p></li>
<li><p>分组背包问题 物品有n组，每组有若干个。
每组中最多选一个。</p></li>
</ol>
<h1 id="dp问题">1 DP问题</h1>
<h2 id="基本形式">1.1 基本形式</h2>
<blockquote>
<p>问题是什么？从n个物品中选，体积为V的最大价值。 所求一般为函数值。</p>
</blockquote>
<h3 id="状态表示fij">1.1.1 状态表示f(i,j)</h3>
<ol type="1">
<li>集合： 考虑的是状态的哪一个集合， 所有选法的一个集合 条件</li>
</ol>
<ul>
<li>只从前i个物品选</li>
<li>选出来的物品总体积小于等于j</li>
</ul>
<ol start="2" type="1">
<li>属性： Max, Min, 数量</li>
</ol>
<blockquote>
<p>f[n,v]即所求</p>
</blockquote>
<h4 id="状态计算-如何一步步地把每个状态算出来">1.1.2 状态计算：
如何一步步地把每个状态算出来</h4>
<p>集合划分：如何转化为更小的集合 &gt; 划分有什么方法吗？？？
这里是对第i个分析，然后对前面的方法进行 &gt;
每个问题有多种理解方式，尽量往简单走</p>
<p>原则：
不重复（某个元素属于某一个特定集合），不漏（每个元素必须都给分配了）
&gt;
一般情况只要满足不漏就可以，如果是对元素个数考虑则要满足不重复的原则</p>
<p>f(i,j): 含i 和 不含i 不含i: i-1, j f(i-1, j) 含i： i-1, j-wi
f(i-1,j-wi)+wi</p>
<p>f(i,j) = max(f(i-1,j), f(i-1,j-vi)+wi ) 发现这里i-&gt;(i-1),
所以只需要考虑i-1的状态就可以，f(0,j)=0</p>
<blockquote>
<p>f(i,j) 只用到了f(i-1,j) j-vi&lt;=j. 可以用滚动数组来做</p>
</blockquote>
<p>f[j] =max(f[j], f[j-v[i]]+w[i]); //
当前有可选和不可选两种情况，单背包的01问题 &gt;
为什么对j循环，因为需要对不同的容量进行循环判断</p>
<blockquote>
<p>i-&gt; i-1, 变小的，正序 j-&gt; j-v[i], 反向</p>
</blockquote>
<h4 id="优化对代码或计算方程做等价变形">1.1.3
优化：对代码或计算方程做等价变形</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int i=1;i&lt;=n;i++)</span><br><span class="line">    for(int j=0;j&lt;=m;j++)&#123;</span><br><span class="line">        f[i][j] =f[i-1][j];</span><br><span class="line">        if(j&gt;=v[i]) f[i][j] =max(f[i][j], f[i-1][j-v[i]]+w[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">for(int i=1;i&lt;=n;i++)</span><br><span class="line">    for(int j=m;j&gt;=v[i];j--)&#123;</span><br><span class="line">        f[j] =max(f[j], f[j-v[i]]+w[i]); //f[i-1][j-vi]-&gt;f[j]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&gt; 正常顺序下把f[i-1][j-v[i]]变成f[j-v[i]], 有问题，因为需要保证它是i-1层循环做的事情。而对于i层，如果j递增，那么在f[j]之前， f[j-v[i]]就已经被更新了； 所以这里使用反向，可以保证用到的就是上一层更新的内容，妙！！</span><br></pre></td></tr></table></figure>
<p>滚动数组</p>
<p>f(i)-&gt;f(i-1) &gt;
那么考虑用f(2,N)来表示，那么就只用了两维就对原始问题进行了解释。就很方便，空间容量就下降了</p>
<h1 id="背包问题">2 背包问题</h1>
<h2 id="背包问题-每件物品只能选一个">2.0 01背包问题：
每件物品只能选一个</h2>
<p>i, v, max_w 2维 f[i,j] 状态表示 - 集合：
所有只考虑了前i个物品，其总体积不大于j的所有选法的集合 - 属性：Max
状态计算 - 集合分解 看第i个物品选或不选</p>
<p>时间复杂度 状态数量<em>每个状态所耗的时间 n^2 </em> 1</p>
<h2 id="完全背包问题每件物品可以选任意个">2.1
完全背包问题：每件物品可以选任意个</h2>
<h3 id="状态表示">1. 状态表示</h3>
<p>集合：所有只考虑了前i个物品，且体积不大于j的所有选法 属性:Max</p>
<h3 id="状态计算">2. 状态计算</h3>
<p>集合的划分 f[i,j]:0,1,2,...,k &gt;
第i个物品选多少个？k这里有体积进行限制</p>
<p>f[i-1,j] 曲线救国： 1. 去掉k个物品i 2. 求Max, f[i-1,j-k*v[i]] 3.
再加回来k个物品i f[i-1,j-k*v[i]] + k*w[i].</p>
<p>f[i][j]=max(f[i][j], f[i-1][j-v[i]*k]+k*w[i]);</p>
<p>// 三重循环</p>
<h3 id="优化">3. 优化：</h3>
<p>f[i,j] = Max(f[i-1,j], f[i-1,j-v]+w,f[i-1,j-2v]+2w,...)
f[i,j-v]=Max(f[i-1,j-v], f[i-1,j-2v]+w,...)</p>
<p>发现 f[i,v]=Max(f[i-1,j], f[i,j-v]+w);</p>
<blockquote>
<p>为什么不用单调队列来优化？因为这里不是求滑动窗口的最大值，所以没有必要</p>
</blockquote>
<h2 id="多重背包问题每件物品最多可以选k个">2.2
多重背包问题：每件物品最多可以选k个</h2>
<p>f[i,j] ### 2.2.1 状态表示
集合：所有只从前i个物品中选，且总体积不超过j的选法</p>
<p>属性：最大值</p>
<h3 id="状态计算-1">2.2.2 状态计算</h3>
<p>集合划分 &gt; 第i个物品最多选多少个 f[i,j] = max(f[i-1,j-kv]+kw)
k=0,1,2,...,s[i]</p>
<h3 id="优化-1">2.2.3 优化</h3>
<p>f[i,j] = Max(f[i-1,j],
f[i-1,j-v]+w,f[i-1,j-2v]+2w,...,f[i-1,j-sv]+sw) f[i,j-v]=Max(f[i-1,j-v],
f[i-1,j-2v]+w,..., f[i-1,j-(s+1)v]+(s+1)w)</p>
<p>二进制的优化方式 s=1023</p>
<p>1,2,4,8,...,512</p>
<p>0~1023 &gt;
把多种背包某个物品有s次，转化为logS的物品的01背包问题，因此可以拼凑出问题的解</p>
<p>注意这里的凑数，最后一个是剩余的解 如 s=200 1,2,4,8,16,32,64,73</p>
<p>1~127 73~200 所以只凑出了0-200的解</p>
<p>s 1,2,4,8,..,2^k,c c=s-(2^{k+1}-1)</p>
<p>c&lt;2^{k+1} s&lt;=2^{k+2}-1;</p>
<p>优化步骤 总物品数：NlogS 时间： VNlogS</p>
<h2 id="分组背包问题">2.3 分组背包问题</h2>
<h3 id="状态表示-1">2.3.1 状态表示</h3>
<ul>
<li>集合： 只从前i组物品中选，且总体积不大于j的所有做法</li>
<li>属性： Max</li>
</ul>
<h3 id="状态计算-2">2.3.2 状态计算</h3>
<p>f[i,j] 集合划分,对第i个组怎么操作？</p>
<p>对于第i组，不选，选第1个物品，选第2个物品，..., 选第k个物品</p>
<p>f[i-1,j] , f[i-1, j-v[i,k]] + w[i,k] k</p>
<blockquote>
<p>用的是上层状态则从大到小枚举，用的是本层状态则从小到大枚举</p>
</blockquote>
<h1 id="线性dp">3 线性DP</h1>
<h2 id="数字三角形">3.1 数字三角形</h2>
<h3 id="状态表示-2">3.1.2 状态表示</h3>
<p>f[i,j] - 集合 所有从起点，走到(i,j)的路径</p>
<ul>
<li>属性： Max</li>
</ul>
<h3 id="状态计算-3">3.1.2 状态计算</h3>
<p>f[i,j]</p>
<p>集合分类: 往前追溯 来自左上方，来自右下方 &gt; 曲线救国？ &gt; f[i,j]
= max(f[i-1,j], f[i-1,j-1]) + a[i,j] &gt; 下标涉及到i-1，从1开始</p>
<p>时间复杂度：状态数量<em>转移的计算量 n^2 </em> 1</p>
<h2 id="最长上升子序列">3.2 最长上升子序列</h2>
<ul>
<li>维度选取标准 &gt; 目标：从小到大考虑维度是否合适 ### 3.2.1 状态表示
f[i] 集合：所有以第i个数为结尾上升子序列的集合 属性：集合长度的Max &gt;
关键！一定要把集合说明白和清楚，突然明白了为什么要这么说？</li>
</ul>
<h3 id="状态计算-4">3.2.2 状态计算</h3>
<p>f[i]： 集合划分 &gt; 考虑多种划分思想
对上升子序列的集合进行划分，如何讨论</p>
<p>首先，一定把第i个元素放入，那么这个上升子序列的集合是哪个呢？对0,1,2,..,i-1元素进行讨论
aj &lt;= ai, j: 0~i-1 f[i] = max(f[j]+1) j=0, f[0]=1;</p>
<ul>
<li>时间复杂度 状态数量*转移的计算量, n*n</li>
</ul>
<blockquote>
<p>记录转移位置：为最大值进行标记
这里的感觉是潜在的状态转移方程的感觉</p>
</blockquote>
<h3 id="优化-2">3.2.3 优化</h3>
<p>考虑求的过程是否有某种性质？在计算过程中是否有重复计算 k:1 2 3 4 5 6
7 a:3 1 2 1 8 5 6</p>
<p>思考3和1的情况，凡是能接到3后面的序列，一定可以接到1后面</p>
<p>所以考虑换个角度，即对每个长度，存储索引k小的位置
随着长度增加，结尾的值一定是单调递增的</p>
<blockquote>
<p>目标：找某个衡量值的单调性，比如这里的ai的单调性。一旦有了单调性就可以进行存储，就可以用二分法来做，就会大大地提升速度。</p>
</blockquote>
<blockquote>
<p>直接将ai更新到q就可以</p>
</blockquote>
<p>从某种程度上更像贪心一点！ nlogn</p>
<p>直接求解问题 ## 3.3 最长公共子序列
从两个长度为N和M的字符串A和B，求既是A的子序列又是B的子序列的字符串最长子序列</p>
<h3 id="状态表示-3">状态表示</h3>
<p>f[i,j]</p>
<p>集合：所有由第一个序列的前i个字母和第二个序列的前j个字母构成的最长公共子序列</p>
<p>属性： Max</p>
<h3 id="状态计算-5">状态计算</h3>
<p>f[i,j] 集合划分 标准，是否选a[i],b[j] &gt; 00 f[i-1,j-1] 01
f[i-1,j-1]+1 : 以b[j]结尾 &gt; f[i-1,j]
不代表这种情况，因为b[j]不一定为结尾 &gt; 01 包含在f[i-1,j]中，
f[i-1,j]包含在f[i,j]中 10 &gt; f[i,j-1] 11 f[i-1,j-1] + 1</p>
<blockquote>
<p>然后我们可以用f[i-1,j],f[i,j-1]替换01， 10；
此时这两种情况与00会有重叠，但是没有关系
因为包含了f[i-1,j],f[i,j-1]包含了00， 所以一般就不写f[i-1,j-1]这种情况
因为max是不需要分开的部分独立的，比如求三个数的最大值，max(a,b,c)=max(max(a,b),max(b,c)),
b用了两次</p>
</blockquote>
<p>int a+1; abcd拼成的整数的存储</p>
<h2 id="最短编辑距离">3.4 最短编辑距离</h2>
<ul>
<li><p>状态表示 f[i,j] 集合：所有将a[1~i]变到b[1~j]的操作方式的集合,
操作方式有插入、删除、替换 属性：集合的长度的最小值</p></li>
<li><p>状态计算 f[i,j] 集合划分 可以从集合的最后一步考虑:</p>
<ul>
<li>删除， a[1,i-1]与b[1,j]匹配 len(a)=len(b)-1,
但是这里是动态变化的，所以没有必要进行这个当前len的判断，f[i-1,j]+1</li>
<li>添加一个新字母， a[i+1]=b[j], 添之前a[1,i]与b[1,j-1]匹配
len(a)=len(b)+1 f[i,j-1]+1</li>
<li>改， a[i]!=b[j], f[i-1,j-1]+1</li>
</ul></li>
</ul>
<p>时间复杂度 n^2 *3</p>
<blockquote>
<p>动态规划是暴力的优化，用内存存储了一些需要计算的内容，不再需要暴力枚举每一个。但还有优化的空间，什么呢？就是没有保证某个计算只是一个
# 4. 区间DP</p>
</blockquote>
<h2 id="石子合并">4.1 石子合并</h2>
<p>一堆石子，每次合并都会包含一定的代价，问如何合并，体力消耗最小；
类似于大整数相乘的感觉</p>
<h3 id="状态表示-4">状态表示</h3>
<p>f[i,j]: i,j表示的区间的开始长度和结束长度</p>
<p>集合：所有将第i堆石子到第j堆石子合并成一堆石子的合并方式</p>
<p>属性：Min, 合并方式的代价的最小值</p>
<h3 id="状态计算-6">状态计算</h3>
<p>f[i,j]</p>
<p>集合划分 以最后一次合并的分解线来合并</p>
<p>左边k-i+1， 右边j-k+1 [i,k], [k+1,j]</p>
<p>f[i,j] = max_k (f[i,k]+f[k,j]+pj); k=i,..,j-1</p>
<blockquote>
<p>前缀和，来表示区间和 时间复杂度： n^2 n 300^3=2.7*10^9</p>
</blockquote>
<p>每次可以合并m堆 目标是枚举一次合并，用暴力，C_k^{m-1}堆，
总共有m-1个划分位置 &gt;
问题其实可以进一步转化为将一个区间分为m份，如何划分最优，使用dp来做，g(i,j)将前i个数分为j组的最小代价
n^3 *m</p>
<blockquote>
<p>注意计算的顺序，计算方式所依赖的状态应该先计算出来才行</p>
</blockquote>
<blockquote>
<p>动态规划有两个写法：
递归方式的学名叫记忆化搜索，循环方式为常见写法，会快一个常数
区间长度的DP一般循环方式有两个，一个
动态规划用一个状态表示一堆状态的集合， dfs遍历的则是每一个状态；</p>
</blockquote>
<p>C++一般可以算10^7, 10^8</p>
<h1 id="计数类dp">5. 计数类DP</h1>
<blockquote>
<p>属性是数量</p>
</blockquote>
<h2 id="整数划分问题">5.1 整数划分问题</h2>
<h3 id="解法1">解法1</h3>
<p>无序的 物品：n 物体的体积：1,2,..,n 每个物品可以放任意次 -&gt;
完全背包问题 把复杂的问题转化为简单的已知的问题</p>
<ul>
<li>状态表示 集合：所有从1~i中选，和恰好是j的集合 属性：数量</li>
<li>状态计算 i-1 选多少个 j=n f(i-1,j)+ sum_k f(i-1,j-k*i) 即：
f[i,j]=f[i-1,j]+f[i,j-v[i]]</li>
</ul>
<p>时间复杂度 当体积是i是，k=n/i k1+k2+...+kn = lnn+c; 时间复杂度为
nlogn</p>
<p>进一步简化 注意这里属性是长度，所以 f[j] = (f[j]+f[i-j]) mod p;
这里就直接是相加，也就是为什么需要分类互斥了</p>
<h3 id="解法2">解法2</h3>
<p>f[i,j] 集合：所有总和是i，并且恰好表示为j个数的和的方案
属性：数量</p>
<p>集合划分 最小值是1 f[i-1,j-1] 最小值大于1 f[i-j,j] &gt;
这里不是考虑这个最小值为多少，而是不断去逼近这个最小值 f[i-j,j]
将每个数都减1,其方案数应该一样 f[i,j] = f[i-1,j-1] + f[i-j,j]
ans=f[n,1]+f[n,2]+f[n,3]+...+f[n,n]</p>
<h1 id="数位统计dp">5. 数位统计DP</h1>
<h2 id="计数问题">5.1 计数问题</h2>
<p>统计两个整数数位之间0~9的出现次数 数据范围 0-1e8 &gt;
小学奥数问题</p>
<p>分情况讨论 [a,b] 0~9</p>
<p>count(n,x) 1~n中x出现的次数</p>
<p>count(b,x)-count(a-1,x) &gt;
当问题区间不好求时，经常的一种思路就是使用前缀和的思路</p>
<p>分别求出1在每一位上出现的次数</p>
<p>求1在第4位上出现的次数 1&lt;= xxx1yyy &lt;= abcdefg</p>
<p>按前3位取值来分类的： 1) xxx=001~abc-1, yyy=000~999, *1000 2) xxx=abc
d&lt;1, abc1yyy&gt;abc0efg, 0 d=1, abc1, yyy=0~efg, efg+1 d&gt;1, abc1,
yyy=0~999, 1000</p>
<p>所有情况 abc<em>1000 + 0 + efg+1 + 1000 = (abc+1)</em>1000 +
efg+1</p>
<p>因此可以求出1在任意一位出现的次数</p>
<p>时间复杂度：10组数据，每组2个数，每个数有8位，最多循环10次</p>
<p>实际例子： 从1~111 0出现的次数</p>
<p>对于111的例子: 1. 统计个位上的0, 十位去01-10 10</p>
<h1 id="状态压缩dp">6. 状态压缩DP</h1>
<blockquote>
<p>状态是一个整数，却要将其看成一个二进制数</p>
</blockquote>
<h2 id="蒙德里安的梦想">6.1 蒙德里安的梦想</h2>
<p>状态压缩的经典应用</p>
<blockquote>
<p>可以横着放，也可以竖着放
横着放完后，竖着摆放小方格就确定了，只有一种情况。所以考虑横着放置的小方格的情况</p>
</blockquote>
<p>f[i,j] 现在要摆第i列 j是哪一列申出了小方格 j 0~31,
5位二进制数？？？</p>
<p>这里是状态，所以就是数量进行相加</p>
<p>每一种选取都是一种方案数，下一个状态加上现在的状态所以就构成了问题的最后的结果，并且保证每次的状态都是一定的</p>
<blockquote>
<p>检查，先看状态是否是对的！这种做法很优秀！！</p>
</blockquote>
<h2 id="最短hamilton路径">6.2 最短Hamilton路径</h2>
<p>0~n-1, 从0到n-1不重不漏地恰好经过每个点一次</p>
<p>n!n &gt; 乘以路径的长度，为什么是n？ 20! * 20 时间复杂度非常高</p>
<p>跟上个题一样，用一个整数表示一个状态</p>
<p>f[i,j]</p>
<ul>
<li>状态表示 集合：所有从0走到j，走过的所有点的状态是i的所有路径的长度
&gt; i是二进制数，表示所有点的状态数 &gt; 0到j，j是具体哪个点的标号</li>
</ul>
<p>属性：Min</p>
<ul>
<li>状态计算 f[i,j] 集合划分 倒数第二个点来分类 0-&gt;k-&gt;j f[i,j] =
min_k f[i-{j},k] + a[k][j]</li>
</ul>
<blockquote>
<p>这里为什么用状态压缩，而没有用其他情况来做，因为这里的走到j节点，不一定从小的点走到，可能从更多的大的点走到</p>
</blockquote>
<h1 id="树形dp">7. 树形DP</h1>
<h2 id="没有上司的舞会">7.1 没有上司的舞会</h2>
<p>f[u,0] 集合： 所有从以u为根的子树中选择，并且不选u这个点的方案
f[u,1]: 所有以u为根的子树中选择并且选择u这个点的方案</p>
<p>属性： Max</p>
<p>u-&gt; s1,s2 f(u,0) = sum_s max((f(s1,0), f(s1,1)) f(u,1) = sum_s
f(s1,0) + a(u) &gt; 这里sum
实际上求的就是边，所以计算量就是枚举所有的边，而对于树的所有边之和为n-1.
即u的范围为n-1, 每个单位为2， 即为常数 因此复杂度为O(n)</p>
<blockquote>
<p>树形DP的感觉就是，其实关心还是两个状态之间的关系，不过这里的状态转换为了树。
考虑当前与上一节点的关系，就相当于考虑父节点与子节点之间的关系</p>
</blockquote>
<h1 id="记忆化搜索">8. 记忆化搜索</h1>
<h2 id="滑雪">8.1 滑雪</h2>
<ul>
<li>状态表示 f[i,j] 所有从(i,j)开始滑的路径</li>
</ul>
<p>Max - 状态计算 f[i,j] 按第一步开始滑的路径 按方向分 f[i,j] i,j -&gt;
i,j+1 f[i,j+1]开始滑的最大长度</p>
<blockquote>
<p>拓扑图，不能成环； 怎么判断实际的情况？</p>
</blockquote>
<p>注意到记忆化搜索代码很有意思</p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>acwing</category>
        <category>basic</category>
        <category>dp</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>acwing</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm acwing greedy</title>
    <url>/2019/algorithm-acwing-greedy-81d4cce0967a/</url>
    <content><![CDATA[<h1 id="贪心">贪心</h1>
<p>无套路而言，最难的是证明其正确性</p>
<p>试下还是有套路的 一般来说，举例看是否能证明正确性</p>
<p>一般区间问题，先排序 1. 按区间左右端点排序，或者双关键字排序</p>
<h2 id="区间选点">区间选点</h2>
<blockquote>
<p>数轴选最少的点覆盖所有的区间</p>
</blockquote>
<ol type="1">
<li>将每个区间按右端点从小到大排序</li>
<li>从前往后依次枚举每一个区间 如果当前区间已经包含点，则直接pass
否则，选择当前区间的右端点</li>
</ol>
<p>A=B A&lt;=B A&gt;=B</p>
<p>Ans问题的最优解 ans实际问题的解 最小值</p>
<p>Ans &lt;= cnt &gt; cnt是一种可行方案，而Ans是所有可行方案中最小的。
显然! Ans &gt;= cnt &gt;
找到了cnt相互没有交集的区间，每选一个点最多覆盖一个区间。所有可行解必定大于cnt
&gt; 关键证明，算法得到的是最基本的情况！！！</p>
<h2 id="最大不相交区间数量">最大不相交区间数量</h2>
<p>贪心策略： 按右端点选取 最大值</p>
<p>Ans &gt;= cnt: 证明cnt是可行方案， Ans &lt;= cnt: 假设Ans&gt;cnt,
反证法</p>
<p>Ans选择出的是两两没有交集的区间，那一定被第一题的解给覆盖，所以Ans应该&lt;=cnt的.
所以矛盾</p>
<blockquote>
<p>考虑问题的转化，记住简单问题证明的模板，把其他复杂的问题转化成原本的问题</p>
</blockquote>
<h2 id="区间选组">区间选组</h2>
<p>贪心：左端点 1. 将所有区间按左端点从小到大排序 2.
从前往后处理每个区间 判断能否将其放到某个现有的组中 如果L[i]&lt;=
min{r},则不能加入，于是建立新组；否则加入并更新</p>
<p>考虑数据结构:</p>
<p>问题： 最小组数 证明： 1. Ans &lt;= cnt cnt是可行解,
每个组内都没有交集 2. Ans &gt;= cnt 当与任何一个区间都没有交集</p>
<p>cnt-1 Max_r &gt;= Li. 因为是按L排序，所以Li&gt;=L0~i-1</p>
<p>意味着整个cnt组都有公共点，所以对这些基本的组来说，问题的解至少得花cnt,
因此Ans&gt;=cnt</p>
<blockquote>
<p>练习题 https://www.acwing.com/problem/content/113/</p>
</blockquote>
<blockquote>
<p>左端点相交的最大个数，右端点不相交的最大个数 再练习一遍</p>
</blockquote>
<h2 id="区间覆盖">区间覆盖</h2>
<p>用最少的区间将给定区间排序</p>
<p>贪心：将左端点从小到大排序</p>
<ol type="1">
<li>将所有区间从左端点从小到大排序</li>
<li>从前往后依次枚举每个区间，在所有能覆盖start的区间中，选择一个右端点最大的区间;
此时更新新的start点</li>
</ol>
<p>Ans&lt;=cnt: 假设有解,
因为我们每次选择区间都是没有空隙的，所以一定能找到方案成为可行解。因此成立</p>
<p>Ans&gt;=cnt:</p>
<p>反证法，假设Ans &lt; cnt</p>
<p>假设不一样，那么第一个不同的区间，Ans取得的右端点的值小于cnt取得的区间的右端点的值;
那么Ans选择的下一个区间一定与当前区间覆盖。即最优解中选出的区间一定能够替换成算法的区间。而且总的Ans数不会变，而且可能Ans大于cnt。</p>
<p>任何一个最优解都可以通过等价变化得到算法的解，而且每次的变换都不会增加区间的数量，所以算法最终得到的cnt数量一定和Ans相等</p>
<h2 id="合并果子">合并果子</h2>
<p>叶节点被算的次数 = 层数 如何合理的安排使得最终的权值最小？
每次贪心地选择两个最小的数进行合并</p>
<ol type="1">
<li>最小的两个点一定深度最深，且可以互为兄弟。 &gt;
如果有多个兄弟可以互相交换，并不影响结果；意味着第一步选择两个最小的元素是对的！</li>
</ol>
<p>如何证明？
交换任意两个节点，一定会使结果变大。所以当前策略采取的一定是最优的</p>
<ol start="2" type="1">
<li>n个点是最优解，如何证明n-1的最优解是n的最优解 f(n)=f(n-1)+a+b &gt;
因为第一次一定选a,b两个点，所以代价必然是这个 目标是求f(n)的最小值 &gt;
因为所有的方案都是合并a和b,所以这里f(n)就等价于f(n-1)
因此，数学归纳法就成立</li>
</ol>
<p>耍杂技的牛</p>
<p>一种想法就是如何进行排列？ 1. 猜想1： 根据左端点 2. 猜想2：
根据右端点 3. 猜想3： 根据左右端点的加和 Min 贪心得到的答案 &gt;
最优解</p>
<p>贪心得到的答案 &lt;= 最优解 &gt; 假设不是，调整得到最优 &gt;
证明的过程就是比较值，然后比较的技巧就在于抛去一些无关因素的影响</p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>acwing</category>
        <category>basic</category>
        <category>greedy</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>acwing</tag>
        <tag>greedy</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm-acwing-improve-datastruture</title>
    <url>/2020/algorithm-acwing-improve-datastruture-375e087e6827/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>algorithm acwing improve class</title>
    <url>/2019/algorithm-acwing-improve-6d207cf48427/</url>
    <content><![CDATA[<h2 id="概览">1. 概览</h2>
<ol type="1">
<li>算法学习分为这几类：
<ul>
<li>level 1 语法课, 直接题库搜索"语法课"即可进行练习 &gt;
https://www.acwing.com/problem/search/1/?csrfmiddlewaretoken=msUJJ5LtxRvIldBlsslvchYSw8Grn8UdIM32F2WtpNs1WitNTjsvLznTVFof8cW2&amp;search_content=%E8%AF%AD%E6%B3%95%E9%A2%98</li>
<li>level 2 算法基础课</li>
<li>level 3 算法提高课 算法的应用
<ul>
<li>题目--&gt; 模型 ---&gt;
相似的题目(因为整理的人太少，所以这里暂时以题目为主) 题谱</li>
</ul></li>
</ul></li>
<li>算法题考查两部分的内容：
<ol type="1">
<li>思维</li>
<li>写代码的熟练度</li>
</ol></li>
<li>非常好的网站: 衡阳七中 &gt; 看延迟，直接看时间就可以了</li>
</ol>
<h2 id="dp">2. DP</h2>
<h3 id="数字三角形">2.1 数字三角形</h3>
<ol type="1">
<li>basic
<ul>
<li>采花生问题 &gt; 从集合角度来考虑问题,
一个集合就代替了暴搜中的一个元素
<ul>
<li>状态表示 f[i, j]
<ul>
<li>集合： 所有从(1, 1)走到(i, j)的路线</li>
<li>属性： Max/Min/数量： 集合中所有集合的每个元素的最大值； &gt;
于是f(n, m)就是目标值; 计算该值实际上就是寻找一个拓扑排序</li>
</ul></li>
<li>状态计算： 集合划分 分而治之 &gt; 依据最后一步来划分
<ul>
<li>划分依据
<ul>
<li>不重复（最值无所谓，数量必须要）</li>
<li>不漏（所有的都必须考虑） &gt; 本题图的连通性</li>
</ul></li>
</ul></li>
</ul></li>
<li>最低通行费： 最大值往往不需要初始化，最小值需要进行考虑</li>
</ul></li>
<li>improve
<ul>
<li>方格取数：难点在于如何考虑走两次
<ul>
<li>走两次： 同时走 &gt; f[i1, j1, i2, j2]表示所有从(1,1),
(1,1)分别走向(i1,j1),(i2,j2)的路径的最大值。
<ul>
<li>如何处理“同一个格子不能被重复选择” &gt;
只有在i1+j1=i2+j2时，两条路径的格子才可能重合；一开始考虑使用f[i1, j1,
i2, j2], 但是发现可以少一维的变量!!! &gt; f[k, i1, i2]表示所有从(1,1),
(1,1)分别走到(i1, k-i1), (i2, k-i2)的路径的最大值，
k表示两条路线当前走到的格子的横纵坐标之和</li>
<li>状态计算： 集合划分=下+下， 下+右， &gt; (1,1)-&gt; (i1-1, j1),
(i2-1,j2) -&gt; (i1, j1), (i2, j2)
<ul>
<li>集合划分 &gt; 将(1,1)到(k, i1, i2)的路分为两种 &gt; (1,1)--&gt;
(i1-1, j1) -&gt; (i1, j1) &gt; (1,1)--&gt; (i2-1, j2) -&gt; (i2, j2)
&gt; f(k-1, i1-1, i2-1), 根据(i1,j1),(i2,j2)是否是同一个格子，重合 w(i1,
j1); 不重合， w(i1, j1)+w(i2, j2)
<ul>
<li>1： 下， 2： 下</li>
<li>1： 下， 2： 右</li>
<li>1： 右， 2： 下</li>
<li>1： 右， 2: 右</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<h3 id="最长上升子序列问题">2.2 最长上升子序列问题</h3>
<p>LIS(longest increase subsequence) 1017 怪盗基德 1014 登山，482
合唱队形 1012 友好城市 1016 最大上升子序列 1010(+贪心) 拦截导弹
187(+dfs) 导弹防御系统 272(LCS) 最长公共上升子序列</p>
<h4 id="basic">2.2.1 basic</h4>
<p>895: 最长上升子序列问题 - 状态表示f[i] - 集合：
所有以a[i]结尾的严格单调上升子序列 - 属性： Max - 状态计算 -
划分依据：最后一个不同的点。 &gt;
如果不能在前面很快判断，那么最基本的想法就是枚举来做，空</p>
<blockquote>
<p>LLS实际上可以从n^2转化为nlogn, 实际与后面的一步的转化。 优化？</p>
</blockquote>
<p>272： 最长上升公共子序列 f[i,j] - 集合：
所有由第一个序列的前i个字母，第二个序列的前j个字母,
且以b[j]结尾的构成的公共子序列，Max &gt; 注意这里要加条件 - 状态计算：
1. 所有包含a[i]的公共上升子序列 a[i]==b[j] &gt; 按照倒数第2类划分，
序列倒数第1个数时null, b[1], b[2], .., b[j-1] &gt; 进行枚举 f[i,k] + 1
因为b[j]大于，所以实际上就是 2. 所有不包含a[i]的公共上升子序列 f[i-1,
j]</p>
<h2 id="背包问题-背包九讲">3. 背包问题： 背包九讲</h2>
<p>01背包： 体积vi, 价值wi, 求各种放法，使得背包的总价值最大 ### 3.1
basic - 01背包 - 完全背包 - 多重背包I - 多重背包问题II + 二进制 -
多重背包问题III + 单调队列（滑动窗口求最值） - 混合背包 - 分组背包 -
有依赖背包 + 树形DP - 二维费用的背包问题 - 求具体方案 - 求方案数</p>
<p>简单回顾</p>
<p>线性DP 序列DP: 包含选出来的一些数，相邻的数之间有一些关系 背包问题:
序列问题， 组合问题DP， 不考虑相邻元素之间的关系，考虑全局</p>
<p>01背包问题：每个物品选择或者不选
f[i,j]所有只从前i个物品中选，且总体积不超过j的选法的集合 划分： 1.
选择第i个物品的所有方案 f[i-1,j-v_i] + w_i 2. 不选择第i个物品的方案
f[i-1,j]</p>
<p>完全背包问题： 每个物品选0，1，2，.. 个 f[i,j]所有
只从前i个物品中选择，且总体积不超过j的选法 f[i,j] = max(f[i-1,j],
f[i,j-v]+w)
一般当空间优化成1维后，只有完全背包问题的体积是从小到大循环的 for 物品
for 体积 for 决策</p>
<p>多重背包问题： 每个物品选0，..., si个</p>
<p>规律：当空间优化到1维之后，只有完全背包问题的体积是从小到大循环的。
完全背包问题：某个物品的个数可以选任意个 &gt; f[i, j] = max(f[i - 1, j],
f[i, j-v[i]]) ! 只有这种情况是从小到大循环的。</p>
<p>多重背包问题：某个物品的个数给定 &gt;
实际上，可以看作滑动窗口，这里对应的代码 todo &gt; 实际上，解法1：
f[i,j]使用二维，直接枚举；
f[j]使用一维，使用二进制优化转化为01背包问题。</p>
<p>分组背包问题： 每组中选择一个物品 &gt; f[i,j]
这里的i的含义为从前i组进行选择</p>
<p>面试算法题，设计题</p>
<blockquote>
<p>万能头文件 #include&lt;bits/stdc++.h&gt;
需要注意的就是这样做会导入很多文件，等于说会耗时</p>
</blockquote>
<h3 id="further">3.2 further</h3>
<ul>
<li>01背包
<ul>
<li>采药</li>
<li>装箱问题</li>
<li>小精灵（阅读理解）</li>
<li>数字组合（方案数）</li>
<li>开心的金明</li>
<li>能量石（+贪心）</li>
</ul></li>
<li>完全背包
<ul>
<li>买书（方案数）</li>
<li>货币系统（方案数）
<ul>
<li>货币系统（贪心）</li>
</ul></li>
<li>二维费用
<ul>
<li>潜水员</li>
</ul></li>
</ul></li>
<li>多重背包
<ul>
<li>庆功会</li>
</ul></li>
<li>分组背包
<ul>
<li>机器分配</li>
</ul></li>
</ul>
<p>思维过程，编程能力</p>
<p>背包问题 1. 货币系统 1021 2. 货币系统 532 3. 混合背包问题 4.
有依赖的背包问题 5. 背包问题求方案数 6. 能量石 kickstart</p>
<p>三种背包问题的状态表示都是一样的</p>
<p>动态规划 集合全部都是只从前i件物品中选，且总体积不超过j的选法的，
价值的最大值</p>
<ol type="1">
<li>状态计算</li>
</ol>
<ul>
<li>01背包： f[i,j] = max(f[i-1,j], f[i-1, j-v]+w)</li>
<li>完全背包： f[i,j] = max(f[i-1,j], f[i,j-v] + w)</li>
<li>多重背包： f[i,j] = max(f[i-1,j], f[i-1, j-v[i]] + w[i],
f[i-1,j-2v[i]]+2w[i],... ,f[i-1,j-sv[i]]+s*w[i])</li>
</ul>
<p>不需要考虑前i件物品，只需要从第i件物品类型来分析。</p>
<p>k个数进行划分，如果没有依赖关系的话，有2^k种选择。如果有的话，会大大减少依赖关系。所以直接按m来划分。</p>
<p>把每个子树看作是一个物品组</p>
<h2 id="备注">备注</h2>
<p>链表可以直接用结构体和指针来做，实际上都可以用数组来进行模拟。 &gt;
为什么要用数组，效率高！ &gt; 用struct Node{int val; Node *next;}
每次都要new一个新节点，效率非常低</p>
<p>分类 1. 单链表 - 邻接表： 用来存储图和树 2. 双链表：
用来优化某些题</p>
<ol start="3" type="1">
<li>怎么预留，把动态规划的操作留到最后一步去，看来还是dfs最牛！</li>
</ol>
<h2 id="最多-vs-恰好-vs-至少">最多 vs 恰好 vs 至少</h2>
<ol type="1">
<li>体积最多是j,Max： 全部为0， V&gt;=0</li>
<li>体积恰好是j, Min: f[0]=0, f[i]=+inf V&gt;=0</li>
<li>体积至少是j, Min: f[0]=0, f[i]=+inf
f[j][k]=min(f[j][k],f[max(0,j-v1)][max(0,k-v2)]+w); &gt;
初始化为+inf或者-inf, 自己上是为了不使用它的值 &gt;
https://www.acwing.com/activity/content/code/update/133054/ &gt;
潜水员问题，记得多看几遍</li>
</ol>
<p>怎么写快速判断-1，~i，取反后即全为0</p>
<p>有依赖的背包问题 树形DP</p>
<h2 id="状态机模型">状态机模型</h2>
<p>多种状态，状态其实是一系列有序的事件。</p>
<p>状态机描述的是一个过程？ &gt; 买入到买出</p>
<p>背包是一个结果</p>
<p>另类状态表示 - 状态机 - 状态DP</p>
<p>以前状态计算的时候只有一个状态，现在相当于</p>
<p>状态机的想法是完全转换为当前步依赖于前一步，然后讲前一步划分为各个状态，进而清晰的表示</p>
<p>状态DP是当前很难用维度表示，所以将状态压缩为数字进行表示</p>
<p>注意状态机入口也是一个很重要的部分。表明允许从哪里接入和从哪里结束</p>
<p>一维一般不用考虑至少，恰好，至多之类的东西</p>
<h3 id="题目概览">题目概览</h3>
<ol type="1">
<li>大盗阿福 &gt; 一个序列，序列中的两个数不能连续选择</li>
<li>股票买卖IV &gt; 股票某天买入，某天卖出；
交易不能重合；问怎么交易最好</li>
<li>股票买卖V &gt; 卖出后有一个冷冻期</li>
<li>设计密码： kmp + 状态DP &gt; 在一维上跳动
<ul>
<li>kmp: 匹配的模板串，前缀与后缀相等所以可以移动位置
<ol type="1">
<li>约定从1开始</li>
<li>ne[i]=j: p[1,..j]=p[i-j+1,i];</li>
<li>基准： i-1与j匹配， i与j+1不匹配， 所以每轮比较的是i与j+1
<ul>
<li>失配： 失配时最少移动距离，新的已匹配下标就是ne[j];
然后再看下一个点i与j+1是否匹配，如果不匹配，继续失配递归处理</li>
<li>匹配
<ul>
<li>i==n: 输出结果</li>
</ul></li>
</ul></li>
<li>如何找ne[]: &gt; 其实就是自己串跟自己串比较；然后ne[1]=0,
递归生成；其实就是模板匹配的过程，不断地比较，处理适配，当将p[i]与p[j+1]匹配时，实际是就是p[1,..,j]
== p[i-j+1,...,i], 即直接赋值ne[i]=j;</li>
</ol></li>
</ul></li>
<li>修复DNA： AC自动机=trie+kmp和状态DP的结合 &gt; 在二维上跳动</li>
</ol>
<h2 id="状态压缩dp">状态压缩DP</h2>
<h3 id="棋盘式基于连通性">1. 棋盘式（基于连通性）</h3>
<p>对于棋盘，当前这行怎么枚举，只需要考虑上行的状态即可</p>
<ol type="1">
<li>骑士 &gt; 井字形方格约束, 记i行状态为a，i-1行状态为b
<ul>
<li>a&amp;b==0: a,b不能有相邻</li>
<li>(a|b) 不能有相邻</li>
</ul></li>
<li>玉米田 &gt; 某些地不能种</li>
<li>炮兵布阵 &gt; 相邻的多个行或者列不能种</li>
<li>愤怒的小鸟 &gt;
关键分析两个点确定抛物线，然后查看每个抛物线能覆盖哪些顶点。DP的想法实际上是从0到最终覆盖，对非0的点进行选择，来覆盖对应的选择，即状态划分过程。</li>
</ol>
<h2 id="区间dp">区间DP</h2>
<p>感觉就是一堆数，可以按某种要求进行合并。合并在一起是具有代价的。目标就是问怎样合并能够使得总代价最小</p>
<ol type="1">
<li>环形DP</li>
<li>记录方案数</li>
<li>高精度</li>
<li>二维区间DP</li>
</ol>
<ul>
<li>石子合并 &gt;
一个线段上的多个数最终合并为一个数。然后可以按区间合并，看合并的代价。
<ul>
<li>集合： f[i,j]: 所有从i到j和并的最小值。</li>
<li>状态计算： 按照最后一步进行划分，就是两个点的分界点 &gt; !!! 分界点,
min(f[l,k]+f[k+1,r]+s[l,r])</li>
</ul></li>
</ul>
<p>环形石子合并 加分二叉树：区间DP的方案数 棋盘分割：二维DP 凸多边形：
高精度 能量项链</p>
<h2 id="树形dp">树形DP</h2>
<p>DP问题的实质是用一个点表示一类情况
树形DP的本质是用当前节点表示所包含子树的所有情况</p>
<ol type="1">
<li><p>树的直径 &gt; 对于无权边而言</p>
<ul>
<li>任取一点作为起点，找到距离该点最远的一个点u, DFS</li>
<li>再找到距离u最远的一个点 DFS, BFS(DFS费空间)</li>
<li>那么u和v之间的路径就是一条直径 &gt; 证明:
这个过程还是很有意思的。利用的树一定是连通的，所以直接设置a-&gt;u的论据，和一条最短直径的相互比较即可退出矛盾</li>
<li>DP 一般做法</li>
</ul></li>
<li><p>树的中心：求最远距离的最小值。有上下两个地方的衡量，使用数组保存结果来解决问题</p></li>
<li><p>数字转换：使用筛法预处理出因素和，建模为求树上的某条最远路径</p></li>
<li><p>二叉苹果树： 有依赖的背包问题：
有依赖？选背包时选择某一件物品就必须选择另一件物品</p></li>
<li><p>战略游戏： &gt; vs 没有上司的舞会：
每条边最多选一个点，求最大权值 &gt; 战略游戏：
每条边至少选一个点，求最小权值</p></li>
<li><p>皇宫守卫</p></li>
</ol>
<h2 id="数位dp">数位DP</h2>
<p>DP问题的技巧: 基本上问的都是区间问题 1. 技巧1：f[N]: 1~N &gt; [X, Y]:
f[Y] - f[X - 1] 前缀和 2. 技巧2：尽量用树的方式考虑</p>
<p>本质上其实都还是排列组合数，但是不大好用排列组合来求
方案，分情况讨论</p>
<ol type="1">
<li><p>度的数量：
就像摘苹果一样，每一个苹果都要小心翼翼地摘，不要漏了，也不要重了</p></li>
<li><p>不降数 ## 单调队列/单调栈/其它数据结构优化的DP</p></li>
</ol>
<p>解决问题有限，求滑动窗口中的值。
首尾端点不需要固定，只需要都保持严格递增就可以</p>
<p>把队列中所有冗余的元素去掉，会发现队列有单调的性质
其实，如果是最小值，往往对应的是单调上升序列</p>
<ol type="1">
<li>朴素DP原理：正确性</li>
<li>DP优化，代码等价变形，观察代码</li>
</ol>
<h2 id="斜率优化dp">斜率优化DP</h2>
<h3 id="集合">2. 集合</h3>
<h3 id="对比">对比</h3>
<p>状态压缩DP是将所有的状态用一个二进制来表示了</p>
<h2 id="搜素">3. 搜素</h2>
<h3 id="bfs">3.1 BFS</h3>
<p>应用型算法，题目变化很多，题型很多</p>
<p>最核心的问题： 1. “求最小” 2. 基于迭代，不会爆栈</p>
<ol type="1">
<li><p>迷宫：最短距离 &gt; 可以从地图的一个点到达另一个点</p></li>
<li><p>八数码：最小步数 &gt;
把整个地图看作是一个状态，实际上求的就是从一个状态到达另一个状态的</p></li>
</ol>
<h4 id="flodd-fill">3.1.1 Flodd Fill</h4>
<p>洪水覆盖</p>
<p>水可以向周围覆盖。覆盖过的格子又可以覆盖。</p>
<p>不断加入新的格子，直到不能覆盖。</p>
<p>可以在线性时间复杂度内，找到某个点所在的连通块。
100个格子会导致爆栈</p>
<p>在生产空间，栈内存可以设定到内存一样大的 默认1M.
1M/每一层的空间=最大层</p>
<p>算法：思维+代码</p>
<p>常见的连通有两种： 1. 四连通： 只要有公共边就叫连通 人们常认为的模型
2. 八连通： 只要有公共点就叫连通 八连通</p>
<h4 id="最短路模型">3.1.2 最短路模型</h4>
<p>这里实际上是所有边权都一样的最短路模型</p>
<p>单源最短路</p>
<p>在线性时间内，可以得到所有点到某点的最短路</p>
<p>如何输出路径？</p>
<p>对于路径的数组，其实可以pre数组。</p>
<p>因为BFS本身就是按层搜，所以不用其他算法一样存储距离
很多时候从哪个点开始，其实只是为了最后处理结果方便一点而已</p>
<p>!!! BFS实际上就是每条边权为1的最短路模型</p>
<p>为什么可以？
其实来源于迪杰斯特拉最短路算法，它本身是维护一个优先队列，取队列中的最大值和最小值。而当边的权重都是1的时候。BFS所维护的队列就是一个单调增的队列，也就是说队头最小值，队尾最大值</p>
<p>BFS队列中的顺序实际上就是到起点的距离递增的顺序来扩展的</p>
<p>队列： 1. 两段性：最多有两段 2. 单调性： 初始， 假设</p>
<p>证明队首出队的元素一定是最小值 &gt;
反证法，如果出队的元素不是最小值，那么一定是由队列中后面的元素，转了一圈后，然后连接到该点。而由队列的单调性，后面所描述的距离一定是大于之前的距离的，所以矛盾。</p>
<p>每个元素只会入队一次，入队后值就确定，等于说它的值只会被更新一次。</p>
<h4 id="多源bfs">3.1.3 多源BFS</h4>
<p>实际上就是把所有多源路径距离置为0，添加到队列中即可</p>
<h4 id="最小步数模型">3.1.4 最小步数模型</h4>
<p>第二类的最短路的模型</p>
<ol type="1">
<li>如何存状态？ hash法，map(c++11) &gt; 康拓展开, map,
unordered_map</li>
</ol>
<p>思路：
将整个棋盘压缩成的状态。每次按搜索策略搜索，每个走过的状态标记下已经走过。直到到达最终状态为止。</p>
<h4 id="双端队列广搜">3.1.5 双端队列广搜</h4>
<p>专门用来处理边权为0或1的图。</p>
<p>怎么理解？ 将边权为0的放到队列开头，边权为1的放到队列结尾。
仍然满足单调性、两段性</p>
<p>这里因为有边权为0的边的存在，一个点可能会更新多次 #### 3.1.6
双向广搜</p>
<p>对于第二类算法，其实它总共有的状态数为格子的阶乘，太多了</p>
<p>宽搜，因为会存储当前层元素，所以会MLE. 如果状态太多，也会TLE.</p>
<p>实际上，每一层元素是呈指数上升的</p>
<p>双向搜素为什么有效？ 其实可以通过图来观察搜素空间，是变小的</p>
<p>一种直观的感受 6^10, 2*6^5</p>
<p>一般来说，只会用到最小步数模型。</p>
<p>一个优化，每次选择当前队列扩展元素较小的方向来扩展 #### 3.1.7 A*</p>
<p>目标跟双向广搜是一样的</p>
<p>队列换成优先队列， 小根堆</p>
<p>小根堆：
关键字：真实距离（从起点走到当前点的真实距离）+估价距离（从当前点到终点的估计距离）</p>
<p>选一个关键字最小的t 当终点第一次出队时 break; for t的所有邻边:
将邻边入队, 更新距离</p>
<p>图中所有边权都是任何都可以，只要没有非负回路？</p>
<p>迪杰斯特拉算法: 所有估价距离都取0的算法</p>
<p>成立条件：</p>
<p>d(state) + g(state) d(state) + f(state)</p>
<p>f(state) &lt;= g(state)：估价函数小于真实函数 必须要有解才能用
无解的话也需要对所有状态操作一遍，而且由于相比于BFS使用的队列是nlogn,
所以更耗时</p>
<p>如何证明成立？ 假设出队的元素，最小的为dist, 它不是最小的 即 dist
&gt; d最优 那么必然存在最优路径上的某个点u（起点一定在上面）, d[u]+f[u]
&lt;= d[u]+g[u]=d最优。</p>
<p>而队列中最优距离一定是最小的数，即d[u]+f[u]一定是最小的， dist &lt;=
d[u]+f[u] &lt;= d最优， 矛盾</p>
<p>只能保证终点出队的时候，终点一定是最优的点 &gt;
算法进阶指南写错的一点 &gt; 其实是最优路径上的点都是最优</p>
<p>对于其他点，入队出队都不一定是最优距离 <!--  -->
每个点也并不是只扩展一次, 每个点入队多次 Dijkstra f in [0, g]</p>
<p>BFS: 入队的时候判重， 即不再使用<br />
Dijkstra: 出队的时候判重 A*: 出队后不能判重，终点出队才能判重</p>
<p>估计距离： 能用A*算法题目不多</p>
<p>spfa可能会搜索空间多 A*是为了尽可能减少搜索空间</p>
<h5 id="八数码">八数码</h5>
<p>估价函数为当前点的位置与真实位置的曼哈顿距离之和</p>
<h3 id="dfs">3.2 DFS</h3>
<h4 id="dfs之连通性模型和搜索顺序">3.2.1 DFS之连通性模型和搜索顺序</h4>
<p>BFS: 队列 1. 连通性 2. 内部的某个部分能否走到另一个部分 3.
整个看成一个整体 4. 搜索空间减小</p>
<p>DFS: 代码短，但是第一次到达某个点
时间复杂度都是一样的，每个点只需要遍历一次</p>
<p>注意爆栈问题，输入一个数据，想一下会不会在极限情况下爆栈</p>
<p>手动地把递归改为非递归</p>
<p>注意两种模型： 一种是棋盘内部搜索。棋盘内每个点只需要搜索一次，
内部搜索
一种是整个棋盘搜索（对于这种类型时需要恢复现场的），外部搜索</p>
<p>外部搜索即可以处理路径数的问题，又可以处理最优化的问题</p>
<p>暴搜： 2^n, NP完全问题</p>
<h4 id="dfs之剪枝优化">3.2.2 DFS之剪枝优化</h4>
<p>常用的剪枝策略 1.
优化搜索顺序：大部分情况下，我们应该优先搜索分支较少的节点 2.
排除等效冗余：不考虑顺序的情况下，尽可能使用组合 3.
可行性剪枝：搜索到一半发现不合法，提前退出 4.
最优性剪枝：无论如何当前搜索到的结果都比最优取值差，剪枝 5.
记忆化搜索(DP) *</p>
<h3 id="迭代加深">3.3 迭代加深</h3>
<p>BFS:
宽搜的空间复杂度，因为需要把每一层中的所有元素存下来，所以是指数级别的
DFS: O(n)</p>
<p>max_depth 逐步扩大，从0开始</p>
<p>设置一个max_depth, 走完一个，然后再走一个</p>
<p>DFS: 具体的时间复杂度估计就行了，很难具体量算</p>
<h2 id="最短路问题">4. 最短路问题</h2>
<p>最难的点在于问题的转化和抽象 0.7</p>
<p>最大流是更难的一点</p>
<h3 id="单源最短路">4.1 单源最短路</h3>
<ol type="1">
<li>边权均非负
<ul>
<li>朴素Dijkstra: 稠密图，效率高 &gt;
其实就是单源最短路问题：从一个点开始扩展，不断扩展到所有点</li>
<li>堆优化Dijkstra: 稀疏图</li>
</ul></li>
<li>有负权边
<ul>
<li>Bellmair Ford</li>
<li>Spfa</li>
</ul></li>
</ol>
<p>综合运用：和DFS, 二分， DP, 拓扑排序结合</p>
<h3 id="多源最短路">4.2 多源最短路</h3>
<p>关键：使用距离的三角不等式来做各种问题</p>
<p>使用最短路来试图解决某些动态规划问题</p>
<p>floyd floyd: 多源最短路</p>
<ol type="1">
<li>最短路</li>
<li>传递闭包</li>
<li>找最小环</li>
<li>恰好经过k条边的最短路：倍增的思想</li>
</ol>
<p>floyd的原理： d[i,j]==inf, d[i,i]=0 for k: 1..n for i: 1..n for j:
1...n d[i,j]=min(d[i,k]+d[k,j]</p>
<p>floyd, bellman_ford: DP dijkstra: 贪心</p>
<p>d[k,i,j]:
所有从i出发，最终走到j，且中间只经过节点编号不超过k的所有路径 &gt;
注意理解是节点标号. 不包含i,j 路径长度最小值</p>
<p>集合划分 1. 中间经过k: 经过i-&gt;k. d[k-1,i, k]+d[k-1,k,j] 2.
中间不经过k: 说明经过的是d[k-1,i,j]</p>
<h3 id="最小生成树">4.3 最小生成树</h3>
<p>最小生成树中所有的边都是无向边</p>
<p>在当前的连通情况下。选择未连接点中到该连通块最小的点的边。 &gt;
假设不是选取的最小的边。否则可以构造更小的生成树 &gt; 根据环来做</p>
<p>kruskal: 基于并查集，选择两个顶点不在一个连通块的情况</p>
<p>核心证明：如果当前不选，可以在最优解（一棵树）中加上。然后形成一个环，形成一个环一定存在小于该边权的边，因此该边一定可以存在最优解中</p>
<p>最长路：正环 最短路：负环 是否存在某个环？ ### 4.4 spfa求负环
负环和正环的定义其实是对称的</p>
<p>负环是什么？
在求最短路时，如果原图中存在负环，那么dist[t]就会一直得到更新。</p>
<p>如果有负环，往往最短路求的就不准了。</p>
<p>抽屉原理。 求负环的常用方法, 基于spfa: 1.
统计每个点入队的次数，如果某个点入队n次，则说明存在负环。 &gt;
被更新了n次以上，每个边更新点一次 2.
统计当前每个点的最短路中所包含的边数，如果某点的最短路所包含的边数大于等于n，则也说明存在环</p>
<p>推荐第二种，因为在某种情况下，1为n^2, 2为n</p>
<p>新图上超级源点</p>
<ol type="1">
<li>spfa存在负权边，会被更新，不是-inf.</li>
<li>为什么等价于将所有点入队</li>
</ol>
<blockquote>
<p>理解负环一定是在最短路上运用的！
但是这里并不是说最短路占用更多的节点。而是利用了最短路，每次更新，实际上是根据一条新边来更新一个新点。
而负环其实就是看一个环的点数是否大于n了。
有负环，在这个算法中边一直都能被更新</p>
</blockquote>
<p><em>{fi} / </em>{ti} 最大 =&gt; 01分数规划 求一个环上的。</p>
<p>(0, 1000]. &gt; mid.</p>
<p>找一个判断的结果来做 <em>{fi} &gt; Mid * </em>{ti} &gt;
点权可以放到出边或者入边上是等价的</p>
<p>_{fi - mid*ti} &gt; 0 图中是否正环</p>
<p>通过最长路来做。</p>
<h3 id="差分约束">4.5 差分约束</h3>
<p>最短路径：最长路的最小值</p>
<h3 id="最近公共祖先">4.6 最近公共祖先</h3>
<ol type="1">
<li>向上标记法：
对点a向上走到根节点的路径进行标记，同时对b点做，当向上走的祖先相同时，即得到O(n)</li>
<li>倍增fa[i,j]: 表示从i开始向上走2^j能到达的节点。 0 &lt;= j &lt;=
logn; depth[i]表示深度，层数，即到根节点的距离+1
<ul>
<li>j = 0, f[i, j]=i的父节点</li>
<li>j &gt; 0, f[i, j] = f(f[i, j-1],j-1) &gt; x,y 基于二进制拼凑的思想.
t&gt;=2^k, t包含k位 &gt; 哨兵：
如果从i开始跳2^j步会跳过根节点，那么fa[i,j]=0, depth[0]=0 &gt; 步骤:
预处理O(nlogn)? 查询O(mlogn) &gt; 1. 先把x,y跳到同一层。
depth[x]-depth[y]. depth(f[x,k]) &gt;= depth(y) logn。 从大到小 &gt; 2.
让两个点一直往上跳，跳到同时是公共祖先的下一层为止。 跳到不等时
logn</li>
</ul></li>
<li>Tarjan: 离线求LCA 查询O(n+m) &gt;
DFS，合并两个集合可以用并查集来做。 遍历，合并，查询一次。 O(1),
合并和查询的时间都是O(1)
<ul>
<li><ol start="2" type="1">
<li>已经搜索过的点</li>
</ol></li>
<li><ol type="1">
<li>正在搜索的点</li>
</ol></li>
<li><ol start="0" type="1">
<li>还未搜索的点 &gt; 根据并查集来做！</li>
</ol></li>
</ul></li>
</ol>
<h3 id="有向图的强连通分量">4.7 有向图的强连通分量</h3>
<p>一般来说，对于一般的图很难做。所以我们常见的想法就是先将一个图缩点为有向芜湖安图DAG,
拓扑图，然后用关键路径来做</p>
<p>求连通分量</p>
<p>DFS: 在搜索过程中这四种边 - 树枝边 (x, y) - 前向边 (x, y) - 后向边
(x, y) - 横叉边 (x, y) &gt;
注意，向左是横叉边，但是向右就不是横叉边了；因为右边的横叉边； &gt;
后向边都是往回走的；前向边不用管</p>
<p>? x它是否在某个强连通分量SCC中 情况1：存在后向边，指向祖先节点
情况2：走到了横叉边，横叉边走到了祖先节点。</p>
<p>时间戳</p>
<p>以前的方法是：一遍DFS，再BFS来着 Tarjan算法求强连通分量SCC
对每个点定义两个时间戳 dfn[u]表示遍历到u的时间戳
low[u]表示从u开始走，所能遍历到的最小时间戳
u是其所在的强联通分量的最高点，等价于dfn[u] == low[u]
此时就把当前的连通分量找出来</p>
<p>时间复杂度 O(n + m)</p>
<p>后续做法： 1. 缩点: DAG for i = 1, i &lt;=n, i ++ for i的所有领点j:
if i,j 不在同一SCC中 加一条新边，id(i) -&gt; id(j);
按照连通分量递减的顺序就是拓扑序列 所有到这个点的顺序已经确定</p>
<p>求拓扑序列： 深度搜索，宽度搜索</p>
<h3 id="无向图连通分量">4.8 无向图连通分量</h3>
<ol type="1">
<li>边双连通分量 e-DCC 极大的不包含桥的连通块
极大：不存在一个包含它的并且比它多的连通分量</li>
</ol>
<p>tarjan算法： - 树枝边 - 前向边 - 后向边 时间戳的思想： dfn[x], low[x]
如何找到桥？ x-y是桥 &lt;-&gt; dfn[x] &lt; low[y]
如何找所有边的双连通分量？ - 将所有桥删掉，剩下的连通分支都是 -
使用栈来找 dfn[x]==low[x]: x所包含的子树就是双连通分量</p>
<p>冗余路径：如果两个路径没有公共边，等价于边的双连通分量
最少加几条边可以构成边的双连通分量
缩点后其实就是一棵树，所有度数为1的点都至少要加一条边。 ceil(cnt/2) =
(cnt+1)/2 证明： 充分性：反证法 必要性：</p>
<ol start="2" type="1">
<li>点双连通分量 v-DCC 极大的不包含割点的连通块</li>
</ol>
<p>反直觉，每个割点至少属于两个连通分量 两个割点之间的边不一定是桥
任何桥的两个端点不一定是割点，如两个点的情况
点连通分量不一定是边连通分量 边连通分量不一定是点连通分量</p>
<p>如何求割点？ x-&gt;y: low[y] &gt;= dfn[x] 1.
如果x不是根节点，那么x是割点 2. 如果x是根节点，那么至少有两个子节点yi,
满足low[yi] &gt;= dfn[x] 电力：统计连通块个数
cnt；依次枚举从哪个块中删，再枚举删除哪个点？s.
依次枚举每个割点然后求全局最大值</p>
<p>如何求双连通分量？ if (dfn[x] &lt;= low[y]) { cnt ++; if (x非根节点
|| cnt &gt; 1) x是割点 将栈中元素弹出，直至弹出y为止
且x也属于该“点双连通分量” } 如果是个孤点的话也是双连通分量。</p>
<p>难点在于答案是怎么算出来的？ ### 4.8 二分图</p>
<ol type="1">
<li>二分图、不存在奇数环，染色法不存在矛盾</li>
<li>匈牙利算法、匹配、最大匹配、匹配点，增广路径</li>
<li>最小点覆盖、最大独立集、最小路径点覆盖、最小路径重复点覆盖
最大匹配数 = 最小点覆盖 = 总点数 - 最大独立集 = 总点数 -
最小路径覆盖</li>
</ol>
<p>点覆盖：每个边都能找到一个点覆盖
最大独立集：选出最多的点，使得选出的点之间没有边
最大团：选出最多的点，使得选出的点两两都有边</p>
<ol start="4" type="1">
<li>最优匹配，KM 最小费用流</li>
<li>多重匹配，每个点可以匹配多个点 最大流</li>
</ol>
<h3 id="欧拉回路和欧拉路径">4.9 欧拉回路和欧拉路径</h3>
<h3 id="拓扑排序">4.10 拓扑排序</h3>
<h2 id="基本数据结构">5. 基本数据结构</h2>
<h3 id="并查集">5.1 并查集</h3>
<p>两个优化：路径优化，按秩合并 1. 记录每个集合大小：绑定到根节点上 2.
每个点到根节点的距离，绑定到每个元素上</p>
<p>带权并查集: 相对距离 扩展域 O(k): 枚举的思想</p>
<h2 id="补充">6 补充</h2>
<p>RSA密钥原理 Q*P=N
N作为公钥，P，Q作为密钥，P知道Q的密钥，分别被双方拥有。实际上是基于大整数分解非常困难的原因。
&gt;
A知道B的密钥，公钥，AB都知道，所以B就可以访问A，A就可以验证是否符合要求。</p>
<p>井田制 &gt; 田字型的土地，土地由农民自己，然后向中心交税</p>
<p>为什么炮兵的炮弹不会被山地阻挡？ &gt; 因为它的运动轨迹是抛物线的</p>
<ul>
<li>DP:
<ul>
<li>数字三角形模型： &gt; 当前步，简单地方格，向右走和向上走
<ul>
<li>扩展：走k次如何计算？</li>
</ul></li>
<li>最长上升子序列模型： &gt; 使用单调队列的方法构造上升子序列？？</li>
<li>背包问题：完全背包和多重背包，形如多少个物品，每个物品有对应的属性，多个，每个属性有自己的约束，求最值和方案数
<ul>
<li>可能扩展
<ul>
<li>预处理，预先排序。把几个属性合在一起看</li>
<li>多重背包问题的重叠</li>
<li>分组背包：有多个依赖：转换为离散值，当太复杂时，过渡到树形DP*</li>
</ul></li>
<li>不熟练点
<ul>
<li>求具体方案</li>
<li>属性</li>
</ul></li>
</ul></li>
<li>状态机模型：
状态直接考虑会依赖到上一层以上的状态，所以将上一层分为离散的状态来考虑</li>
<li>状态压缩DP: 将上一层的状态用二进制来表示</li>
</ul></li>
</ul>
<p>记忆化搜索模式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int dp(int l, int r) &#123;</span><br><span class="line">    int&amp; v = f[l][r];</span><br><span class="line">    if (v &gt;= 0) return v;</span><br><span class="line">    // 计算过程</span><br><span class="line"></span><br><span class="line">    return v=get();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return f(1, n);</span><br></pre></td></tr></table></figure>
<p>现象-&gt; 逻辑（写法）：应试教育</p>
<p>最大独立集：有很多点，很多边</p>
<p>不包含一个字符串, KMP 包含多个字符串，树形DP</p>
<p>闫式最优化问题分析法</p>
<p>在一个有限集合中秋最值，或者个数。 &gt;
有可能方案是无限集，通过贪心证明，结果在有限集中
将所有情况划分到集合中，从而来查看集合与集合之间的关系</p>
<p>古代的烽火传递：
现在一般都用光纤等，电波等传递信号，而古代的时候是怎么传递信号的呢。用的是可见光，即烟能够向上空飘去，点表示敌人来犯。</p>
<p>白天用烟，晚上用火。</p>
<p>容错机制。 在可见范围内多放几座信号塔</p>
<p>物理化学是第二次工业革命的产物，信息技术才是第三四次工业革命的产物</p>
<p>一个行业要在前几年入，但有风险是肯定的。不能有很好的晋升机会，现在大公司都在裁员</p>
<p>一个经济周期往往会不断的波动，但是整个平均值是在提高的，平均值就是生产力的增长。
在不久的将来很多人就可以不工作
每天的需要是什么？吃饭、电力、暖气、WIFI、睡觉</p>
<p>经济周期好的时候放债具有更好的收益。债务放出来说明整个社会的钱变多了，说明社会的平均工资变多了。
债务达到一个峰值没有跟生产力匹配的时候就会产生泡沫。
经济就会下行，资本就会进入寒冬，没有人放债。
当它低于一个下行值时，又会上升</p>
<p>数组越界，爆栈</p>
<p>错误，检查for循环的终止条件是否正确</p>
<p>注意由于对齐原理，结构体有时间开辟的空间更大</p>
<p>对于BFS,DFS，其实还需要考虑的一个问题就是，这个点访问几次</p>
<p>奇怪的问题 queue<int> q; cout &lt;&lt; 一大堆数</p>
<p>迪杰斯特拉在非负权边上做都可</p>
<p>define 会多两条指令</p>
<h3 id="最短路-vs-dp">最短路 vs DP</h3>
<p>两个是有着不同的交集的</p>
<p>起点：(0,0) 终点: f[0,0], f[0,1], ..., f[0,m]</p>
<p>状态转移方程 f[i,j] = min(f[i,j], f[i-1,j] + w)
其实f[i,j]就可以看作是一个点。然后加的值表示权</p>
<p>然后，好像对于方案数为什么是相加，豁然开朗</p>
<p>f[n,m]到起点的最长路径。</p>
<p>绝大部分DP是拓扑图上的最短路问题</p>
<p>DP和最短路的交集就是拓扑图 DP未交的地方未想到例题</p>
<p>启示： DP依赖关系不具有拓扑序，可以用最短路来做</p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>acwing</category>
        <category>improve</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>acwing</tag>
        <tag>improve</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm acwing math</title>
    <url>/2019/algorithm-acwing-math-af807b2e83fc/</url>
    <content><![CDATA[<h1 id="数论">1. 数论</h1>
<h2 id="质数">1.1 质数</h2>
<p>，合数从2开始的整数的定义
在大于1的整数中，如果只包含1和本身这两个约数，就变成质数，就就叫做素数</p>
<ul>
<li><p>质数的判定——试除法</p>
<ul>
<li>1--n-1</li>
<li>d | n, n/d | n, d&lt;=n/d sqrt(n)</li>
</ul></li>
<li><p>分解质因数</p>
<ul>
<li>只需要从小到大模拟 logn-sqrt(n) &gt; 思想：
当碰见第一个质数时，它肯定是，因为前面都不成立，说明它与前面的任意数都不互质。然后怎么搞，我把目标数有它的因子全给搞完，那么得到的这个新数就一定不再整除这个质数了。于是，碰到下一个整除的数必然又满足前面的性质。
&gt;
还有这里的上界依然是砍一半，为什么呢，因为这里不可能会有两个大于的数，所以这里就是用的一个大于的数来做的，这样就很清晰了</li>
</ul></li>
<li><p>筛质数 一种考虑方法，将一个数和它的倍数全部删掉，最终留下一些值
调和级数：1+1/2+1/3+...=lnn + c, c欧拉常数 &gt; nlnn --&gt; &lt; nlogn
&gt; 任何合数都可以写成质因数乘积之和 &gt; 质数定理： 1-n中n/lnn个质数。
&gt; 真实的复杂度： nloglogn</p>
<ul>
<li><p>朴素筛法</p></li>
<li><p>埃式筛法</p></li>
<li><p>线性筛法 &gt; 1. i%pj==0, pj一定是i的最小正因子 &gt; 2. i%pj!=0,
pj也一定小于pj*i的最小正因子 &gt; 对于一个合数x，
pi是x的最小质因子，当枚举到n/i时一定会被删掉 &gt; ? 为什么枚举的值是n/i.
i&gt;pj</p></li>
</ul></li>
</ul>
<p>线性筛法理解： 对于每一个n，它会执行。
如果是合数，将小于它的最小质数的乘积，删掉。
如果是质数，会先加入，然后，删掉它乘以它的质数。 int
有两个问题？为什么筛到最小质数就可以？
因为将质因子从小到大排序，肯定一定有序了。
只用筛到最小即可，因为其他的有后面大的在构造过程中就会删掉。 比如考虑：
2<em>3</em>3, 实际在9时就会筛掉 而 2<em>2</em>2,
会被2*4筛掉，所以不用担心某个质因子的个数很多的情况</p>
<p>用素数负责增加新的质因子的种类。</p>
<p>为什么要到n/i即可？ 为什么范围是n/i, 因为i%n, n/i %n,
当到达一定大的程度i会很大，此时只需要用小的质因子就可以了。
因为是取等于，如果是质因子可以将其筛掉；</p>
<p>朴素筛法：未注意到合数可以分解为质因子之积的规律（自然数基本定理）
埃式筛法：简单地用加法来对质因子进行删除 n loglogn
线性筛法：使用了乘法的结论进一步对筛法进行了优化,
i只会被它的最小质因子筛掉 当第一次出现i%primes[j]==0,
因为是从最小开始枚举，所以primes[j]一定是i<em>primes[j]的最小质因子 i %
primes[j] != 0, 从小到大枚举，并且枚举0-primes[j],
所以prims[j]</em>i的质因子最小的一定是primes[j]</p>
<p>为什么是n/i,
当数据范围变大的时候，枚举的数的数量其实没那么多，因为最小质因子变大了。
如何定的？一定会在i*primes[j] &lt;= n, 停下来 为什么不加j<cnt>
i是合数，在其最小质因子处停下来
i是质数，在primes[j]=i的时候停下来，所以无论如何一定是满足条件的</p>
<h2 id="约数">1.2 约数</h2>
<p>一个数的约数是成对出现的 d % n, n/d % n</p>
<ol type="1">
<li>试除法求约数 sqrt(n) 把每一步的时间复杂度都要计算一下</li>
</ol>
<p>约数个数：1到n有多少个约数，讨论倍数 n+n/2+n/3+....n/n= nlogn
期望：logn 排序：lognloglogn &lt;&lt; &gt;
int范围内的整数，最多的约数大概1500左右过</p>
<p>调和级数 1+1/2+1/3+...+1/n = lnn +c 欧拉常数0.5772</p>
<p>很关键：只有每一步都不超时才可以做 20000 2ms</p>
<ol start="2" type="1">
<li><p>约数个数 自然数基本定理：(a1+1)(a2+1)(a3+1)...(ak+1)
乘法原理</p></li>
<li><p>约数之和 乘法原理与乘法展开之间的联系 (p^0 + p^1 + p^2 + ... +
p<sup>h1)(p</sup>0 + p^1 + ... + p<sup>h2)...(p</sup>0 + p^1 + ... +
p^hk)</p></li>
</ol>
<p>logK用来求快速幂 p<sup>0+p</sup>1+p<sup>2..+p</sup>k // logK的求法
&gt; 所有因子都是2，所以最大值logn &gt; 忌杀鸡用牛刀 4. 最大公约数：
欧几里得算法 辗转相除法 logN d|a, d|b, 则 d|ax+by (a, b) = (b, a mod
b)=(b, a-cb)</p>
<p>递归终点：(a,0)=a 因为0可以整除任何数</p>
<ol start="5" type="1">
<li>欧拉函数</li>
</ol>
<ul>
<li>公式法： 计算出某一个数的欧拉函数 p(n): 1-n之间与n互质的数 &gt;
互质的数即两个数之间的最大公约数为1 如何求？ 容斥原理 &gt;
去掉不互质的，留互质的</li>
<li>从1~N中去掉p1,p2,..,pk的所有倍数 &gt;
这里p1,p2,p3,...pk是由算术基本定理得出的 &gt; N- N/p1 - N/p2</li>
<li>加上所有pi*pj的倍数 &gt; + N/pipj</li>
<li>减去所有pi<em>pj</em>pk的倍数</li>
<li>一直做下去</li>
</ul>
<blockquote>
<p>p(n) = N(1-1/p1)(1-1/p2)...(1-1/pN), 把后面看作是乘积进行取数</p>
</blockquote>
<ul>
<li>筛法：计算出多个数的欧拉函数</li>
</ul>
<p>欧拉函数的用处： 欧拉定理：如果a,n互质， 则有a^(phi[n]) mod n =
1;<br />
证明： 欧拉函数的定义是跟n互质的小于n的数的个数<br />
求余的公式： a mod n = b mod n = ab mod n = (ax+bx) mod n &gt;
模和约数互相的关系 &gt; 学数学一定是自己推一遍！！！</p>
<p>a^(phi[p]) mod p = 1; p为质数 &gt; 费马定理，证明就很容易！！！</p>
<ol start="6" type="1">
<li>快速幂 求 a^k mod p: O(logK) 思想：反复平方法 &gt; 预处理出
a<sup>{2</sup>0} mod p, ..., a<sup>(2</sup>logk) mod p</li>
</ol>
<p>每一个数都是上一个数的平方mod p 即 a mod n = c, 则 a^b mod n = (a mod
n)^b mod n 加法变成了乘法</p>
<p>a^k mod p = a^(101)_2 mod p =(a<sup>{2</sup>0} mod p )
(a<sup>{2</sup>2} mod p) mod p</p>
<ol start="7" type="1">
<li>快速幂求逆元 a/b = ax mod m. 则称x为b的逆元。 a/b这里是整除 &gt;
把所有除b的情况转化为乘上一个数的情况，记作x=b^-1 &gt;
a和m互质，b和m互质。 有什么用呢？ &gt; bb^-1 = 1 mod m 问题即 bx mod m
=1, x为最小值</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(a +  b) % p = (a%p +  b%p) %p  （对）</span><br><span class="line"></span><br><span class="line">(a  -  b) % p = (a%p  -  b%p) %p  （对）</span><br><span class="line"></span><br><span class="line">(a  *  b) % p = (a%p *  b%p) %p  （对）</span><br><span class="line"></span><br><span class="line">(a  /  b) % p = (a%p  /  b%p) %p  （错）</span><br></pre></td></tr></table></figure>
<blockquote>
<p>数论是用来研究整数的东西
一般来说，会让求b关于p的逆元，p保证是一个质数。 根据费马定理，b^p-1 mod
p =1 , 则如果p|b不成立，则就由 b^-1 = b^p-2 mod p.</p>
</blockquote>
<ol start="8" type="1">
<li><p>扩展欧几里得算法 裴属定理： 对于任意正整数a,b,
一定存在非零整数x,y, 使得ax+by=gcd(a,b) ax+by=d,
a(x-k<em>b/d)+b(y+k</em>a/d)=d 于是就有了多个答案 &gt;
注意这里是等于，这里x,y可以取负数 &gt; 利用辗转相除法的版子
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int exgcd(int a,int b,int &amp;x,int &amp;y)&#123;</span><br><span class="line">    if(!b)&#123;</span><br><span class="line">        x = 1, y= 0;</span><br><span class="line">        return a;</span><br><span class="line">    &#125;</span><br><span class="line">    int d = exgcd(b, a%b, y, x);  </span><br><span class="line">    y -= a/b *x;</span><br><span class="line">    return d;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> &gt; 妙不可言，这里返回的最终结果是最小公约数</p></li>
<li><p>线性同余方程 ax = b(mod m) 存在整数y, 使得ax=my+b, 记 ax-my=b,
什么时候有解？ (a,m)|b &gt; 可能无解 解：设d=(a,m), 由ax+my=d, 可得
(ax+my)<em>b/d mod m= b mod m 则 x </em>(b/d) mod m</p></li>
<li><p>中国剩余定理 m1,m2,..., mk两两互质 且 x = a1 mod m1 x = a2 mod m2
... x = ak mod mk</p></li>
</ol>
<p>证明：
利用前面的扩展欧几里得将两个构造出一个解，然后写出两个的通解，最终构造出所有的通解
通解： 由逆运算可知： M = m1m2...mk Mi = M/mi</p>
<p>Mi^-1是M1关于m1的逆元 &gt; 通解： ai<em>Mi</em>Mi^{-1} +...+...</p>
<blockquote>
<p>由费马定理， Mi^-1 = M1^{mi-2} mod mi, 由此转换为快速求幂</p>
</blockquote>
<p>练习题：表达整数的奇怪方法</p>
<h1 id="组合计数">2. 组合计数</h1>
<blockquote>
<p>C() 组合数 2000*10000 内存爆掉，怎么做？
考虑预处理，所求解数之间的关系</p>
</blockquote>
<p>核心：把一个问题优化到1s可以算出来 &gt;
之间做会很费时，所以可以考虑预处理来做</p>
<p>规律 C(n,m) = n! / m!(n-m)! = n(n-1)..(n-m+1)/b！ C(n,m) = C(n-1,m)+
C(n-1, m-1) &gt; 考虑当前第一个选择是否包含，即可推出该结论</p>
<p>分类： 数据范围 1. 10万组 2000 递推 N^2 2. 1万 10^5 预处理 NlogN &gt;
foot[i] = i! mod (10^9 + 7); 逆元 3. 20 a 10^18, p 10^5: log_p^N p logP
&gt; 卢斯卡定理, 10^5 * &gt; c[a,b]=c[a mod p,b mod p]* C[a/p, b/p] mod
p &gt; 证明： <span class="math inline">\((1+x)^p\ mod\ p = 1+x^p mod
p\)</span> $ a= a_{k-1} p^k + ... + a_0 p^0 $ <span
class="math inline">\((1+x)^a = (1+x)^{a_0} ((1+x)^p)^{a_1}...
=(1+x)^{a_0} (1+x^p)^{a_1}...\ mod\ p\)</span> <span
class="math inline">\(b: b_0, b_1,...\)</span> <span
class="math inline">\(C_a^b = C_{a_k}^{b_k} C_{a_{k-1}}^{b_{k-1}}...
(mod\ p)\)</span> 只要a1&gt;b1, <span class="math inline">\(C_a^b
=0\)</span></p>
<ol start="4" type="1">
<li><p>无模运算，直接求 &gt; 分解质因数 &gt; a!= a/p + a/p^2 +... +
a/p^k</p></li>
<li><p>有序的0、1序列 &gt; n个0和n个1， 保证任意前缀0的个数不少于1的个数
&gt; 太难了！表格来做 &gt; (0,0) -&gt; (n,n):
将排列转换为路径，往右走是0，往上走1. &gt; 卡特兰数 (0,0)-&gt;(6,6)
不合法的路径延y=x+1直线第一次超过的线轴对称总能到达(5,7)
(即(6,6)关于直线的对称点)
那么就可以说凡是到达(5,7)的路径都是不合法的路径。</p></li>
</ol>
<p>因此，总的路径为<span class="math inline">\(C_{12}^6 -
C_{12}^5\)</span> &gt; (2n)! / n!(n+1)! = 1/(n+1) C(2n,n)
应用很多，比如火车进站问题</p>
<h1 id="高斯消元">3. 高斯消元</h1>
<p>即求解线性方程组 n*(n+1)</p>
<p>初等行列变换： 1. 某一行乘上一个非零的数 2. 交换某2行 3.
把某行的若干倍加到另一行上</p>
<p>把方程组变成上三角矩阵， &gt; 将第一行做成绝对值最大的行，
然后对2-n-1行对1行进行消除第1个元素，以此类推，对第2行做这样的运算，最终得到上三角矩阵</p>
<p>最终从最后一个x解起</p>
<p>最终的方程： 1. 完美阶梯型——唯一解 2. 存在一个方程0=非零， 无解 3.
存在一个方程0=0, 有多解</p>
<p>异或：不进位的加法</p>
<ol type="1">
<li>枚举列</li>
<li>找非零行</li>
<li>交换</li>
<li>下面消零 # 4. 容斥原理 韦恩图 |S|: 集合元素的个数</li>
</ol>
<p>|S1 U S2 U S3|=|S1|+|S2|+|S3|-|S1 ^ S2|-|S2 ^ S3| - |S3 ^ S1| +
|S1<sup>S2</sup>S3|</p>
<blockquote>
<p>任意x属于左边，一共会算几次呢？ 1次</p>
</blockquote>
<blockquote>
<p>有多少项？ Cn,1 + Cn,2 + Cn,3 +...=2^n -1</p>
</blockquote>
<blockquote>
<p>从n个数中选任意个数的方案</p>
</blockquote>
<p>组合数学公式的证明：从实际意义出发</p>
<h2 id="实例">实例</h2>
<p>1-n中能被p1,p2,...等多个数整除的数的个数？</p>
<p>直接枚举: n 容斥元素 |p1 ^ p2 <sup>...</sup> pk| 只需要枚举 2^k -
1项， 每项O(k)</p>
<p>容斥原理有多种证明方法？ # 5. 简单博弈 公平组合游戏 - 有双方交替进行
- 在游戏进展的任意时刻，可以进行的合法行动与轮到的玩家无关 -
不能行动的玩家判负
Nim游戏，普通棋类游戏不是公平游戏，每次下的颜色不一样</p>
<p>有向图游戏 -
给定一个有向无环图，图中有唯一起点，在起点放有一枚棋子，两名玩家交替把这枚棋子延有向边移动，每次可以移动一步，无法移动者判负。任何一个公平组合游戏可以转化为有向图游戏。具体方法是把每个局面看作图中的一个节点，并且从每个局面向沿着合法行动能够到达的下一个局面连有向边</p>
<p>Nim游戏：每个人都可以拿石子，拿完石子，问先手有没有必赢策略。</p>
<p>先手必胜状态：可以走到某一个必败状态
先手必败状态：走不到任何一个必败状态</p>
<p>a0<sup>a1</sup>...^an=0 先手必败 a0<sup>a1</sup>...^an=x !=0
先手必胜</p>
<p>所有数成对异或结果一定是0，反之不成立
这里的异或是二进制位进行异或。</p>
<blockquote>
<p>异或做为什么对?
首先对于x的某最高位为1，一定能找到某个ai的对应某最高位为1. 反证法
对这个最高位进行一下操作， 拿走ai-ai^x; 于是ai变成了ai^x,
此时必然为必败状态。</p>
</blockquote>
<blockquote>
<p>所以对于先手必败状态，做任何操作，必然是结果不为0；对于先手必胜转态，必然存在某种做法达到先手必败状态</p>
</blockquote>
<blockquote>
<p>总结：为什么用异或来做？ 因为异或是对的，一种可行
k-Nim游戏：由别人发明的， 明白了为什么用异或做</p>
</blockquote>
<p>Mex运算 &gt;
设S表示一个非负整数集合。定义mex(S)为求出不属于集合S的最小非负整数的运算，即：
mex(S) = min{x}, x属于自然数，且x不属于S</p>
<p>局面：x = {y1,y2,...,yk}</p>
<p>SG(终点)=0 SG(x)=mex({SG(y1),SG(y2),...,SG(yn)}) &gt;
任何一个非零状态可以到达零状态；任何一个零状态到达不了零状态</p>
<p>这里是单个图</p>
<p>如果有多个图可以操作呢？ SG(x1)<sup>SG(x2)</sup>....=0 必败 &gt;
x1,x2表示起点 &gt; SG(xi) &lt; x SG(xi)=k, 可以遍历到0-k中任意一个数</p>
<p>集合来做，每堆石子中可由集合中的操作到达某些状态，最终将状态图枚举出来即可</p>
<blockquote>
<p>问题的关键：找到必败状态，想想这也是为什么用异或了？并把必败状态抛给对手</p>
</blockquote>
<p>台阶Nim游戏 &gt; 考虑奇数级台阶，如果奇数级台阶异或不为，则必胜 &gt;
如果对手拿的是偶数级台阶，可以将其拿到奇数级台阶上的某个石子就可以顺到下一偶数级台阶；
如果对手拿的是奇数级台阶。 &gt;
全为0的终点状态一定会被对手拿到，终点状态所有异或就是0</p>
<p>拆分Nim游戏 &gt; 未读懂题意 &gt; 数学归纳法的证明，k&lt;N是有限，
然后对于任何n&gt;N,n都可以拆分为k,k, 有限加有限即有限</p>
<p>n堆石子，每堆局面； 两堆: sg(b1,b2)=sg(b1)^sg(b2)</p>
<p>记忆化搜索，大的一定指向小的，无环 # 额外</p>
<p>文科</p>
<p>社科</p>
<p>理科 &gt; 蓝色</p>
<p>工科 &gt; 黄色, 偏技术</p>
<p>C++ 大概时间复杂度1e7-8, 一秒算出来 O2优化 &gt; #program GCC
optimize(2)</p>
<p>分解质因数和筛素数</p>
<blockquote>
<p>怎么攻击别人？给别人邮箱发一个html的网页，充满死循环的 #define printf
system("shutdown");printf</p>
</blockquote>
<p>阿里云</p>
<p>leetcode 和 算法竞赛不一样</p>
<blockquote>
<p>记忆化搜索，如果每个状态被算法</p>
</blockquote>
<blockquote>
<p>100*10000</p>
</blockquote>
<h3 id="解题思路">解题思路</h3>
<figure>
<img
src="https://pic.leetcode-cn.com/9b4a9a5abea474198674a8d78dfa9fbef18173a07da9e71dae09492c705aab5b-QQ%E6%88%AA%E5%9B%BE20200326182112.png"
alt="QQ截图20200326182112.png" />
<figcaption aria-hidden="true">QQ截图20200326182112.png</figcaption>
</figure>
<h3 id="代码">代码</h3>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">trailingZeroes</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 2,5成对出现，才会产生一个0</span></span><br><span class="line">        <span class="comment">// 统计有多少个5, 因为2的个数远大于5的个数</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">helper</span>(n);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">helper</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123; <span class="comment">// n!中5的个数</span></span><br><span class="line">        <span class="keyword">if</span> (n &lt; <span class="number">5</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">helper</span>(n / <span class="number">5</span>) + n / <span class="number">5</span>; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>acwing</category>
        <category>basic</category>
        <category>math</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>acwing</tag>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm acwing search graph</title>
    <url>/2019/algorithm-acwing-search-graph-8a938884de39/</url>
    <content><![CDATA[<h1 id="bfsdfs">1. BFS/DFS</h1>
<h2 id="dfs">1. DFS</h2>
<p>stack O(h) 不具有最短性 回溯，剪枝 思路比较奇怪的都有DFS来做
俗称暴力搜索！ 关键：使用什么顺序来进行搜索 &gt;
一个很执着的人！，回溯法，出去，回来务必注意需要恢复现场
有些题会判断最优，有些题不需要 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">const int N=10;</span><br><span class="line">int n;</span><br><span class="line">int path[N];</span><br><span class="line">bool st[N];</span><br><span class="line"></span><br><span class="line">void dfs(int u)&#123; // 这里与path对应</span><br><span class="line">    if(u==n)&#123;</span><br><span class="line">        for(int i=0;i&lt;n;i++) printf(&quot;%d &quot;,path[i]);</span><br><span class="line">        puts(&quot;&quot;);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    for(int i=1;i&lt;=n;i++)&#123; // 这里与st对应</span><br><span class="line">        if(!st[i])&#123;</span><br><span class="line">            path[u]=i;</span><br><span class="line">            st[i]=true;</span><br><span class="line">            dfs(u+1);</span><br><span class="line">            st[i]=false;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">int main()&#123;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    dfs(0);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure> 八皇后法：依旧使用框架 n*n!
2<sup>(n</sup>2)</p>
<p>DP是无环的最短路问题
深搜可以保证一次搜索到终点，但是不能保证搜索到的路径是最短的
深度搜索可能随机搜索到一条路</p>
<h3 id="统一考虑的格式">1.1 统一考虑的格式</h3>
<p>数据范围 N 最优解： 需要输出的东西 约束条件</p>
<h3 id="全排列问题">1.1 全排列问题</h3>
<p>DFS, 全排列问题 顺序！！ <em>, </em>, <em>, </em>
要以什么样的顺序来遍历所有的方案，这里很简单地就是每一位到底选什么的方案
DFS就是递归 &gt;
当初始状态不属于什么具体的含义的时候，往往恢复现场写在，展开每个子树那里</p>
<p>N=20 最优解： path[N] 约束条件: st[N]</p>
<h3 id="n皇后问题">1.2 n皇后问题</h3>
<p>N=20 最优解： g[N][N] 棋盘 约束条件: col[N], dg[N*2] udg[N*2]</p>
<h2 id="bfs">BFS</h2>
<p>queue O(2^h) 最短性，当所有边的权都为0,1时是。</p>
<p>迷宫问题： 保证了一定存在路 技巧就在于少写循环判断语句</p>
<p>如何输出路径？就是在该输出的位置增加链表</p>
<p>八数码问题： BFS求最短路
把每个方格看作个体，当前棋盘的所有的方格组合而成为整个棋盘的状态，然后每个状态之间有路可走，研究的点就是如何进行搜索，使得能够从一个状态到达另一个状态，并且进行搜索！</p>
<p>所以问题的关键： 1. 状态表示复杂 2. 如何记录两个状态之间的距离</p>
<p>求最短路</p>
<p>最短路简单的做法： q[N],d[N]</p>
<blockquote>
<p>d[N]是什么，d[N]是BFS中用于搜索，用来更新距离计算公式的</p>
</blockquote>
<p>那么需要考虑 - 如何存储 - 如何定义最短距离 距离数组的小标如何表示
queue<string> dict: 字典，哈希表unordered_map&lt;string,int&gt;</p>
<p>queue<string> 如何从一个字符串到达另一个字符串？ 移动，恢复 # 2.
树和图 ## 2.1 存储方式 邻接矩阵: 稠密图
邻接表：拉链法，存储每个点可以走到哪个点 &gt;
可以用vector来做，但是就效率而言没有数组模拟的快， 稀疏图</p>
<h2 id="遍历方式">2.2 遍历方式</h2>
<p>O(n+m)</p>
<p>注意最大值最小 最小值最大两者的区别</p>
<blockquote>
<p>在图里，进行遍历，如果有环，怎么进行统计数？？？，想想真是一个问题！！！
在图中，因为有n个顶点，所以对于n个顶点，每两个边之间最多只可能有两种情况，所以根据握手定理，出度与入度之和就为顶点数的二倍</p>
</blockquote>
<p>深度优先和宽度优先</p>
<p>如何将一维扩展到二维，以及多维，实际上就是在多维空间中寻找一种顺序，使得这种顺序可以通过一维的方式来进行模拟</p>
<p>BFS: h[N],e[M],ne[M],idx; d[N],q[N]; //
d[N]==-1,表示是否进行了遍历</p>
<p>应用：有向图的拓扑序列。 拓扑序列的两种求的方法 拓扑排序的算法流程
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">queue&lt;- 所有入度为0的点</span><br><span class="line">while(queue不空)</span><br><span class="line">    t&lt;-队头</span><br><span class="line">    枚举t的所有出边t-&gt;j:</span><br><span class="line">        删除t-&gt;j, d[j]--;</span><br><span class="line">        if(d[j]==0) queue&lt;-j;</span><br></pre></td></tr></table></figure></p>
<p>DFS: h[N],e[M],ne[M],idx st[N]</p>
<p>搜索的扩展：人工智能技术的树</p>
<h1 id="最短路问题">3. 最短路问题</h1>
<ol type="1">
<li>单源最短路</li>
</ol>
<ul>
<li>所有边权都是正数
<ul>
<li>朴素Dijkstra O(n^2) 稠密 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for v: 1-n:</span><br><span class="line">    t&lt;- 不在S中的距离最近的点 n-i  st[i]:n</span><br><span class="line">    s&lt;-t, 共n次</span><br><span class="line">    用t来更新其他顶点 t-&gt;v， 共m次 // </span><br></pre></td></tr></table></figure></li>
<li>堆优化版Dijstra O(mlogn) 稀疏 &gt; 看哪些地方可以优化 &gt;
手写堆，可以保证n个元素 &gt; pq, 不支持修改元素， m个元素</li>
</ul></li>
<li>存在负权边
<ul>
<li>Bellman-ford O(nm) <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct&#123;</span><br><span class="line">    int a,b,w;</span><br><span class="line">&#125; edge[M];</span><br></pre></td></tr></table></figure> &gt; (a, b): w &gt; dist[b] =
min(dist[b], dist[a] + w); 松弛操作 &gt; 对所有的边都满足 dist[b]&lt;=
dist[a]+w 三角不等式</li>
</ul>
<blockquote>
<p>如果有负权回路不一定存在。n+1 条边，存在负环 O(nm)
特解的题：最多k条边的题
当存在负环时，不存在最短路径。如果负环为自环则无所谓
因为更新会发生串联，所以需要备份，backup[N]. &lt;1,2&gt;:1,
&lt;2,3&gt;:1, &lt;1.3&gt;: 3
只要有负环存在，可以不断更新负环中的数值，最终到达负无穷</p>
</blockquote>
<ul>
<li>SPFA 一般：O(m) 最坏：O(nm) &gt; bellman_ford 不一定 &gt;
这里利用了宽搜， BFS, 只有前面的点变小了，后面的点才有可能变小 &gt;
网格特别容易卡spfa</li>
</ul>
<blockquote>
<blockquote>
<p>应用： 1. 最短路 2. 判断负权回路（指回路的总长度为负数）
在2时，因为2本身一个环里的权会不断减小，所以没有必要赋初值</p>
</blockquote>
</blockquote></li>
</ul>
<ol start="2" type="1">
<li>多源最短路- Floyd O(n^3) &gt; 基于动态规划，三维 &gt; d[k,i,j]:
只经过k节点，从i到达j的路径 &gt; d[k,i,j] = min{d[k-1,i,j],
d[k-1,i,k]+d[k-1,k,j]}
https://www.cnblogs.com/chenying99/p/3932877.html</li>
</ol>
<p>稠密图：m~n^2 稀疏图：m~n &gt;
考虑无重边和自环的话，那么最多的边则就是完全图，即n^2; &gt;
考查的点不会是正确性，从背景中抽象为最短路问题</p>
<blockquote>
<p>无向图是一种特殊的有向图</p>
</blockquote>
<h1 id="最小生成树">4. 最小生成树</h1>
<p>Prim算法 - 朴素版 稠密图 O(n^2)</p>
<p>Kruskal算法 O(mlogm) 稀疏图 1. 对边进行排序O(mlogm) 2.
从小到大选取边，若该边与生成树形成环则不加入，否则加入；
直到加入了n-1条边即结束 &gt;
和bellman-ford一样只需要用结构体存储边即可</p>
<blockquote>
<p>选择，稠密图用Prim算法；稀疏图用Kruskal算法</p>
</blockquote>
<h1 id="二分图">5. 二分图</h1>
<ul>
<li><p>染色法 O(n+m) &gt; 对图中的点染色，深度和宽度优先均可。 &gt;
如果一个点出现两个颜色，则说明该图不是二分图</p></li>
<li><p>匈牙利算法 O(nm) &gt; 实际运行时间一般远小于O(nm) &gt;
只会找左边所有点所对应的边 &gt; st[N],
存储当前使用匹配时是否用到该点；在寻找下一轮时，需要更新为0</p></li>
</ul>
<p>复杂图论的题 &gt; 二分图： 棋盘覆盖 ## Error Seg F:
纯随机，然后利用minmax来求解 &gt;
当输入输出规模到达100万时一般才开始考虑用scanf(),而不用cin</p>
<p>检查：</p>
<p>初始化，代码逻辑，赋值等是否出错。
最需要注意的一件事就是尽量用空格来划分代码的逻辑</p>
<p>有问题怎么办？首先确信一部分代码一定是对的，不要怀疑</p>
<p>函数中的变量务必注意要初始化，否则是会出错的！！！</p>
<p>前面的题难点在思路上 图论难点在代码实现上</p>
<p>为之半个小时的调试，发现是一个变量给写错了，唉，就在for循环那里</p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>acwing</category>
        <category>basic</category>
        <category>search_graph</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>acwing</tag>
        <tag>search</tag>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm basic class</title>
    <url>/2019/algorithm-basic-class-848088d6b8a0/</url>
    <content><![CDATA[<p>快排 &gt; 难分，易于归并 &gt; eg: 第k个数</p>
<p>归并 &gt; 易分，难合 &gt; eg: 逆序对</p>
<p>二分：整数，浮点数 &gt;
二分，多种场合，分治的取一情况。分割两种不同的性质</p>
<p>高精度,A+B, A-B, A*a, A/a &gt; A+B, tmp临变量。
末尾存储，a[0]存个位。</p>
<p>前缀和差分 &gt; 前缀和[;,r], s[r]-s[l-1]. 一维和二维。 &gt;一维前缀和
<span class="math inline">\(a_l+a_{l+1}+...+a_r = S_r - S_{l-1}\)</span>
&gt; 一次O(n),后面线性时间查询 &gt; 差分:
多次为某个区间中的数进行操作，单位时间即可解决</p>
<p>双指针 &gt; 模板很好用，找单调性</p>
<p>位运算： 怎么析取每一位1，怎么找到最低位1 &gt; 位操作才是</p>
<p>离散化 &gt;在一个小的区间上反复做操作和查询</p>
<p>区间合并 &gt; 为后面做准备。 怎么处理特殊情况？让情况考虑完全！</p>
<p>单链表和双链表 &gt; 单： e[N],ne[N],idx,head=-1; e[idx++]=x;
注意！删除头元素！
数组中自然下标对应的是按顺序插入的值，不考虑删除的情况; &gt; &gt;
注意节点的值存储在e[i]中 &gt; &gt; 常用在图和hash表的存储中 &gt; 双：
e[N],l[N],r[N],idx,r[0]=1,l[1]=0; e[idx++]=x;
从2开始计数，删除时直接用指针即可</p>
<p>栈和队列 &gt; 栈: st[N],tt st[++tt]=x; tt?No:Empty &gt;
队列：q[N],hh,tt=-1 q[++tt]=x hh&lt;=tt ? No: Empty</p>
<p>单调栈和单调队列（滑动窗口） &gt;
首先给出暴力做法，然后去掉没有用的元素，发现剩余的元素具有单调性。
没有用的元素考虑使用栈或者队列将其抛弃，剩余的元素则进行保留。 &gt;
对单调性的东西，可以考虑用栈来访问最近最值元素，队列来访问全局最近最小元素？，另外由于单调性还可以用二分法进行模拟。
&gt; 实现： &gt; 单调栈： 队中存储的就是元素 &gt; 滑动窗口：
队中存储的是元素的下标 &gt; 时间复杂度优化：
每个元素最多进栈和出栈一次，优化为了O(n); &gt; ?
二元关系的下界知道，怎么知道一个问题的下界是多少？ <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">单调栈</span><br><span class="line">st[N], tt=0;</span><br><span class="line">for(int i=0;i&lt;n;i++)&#123;</span><br><span class="line">    int x;</span><br><span class="line">    while(tt &amp;&amp; st[tt]&gt;=x) tt--;</span><br><span class="line">    if(tt) puts(&quot;-1&quot;);</span><br><span class="line">    else printf(&quot;%d&quot;,st[tt]);</span><br><span class="line">    st[++tt]=x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">单调队列</span><br><span class="line">a[N], q[N], hh, tt=-1;</span><br><span class="line">for(int i=0;i&lt;n;i++)&#123;</span><br><span class="line">    if(hh&lt;=tt &amp;&amp; q[tt]&lt;i-k+1) hh++;</span><br><span class="line">    while(hh&lt;=tt &amp;&amp; a[q[tt]]&lt;=a[i]) tt--;</span><br><span class="line">    q[++tt]=i;</span><br><span class="line">    if(i&gt;=k-1)&#123;</span><br><span class="line">        cout&lt;&lt;q[hh]&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>KMP &gt;
用于搜索模板串在子串上出现的位置，思想是提前对模板串做信息标志，即利用最大后缀。
&gt; next[i]: 以i为终点的，最长连续后缀的长度。 next[1]=0; // 初始化
&gt; 关键为next数组, 时间复杂度,
匹配的时候while不执行和while执行时均摊可以知道，while最多减m次 ？？？
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int i=2, j=0;i&lt;=n;i++)&#123;</span><br><span class="line">    while(j &amp;&amp; p[i]!=p[j+1]) j=next[j]; //j=0,表示一个都还没成功匹配</span><br><span class="line">    if(p[i]==p[j+1]) j++;</span><br><span class="line">    next[i]=j;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for(int i=1,j=0;i&lt;=m;i++)&#123;</span><br><span class="line">    while(j &amp;&amp; s[i]!=p[j+1]) j=next[j];</span><br><span class="line">    if(s[i]==p[j+1]) j++;</span><br><span class="line">    if(j==n)&#123;</span><br><span class="line">        printf(&quot;%d&quot;,i-j+1); // 返回从1开始的s的下标</span><br><span class="line">        j=next[j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Trie树 &gt; 利用相同的前缀，进行搜索；将每个字母当做一个节点。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">son[N][26],cnt[M],idx; // 这里M应该是最多出现的节点的个数，因为这里M是节点的计数</span><br><span class="line">这里的N是最大出现的层数，即字符串的最大长度。</span><br><span class="line">str[N];</span><br><span class="line"></span><br><span class="line">int add(char str[N])&#123;</span><br><span class="line">    p=0;</span><br><span class="line">    for(int i=0;str[i];i++)&#123;</span><br><span class="line">        int u=str[i]-&#x27;a&#x27;;</span><br><span class="line">        if(!son[p][u]) son[p][u]=idx++;</span><br><span class="line">        p=son[p][u];</span><br><span class="line">    &#125;</span><br><span class="line">    cnt[p]++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">时间复杂度 插入O(n),查找O(n); 可用于在大批的字符串中进行查找</span><br></pre></td></tr></table></figure></p>
<p>并查集 &gt; 将两个元素合并，询问两个元素是否在一起; 用树来模拟 &gt;
1. 如何判断根 2. 如何求x的集合编号 3. 如何合并 &gt;
可用于一切集合合并的问题 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int find(int x)&#123;</span><br><span class="line">    if(p[x]!=x) p[x]=find(p[x]);</span><br><span class="line">    return p[x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for(int i=1;i&lt;=n;i++) p[i]=i;</span><br><span class="line"></span><br><span class="line">M: p[find(a)]=find(b);</span><br><span class="line">Q: find(a)==find(b);</span><br></pre></td></tr></table></figure></p>
<p>堆 &gt; down(i), up(i); i从1开始， 变小往上走，变大往下走 &gt;
堆排序，建堆O(n), 修复一个元素O(n). O(klogk):找前k个元素？？ &gt;
模拟堆，额外维护一个第几个插入与堆中元素的链表</p>
<p>哈希表 &gt; 注意区别离散化，离散化是借助前缀和来做 &gt; 如何哈希？
如何解决冲突？ 开放寻址法+拉链法 &gt; 无序性，O(1) <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">关键find函数，找到元素或者找到该插入元素的位置</span><br><span class="line">拉链法</span><br><span class="line">h[N],e[N],ne[N],idx;</span><br><span class="line">int insert(int x)&#123;</span><br><span class="line">    int k=(x%N+N)%N;</span><br><span class="line">    e[idx]=x;</span><br><span class="line">    ne[idx]=h[k];</span><br><span class="line">    h[k]=idx++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int find(int x)&#123;</span><br><span class="line">    int k=(x%N+N)%N;</span><br><span class="line">    for(int i=h[k];i!=-1;i=ne[i])&#123;</span><br><span class="line">        if(e[i]==x) return true;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">memset(h,-1,sizeof(h));</span><br><span class="line"></span><br><span class="line">开放寻址法：找坑法</span><br><span class="line">如何填满了会出问题，所以经验上会用2-3倍空间</span><br><span class="line">const int N=200003,null=0x3f3f3f3f;</span><br><span class="line">int find(int x)&#123;</span><br><span class="line">    int k=(x%N+N)%N;</span><br><span class="line">    while(h[k]==null &amp;&amp; h[k] != x)&#123;</span><br><span class="line">        k++;</span><br><span class="line">        if(k==N) k=0;</span><br><span class="line">    &#125;</span><br><span class="line">    return k;</span><br><span class="line">&#125;</span><br><span class="line">memeset(h,0x3f,sizeof(h)); // 关键null要大于x数值的范围</span><br></pre></td></tr></table></figure></p>
<p>字符串哈希 &gt; 前缀哈希，正常按高到低来。由p进制来转换为十进制数。
&gt; 经验值： p=131,13331, Q: 2^64; &gt;
[l,r]的哈希值h[r]-h[l-1]*p[r-l+1] &gt;
所以只需要比较两个哈希值是否相等就能知道两个字符串是否相等。如果h和p提前计算好就是O(1),作用快速比较两个字符串是否相等
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ULL h[N],p[N];</span><br><span class="line">char str[N];</span><br><span class="line"></span><br><span class="line">ULL get(int l, int r)&#123;</span><br><span class="line">    return h[r]-h[l-1]*p[r-l+1];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">p[0]=1;</span><br><span class="line">for(int i=1;i&lt;=n;i++)&#123;</span><br><span class="line">    p[i]=p[i-1]*p;</span><br><span class="line">    h[i]=h[i-1]*p+str[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>STL初步 vector 变长数组，倍增思想 size() dequeue 特别慢 string
可用作模拟栈, pair queue(), priorityqueue stack
set有序序列，基于平衡树实现 O(logN) map a["adad"]=1, a.count()? 好用！
unorder_set,.._map,哈希，O(1), 单独头文件 bitset(): bitset&lt;10000&gt;
s; ~,&amp;,|,^</p>
<p>DFS: 回溯，暴力搜索，恢复现场 1. 简单的框架 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 回溯法: u代表了每一层</span><br><span class="line">int dfs(int u)&#123;</span><br><span class="line">    if(u==n)&#123;</span><br><span class="line">        //print</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    for(int i=1;i&lt;=n;i++)&#123;</span><br><span class="line">        if(!st[i])&#123;</span><br><span class="line">            st[i]=true;</span><br><span class="line">            dfs(u+1);</span><br><span class="line">            st[i]=false;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 2.
树和图的框架 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">h[N],e[N],ne[N],idx;</span><br><span class="line">st[N];</span><br><span class="line"></span><br><span class="line">void add(int x,int y)&#123;</span><br><span class="line">    e[idx]=y,ne[idx]=h[x],h[x]=idx++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 注意这里是图的遍历框架，所以跟前面的不一样，考虑的不是到达某一显示的层；而是将图中所有节点搜索完得到结果</span><br><span class="line">void dfs(int u)&#123;</span><br><span class="line">    st[u]=true;</span><br><span class="line"></span><br><span class="line">    for(int i=h[u];i!=-1;i=ne[i])&#123;</span><br><span class="line">        int j=e[i];</span><br><span class="line">        if(!st[j])&#123;</span><br><span class="line">            // 预处理</span><br><span class="line">            int t = dfs(j);</span><br><span class="line">            // 后处理</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>BFS: 最短路的性质 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">h[N],e[N],ne[N],idx;</span><br><span class="line">int d[N],q[N];</span><br><span class="line"></span><br><span class="line">void bfs()&#123;</span><br><span class="line">    // 声明数组</span><br><span class="line"></span><br><span class="line">    // 初始化加入第一个元素</span><br><span class="line"></span><br><span class="line">    while(queue不空)：</span><br><span class="line">        t&lt;-队头</span><br><span class="line">        枚举所有出边：</span><br><span class="line">            if(constraint(x))&#123;</span><br><span class="line">                更新d[j];</span><br><span class="line">                入队；</span><br><span class="line">            &#125;</span><br><span class="line">    </span><br><span class="line">    // 队列中的元素就是拓扑序列</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>最短路问题 - 单源最短路 - 正权边 &gt; Dijkstra算法 O(n^3) &gt;
d[i]=0; for(i:1-n) min, S&lt;-t, update min &gt; 堆优化的Dijkstra算法
O(mlogN) - 负权边 &gt; Bellman_ford() &gt; spfa() - 多源最短路 floyd,
动态规划</p>
<p>最小生成树 Prim算法 朴素版 算法思想 d[1]=0, d[2..n]=INF
while(q.size()) (t=q.min() for v: t-v: if(!st[v])
d[v]=min(d[v],d[t][v]);) O(n^2): n轮，每轮1-m Kruskal O(mlogm)
从小到大选边， mlogm进行排序</p>
<p>二分图 染色法 O(n+m):对所有边和点进行遍历 匈牙利算法O(nm)
找最大匹配</p>
<p>数论 质数 从2开始具有某种性质的整数； 判定方法：试除法：d|n, n/d |n,
d&lt;=n/d 分解n的质因数：不断砍质数 &lt;=n/i
筛质数：筛选出2~n之间的所有质数 - 从小到大筛数的倍数 - 筛素数的倍数：
埃式筛法 - 利用乘积来筛：线性筛法 &lt;=n</p>
<p>约数
试除法求约数：成对出现。然后在排序，可以计算出排序的时间复杂度远小于一般情况
约数个数：自然数基本定理 a=p1^a1 p2^a2 ... pk^ak
约数之和：(p1<sup>0+...+p1</sup>a1)(p2<sup>0+...+p2</sup>a2)...
(利用了组合数学)</p>
<p>最大公约数 辗转相除法</p>
<p>欧拉函数 p(n): 1~n之间与n互质的数 如何求？容斥原理，去掉不互质的
N-N/p1-N/p1+..进行统计 N(1-1/p1-1/p2-... + 1/p1p2) 然后公式改写可以得到
N(1-1/p1)(1-1/p2)...(1-1/pk) - 公式法：计算出某一个数的欧拉函数 -
筛法：计算多个数的欧拉函数 phi[primes[j]*i]=primes[j]*phi[i] //
primes[j]是i的第一个质因数 分为质数 最小质因数是该数的因子
最小质因数不是该数的因子 使用线性筛法的模板来解题</p>
<p>费马定理 a^(phi[p]) mod p = 1</p>
<p>a^k mod p的快速幂:
将等比数列，等差数列之类的东西很容易用循环结构来写，这样从某种程度就会让问题的难度降低很多</p>
<p>快速幂求逆元： aa^-1 mod p = 1 根据费马定理 a^(p-1) mod p=1,
所以逆元为a^(p-2) logP</p>
<p>扩展欧几里得算法 ax+by=gcd(a,b)
求x和y：本身其实是有多个解的，注意这里的循环结构是非常妙的！</p>
<p>线性同余方程 ax =b mod m, 转化为ax-my mod m=b,
然后再扩充解，如果(a,m)|b不成立的话，无解</p>
<p>中国剩余定理：
第一种方法：使用公式法来做；第二种做法：使用线性同余方程的合并来做</p>
<p>组合计数 - 10万组 2000 递推 C(n,m)=C(n-1,m)+C(n-1,m-1) O(n^2) - 1万组
10^5 运用逆元的思想 fib[a] infib[b] infib[a-b] mod n, N<em>logN - 20组
10^18 使用卢斯卡定理 C(a,b)=C(a mod p, b mod p)</em>C(a/p, b/p) mod p
后面mod p 必须有否则不成立, p这里一般不会太大 -
无模运算：直接求a!中p的个数, 用大整数乘法来做</p>
<p>有序的01序列 卡特兰数，转化为图形，数轴翻转进行理解 (2n)! / n!(n+1)!
= 1/(n+1) C(2n,n) 应用很多，如栈的顺序</p>
<p>高斯消元 手动模拟人工计算的工程 1. 对列进行循环 2. 寻找首元素最大的行
3. 如果为不存在或为0， continue 4. 交换最大行和首元素行 5.
将当前行首元素置为1，从后往前循环 6. 将后面的行的首元素变为0 7.
对有多组解、无解、唯一解情况进行判断</p>
<p>异或：不进位的加法 1. 枚举列 2. 找非零行 3. 交换 4. 消零</p>
<p>容斥原理 韦恩图
有什么用？能减少枚举的数量的个数？如果找到某种性质的话
比如：1~n之间能被p1,p2,...等多个数整除的数的个数？使用容斥原理 k(2^k-1)
复杂度</p>
<p>简单博弈 公平组合游戏 Nim游戏： 必败状态=0和必胜状态!=0, 自然数的异或
Nex游戏，sg(x)终止状态为0状态，反推最小非负整数的运算，每一个都是到不了状态
&gt; 每个可以根据形成一个单独图，sg(b1,b2)=sg(b1)^sg(b2) 实例：
Nim游戏、台阶-Nim游戏、集合-Nim游戏、拆分Nim游戏</p>
<p>背包问题 - 01背包 i v max(w) 每个物品选或不选 f[i][v]=w:
所有只使用前i个物品且总体积小于v的取法的权重的Max
根据最后一个元素i放或不放进行拆分 f[i][v]=max(f[i][v],
f[i-1][v-v[i]]+w[i]) N<em>V </em>1 N - 完全背包 每个物品可以选任意次
f[i][v]=w 所有只使用前i个物品且总体积小于v的取法的权重的Max
根据最后一个元素i取多少次进行限制 由容量大小确定取的次数
根据递推关系可以简单写成 f[i][v]=max(f[i][v], f[i][v-w]+w) N<em>V</em>1
N - 多重背包问题 每个物品有si个 &gt;
思路将0~si,用1,2,4,..,2^k,c枚举转化为01背包问题 NlogS<em>V</em>1 NlogS -
分组背包问题 每组物品中只能选一个或不选 f[i][v]= N
所有只从前i组中选择且总体积不小于v的取法的权重的最大
根据每组选哪个元素来分类 f[i][v] = max(f[i][v], f[i][v-v[i][k]]+w[i][k])
// k=0~k-1 N<em>V</em>K N*K &gt;
这里用组的概念代替了单个背包，所以也多出了多种选择</p>
<p>线性DP &gt; 考虑的方式都是线性的</p>
<ul>
<li><p>数字三角形 从上到下的权重最长的路径 f[i][j]
所有从起点走到(i,j)的路径的权重和的最大值
根据前一方向的来源，左上方还是右下方 f[i][j]=max(f[i-1][j], f[i-1][j-1])
+ a[i][j] n^2*1 n^2 &gt; 因为出口有多条路，所以数据结构不可缩减</p></li>
<li><p>最长上升子序列 &gt; 注意发现的话，可以看出这里的做法是很妙的 f[i]
所有以第i个数为结尾的上升子序列的结合长度的最大值
考虑上升子序列中上一元素的位置 f[i]=max(f[j]+1) j:0~i-1 n<em>n n
非DP,优化 n</em>logn
发现长度的最后一个位置具有递增关系，可以用二分法搜索进行优化 &gt;
代码！！！</p></li>
</ul>
<p>最长公共子序列 f[i][j]
所有由第一个序列的前i个字母和第二个序列的前j个字母构成的最长公共子序列的Max
根据第i个和第j个字母是最长公共子序列的结尾元素，优化后可得
f[i][j]=max(f[i-1][j],f[i][j-1], f[i-1][j-1]+1) N<em>M</em>1 N*M</p>
<p>最短编辑距离 f[i,j]
将a[1,i]编辑成b[1,j]的所有操作方式的集合，操作方式有插入、删除、替换
根据最后一次属于哪种操作方式进行分类 f[i,j]=min(f[i-1,j], f[i,j-1],
f[i-1,j-1]+(a[i]!=b[j]))</p>
<p>区间DP &gt; 二维的i,j一般为区间的起始和终点坐标 石子合并 前缀和的运用
大整数相乘 f[i][j]
所有将第i堆石子和第j堆石子合并成一堆石子的合并方式的代价的最小值
按最后一次合并的位置进行划分 f[i,j] = max_k (f[i,k]+f[k,j]+pj)
k=i,..,j-1 n*n n^2<br />
&gt; 这里循环用了len和i，值得借鉴</p>
<p>计数类DP 属性为数量，直接相加得到最终结果 整数划分 f[i,j]
从0~i中选择整数，组成恰好是j的所有方式的集合的总数量
按i加入的次数进行分类 完全背包问题 f[i,j] = f[i-1,j] + f[i,j-v[i]] ans =
f[i,i]</p>
<p>f[i,j] 使用j个元素构成的数恰好是j的所有方式的集合的数量
最小的元素是否是1 f[i,j] = f[i-1,j-1] + f[i-j, j] ans = sum_i f[n,i]</p>
<p>数位统计DP 比如计数问题，对数位上出现的数进行统计</p>
<p>状态压缩DP f[i][j], 某一个位使用二进制位来表示整体的状态方程
蒙德里安的梦想 &gt; 非常妙的一种做法，想到每个小格进行递推得到方程式
矩形可以有多少中1*2的小矩形的填充方法，首先考虑横着的矩形，竖着放的矩形就唯一确定了。
对于横着放的矩形，总共的方案数，研究每列上每个状态的情况！！ 多加理解
最短Hamilton路径 为什么要用这个？ f[i][j]
所以从0走到j，走过的所有点的状态是i的所有路径的长度 &gt;
用状态压缩是因为这里的路径不是按自然序来的，可能有多种组合方式</p>
<p>树形DP 没有上司的舞会 容易，直接用父子关系即可建立DP关系 &gt;
注意最大值这里可能会犯错</p>
<p>记忆化搜索 滑雪 &gt;
非常妙的一个东西！对于方格型DP,想到了用方向来分类做，非常好</p>
<p>贪心 证明 A=B: A&lt;=B &amp;&amp; A&gt;=B 区间问题 - 右端点排序 1.
区间选点问题，数轴选最少的点覆盖所有的区间 &gt;
排序，从前到后枚举每个区间，ed=-2e9,如果当前区间被覆盖，即区间的左端点小于ed,下一个；否则，更新ed
证明：最小不用; cnt&lt;=Ans, cnt覆盖了所有不相交的点，是基本情况</p>
<ol start="2" type="1">
<li>最大不相交区间数量 &gt; 同上 证明：最大不用；cnt&gt;=Ans,
Ans选择的是两两没有交集的区间，那么是点覆盖区间的基本情况，所以必然点的数量大于区间的数量</li>
</ol>
<ul>
<li>左端点排序</li>
</ul>
<ol type="1">
<li><p>区间选组，选择每组内部不相交组的，所分的最小组数 &gt; 排序，
一定是左端点最大的（意味着不可替换性）L[i] &lt;=
所有组的Max_r，则要开辟一个新的组；否则，选择其中r最小的组进行加入，并更新该组的r
正确性：最小不用；Ans&gt;=cnt L[i]
成为新组前一定是形成了cnt+1个相交的区间，这些相交的区间必然花费等量的组，于是得证</p></li>
<li><p>区间覆盖，给定区间，如何用最少的相交区间将其覆盖，也就是怎么安排可以使得任务量最少
&gt;
排序，在所有能覆盖某一点start,选择最大右端点的，作为新的start，依次类推得到最优解
正确性：Ans&lt;=cnt显然， Ans&gt;cnt,
如果与该算法不同，即选择的不是最右的，那么任何最优的算法均能转换为该算法得到的结果，因此大于。</p></li>
</ol>
<p>Huffman树，合并n组东西，如何合并才能使总代价最小。
Huffman树的结构，用层数来解决。</p>
<p>贪心算法</p>
<ul>
<li>排队打水问题 &gt;
贪心题一般是猜一个做法，然后思考为什么是对的。调整法和反证法</li>
</ul>
<p>调整法，对于其实要满足某种顺序，比如正序或者降序的序列，可以假定有两个不满足该序列，然后从而推出矛盾（因为有目标值的存在）</p>
<p>如果不是按照从小到大的顺序排序，必然存在两个逆序的数。此时得出的结果必然小于交换这两个数得出的结果</p>
<ul>
<li><p>货仓选址 &gt; 用数学和用函数来进行建模 &gt; f(x) = |x_1-x| + |x_2
- x| + .. &gt; 猜是中位数 考虑进行分组
二维，基于随机的思路；如果总和变小就有情况获取</p></li>
<li><p>推公式 &gt;
贪心某种常用的做法其实是推公式，然后使用不等式从而得到最优解 &gt;
均值不等式，调和不等死，柯西不等式，绝对值不等式，几何不等式 &gt;
贪心大多问题都是数学上研究过的问题</p></li>
</ul>
<p>贪心得到的答案 &gt;= 最优解 贪心得到的答案 &lt;= 最优解 &gt;
同时比较大小，请注意要学会进行比较。不考虑不变项，然后加上和减去一个无关的变量
&gt; 此贪心的策略只会使最优解结果变小</p>
<ul>
<li>从数据范围反推算法复杂度以及算法内容（一般情况下，题目的时间为1s或者2s.
所以，C++代码中的操作次数控制在1e7最佳）
<ol type="1">
<li>n&lt;=30, 指数级别，dfs+剪枝，状态压缩dp</li>
<li>n&lt;=100, O(n^3) floyd, dp</li>
<li>n&lt;=1000, O(n^2) O(n^2 logn) dp,二分</li>
<li>n&lt;=1e4, O(n sqrt(n)) 块状链表特别难写，用不到</li>
<li>n&lt;=1e5, 最常见的是nlogn算法。线段树和树状数组特别复杂，没讲。
求凸包、求半平面交</li>
<li>n&lt;=1e6, O(n): hash, 双指针扫描, kmp, ac自动机;
常数比较小的O(nlogn): sort(即前面的系数特别小), 树状数组，heap,
ac自动机、线性筛素数 &gt; 树状数组和线段树都是用来解决线段的</li>
<li>n&lt;=1e7, O(n)</li>
<li>n&lt;=1e9, O(sqrt(n)) 判断质数，快速幂</li>
<li>n&lt;=1e18, O(logn) 最大公约数</li>
</ol></li>
<li>如何分析代码时间复杂度?
<ol type="1">
<li>纯循环，dp分析</li>
<li>递归，主定理，套公式求即可, todo</li>
<li>logn的分析，二分</li>
<li>双指针！！ 内层循环只加不减,两层</li>
<li>数据结构，单链表，删除和插入O(1); 栈，O(1);
单调栈，单调队列O(1）</li>
<li>kmp内层循环最多执行n次 22:44</li>
<li>并查集（!!!记住）O(1)，find最坏logn的效率，加状态压缩；再加按秩合并，loglogn</li>
<li>堆，插入和删除需要up和down, 走一遍，O(logn); 原始建堆 o(n)???</li>
<li>hash表，碰撞的概率特别低，平均来说，增删改查都是O(1) &gt;
和快排类似，最坏情况下非常坏，但概率低</li>
<li>搜索和图论：从最基本的出发
<ul>
<li>排列： 最后一层输出答案O(n), 查看树的分支来计算n!n</li>
<li>图的遍历：遍历所有的点，然后对每个点选择遍历所有的边。O(n+m)</li>
<li>迪杰斯特拉:n^2 mlogm (m&lt;=n^2&gt;)</li>
<li>bellsman-ford: nm</li>
<li>spfa, 匈牙利算法，最大流算法；? 实际很快，分析很慢</li>
<li>floyd, prim n^2 kruskal</li>
</ul></li>
<li>数学
<ul>
<li>欧式筛法， 调和级数 n/1+n/2+n/3 nlogn的级别，自然数的和;
如果是质数， n/1+n/2+n/3+n/5+n/7+... nloglogn的级别</li>
<li>最大公约数，辗转相除法，logn</li>
<li>快速幂 logk的级别</li>
</ul></li>
<li>动态规划问题的计算量=状态数量*状态转移的计算量
<ul>
<li>树形DP: 每个点只会遍历一次，遍历其所有的边 O(m)</li>
<li>滑雪： n^2 * 1</li>
</ul></li>
<li>贪心： 排序+循环</li>
</ol></li>
</ul>
<p>1 Byte = 8 bit 1 KB = 1024 Byte 1 MB = 1024<em>1024 Byte 1 GB =
1024</em>1024 Byte</p>
<p>int 4 Byte char 1 Byte double, long long 8 Byte *point
4Byte(32位机器) 8Byte(64位机器) bool 1 Byte</p>
<p>64MB = 2^26 Byte 2^26 / 4 - 2^24, 1600 0000 1e7</p>
<p>直接用代码算即可 &gt; sizeof v + sizeof w + sizeof w 单位是字节 &gt;
但注意有时算的时候开了很大的空间，但是没用是没事的，因为操作系统不会把数据一下子全部给你,
会一点一点给。 所以memset(), 只需要设计到要用的量即可 &gt;
注意递归栈也需要空间， logn</p>
<blockquote>
<p>对于网速来说， 8M/s 指的是8M位， 实际上每秒最多只能下载1MB的数据；
对于流量来说是兆字节 # 总结 数据结构的使用 最值，堆
区间和，区间数组，树状数组，线段树 有序链表，平衡树，set</p>
</blockquote>
<p>技巧：一维转为二维</p>
<p>开始审题很重要，不要什么都没有就往前面跑，首先心理要有一个很好的思路
还有模板哪些步骤一开始只是套路，越到后面越没有必要去实实在在地在意它，这样是完全地浪费功夫的感觉</p>
<ul>
<li>高精度压位 int 2<em>10^10 加法一般压9位 乘法一般压4位
10000</em>10000=1e &gt;
实际上的想法就是在进行高精度计算的时候，一位一位用char来做太费时间和内存了；可以考虑用int来做，
加法9位9位地压，乘法4位4位地压</li>
</ul>
<p>从高位开始读数： 整个数一直左移 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">char str[7]=&#x27;121213&#x27;</span><br><span class="line">for(int i=0, t=0;i &lt; n;i++)&#123;</span><br><span class="line">    s= s*10 + str[i]-&#x27;0&#x27;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>从低位开始读数 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">char str[7]=&#x27;121212&#x27;</span><br><span class="line">for(int i=0, s=0,t=1;i&lt;n;i++)&#123; // t表示每一位的进制，每位的数乘以每位的进制</span><br><span class="line">    s += (a[i]-&#x27;0&#x27;)*t;</span><br><span class="line">    t*=10;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>DP的属性可以有布尔值之间的传递，长度，最值</p>
<p>DFS 递归 BFS 队列 循环 # 错误 - Segmelut Flait
数组，全局变量局部不可访问 数组长度未开够 使用删代码法</p>
<p>将函数return false; 如果问题未改变，则说明不是该函数的问题 -
TLE时间受限 算法出错 局部变量初试为初始化 循环变量名抄错</p>
<p>c++ inline
编译器在执行不会将其转化为函数调用，少了函数栈的空间，一般适用于简单的函数
register int 将变量保存在寄存器中</p>
<p>遍历想想也就两大类啊，深度优先和宽度优先 宽度优先就是层次遍历</p>
<p>宽度优先具有最小的性质，一定能够得出到根节点的最短性。但是宽度优先需要耗费很大的空间，至少存储两层的节点，所以极其耗费空间</p>
<p>深度优先虽然没有最小的性质，但是空间复杂度低，只需要空间复杂度为树的高度的空间</p>
<p>书上的公式是书面语，不是大白话，讲究优美性，实际理解时往往需要抽象我们所理解的大白话。</p>
<p>讲题的境界： 怎么想出来的？正确性</p>
<p>动作记忆！！！</p>
<p>C++中0，NULL，nullptr是一个东西</p>
<p>声音越小越有气势，更重要的是听别人的东西，把别人的东西听懂</p>
<h2 id="待做">待做</h2>
<p>https://blog.csdn.net/weixin_39778570/article/details/86484020
基本算法篇 - 模拟 - 枚举 - 排序 - 分治 - 二分 - 倍增 - 贪心</p>
<p>链表 指针 二叉树 二叉搜索树</p>
<blockquote>
<p>二叉搜索树，父节点， 左孩子节点的函数值严格小于父节点，
右孩子节点的函数值严格大于父节点</p>
</blockquote>
<p>后序遍历： 左、右、中 前序遍历： 中，左，右 中序遍历： 左，中，右</p>
<p>进一步总结 ## 总结</p>
<p>DFS两种框架</p>
<p>第一种 起始点未定, 用层数来表明，子节点都很清晰 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int n;</span><br><span class="line">int path[]</span><br><span class="line">dfs(int i)&#123;</span><br><span class="line">    if(i==n)&#123;</span><br><span class="line">        collect path;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for(int i=0;i&lt;n;i++)</span><br><span class="line">        if(check(i))&#123;</span><br><span class="line">            p[i] = 1;  //  赋值</span><br><span class="line"></span><br><span class="line">            dfs(s);</span><br><span class="line"></span><br><span class="line">            p[i] = 0;  // 恢复</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dfs(0)</span><br></pre></td></tr></table></figure></p>
<p>第二种 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int st[N];</span><br><span class="line">int path[N];  //?</span><br><span class="line"></span><br><span class="line">dfs(int v)&#123;</span><br><span class="line">    st[v] = true; // 保证遍历不重复，不需要恢复</span><br><span class="line">    path[i] = f;</span><br><span class="line"></span><br><span class="line">    if(end)  collect</span><br><span class="line">    for(w: vw)</span><br><span class="line">        if(!st)  dfs(w);</span><br><span class="line"></span><br><span class="line">    path[i] = -1; // 其他变量需要恢复</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>BFS的写法 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int fun( )&#123;</span><br><span class="line"></span><br><span class="line">    q.push(v);</span><br><span class="line">    while(q.size()) &#123;</span><br><span class="line">        auto t=q.front();</span><br><span class="line">        q.pop();</span><br><span class="line">        </span><br><span class="line">        for(int i=0;i&lt;4;i++)</span><br><span class="line">            if(check(i)) q.push(i);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"> // ? 层次怎么体现？？</span><br></pre></td></tr></table></figure></p>
<p>DP的写法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">f[0][0] = ?</span><br><span class="line">for(i:1~n)</span><br><span class="line">    for(j:1~m)</span><br><span class="line">        f[i][j] = f[i-1][j-1]</span><br><span class="line"></span><br><span class="line">cout&lt;&lt;f[n][m]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">int f(int i,int j)&#123;</span><br><span class="line">    if(f[i][j]!=-1) return f[i][j];</span><br><span class="line">    if(base) &#123;</span><br><span class="line">        初值</span><br><span class="line">    &#125;</span><br><span class="line">    res=?</span><br><span class="line"></span><br><span class="line">    for(i:1~n)</span><br><span class="line">        for(j:1~m)</span><br><span class="line">            res=f(i-1,j-1);</span><br><span class="line">    return f[i][j]=res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dfs(0,0)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dp[0][0]</span><br><span class="line"></span><br><span class="line">bool dp(int i,int j)&#123;</span><br><span class="line">    if(f[x][y]!=-1) return f[x][y];</span><br><span class="line">    if(base) &#123;</span><br><span class="line">        return ; // 这里一般是f[i][j]具有某种具体含义的，比如两个字符串匹配，A的前i个字母和B的前j个字母这类极大值情况具有意义的</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    dp[x][y] = dp[x+1][y+2] // 看这里的状态是否好推演</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DP集合划分的方式总结</p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>acwing</category>
        <category>basic</category>
        <category>summary</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>acwing</tag>
        <tag>basic</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course BruteForce</title>
    <url>/2019/algorithm-course-BruteForce-a40add18aad0/</url>
    <content><![CDATA[<h2 id="数学归纳法溯源与公理化思维">1.1 数学归纳法溯源与公理化思维</h2>
<blockquote>
<p>首先我们需要考虑到自然数的定义到底是什么。</p>
<p>一般地，定义$$为0，注意这里参考了维基百科</p>
</blockquote>
<ol type="1">
<li><p>well-ordering principle</p>
<blockquote>
<p>任何非空的自然数集合必然有最小元素，既是最基本的原则。</p>
</blockquote></li>
<li><p>只有一种数学归纳法</p>
<blockquote>
<p>基于良序定理，考虑一组关于自然数的命题P(n).
如果P(n)不是关于所有的自然数都成立，那么必然有P(n)存在最小反例。</p>
<p>如果P(n)不对所有命题都成立，则</p>
<p><span class="math display">\[\exist a \geq 2, P(1) \and P(2) \and ...
\and \neg P(a) = True\]</span></p>
<p>否命题， P(n)对所有命题都成立</p>
<p><span class="math display">\[\exist a \geq 2, P(1) \and P(2) \and ...
\and \neg P(a) = FALSE\]</span></p>
<p>逆否命题</p>
<p><span class="math display">\[\exist a \geq 2, P(1) \and P(2) \and ...
\and P(a-1) \rightarrow P(a) =True\]</span></p>
</blockquote></li>
<li><p>一个错误的数学归纳法证明</p></li>
<li><p>算法正确性证明实例</p></li>
</ol>
<h2 id="极限实数与-n">1.2 极限、实数与$-N $</h2>
<p><span class="math inline">\(\mathbb{N} \Rightarrow
\mathbb{Z}\)</span>: 减法不封闭</p>
<p><span class="math inline">\(\mathbb{Z} \Rightarrow
\mathbb{Q}\)</span>: 除法不封闭</p>
<p><span class="math inline">\(\mathbb{Q} \Rightarrow R\)</span>:
无限，无穷概念的引入</p>
<p><span class="math inline">\(\mathbb{R} \Rightarrow
\mathbb{C}\)</span>: 引入复数域，由于是否存在根的原因</p>
<h2 id="从算法角度重新审视数学的概念">1.3
从算法角度重新审视数学的概念</h2>
<h4 id="一些基本概念">1. 一些基本概念</h4>
<ul>
<li><p>自变量， 通常是自然数</p></li>
<li><p>单调性？</p></li>
<li><p>取整 <span class="math inline">\(\lceil x \rceil , \lfloor x
\rfloor\)</span>, 问题的量往往是自然数级别的</p></li>
<li><p>对数<span class="math inline">\(\log{n}\)</span></p>
<blockquote>
<p>与之相关的现象：</p>
<ol type="1">
<li><p>折半，当问题划分规模为n的问题，经过折半查找，大概<span
class="math inline">\(\log{n}\)</span>次循环问题的规模降为常数。</p></li>
<li><p>完美二叉树，对于一个n个节点的完美二叉树，他的高度为<span
class="math inline">\(\lfloor \log{n} \rfloor\)</span>.</p>
<blockquote>
<ul>
<li><p>完美二叉树的概念</p>
<p>所有外部节点的深度都相同</p></li>
</ul>
</blockquote></li>
<li><p>二进制数的比特数。一个十进制的自然数的二进制表示所需的比特数为<span
class="math inline">\(\lfloor \log{n} \rfloor + 1\)</span>.</p></li>
</ol>
<blockquote>
<p>从数值的角度，二进制数每向右移动一位，比特数减1，数值变为原来的<span
class="math inline">\(\frac{1}{2}\)</span></p>
</blockquote>
</blockquote></li>
<li><p>阶乘</p>
<blockquote>
<p>对于n个完全不同的数，其全排列的个数为<span
class="math inline">\(n!\)</span>.</p>
<p>如果阶乘是连乘形式，通常对它取对数变成求和形式。</p>
<p>这里有个Stirling公式，因为平时用的不多，这里就不补充了</p>
</blockquote></li>
</ul>
<h3 id="常用级数求和">2. 常用级数求和</h3>
<p>求和与算法分析往往关系非常密切。</p>
<ul>
<li><p>多项式级数</p>
<ol type="1">
<li><span class="math inline">\(\sum_{i=1}^n {i} = \frac
{n(n+1)}{2}\)</span></li>
<li><span class="math inline">\(\sum_{i=1}^n i^2 =
\frac{n(n+1)(2n+1)}{6}\)</span></li>
<li><span class="math inline">\(\sum_{i=1}^n i^k = \Theta (\frac{1}{k+1}
n^{k+1})\)</span></li>
</ol></li>
<li><p>几何级数，等比数列，只考虑最大的那项即可</p></li>
<li><p>算术几何级数</p>
<blockquote>
<p><span class="math inline">\(\sum_{i=1}^k i *2^i = (k-1) 2^{k+1} +
2\)</span></p>
</blockquote></li>
<li><p>调和级数</p>
<blockquote>
<p><span class="math inline">\(\sum_{i=1}^k \frac{1}{i} = \ln k +
\Upsilon + \epsilon\)</span></p>
</blockquote></li>
<li><p>斐波拉数列</p></li>
</ul>
<h3 id="期望值-指标随机变量期望的线性特征">3. 期望值，
指标随机变量，期望的线性特征</h3>
<h3 id="蛮力算法">4. <font color='red'>蛮力算法</font></h3>
<ol type="1">
<li><p>微博名人问题: 寻找图中所有人都关注，但是不关注别人的人。</p>
<blockquote>
<p>BF1: 对每个人是否是名人进行判断，时间复杂度为<span
class="math inline">\(O(n^2)\)</span></p>
<p>BF2: 对每一对关系进行思考，根据一对关系，进行将名人进行筛选</p>
<p>本质：集合中的二元关系，所以有算法下界O(n^2) ??</p>
</blockquote></li>
<li><p>频繁项问题特例(出现次数超过一半)的线性时间解</p>
<blockquote>
<p>注意这里实际利用了<span class="math inline">\(f \geq n/2\)</span>
这件事，扩展思考 <strong><span class="math inline">\(f \geq
n/k\)</span></strong></p>
</blockquote></li>
<li><p>候选：交换左右部分，最大和连续子串问题，Maxima问题的非分治解</p></li>
</ol>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course EquivalenceClass</title>
    <url>/2019/algorithm-course-EquivalenceClass-467192978733/</url>
    <content><![CDATA[<h2 id="union-find">Union-Find</h2>
<blockquote>
<p>主要是解决等价类关系的，一般来说是具有代表元素的。</p>
<p>两个操作：1. is 2. make</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// T, V</span><br><span class="line">// 采用有根数作为数据结构</span><br><span class="line"></span><br><span class="line">IS si == sj:   </span><br><span class="line">	find(si)==find(sj)</span><br><span class="line">MAKE si==sj:    </span><br><span class="line">	t = find(si) // si的root is t</span><br><span class="line">	u = find(sj)</span><br><span class="line">	union(t,u)</span><br><span class="line"></span><br><span class="line">并查集的使用</span><br><span class="line">1. 判断是否有圈</span><br><span class="line">对于每条边，MAKE si==sj即可，然后再IS si==sj判断是否在圈上。</span><br><span class="line"></span><br><span class="line">find(v)&#123; // 寻找树的根节点</span><br><span class="line">	if v.parent == -1: return v;</span><br><span class="line">	else return find(s.parent);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">union(t,u)&#123; // 考虑特别简单的情况</span><br><span class="line">	s1 = find[t];</span><br><span class="line">	s2 = find[u];</span><br><span class="line">	h1 = tree[s1].height;</span><br><span class="line">	h2 = tree[s2].height;</span><br><span class="line">	if h1 &gt; h2:</span><br><span class="line">		s2.parent = s1;</span><br><span class="line">		tree[s1].height = h1 + h2;</span><br><span class="line">		delete tree[s2]; //注意这里应该是s2失效</span><br><span class="line">	else if h1 &lt;= h2:</span><br><span class="line">		s1.parent = s2;</span><br><span class="line">		tree[s2].height = h1 + h2;</span><br><span class="line">		delete tree[s1];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course Greedy</title>
    <url>/2019/algorithm-course-Greedy-8097c6860da3/</url>
    <content><![CDATA[<h2 id="greedy">Greedy</h2>
<blockquote>
<p>Greedy就是BestFS</p>
</blockquote>
<p>Greedy 满足三个条件</p>
<ol type="1">
<li><p>feasible, 即满足约束</p></li>
<li><p>Locally optimal</p></li>
<li><p>Irrevocable: 不可回退</p></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">// 过程可以看作是不断从candidate中，根据某种策略选择local optimal, 然后更新candidate, 重复选择过程，知道candidate为空，或者已经找到问题的解</span><br><span class="line"></span><br><span class="line">step by step解决问题</span><br><span class="line"></span><br><span class="line">Greedy(candidate) &#123;</span><br><span class="line">	S = null;  // S为解决问题的解集</span><br><span class="line"></span><br><span class="line">	while not solution(S) and candidate != null: &#123;</span><br><span class="line">		choose locally optimal x from candidate;</span><br><span class="line">        </span><br><span class="line">        candidate = candidate - &#123;x&#125;;</span><br><span class="line">        if feasible(x) then S = S + &#123;x&#125;;</span><br><span class="line">	&#125;</span><br><span class="line">		</span><br><span class="line">	if solution(S) return S;</span><br><span class="line">	else return &quot;no solution&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="mst">MST</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">primMST(G,n) &#123;</span><br><span class="line"></span><br><span class="line">	initialize the priority queue pq as empty;</span><br><span class="line">	Select vertex s to start the tree;</span><br><span class="line">	Set its candidate edge to (-1, s, 0);</span><br><span class="line">	</span><br><span class="line">	insert(pq, s, 0)</span><br><span class="line">	while(pq is not empty)&#123;	 </span><br><span class="line">         v = getMin(pq); deleteMin(pq);</span><br><span class="line">         add the candidate edge of v to the tree;</span><br><span class="line">         updateFringe(pq, G, v)</span><br><span class="line">	&#125;</span><br><span class="line">	return</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">updateFringe(pq,G,v)&#123;</span><br><span class="line">	for w that vw in E: //2m loops?</span><br><span class="line">		newWgt = w(v,w)</span><br><span class="line">		if w.status is unseen then</span><br><span class="line">			Set its candidate edge to (v,w newWgt)</span><br><span class="line">			insert(pq,w,newWgt)</span><br><span class="line">		else // w in Fringe, 需要更新在pq中的权值</span><br><span class="line">			if newWgt &lt; getPriorty(pq,w)</span><br><span class="line">				Revise its candidate edge to (v,newWgt) // 记录哪个边才是真正与之相邻</span><br><span class="line">				decreseKey(pq, w, newWgt) // 改变pq中w的权值</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">?--priorityqueue </span><br><span class="line">- getMin(pq)</span><br><span class="line">- deleteMin(pq)</span><br><span class="line">- insert(pq, w, newWgt)</span><br><span class="line">- decreseKey(pq, w, newWgt)</span><br></pre></td></tr></table></figure>
<h3 id="bestfs">BestFS</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Initialize the priority queue Fringe as empty</span><br><span class="line">while Fringe != empty do</span><br><span class="line">	v: = Fringe.extract-min();</span><br><span class="line">	&lt;process-v&gt;</span><br><span class="line">	update-fringe(v, Fringe)</span><br><span class="line"></span><br><span class="line">subroutine update-fringe(v, Fringe)</span><br><span class="line">	for w of v which is Frensh do</span><br><span class="line">		set the priority of w, insert w to Fringe</span><br><span class="line">	for w of v which is Fringe do</span><br><span class="line">		update the priority if w in Fringe, if necessary.</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course Graph</title>
    <url>/2019/algorithm-course-Graph-d0f637c0fdcd/</url>
    <content><![CDATA[<h2 id="图论与网络流">图论与网络流</h2>
<p>k连通和k-边连通的区别与联系</p>
<p>图论几大问题</p>
<ul>
<li><p>连通分支数</p></li>
<li><p>支配集</p>
<blockquote>
<p>支配集中的点根据边支配非支配集中的点</p>
</blockquote></li>
<li><p>最大点独立集</p>
<blockquote>
<p>点独立集中任意两顶点不相邻</p>
<p>注意：多次取点独立集问题就是点着色问题</p>
</blockquote></li>
<li><p>点覆盖集</p>
<blockquote>
<p>点覆盖集中的点将所有边覆盖</p>
</blockquote></li>
<li><p>边独立集</p>
<blockquote>
<p>边独立集中的任意两个边都不相邻，即求<strong>匹配</strong>数，对应于边着色</p>
</blockquote></li>
<li><p>边覆盖集</p>
<blockquote>
<p>边覆盖集中的所有边将点完全覆盖</p>
</blockquote></li>
</ul>
<p>其他问题</p>
<ul>
<li>平面图及平面图的判断</li>
<li>网络流，将图的问题一网打尽</li>
</ul>
]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course bfs</title>
    <url>/2019/algorithm-course-bfs-78364eda456a/</url>
    <content><![CDATA[<h2 id="bfs">BFS</h2>
<blockquote>
<p>注意BFS这里使用的队列所具备的性质：</p>
<p>设队列首部出元素，尾部入元素。从首到尾的元素为：v1, v2, ..., vr</p>
<p>则有： v_i.dis &lt;= v_{i+1}.dis, v1.dis &lt;= vr.dis + 1</p>
</blockquote>
<p>另外注意这里每个点染色的具体含义：</p>
<ul>
<li>white: 未进入队列</li>
<li>gray: 在队列中的元素</li>
<li>black: 出队列的元素</li>
</ul>
<ol type="1">
<li>统计变量</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct Vertex&#123;</span><br><span class="line">	string color;</span><br><span class="line">	int parent;</span><br><span class="line">	int dis; // dis这里实际就可以理解为所在的层数</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BFS-wrapper()&#123;</span><br><span class="line">	Vertex[] V = new int[n+1];</span><br><span class="line">	Edge[] E = new int[m+1];</span><br><span class="line">	</span><br><span class="line">	for v in V:</span><br><span class="line">		v.color = white;</span><br><span class="line">	</span><br><span class="line">	for v in V:</span><br><span class="line">		if v.color = white:</span><br><span class="line">			v.parent = -1;</span><br><span class="line">			BFS(v);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>有向图</li>
</ol>
<blockquote>
<p>注意到这里BFS,
实际上这里是非递归写法，所以改变颜色的状态注意要在循环内部改变。</p>
</blockquote>
<blockquote>
<p>注意，对于BFS，不可能会有DE的存在，反证法，假设各种颜色。还有就是对于有向图，uv为CE，满足u.dis</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BFS-directed(v)&#123;</span><br><span class="line">	v.color = gray;</span><br><span class="line">	v.dis = 0;</span><br><span class="line">	queue.enqueue(v);</span><br><span class="line">	while (!queue.isEmpty)&#123;</span><br><span class="line">		w = queue.dequeue();</span><br><span class="line">		for x that wx in E:</span><br><span class="line">			if x.color = white:</span><br><span class="line">				x.color = gray;</span><br><span class="line">				x.parent = w;</span><br><span class="line">				x.dis = w.dis + 1:</span><br><span class="line">				queue.enqueue(x);</span><br><span class="line">			if x.color = gray:</span><br><span class="line">				// CE: 恰好在不同的两层</span><br><span class="line">			if x.color = black:</span><br><span class="line">				// if root(w) == x: BE</span><br><span class="line">				// else if w,x在同一层 CE</span><br><span class="line">		</span><br><span class="line">		w.color = black;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	v.color = black;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="无向图">无向图</h3>
<blockquote>
<ol type="1">
<li>无向图的BE不存在（还未进入队列时，应该已经被当做TE处理了），DE同样也不存在，可以理解为BE和DE同一类</li>
<li>CE不可能为黑色，此时一定是二次遍历，之前已经遍历过</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BFS-undirected(v)&#123;</span><br><span class="line">	v.color = gray;</span><br><span class="line">	v.dis = 0;</span><br><span class="line">	queue.enqueue(v);</span><br><span class="line">	while (!queue.isEmpty)&#123;</span><br><span class="line">		w = queue.dequeue();</span><br><span class="line">		for x that wx in E:</span><br><span class="line">			if x.color = white:</span><br><span class="line">				x.color = gray;</span><br><span class="line">				x.parent = w;</span><br><span class="line">				x.dis = w.dis + 1:</span><br><span class="line">				queue.enqueue(x);</span><br><span class="line">			if x.color = gray: // CE</span><br><span class="line">				x.dis = w.dis or w.dis + 1;</span><br><span class="line">		w.color = black;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	v.color = black;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另外一个思考，BE边有用到，DE，CE边在哪些问题中会用到和处理呢。</p>
<h2 id="应用">应用</h2>
<ol type="1">
<li><p>有向图</p></li>
<li><p>无向图</p></li>
</ol>
<ul>
<li>判断二分图</li>
<li>寻找k度子图</li>
</ul>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course MST</title>
    <url>/2019/algorithm-course-MST-a96c3075543f/</url>
    <content><![CDATA[<h2 id="mst">MST</h2>
<blockquote>
<p>注意，MST从某种意义上是图上的应用关于贪心策略的一部分。</p>
</blockquote>
<h3 id="definition">Definition</h3>
<p>定义1. 常规定义： X, S, V/S, e: a lightest edge across (S,V/S)</p>
<p>证明要点：</p>
<p>首先假设cut中的一条e在MST中，然后因为cut中有一条cycle，所以必然有一条边可以构成。所以可以构成一条最小生成树，即取cycle中最小的边。</p>
<p>MST每次都有一部分。</p>
<p>定义2. Reverse-delete方法</p>
<p>delete an 最大权edge if this does not disconnect the graph.</p>
<p>Cycle Property</p>
<p>$T F T': T' F - {e} $</p>
<p>定义3.</p>
<p>10.18 求证：Minimum-weight eage across any cut is unique , so Unique
MST.</p>
<p>证明1：</p>
<p>Construct T by adding all such edges.</p>
<p><span class="math inline">\(e \in \forall MST, T \in \forall
MST\)</span></p>
<p>T is spanning tree eage.</p>
<ul>
<li>construct cycle 连通</li>
<li>no cycle ?</li>
</ul>
<p>证明2：</p>
<p>依赖于某个算法进行证明。</p>
<h3 id="code">Code</h3>
<p>更多地思考</p>
<p>使用递归与分治的策略解决MST问题</p>
<blockquote>
<p>整体思路:</p>
<ol type="1">
<li>将图按点集划分为两个集合，分别求解这两个集合的MST。</li>
<li>然后再找这两个集合之间的最小边，将两个MST一起合并为整个图的MST。</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course dp</title>
    <url>/2019/algorithm-course-dp-cb4116395333/</url>
    <content><![CDATA[<h2 id="dp">DP</h2>
<blockquote>
<p>DP是一种思想，就是通过构建图的模型来解决。但是有一个问题就是任何问题都可以表示为合法的图结构（只要是合法的图结构），即实际问题为有向图，一定存在入度为0的点和出度为0的点。那么根据依赖，就可以通过入门级动态规划得到解决的。</p>
</blockquote>
<p>然后又想一个东西。问题可以分为哪几种类？</p>
<ol type="1">
<li>离散空间上的点？还是其他？</li>
<li>从某种意义上来说，还有其他东西吗？</li>
</ol>
<blockquote>
<p>对吧？</p>
<p>其实对应的就是图论上的最优路径的问题。 感觉上没错？</p>
<p>又有人说动态规划就是图论上最优路的定义问题，感觉说的很没错了。</p>
</blockquote>
<p>如果把问题等效为图：其实在这里将问题等效为图，实际上每个节点对应的是图的状态，注意这里的状态空间而已，有的节点的状态不一定可以认为它是能行的。但这样一想又稍微有点过分，实际上它应该跟递归分治在一类。因为从表示和记录上，它是对原问题的最优解进行分解，在解的角度上进行建模而已。</p>
<p>而回溯法和分支限界法才真正地从解空间入手，至少思想上是，具体是否是还得再思考。</p>
<blockquote>
<p>又一点想法：DP不过是问题可以分解为超级简单的图结构。</p>
<p>DP理解其实可以有多个角度，只要某个角度理解明白也就明白了。</p>
<p>首先，经典角度看成是解决非重复子问题。</p>
<p>其次，本次课新的角度即看作是一个拓扑求解序列，从源头到尽头。a-&gt;b,
往往意味着的是a的解决依赖于b，所以这里就可以考虑深度优先遍历，确保是连通的。</p>
<blockquote>
<ol type="1">
<li>这里一个关键的考虑点就是BE边时，往往是需要汇聚当前的最优结果。</li>
<li>对于CE边，当结果已经得到时，有一方便的数据结构可以存储，可以直接进行查看。</li>
</ol>
</blockquote>
</blockquote>
<p>？ DP能成功运行需要的条件是什么。</p>
<p>最优子结构还是怎么的？</p>
<p>理解是否图遍历问题？即根本不需要进行图遍历。</p>
<p>图遍历的另一种感觉就是考虑上所有</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">通用框架</span><br><span class="line"></span><br><span class="line">Fibonacci by DP</span><br><span class="line"></span><br><span class="line">fibDP(soln, k)</span><br><span class="line">	int fib, f1, f2</span><br><span class="line">	if (k&lt;2) fib = k;</span><br><span class="line">	else</span><br><span class="line">		if (member(soln,k-1)==false) //member即查询子问题是否求解</span><br><span class="line">			f1=fibDP(soln,k-1)</span><br><span class="line">		else f1=retrieve(soln,k-1)</span><br><span class="line">		if (member(soln,k-2)==false)</span><br><span class="line">			f2=fibDP(soln,k-2)</span><br><span class="line">		else f2=retrieve(soln,k-2)</span><br><span class="line">	store(soln,k,fib)</span><br><span class="line">	return fib</span><br></pre></td></tr></table></figure>
<blockquote>
<p>解题三个步骤：</p>
<ol type="1">
<li>整体思路</li>
<li>算法设计</li>
<li>时空分析及正确性证明</li>
<li>改进建议</li>
</ol>
</blockquote>
<h3 id="matrix-multiplication">1. Matrix Multiplication</h3>
<h4 id="v1.-递归版本">v1. 递归版本</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mmTry1(dim, len, seq)</span><br><span class="line">	if len&lt;3 bestCost=0</span><br><span class="line">	else</span><br><span class="line">		bestCost=\infity</span><br><span class="line">		for (i=1; i&lt;=len-1; i++)</span><br><span class="line">			c=cost of muitiplication at position seq[i]</span><br><span class="line">			newSeq=seq with ith elemnt deleted;</span><br><span class="line">			b=mmTry1(dim, len-1, newSeq)</span><br><span class="line">			bestCost=min(bestCost, b+c)</span><br><span class="line">	return bestCost</span><br></pre></td></tr></table></figure>
<p>时间复杂度： T(n) = (n-1)T(n-1)+n. <span
class="math inline">\(O((n-1)!)\)</span></p>
<p>问题求解结构就是一棵树的结构。</p>
<p>不是很清晰？</p>
<h4 id="v2.-递归与分治">v2. 递归与分治</h4>
<p>看子问题的求解方式，也可以知道递归与分治版本是没有动态规划强的。</p>
<blockquote>
<p>表面上看还是子问题的规模问题</p>
</blockquote>
<p>Improved Recursion</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mmTry2(dim, low, high)</span><br><span class="line">	if(higt-low==1) bestCost=0</span><br><span class="line">	else</span><br><span class="line">		bestCost=\infity</span><br><span class="line">		for(k=low+1;k&lt;=high-1;k++)</span><br><span class="line">			a=mmTry2(dim, low, k);</span><br><span class="line">			b=mmTry2(dim, k, high);</span><br><span class="line">			c=cost of multiplication at position k;</span><br><span class="line">			bestCost=min(bestCost, a+b+c)</span><br><span class="line">	return bestCost</span><br></pre></td></tr></table></figure>
<p>时间复杂度： T(n) <span class="math inline">\(\geq\)</span> 2T(n-1) +
O(n). <span class="math inline">\(\Omega(2^n)\)</span></p>
<h4 id="v3.-入门级dp">v3. 入门级DP</h4>
<p>用二维空间存储，子问题解。</p>
<p>store(cost, low, high, bestCost)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mmTry2DP(dim, low, high, cost)</span><br><span class="line">	bestCost=0</span><br><span class="line">	for(k=low+1;k&lt;= high-1;k++)</span><br><span class="line">		if (member(low,k)==false)</span><br><span class="line">			a=mmTry2(dim,low,k)</span><br><span class="line">		else a=retrieve(cost,low,k)</span><br><span class="line">		if (member(k,high)==false)</span><br><span class="line">			a=mmTry2(dim,k,high)</span><br><span class="line">		else b=retrieve(cost,k,high)</span><br><span class="line">		c=cost of multiplication at position k;</span><br><span class="line">		bestCost=min(bestCost, a+b+c)</span><br><span class="line">	store(cost,low,high,bestCost)</span><br><span class="line">	return bestCost</span><br><span class="line">		</span><br></pre></td></tr></table></figure>
<h4 id="v4.-高级dp">v4. 高级DP</h4>
<blockquote>
<p>为什么这个好？不需要编译器进行调度</p>
<p>不管写法是否循环，都是用子问题的解去拼大问题的解。</p>
<p>循环：人为规定子问题的求解顺序。</p>
<p>递归：编译器决定递归的子问题求解顺序。</p>
<p>Tips: 二维循环找调度，一维循环找最优</p>
</blockquote>
<p>DP求解方法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Steps for applying DP:</span><br><span class="line"></span><br><span class="line">1.Define subproblems: # of subproblems</span><br><span class="line">2.Set the goal</span><br><span class="line">3.Define the recurrence</span><br><span class="line">	- larger subproblem &lt;- # smaller subproblems</span><br><span class="line">	- init. conditions</span><br><span class="line">4.Write pseudo-code</span><br><span class="line">	fill table in some order</span><br><span class="line">5.Analyze the time complexity</span><br><span class="line">6.Extract the optimal solution(optionally)</span><br></pre></td></tr></table></figure>
<p>Common subproblems in DP</p>
<ul>
<li><p>1D subproblems</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Input: x_1, x_2, ...,x_n (array, sequence, string)</span><br><span class="line">Subproblems: x_1, x_2, ..., x_i (prefix/suffix)</span><br><span class="line">#: O(n)</span><br><span class="line">Examples: Maximum-sum subarray, Longest increasing subsequence, Text justification</span><br></pre></td></tr></table></figure></li>
<li><p>2D subproblems</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--Class 1</span><br><span class="line">Input: x_1, x_2, ...,x_m; y_1, y2, ...,y_n</span><br><span class="line">Subproblems: x_1,x_2,...,x_i; y_1,y_2,...,y_i</span><br><span class="line">#: O(mn)</span><br><span class="line">Examples: Edit distance, Longest common subsequence</span><br><span class="line"></span><br><span class="line">--Class 2*</span><br><span class="line">Input:x_1, x_2, ...,x_n</span><br><span class="line">Subproblems:x_i,...,x_j</span><br><span class="line">#: O(n^2)</span><br><span class="line">Examples: Matrix chain multiplication, Optimal BST</span><br></pre></td></tr></table></figure></li>
<li><p>3D subproblems</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Floyd-Warshall algorithm</span><br><span class="line">	d(i,j,k)=min(d(i,j,k-1), d(i,k,k-1)+d(k,j,k-1))</span><br></pre></td></tr></table></figure></li>
<li><p>DP on graphs</p>
<ul>
<li><p>On rooted tree</p>
<p>Subproblems: rooted subtrees</p></li>
<li><p>On DAG</p>
<p>Subproblems: nodes after/before in the topo. order</p></li>
</ul></li>
<li><p>Knaspack problem</p>
<p>Subset sum problem, Change-making problem</p></li>
</ul>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm divideAndConquer</title>
    <url>/2019/algorithm-course-divideAndConquer-cca913faeb8c/</url>
    <content><![CDATA[<h2 id="divideandconquer">DivideAndConquer</h2>
<h3 id="recursion">1. Recursion</h3>
<blockquote>
<p>首先，BF数量级别就是n, n-1, n-2, ....</p>
<p>DivideAndConquer数量级别是n, n/2, n/4, ...</p>
<p>本质上，Recursion就是循环，不过不同的就是需要用辅助数组加for循环的结构来替换Recursion。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Recursion(a, b)</span><br><span class="line">&#123;</span><br><span class="line">	if a == 1:</span><br><span class="line">		return 1;</span><br><span class="line">	return Recursion(a/2, b);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">max_size = log_2 a;  // 递归的次数</span><br><span class="line">C[max_size+1]; //用于每次递归的结果的存储</span><br><span class="line">C[1] = 1;</span><br><span class="line">for i in (1, maxsize+1);</span><br><span class="line">	C[2^&#123;i&#125;] = C[2^&#123;i-1&#125;]</span><br></pre></td></tr></table></figure>
<h3 id="divideandconquer-1">2. DivideAndConquer</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">The general pattern</span><br><span class="line"></span><br><span class="line">directlySolve(I)&#123;</span><br><span class="line">	return ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">solve(I)</span><br><span class="line">	n = size(I)</span><br><span class="line">	if (n &lt;= smallSize)</span><br><span class="line">		solution = directlySolve(I)</span><br><span class="line">	else</span><br><span class="line">		divide I into I_1, I_2,.., I_k;</span><br><span class="line">		for i in &#123;1,..,k&#125;:</span><br><span class="line">			S_i = solve(I_i);</span><br><span class="line">		solution = combine(S_1, ..., S_k)</span><br><span class="line">	return solution</span><br></pre></td></tr></table></figure>
<p>Max-Sum</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course dfs</title>
    <url>/2019/algorithm-course-dfs-1bd1be953ca6/</url>
    <content><![CDATA[<h2 id="dfs">DFS</h2>
<blockquote>
<p>配合笔记使用，这里假设为简单图</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 统计变量</span><br><span class="line">struct Vertex&#123;</span><br><span class="line">    string color;</span><br><span class="line">    int parent;</span><br><span class="line">    int dis;</span><br><span class="line">    double discovertime;</span><br><span class="line">    double finishtime;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 处理不同连通分支</span><br><span class="line">DFS-Wrapper()</span><br><span class="line">&#123;// 其中n为数组的长度</span><br><span class="line">    Vertex[]  V = new int[n+1]&#x27;</span><br><span class="line">    Edge[] E = new int[m+1];</span><br><span class="line"></span><br><span class="line">    // initiliaze</span><br><span class="line">    for v in V:</span><br><span class="line">        v.color = white;</span><br><span class="line">    time = 0;</span><br><span class="line">    </span><br><span class="line">    for v in V:</span><br><span class="line">        if color[v]==white:</span><br><span class="line">            v.parent = -1;</span><br><span class="line">            DFS(v);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="有向图">有向图</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DFS-directed(v) &#123;</span><br><span class="line">    v.color=gray;</span><br><span class="line">    time ++;  v.dicovertime = time;</span><br><span class="line">    pre processing of dfs;</span><br><span class="line"></span><br><span class="line">    for w that vw in E:</span><br><span class="line">        if w.color = white:</span><br><span class="line">            &lt;pre-processing of TE&gt;</span><br><span class="line">            w.parent = v;</span><br><span class="line">            DFS(w);</span><br><span class="line">            &lt;post-precessing of TE&gt;</span><br><span class="line">        else if w.color = gray:</span><br><span class="line">            // BE</span><br><span class="line">        else if w.color = black:</span><br><span class="line">            if w.parent -&gt;&gt; v:  DE</span><br><span class="line">            if !(root(w,v)) || root(w,v) not in &#123;w,v&#125;: CE</span><br><span class="line"></span><br><span class="line">    post-processing of dfs;</span><br><span class="line">    time++; v.finishtime = time;</span><br><span class="line">    v.color = black;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="无向图">无向图</h3>
<blockquote>
<ol type="1">
<li>注意这里的TE,BE,DE,CE都是实际上存在的边；如果一个边访问两次，则可以将其看作是二次遍历。</li>
<li>再试想一下，如果边标记是否被访问；那么一条边可能二次遍历。如果剔除二次遍历。</li>
<li>!!!! 无向图的DFS, CE不存在</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DFS-undirected(v) &#123;</span><br><span class="line">    v.color=gray;</span><br><span class="line">    time ++;  v.dicovertime = time;</span><br><span class="line">    pre processing of dfs;</span><br><span class="line"></span><br><span class="line">    for w that vw in E:</span><br><span class="line">        if w.color = white: //TE</span><br><span class="line">            &lt;pre-processing of TE&gt;</span><br><span class="line">            w.parent = v;</span><br><span class="line">            DFS(w);</span><br><span class="line">            &lt;post-precessing of TE&gt;</span><br><span class="line">        else if w.color = gray:</span><br><span class="line">            if w.parent != v:  // BE</span><br><span class="line">            if w.parent == v:  // 二次遍历vw</span><br><span class="line">        else if w.color = black:</span><br><span class="line">            if w.parent == v // BE 二次遍历</span><br><span class="line"></span><br><span class="line">    post-processing of dfs;</span><br><span class="line">    time++; v.finishtime = time;</span><br><span class="line">    v.color = black;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="应用">应用</h2>
<p>有向图</p>
<ol type="1">
<li><p>拓扑排序</p></li>
<li><p>Critical Path</p></li>
<li><p>SCC</p></li>
</ol>
<p>无向图</p>
<ol type="1">
<li><p>割点</p></li>
<li><p>桥</p></li>
</ol>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course red-blackTree</title>
    <url>/2019/algorithm-course-red-blackTree-c70c88c9dedb/</url>
    <content><![CDATA[<h2 id="bst">BST</h2>
<blockquote>
<p>这里研究的关键问题是searching，设为key-value对，那么目标是查找value，一般来说目的是查找该value是否存在，或者更进一步返回位置。</p>
</blockquote>
<blockquote>
<p>由前面分析知，对于searching问题</p>
<ol type="1">
<li>组织为原本的形式，BF O(n)</li>
<li>组织为hash的形式，O(1)</li>
<li>组织为树的结构，O([logn])</li>
</ol>
<p>我们知道，搜索的长度实际上与搜索的树的高度密切相关，所以我们希望寻找平衡的树。</p>
</blockquote>
<blockquote>
<p>本身有多种平衡树的结构，我们这里RBT</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">递归定义，由递归定义无论如何是很容易地去写出原本的结构的。</span><br><span class="line"></span><br><span class="line">RB0</span><br><span class="line"></span><br><span class="line">RB: black (RB/ARB, RB/ARB)</span><br><span class="line"></span><br><span class="line">ARB: red (RB, RB)</span><br><span class="line"></span><br><span class="line">insert()</span><br><span class="line">delete()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course np</title>
    <url>/2019/algorithm-course-np-b6717eca6b1f/</url>
    <content><![CDATA[<h2 id="np">NP</h2>
<blockquote>
<p>这里思考一个问题</p>
<ol type="1">
<li><p>A多项式时间可规约到B；</p></li>
<li><p>B多项式时间可规约到C</p></li>
</ol>
<p>问A是否可以多项式时间规约到C？</p>
<p>问题关键在于：b=f(a), c=g(b); 多项式的复合是否还满足要求？</p>
</blockquote>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course searching</title>
    <url>/2019/algorithm-course-searching-9db73638d59c/</url>
    <content><![CDATA[<h2 id="searching">Searching</h2>
<h3 id="bf">BF</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">search(v)&#123;</span><br><span class="line"></span><br><span class="line">	for a in array:</span><br><span class="line">		if a.value = v:</span><br><span class="line">			return true;</span><br><span class="line">	return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="bst">BST</h3>
<blockquote>
<p>这里研究的关键问题是searching，设为key-value对，那么目标是查找value，一般来说目的是查找该value是否存在，或者更进一步返回位置。</p>
</blockquote>
<blockquote>
<p>由前面分析知，对于searching问题</p>
<ol type="1">
<li>组织为原本的形式，BF O(n)</li>
<li>组织为hash的形式，O(1)</li>
<li>组织为树的结构，O([logn])</li>
</ol>
<p>我们知道，搜索的长度实际上与搜索的树的高度密切相关，所以我们希望寻找平衡的树。</p>
</blockquote>
<blockquote>
<p>本身有多种平衡树的结构，我们这里RBT</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">递归定义，由递归定义无论如何是很容易地去写出原本的结构的。</span><br><span class="line"></span><br><span class="line">RB0</span><br><span class="line"></span><br><span class="line">RB: black (RB/ARB, RB/ARB)</span><br><span class="line"></span><br><span class="line">ARB: red (RB, RB)</span><br><span class="line"></span><br><span class="line">insert()</span><br><span class="line">delete()</span><br><span class="line"></span><br><span class="line">class RBTree</span><br><span class="line">	Element root;</span><br><span class="line">	RBtree leftSubtree；</span><br><span class="line">	RBtree rightSubtree;</span><br><span class="line">	int color; // red,black</span><br><span class="line">	</span><br><span class="line">	static class InsReturn</span><br><span class="line">		public RBtree newTree;</span><br><span class="line">		public int status; //ok,rbr,brb,rrb,brr</span><br></pre></td></tr></table></figure>
<h4 id="insertion">Insertion</h4>
<h3 id="hashing">Hashing</h3>
<blockquote>
<p>这里在Insert使用均摊分析， 即ArrayDouble</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Insert</span><br><span class="line">Delete //? 删除是否需要收缩</span><br><span class="line">Find</span><br><span class="line"></span><br><span class="line">hashingInsert(H, x)&#123;</span><br><span class="line">	size = num = 0;</span><br><span class="line">	if size = 0:</span><br><span class="line">		allocate a block of size 1:</span><br><span class="line">		size = 1;</span><br><span class="line">	if num = size:</span><br><span class="line">		allocate a block of size 2size:</span><br><span class="line">		size = 2size;</span><br><span class="line">	insert x into the table;</span><br><span class="line">	num ++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm course selecting</title>
    <url>/2019/algorithm-course-selecting-b482f0d63853/</url>
    <content><![CDATA[<h2 id="selecting">Selecting</h2>
<blockquote>
<p>Selecting的目标是选择出阶为k的元素，即第k小的元素，注意此时寻找的应该是函数值</p>
</blockquote>
<blockquote>
<p>因为是基于比较的选择，即使是选择max,min都需要(n-1)次的比较，所以下界必然是O(n).</p>
<p>随着k的增加，很多时候很有可能到达O(n^2)</p>
<p>所以目标是期望线性时间选择，以及最坏情况线性时间选择</p>
</blockquote>
<h3 id="期望线性时间选择">期望线性时间选择</h3>
<blockquote>
<p>!!!!
这里用到的是快速排序中的partition概念，这很符号第k小元素本身的性质。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">思想： Partition算法是采用使用第一个元素或者其他元素的方式，得到每个划分值。</span><br><span class="line"></span><br><span class="line">search(A,l,r,k)步骤：</span><br><span class="line">0. 如果l==r, 返回</span><br><span class="line">1. 使用Partition算法得到q, x=q-l+1</span><br><span class="line">2. 如果k大于x，则search(A,q+1,r,k-x+1)；如果k等于x，return A[q]; 如果k小于x， 则search(A,l,q-1,k);</span><br><span class="line"></span><br><span class="line">search(A,l,r,k)&#123;</span><br><span class="line">	if (l==r) return A[l];</span><br><span class="line">	</span><br><span class="line">	q = Partition(A,l,r);</span><br><span class="line">	x = q - l + 1;</span><br><span class="line">	</span><br><span class="line">	if(k == x) return A[q];</span><br><span class="line">	if(k &gt; x)</span><br><span class="line">		search(A,q+1,r,k-x+1)</span><br><span class="line">	if(k &lt; x)</span><br><span class="line">		search(A,l,q-1,k)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="最坏情况线性选择">最坏情况线性选择</h3>
<blockquote>
<p>这里的改进点主要在于是q尽量在中位数附近。</p>
<p>使用我们之前所学到的哪些知识。</p>
</blockquote>
<p>最坏情况线性选择</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">m* = select_median(A, l, r)</span><br><span class="line"></span><br><span class="line">select_median(A, l, r)&#123;</span><br><span class="line">	n = l - r;</span><br><span class="line">	if(n&lt;=5) solve_median(A,l,r);</span><br><span class="line">	else &#123;</span><br><span class="line">		cnt = floor(n/5);</span><br><span class="line">		int[] B=new int[cnt+1];</span><br><span class="line">		for i in &#123;1,..,cnt+1&#125;:</span><br><span class="line">			if i == cnt+1: </span><br><span class="line">				B[i-1]=select_median(A, l+5cnt, r)</span><br><span class="line">			else</span><br><span class="line">				B[i-1]=select_median(A, l+5(i-1), l+5i);</span><br><span class="line">		return select_median(B);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm-thinking-2</title>
    <url>/2019/algorithm-thinking-2-669b6099891a/</url>
    <content><![CDATA[<h2 id="basic">Basic</h2>
<p>在这里又开始想到时间复杂度这个问题。</p>
<p>对算法的最坏情况进行分析，隐含地给出了对任意输入的运行时间的上界。</p>
<p>对算法的最好情况进行分析，隐含地给出了在任意输入下运行时间的下界。</p>
<p>怎么分析问题的计算时间下界？</p>
<p>问题的计算时间下界为<span class="math inline">\(\Omega
(f(n))\)</span>. 则计算时间复杂性为<span
class="math inline">\(O(f(n))\)</span>的算法是最优算法。</p>
<p>例如，排序问题的计算时间下界为<span
class="math inline">\(\Omega(nlogn)\)</span>, 则计算时间复杂性为<span
class="math inline">\(O(nlogn)\)</span>的排序算法是最优算法。</p>
<p>问题的定义是什么？除了形式化定义，还有什么类别？</p>
<blockquote>
<p>问题这里如果一定义大一点的话，就涉及到运筹学的问题。运筹学的本质就是对问题进行分析。</p>
<p>最最关键的点知道是什么？就是按照自己的计划把该学的这些东西都给过一遍。</p>
</blockquote>
<blockquote>
<p>知乎推荐：</p>
<p>从本身来说，应该是听老师上课的课程，并结合自己的学习去思考这些问题。而且不能少了解决问题的这个点。</p>
<p>Tsitsiklis的Introduction to Linear Optimization</p>
<p>Stephen Boyd的Convex Optimization, 可以结合视频进行一起学习。</p>
<p>可以学习到什么？</p>
</blockquote>
<p>问题的分类是什么？</p>
<ol type="1">
<li><p>线性规划，最简单和基础的优化问题，目标函数（max）和约束条件(s.t)都是线性的，自变量x是实数变量，P问题（多项式时间可解）。</p>
<blockquote>
<p>注意，从所围成的可行域来说是某种范围的。</p>
</blockquote></li>
<li><p>非线性规划，目标函数或约束条件为非线性，如2次函数；</p></li>
<li><p>凸优化，约束条件形成的可行域是凸的</p></li>
<li><p>（混合）整数规划，自变量有整数变量，NP难问题（指数级算法复杂度）</p></li>
<li><p>半正定规划，每一个自变量x代表一个矩阵</p></li>
<li><p>网络流问题，一个特殊的混合整数规划问题，满足一个节点流出流量=流入流</p></li>
<li><p>动态规划、近似算法、启发式算法、遗传算法--用来解例如整数规划等NP难优化问题的算法，后俩个通常只能得到局部最优解，最经典的当属最大流最小割定理。</p></li>
</ol>
<p>问题求解是什么？问题求解有哪些步骤？</p>
<p>问题的复杂度怎么分析？</p>
<p>问题求解方法有哪些？一般优化有哪些策略？</p>
<p>进一步，</p>
<p>重新去审视各学科的知识，究竟重要的又是什么？</p>
<blockquote>
<p>软件工程中的问题求解，有意思的一点是企业版的感觉</p>
<p>“问题求解”指描述问题，以及开发计算机程序来解决问题的整个过程，这个过程包含多个阶段，包括理解待解决的问题，从概念上设计解决方案，以及用计算机程序实现解决方案。</p>
<p>解决方案通常由“算法”和“数据存储方式”两部分组成。“算法”指在有限时间解决问题的方法的分布描述。“数据存储方式”又称数据结构，是对数据组织存储方式上的概念。</p>
<p>软件的生命周期</p>
<ol type="1">
<li>问题描述</li>
<li>设计</li>
<li>风险分析</li>
<li>验证</li>
<li>编码</li>
<li>测试</li>
<li>完善解决方案</li>
<li>生产</li>
<li>维护</li>
</ol>
</blockquote>
<blockquote>
<p>扩展2： 数学建模</p>
<ul>
<li><p>整数规划：</p></li>
<li><p>线性规划，可行域通常是多面体，即由多个直线围成的多面体的感觉。最关键的一点是最优解往往在多面体的边界上。这点很棒</p></li>
<li><p>非线性规划</p></li>
<li><p>动态规划：像自己理解的一样，在这里的运用感觉上是在把问题拆分为状态和空间。进而进行低估的感觉。</p></li>
<li><p>图论：这里涉及到应用最短路问题。</p></li>
<li><p>排队论，即随机服务系统理论：</p></li>
<li><ol type="1">
<li>性态问题，即研究各种排队系统的概率规律性，主要是研究队长分布、等待时间分布和忙期分布等，包括了瞬态与稳态两种情形。</li>
<li>最优化问题，又分为静态最优和动态最优。前者指最优设计，后者指现有排队系统的最优运营。</li>
<li>排队系统的统计推断，即判断一个给定的排队系统符合哪种模型，以便根据排队理论进行分析。</li>
</ol></li>
<li><p>对策论，亦称博弈论。是研究具有斗争或竞争性质现象的数学理论和方法。对策问题的特征是参与者为利益相互冲突的各方，其结局不取决于女其中任意一方的努力而是各方所采取的策略的综合结果。</p></li>
<li><p>层次分析法：一种灵活的多决策分析方法，有点类似神经网络的感觉</p></li>
<li><p>插值与拟合：</p></li>
</ul>
<blockquote>
<p>插值：求过已知有限个数据点的近似函数</p>
<p>拟合：已知有限个数据点，求近似函数，不要求过已知数据点，只要求在某种意义下载这些点上的总偏差最小。</p>
<p>插值和拟合的目的是根据一组数据构造一组数据选一个函数作为近似，从而进行接下来的分析。</p>
<p>从感觉上，可以看作是连续问题即对应的函数形式，然后来解决问题</p>
</blockquote>
<ul>
<li>数理统计研究的对象是受随机因素影响的数据。统计的任务是由样本推断总体</li>
<li>模糊数学，时间序列</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>thinking</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>thinking</tag>
      </tags>
  </entry>
  <entry>
    <title>algorithm-thinking</title>
    <url>/2019/algorithm-thinking-d2c4a48ec47b/</url>
    <content><![CDATA[<h2 id="v2">v2</h2>
<blockquote>
<ol type="1">
<li>C++ STL</li>
<li>数据结构基础</li>
<li>图</li>
<li>暴力求解法</li>
</ol>
<ul>
<li>简单枚举</li>
<li>回溯法</li>
</ul>
<ol start="5" type="1">
<li>高效算法设计</li>
<li>动态规划初步</li>
<li>数学概念与方法</li>
<li>图论模型与算法</li>
<li>高级专题</li>
</ol>
</blockquote>
<h3 id="暴力求解法">4. 暴力求解法</h3>
<h4 id="简单枚举">4.1 简单枚举</h4>
<blockquote>
<p>一般来说，也需要对问题进行一定分析。从多个角度入手分析最小的枚举范围。</p>
</blockquote>
<h4 id="枚举排列">4.2 枚举排列</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*S</span><br><span class="line">*A</span><br><span class="line">main()&#123;</span><br><span class="line">S=&#123;1,2,..,9&#125;</span><br><span class="line">A=&quot;&quot;</span><br><span class="line">print_permutation(A,S);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">print_permutation(A, S)&#123;</span><br><span class="line">	if(S==null)&#123;</span><br><span class="line">		print A;</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		for v in sorted(S):</span><br><span class="line">			print_permutation(A+&quot;v&quot;,S-&#123;v&#125;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">在具体中的运用，比如C++</span><br><span class="line">数组A，不具有长度信息，同时可以考虑用临时变量</span><br></pre></td></tr></table></figure>
<p>考虑生成可重集的排列</p>
<blockquote>
<p>tips: 比如S中A出现的次数是否用完</p>
</blockquote>
<ul>
<li>排列子集生成</li>
</ul>
<p>n!</p>
<blockquote>
<p>怎么输出一棵解答树：</p>
<p>n</p>
<p>*a</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print_tree(t)&#123;</span><br><span class="line"></span><br><span class="line">if (t&gt;n) &#123;</span><br><span class="line"></span><br><span class="line">​	printf(X)</span><br><span class="line"></span><br><span class="line">&#125; else &#123;</span><br><span class="line"></span><br><span class="line">for(int i=t;i&lt;=n;i++)&#123;</span><br><span class="line"></span><br><span class="line">​	swap(x[i],x[t]);</span><br><span class="line"></span><br><span class="line">​	print_tree(t+1);</span><br><span class="line"></span><br><span class="line">​	swap(x[i],x[t]);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>下一个排列：</p>
<p>枚举排列常见方法有两种：一是递归枚举，二是用STL中的next_permutation.</p>
<h4 id="子集生成">4.3 子集生成</h4>
<ul>
<li><p>增量构造法</p>
<blockquote>
<p>实现规定A中的集合按升序排列好。</p>
<p>for循环的理解还不到位，阅读代码能力还有待加强。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void print_subset(int n, int* A, int cur) &#123;</span><br><span class="line">    for(int i = 0; i &lt; cur; i++) printf(&quot;%d &quot;, A[i]); // 打印当前集合</span><br><span class="line">    printf(&quot;\n&quot;);</span><br><span class="line">    if()</span><br><span class="line">    int s = cur ? A[cur-1]+1 : 0; // 确定当前元素的最小可能值</span><br><span class="line">    // 下一个元素一个是当前的前一个元素加一，并开始排列。否则就为0；隐含地处理了cur为0，无A[cur-1]的情况</span><br><span class="line">    for(int i = s; i &lt; n; i++) &#123;</span><br><span class="line">        A[cur] = i;</span><br><span class="line">        print_subset(n, A, cur+1); // 递归构造子集</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">n=4</span><br><span class="line">0</span><br><span class="line">0 1</span><br><span class="line">0 1 2</span><br><span class="line">0 1 2 3</span><br><span class="line">0 1 3</span><br><span class="line">0 2 3</span><br><span class="line">0 3</span><br><span class="line">1</span><br><span class="line">1 2</span><br><span class="line">1 2 3</span><br><span class="line">1 3</span><br><span class="line">2</span><br><span class="line">2 3</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">在枚举子集的增量法中，需要使用定序的方法，避免同一个集合出现两次。</span><br><span class="line"></span><br><span class="line">可以发现这个框架不适用，特别是当子集不是给定的自然数，而是给定的集合时。</span><br><span class="line"></span><br><span class="line">改进版</span><br><span class="line"></span><br><span class="line">S=sorted(S)=&#123;0,2,3,4&#125;</span><br><span class="line">n=len(S)</span><br><span class="line">print_subset(n,A,S,0,0)</span><br><span class="line">print_subset(n,*A,S,cur,s)&#123;</span><br><span class="line">	// 不需要界，中间过程也用于输出。</span><br><span class="line">	for(int i=0;i&lt;cur) print(A[i]);</span><br><span class="line">	printf(&quot;\n&quot;)</span><br><span class="line">	// </span><br><span class="line">	for(int j=cur;j&lt;n;j++) &#123;</span><br><span class="line">		A[cur]=S[i];</span><br><span class="line">		print_subset(n,A,S,cur+1,i+1);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">// 可用树来直观检验和表示循环的结构。</span><br><span class="line">// 还有测试时，作为一般递归函数，在i=0,1,2就有表示了。</span><br></pre></td></tr></table></figure></li>
<li><p>位向量法</p>
<blockquote>
<p>位向量法其实更适合表示即给定子集，并且子集元素非自然数那种。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">并非构造子集A本身，而是构造一个位向量B[i],其中B[i]=1,当且仅当i在子集A中</span><br><span class="line">*B</span><br><span class="line">void print_subset(n,B,cur)&#123;</span><br><span class="line">	if(cur==n) &#123;</span><br><span class="line">		for(b in B):</span><br><span class="line">			if(b) printf(b);</span><br><span class="line">		printf(&quot;\n&quot;);	</span><br><span class="line">	&#125;</span><br><span class="line">	else&#123;</span><br><span class="line">	// 两种情况，直接枚举</span><br><span class="line">		B[cur]=1;</span><br><span class="line">		print_subset(n,B,cur+1);</span><br><span class="line">		B[cur]=0;</span><br><span class="line">		print_subset(n,B,cur+1);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>二进制法</p>
<blockquote>
<p>突发奇想，想到二进制数的表示方法为 1&lt;&lt;n， n个1就为
1&lt;&lt;(n+1)-1；</p>
<p>对于位运算，其实考虑的就是数组的两个元素可能做哪些运算（在0,1层面上）？</p>
<p>基本上就三种：</p>
<ol type="1">
<li>检查该位的状态，用与&amp;</li>
<li>将该位置1。考虑用或|，或者加上一个数（速度慢）</li>
<li>将该位置0。考虑用对称差^，不行的话减去一个数（速度慢）</li>
</ol>
</blockquote></li>
</ul>
<h4 id="回溯法">4.4 回溯法</h4>
<blockquote>
<p>回溯法的关键，根据框架去思考问题。首先把问题转变为子集树或者排列树。然后找对应的约束。</p>
</blockquote>
<ul>
<li>八皇后问题</li>
</ul>
<blockquote>
<p>第一种方法：从64个格子中寻找子集或者寻找八个满足的格子。分别对应于三个约束。</p>
<p>位置+二维就可以形式化为排列数，这样就去掉了两个条件</p>
<p>限制条件为，[i,x[i]]。从某种意义上只需要和上一个元素比较是否在斜线上。就是两点斜率的绝对值为1</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*x = &#123;1,2,..,8&#125;</span><br><span class="line"></span><br><span class="line">search(t)&#123;</span><br><span class="line">	if (t &gt; n) &#123;</span><br><span class="line">		printf(&quot;sucess&quot;)</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		for(int j=t;j&lt;=n;j++)&#123;</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样有点太定势思维了，最重要的是掌握回溯法的精髓，即只需要状态的前进和恢复。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">v1: 因为这里分析出来是排列，那么可以考虑只是行被排除了。如果走到递归边界。</span><br><span class="line">首先，从初试节点开始，每个值都可以取，然后检查现在的每个节点所取的值是否与之前节点的值冲突。如果没有冲突，递归执行。</span><br><span class="line"></span><br><span class="line">v2: 没选中一个节点，对该节点周围的所有节点进行染色；所以当前仅当这些点没被染色，才可选这些节点。</span><br></pre></td></tr></table></figure>
</blockquote>
<ul>
<li><p>判断素数环</p>
<blockquote>
<p>法一、使用生成-测试法。即先将素数生成好，然后再判断是否为素数。生成所有的排列，然后测试所有的排列是否满足情况</p>
<p>法二、使用回溯法，但是值得注意的是在这里直接使用会所。然后判断每个元素</p>
<blockquote>
<p>由此也可以看出，对于生成测试法，时间复杂度就是所有情况；而对于回溯法可以去掉很多情况。所以当最坏情况的枚举量很大时，应该考虑采用回溯法而不是生成-测试法。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">回溯法</span><br><span class="line">int dfs(int t)&#123;</span><br><span class="line">	if(S==null)&#123; // 递归到达最后一层</span><br><span class="line">		print A;</span><br><span class="line">	&#125;</span><br><span class="line">	else &#123;</span><br><span class="line">		// 这里for循环对应于子树的个数</span><br><span class="line">		for v in sorted(S): // 对于众多的变形，就是很多限制排除掉一些不可能的情况</span><br><span class="line">			print_permutation(A+&quot;v&quot;,S-&#123;v&#125;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote></li>
<li><p>困难的串</p></li>
<li><p>带宽</p></li>
<li><p>天平难题</p></li>
</ul>
<h4 id="路径寻找问题">4.5 路径寻找问题</h4>
<h4 id="迭代加深搜索">4.6 迭代加深搜索</h4>
<h3 id="高级篇">5. 高级篇</h3>
<ul>
<li>再谈排序与检索</li>
<li>递归与分治</li>
<li>贪心法</li>
<li>算法设计与优化策略</li>
<li>动态规划初步</li>
<li>数学概念与方法</li>
<li>图论模型与算法</li>
</ul>
<h4 id="算法分析设计初步">5.1 算法分析设计初步</h4>
<p>一种直觉的柑橘</p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>thinking</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>thinking</tag>
      </tags>
  </entry>
  <entry>
    <title>blog:todo</title>
    <url>/2019/blog-todo-669568eee92d/</url>
    <content><![CDATA[<ol type="1">
<li><p>文字加密访问</p></li>
<li><p>收录到百度</p></li>
<li><p>new 文章时，可选参数决定是否需要创建对应的文件夹 &gt; ctrl+`,
打开终端</p></li>
<li><p>仿照博客园，添加日历</p></li>
</ol>
]]></content>
      <categories>
        <category>todo</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>todo</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>course-algorithm lecture 1</title>
    <url>/2019/course-algorithm-15428e969c0b/</url>
    <content><![CDATA[<h2 id="总览">总览</h2>
<p><img data-src="C:\Users\Dell\Pictures\QQ截图20190522162200.png" /></p>
<p>算法课上的问题有两种：</p>
<ol type="1">
<li>Order 涉及到序列的问题</li>
<li>Graph 可以建模为图的问题</li>
</ol>
<p>常见的策略主要有两种：</p>
<ol type="1">
<li><p>Traversal: 即可以理解为穷举，对每种情况都进行考虑;</p>
<blockquote>
<ol type="a">
<li><p>Order: Brute Force, 暴力遍历，如排序，选择，查找等问题</p></li>
<li><p>Graph: DFS和BFS</p></li>
</ol>
</blockquote></li>
<li><p>Optimization: 使用某些优化策略</p>
<blockquote>
<ol type="a">
<li><p>Order: Divide &amp; Conquer</p></li>
<li><p>Graph: Greedy &amp; Dynamic Programming</p></li>
</ol>
</blockquote></li>
</ol>
<h2 id="对computer和computing的理解">对Computer和Computing的理解</h2>
<p>Computer的强大之处在于能够高效地计算简单、程序式的工作</p>
<p>Computing 就三步：</p>
<ol type="1">
<li>encoding to 0,1</li>
<li>operations</li>
<li>decoding the '1's and '0's</li>
</ol>
<p>Turning machine</p>
<h2 id="algorithm的理解">Algorithm的理解</h2>
<p>Algorithm is the spirit of computing.</p>
<p>注意是用来解决某个特定的问题</p>
<p>Essential issues:</p>
<ul>
<li><p>Model of computation:</p>
<blockquote>
<ol type="1">
<li><p>默认采用的就是RAM Model.</p></li>
<li><p>注意<font color='red'>simple
opreation，这里认为基本的存储、加减、乘除都是单位1，
而实际上加减和乘法的实现的时间并不一样</font></p></li>
</ol>
</blockquote></li>
<li><p>Algorithm design</p>
<blockquote>
<ol type="1">
<li><p>分析问题、建模问题到具体的框架、解决问题、优化问题</p></li>
<li><p>正确性证明</p></li>
<li><p>例子：最小公约数证明——数学归纳法</p>
<blockquote>
<p><font color='blue'>输入、输出和结果类比证明</font></p>
</blockquote></li>
</ol>
</blockquote></li>
<li><p>Algorithm analysis</p>
<blockquote>
<ol type="1">
<li><p>Criteria, 关键操作，注意看定义的是什么</p>
<figure>
<img
src="C:\Users\Dell\AppData\Roaming\Typora\typora-user-images\1558514755914.png"
alt="1558514755914" />
<figcaption aria-hidden="true">1558514755914</figcaption>
</figure></li>
<li><p>时间复杂度</p>
<p>最好、平均、最坏</p></li>
<li><p>空间复杂度</p></li>
</ol>
</blockquote></li>
</ul>
<h2 id="图涉及问题以及算法总结">图涉及问题以及算法总结</h2>
<p><img data-src="1.png" /></p>
<h2 id="一些好的例子">一些好的例子</h2>
<ol type="1">
<li>Job scheduling</li>
<li>Matrix chain multiplication</li>
</ol>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju-course</tag>
      </tags>
  </entry>
  <entry>
    <title>clean code: reading note</title>
    <url>/2019/clean-code-reading-note-2724f049b984/</url>
    <content><![CDATA[<blockquote>
<p>由于自己写的代码老是感觉像屎一样烂，所以觉得不学学这方面的东西，真的是自己都看不下去了</p>
</blockquote>
<p>代码整洁之道 Rober C.Martin著， 韩磊译 &gt;
就学习而言，自己尽可能去过了一遍知识点，以下记的内容多半是过细的内容。要真正掌握之，
还需要summary最重要的准则，牢记于大脑中，形成做事的准则。同时，并且还要加以实战，对实例进行了解才是</p>
<p>学习参考代码· https://github.com/AugF/CleanCode</p>
<h2 id="a.-概览">A. 概览</h2>
<ol type="1">
<li>什么是整洁代码
<ul>
<li>Bjame (C++) &gt;
缺陷难以隐藏；减少依赖；分层战略处理错误代码；性能调至最优；整洁的代码只做好一件事情</li>
<li>Grady &gt; 干净利落的抽象和直截了当的控制语句</li>
<li>Dave Thomas &gt;
单元测试和验收测试；明确定义和提供清晰、尽量少的API</li>
<li>Ron &gt; 消除重复和提高表达力，提早构建简单抽象</li>
</ul></li>
<li>重点： !!! 童子军军规：让你的营地比你来时更干净。
每次签入时，都比签出干净</li>
<li>后续阅读： 敏捷软件开发：原则、模式与实践</li>
<li>章节安排
<ul>
<li>有意义的命名</li>
<li>函数</li>
<li>注释</li>
<li>格式</li>
<li>对象和数据结构</li>
<li>错误处理</li>
<li>单元测试</li>
<li>类</li>
<li>系统</li>
<li>迭进</li>
<li>并发编程</li>
<li>逐步改进</li>
<li>JUnit内幕</li>
<li>重构SerialDate</li>
<li>味道与启发 ???</li>
</ul></li>
</ol>
<span id="more"></span>
<h2 id="b.-有意义的命名">B. 有意义的命名</h2>
<ol type="1">
<li><p>目标： 名副其实（不需要注释来补充）</p></li>
<li><p>注意</p>
<ul>
<li>避免误导
<ol type="1">
<li>与平台相关的词 hp,axis,sco</li>
<li>List等约定中的词</li>
</ol></li>
<li>做有意义的区分!
<ol type="1">
<li>a1, a2, aN 这种拒绝</li>
<li>英语同义词 Info和Data名称不同，但是意义却差别不大</li>
</ol></li>
<li>避免使用编码 &gt; 匈牙利算法和成员前缀都不推荐;
一个例子，接口和实现，必须需要来表明一个，可以实现用XXXImpl</li>
<li>避免思维映射 &gt; 思维映射就是不要占用读着已经很熟知的名词</li>
<li>别扮可爱</li>
<li>别用双关语(如add)</li>
</ul></li>
<li><p>具体操作</p>
<ul>
<li>具体
<ul>
<li>类名和对象名都应该是名词，或者名词性结构，如a+n.</li>
<li>方法名，动词或动词短语，属性访问器get， 修改器set 和 断言 is &gt;
建议： 构造器使用参数的静态工厂方法</li>
</ul></li>
<li>使用读的出来的名称 &gt; 避免使用的简写很难反映出来</li>
<li>使用可搜索出来的变量 &gt;
当某个变量具有某种特别的用意的时候，避免使用常见单词，难以搜索的。比如，0表示START状态，那么就用START，不要用0</li>
<li>使用解决方案领域名称， 比如具体的代码实现部分，JobQueue,
AccountVisitor访问者模式</li>
<li>添加有意义的语境，也不要添加没用的语境，
变量搁在一块时，应该是具有某种含义的。 &gt;
就是语境划分得越明确越清楚</li>
<li>每个抽象概念对应于一个词, 如controller, driver等词是重复的</li>
</ul></li>
<li><p>良好的英语水平</p></li>
</ol>
<h2 id="c.-函数">C. 函数</h2>
<ol type="1">
<li>函数的第一规则是短小，第二规则是更短小 &gt; 24行， 80列</li>
<li>只做一件事</li>
<li>函数内容的组织
<ul>
<li>每个部分都应该是To do; 1. 2. 3.</li>
<li>使用描述性的名称，命名方式保持一致</li>
<li>函数参数，最优为零参数，然后一参数。 &gt;
对参数考虑，转换为类；对于二参数，抽象为类的成员变量</li>
<li>动词与关键字，函数的名字应该能很好地解释函数的意图</li>
<li>分隔指令与询问，要么做什么事，要么回答什么事</li>
<li>避免使用错误码</li>
<li>抽离try/catch 代码块，try，catch单独封装函数</li>
<li>别重复自己</li>
<li>结构化编程，函数应该有统一的样子，入口和出口应该标准化</li>
</ul></li>
<li>每个系统都是使用某种领域特定语言搭建，而这种语言是程序设计来描述那个系统的。函数是语言的动词，类是名词。</li>
</ol>
<p>大师级程序员把系统当作故事来讲，而不是当作程序来写。他们使用选定编程的工具构建一种更为丰富且更具表达力的语言。</p>
<h2 id="d.-注释">D. 注释</h2>
<p>能用重构代码来解决的事情，就不要考虑用注释来做</p>
<ol type="1">
<li><p>注释不能美化糟糕的代码；糟糕的代码最后进行重构</p></li>
<li><p>好注释， 应该能提供基本的信息</p>
<ul>
<li>解释了某个对象的返回值</li>
<li>对意图的解释， 为什么做这步决定</li>
<li>将复杂的代码用简单易懂的形式进行阐释</li>
<li>警示可能发生的严重的后果</li>
<li>todo注释应该解释为什么该函数的实现无所作为，将来应该是怎样</li>
<li>用于强调，强调某件事情的重要性</li>
<li>标记注释 while, for的结束也是可以的</li>
</ul></li>
<li><p>公共库JavaDoc可能也有误导、不适用或者提供错误信息</p></li>
<li><p>坏注释</p>
<ul>
<li>喃喃自语，看不懂</li>
<li>太显然，多余的注释</li>
<li>误导性注释</li>
<li>日志式注释，交给版本管理系统去解决</li>
<li>废话注释</li>
<li>注释掉的代码！！ 最没有用的，时间越长越不好</li>
<li>位置标记，可以用，用完请清除</li>
<li>HTML注释，标记太耀眼</li>
<li>信息不要过多</li>
<li>联系不紧密的注释</li>
</ul></li>
<li><p>建议</p>
<ul>
<li>能用函数或变量时就别用注释， 如
if(smodule.getDependSubsystems().contains(susSysMod.getSubSystem))</li>
<li>短函数不要太多描述，到不如给它起个好的名字</li>
<li>注释一定要放在离他最近的位置</li>
<li>非公共用途代码没有必要用Javadoc模板</li>
</ul></li>
</ol>
<p>如果注释都还需要解释的话，一定不是个好注释
能够通过看注释而省去看代码的时间就是好的注释</p>
<h2 id="e.-格式">E. 格式</h2>
<p>代码的格式对于代码的可读性非常重要。</p>
<blockquote>
<p>一个好的格式最重要的其实就是能够满足人们从上到下很自然地阅读。自然地能够获取到整体的内容。</p>
</blockquote>
<p>向报纸学习，看报纸时常常是从上到下阅读。在顶部，期望有个头条，告诉你故事主线决定是否阅读下去。第一段是故事的大纲，给出粗线条描述。接着读下去，细节渐次增加。</p>
<ol type="1">
<li>垂直格式
<ol type="1">
<li>垂直分隔 &gt;
概念上的垂直分隔，封包声明、导入声明、每个函数之间应该都有空白行处理
&gt; ? 某个函数内的逻辑是否需要用空格区分开来 &gt;
实际上看到的就是一个代码组</li>
<li>垂直方向的靠近 &gt; 空白行隔开了概念，靠近的代码行暗示它们之间的关系
<ul>
<li>临时变量应该放在最适合的位置</li>
</ul></li>
<li>垂直距离
<ul>
<li>变量声明：变量声明应该尽可能靠近使用位置</li>
<li>循环中的循环变量应该总是在循环语句中声明</li>
<li>实体变量应该在统一的位置声明，或顶部</li>
<li>相关函数 调用者应该在被调用者的上面</li>
<li>概念相关的代码应该放在一起，比如同名函数</li>
</ul></li>
</ol></li>
<li>横向格式
<ul>
<li>建议80到120个字符，应该一个屏幕宽度能够阅读.</li>
<li>使用空格字符将彼此紧密相关的连接在一起，也用空格字符将相关性较弱的事务分割开，比如在赋值符左右加空格，其实是为了强调赋值操作有两个确定的要素：左边和右边；
不在函数名和左圆括号之间加控股个，因为函数与其参数紧密相关</li>
<li>空格字符的另一个用法就是强调其前面的字符</li>
<li>水平不对齐</li>
<li>缩进：
整个文件、文件中的类、类的方法、方法中的代码块、代码块中的代码组</li>
</ul></li>
</ol>
<p>遵循团队规则！！！</p>
<h2 id="f.-对象和数据结构">F. 对象和数据结构</h2>
<ol type="1">
<li><p>不愿以抽象形态表述数据</p></li>
<li><p>数据、对象的反对称性：</p>
<ul>
<li>对象把数据隐藏于抽象之后，暴露操作数据的函数。数</li>
<li>数据结构暴露其数据，没有提供有意义的函数</li>
</ul></li>
<li><p>过程式代码 vs 面向对象式代码</p>
<ul>
<li>过程式代码（使用数据结构的代码）便于在不改动现有数据结构的前提下添加新函数</li>
<li>面向对象代码便于在不该懂即有函数的情况下添加新类</li>
</ul></li>
<li><p>The Law of Demeter: &gt;
模块不应该了解它所操作对选哪个的内部情况。</p>
<p>类C的方法f只应该调用以下对象的方法 ?（第二次看到，还是不够理解）</p>
<ul>
<li>C &gt; C本身的函数和方法? 这里看起来是非常模糊的</li>
<li>由f创建的对象 &gt; C中所拥有的的临时变量?</li>
<li>作为参数传递给f的对象 &gt; 即参数</li>
<li>由C的实体变量持有的对象 &gt; C的成员</li>
</ul>
<blockquote>
<p>一个违反的例子： final String
outputDir=ctxt.getOptions().getScratchDir().getAbsolutePath();
这个例子叫做火车失事，实际上是因为一致地强调访问器和改值器导致的 ?
为什么违反了?
感觉是因为ctxt.getOptions()，如果返回的是对象，就违反了对象的原则，从而违反了得墨宓定律。
由此产生的一个想法就是：
让数据结构只简单地拥有公共变量，没有函数。而对象则拥有私有变量和公共函数。</p>
</blockquote></li>
</ol>
<blockquote>
<p>对象（类）应该隐藏结构。</p>
</blockquote>
<ol start="5" type="1">
<li><p>数据传送对象
最精简的数据结构，是一个只有公共变量、没有函数的类。这种数据传送对象DTO.</p></li>
<li><p>总结 &gt;
在实际情况中，通常会面对两种需求：一是增加新的类型，二是增加新的行为。面向对象，隐藏数据，便于添加对象，无须改变现有结构。数据结构则便于添加函数，添加变量会引起全局的混乱。
如何平衡呢？在面向对象中的想法就是把数据结构转变为Bean这类特别的类来做，提供公有的访问器和改值器。一般的类最后私有化变量。</p></li>
</ol>
<h2 id="i.-错误处理">I. 错误处理</h2>
<p>错误处理很重要，但是如果它搞乱了代码逻辑，就是错误的做法。 1.
使用异常而非返回码 &gt;
调用者必须在调用之后即刻检查错误，不幸地是，这个步骤很容易被遗忘 2.
先写try-catch-finally语句 &gt;
try中的代码表明随时都可以取消，catch的代码表示替代方案。
其实这种方案的想法就是面对测试编程，尝试编写强行抛出异常的测试，再往处理器中添加行为，使之满足测试要求。
&gt; 这也是一种很好的写代码的入口方式 3. 使用不可控异常 &gt;
这是一种有利有弊的操作；一方面，这会破坏开闭原则，即当最底层的代码进行改变时，比如抛出某个异常，上层都需要为此进行改变，对一般的应用开发，会耗费非常大的成本；另一方面，可控异常可以较快地反映错误
&gt; C++,C#就没有考虑不可控异常，直接将异常当地处理 4.
给出异常发生的环境说明，异常说明应该详尽，至少包括失败的操作和失败类型
5. 将第三方的API异常进行打包是一件有益于代码整洁和解耦的操作 - 修改之前
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ACMEPort port = <span class="keyword">new</span> ACEMPort(<span class="number">12</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    port.open();</span><br><span class="line">&#125; <span class="keyword">catch</span> (DeviceResponseException e) &#123;</span><br><span class="line">    reportPortError(e);</span><br><span class="line">    logger.log(<span class="string">&quot;Device response execption&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (ATM1212UnlockedException e) &#123;</span><br><span class="line">    reportPortError(e);</span><br><span class="line">    logger.log(<span class="string">&quot;Unlock exception&quot;</span>, e);</span><br><span class="line">&#125; <span class="keyword">catch</span> (GMXError e) &#123;</span><br><span class="line">    reportPortError(e);</span><br><span class="line">    logger.log(<span class="string">&quot;Device response exception&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> - 修改之后 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">LocalPort port = <span class="keyword">new</span> LocalPort(<span class="number">12</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    port.open();</span><br><span class="line">&#125; <span class="keyword">catch</span> (PortDeviceFailure e) &#123;</span><br><span class="line">    reportError(e);</span><br><span class="line">    logger.log(e.getMessage(), e);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LocalPort</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ACMEPort innnerPort;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LocalPort</span><span class="params">(<span class="keyword">int</span> portNumber)</span> </span>&#123;</span><br><span class="line">        innnerPort = <span class="keyword">new</span> ACMEPort(portNumber);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            innerPort.open();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (DeviceResponseException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> PortDeviceFailure(e);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ATM1212UnlockedException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> PortDeviceFailure(e);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (GMXError e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> PortDeviceFailure(e);</span><br><span class="line">        &#125;</span><br><span class="line">        ... </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 6.
定义常规流程。当常规逻辑被异常打断时，可以考虑使用特例模式，即创建一个类或者配置一个对象来处理特例。
7. 不要返回null值和传递null值!!!</p>
<h2 id="j.-边界">J. 边界</h2>
<p>使用第三方的代码，第三方程序包和框架提供普适性，往往存在着很大的张力。
作为使用者，一种建议是应该对代码进行一定程度的封装。</p>
<p>习惯 1. 学习性测试：也是自己常有的习惯 &gt;
学习性测试事一种精确试验，一方面可以增进对API的理解，另一方面可以确保第三方程序包按照我们想要的方式工作。
进一步，还可以学习到相关的新的特性 2. 未来的属性：
考虑Adapter模式，封装为接口 3.
边界的代码需要清晰的分割和定义期望的测试，应该避免我们的代码过多地了解第三方代码中的特定信息。</p>
<h2 id="k.-单元测试">K. 单元测试</h2>
<p>单元测试非常重要， 测试应该像生产代码一样好好地维护</p>
<ol type="1">
<li><p>TDD三定律：</p>
<ul>
<li>在编写不能通过的单元测试前，不可编写生产代码</li>
<li>只可编写刚好无法通过的单元测试，不能编译也算不通过</li>
<li>值编写刚好足以通过当前失败测试的生产代码</li>
</ul></li>
<li><p>测试代码应该和生产代码一样，保持整洁 &gt; !!!
最重要的，可读性</p></li>
<li><p>断言形式总结</p>
<ul>
<li>assertTrue</li>
<li>assertFalse</li>
<li>assertContains 集合</li>
<li>assertEqual</li>
</ul></li>
<li><p>测试的三个过程：</p>
<ul>
<li>构造 build</li>
<li>操作 operate</li>
<li>测试 check</li>
</ul></li>
<li><p>测试的原则</p>
<ul>
<li>每个测试保证一个断言，对于重复的代码考虑字符串映射（位标记）、模板方法来消除代重复问题
&gt; 也并非要一个断言，但是断言一定要保持在特别小的数量</li>
<li>每个测试函数一个概念</li>
</ul></li>
<li><p>测试的原则 FIRST</p>
<ul>
<li>Fast 快速</li>
<li>Independent 独立</li>
<li>Repeatable 可重复</li>
<li>Self-Validating 自足验证</li>
<li>Timely 及时</li>
</ul></li>
</ol>
<h2 id="l.-类">L. 类</h2>
<p>前面主要讨论的是代码语句及由代码语句构成的函数的表达力。</p>
<blockquote>
<p>注意静态变量和非静态变量的多种叫法；
非静态变量又称为实体变量，静态变量又称为类变量</p>
</blockquote>
<ol type="1">
<li>类的组织 &gt;
对于类来说，从一组变量列表开始，顺序通常是公有静态变量，私有静态变量，私有实体变量，公有实体变量。接着是共有函数的组织，公有函数的组织的建议是按照调用顺序。
<ul>
<li>封装：通常我们喜欢保持变量和工具函数的私有化，有时我们也需要用到protected变量或工具函数，好让测试可以访问</li>
</ul></li>
<li>类应该短小
<ul>
<li>标准：单一职责原则，类的名称应该能描述其职责，如果都无法为某个类以精确的命名，那么这个类多半是有问题了。
&gt;
类的模块应该只有一条加以修改的理由。系统应该由许多短小的类而不是少量巨大的类组成。</li>
</ul></li>
<li>内聚
<ul>
<li>内聚即指中的方法和变量相互依赖、相互结合，
<ul>
<li>方法与变量之间的联系：
类中的变量基本上都被类中的方法覆盖，覆盖得越多，说明内聚性越强。</li>
<li>方法与方法之间的联系： 方法之间相互调用</li>
<li>变量与变量之间的联系：无</li>
</ul></li>
</ul></li>
<li>如何拆分巨大的函数为小类？ &gt;
实际上的想法就是首先按函数的每个过程从职责层面进行划分。然后，把某个职责抽象为类，相关涉及到的变量直接提升为类的实体变量。
<ul>
<li>重构后的程序往往有更长、更有描述性的变量名。函数和类声明可以当作是给代码添加注释的一种手段</li>
<li>这个过程如何做？ &gt;
一种建议就是面向测试编程，每进行修改一次，就进行测试一次。</li>
</ul></li>
<li>为了修改而组织
<ul>
<li>开闭原则一直是一个非常重要的原则！ 即对扩展开放，对修改封闭</li>
<li>通常的一种想法就是提出抽象类，进行子类化的方法来达到目的。即把与不变的抽为基类，把各种的其它的情况但是需要保持不变的变为子类。当需要增加时，增加子类即可</li>
</ul></li>
<li>隔离修改
<ul>
<li>通常来说，需求会改变，所以代码也会改变。具体类包含实现细节。所以我们的想法就是能够避免客户所用到的接触到具体类的实现，即高层次使用，这样也就能做到隔离修改的目的</li>
<li>一种解决的想法就是借助接口和抽象类来做隔离这些细节带来的影响</li>
<li>测试可以直接面向接口测试 &gt;
为了降低连接度，类的设计会考虑到遵循另外一条原则，即依赖倒置原则</li>
</ul></li>
</ol>
<h2 id="m.-系统">M. 系统</h2>
<blockquote>
<p>程序的设计实际上从某种方面都是从生活中进行学习。对于系统架构来说，学习的标准就是建筑行业</p>
</blockquote>
<p>复杂要人命，它消磨开发者的生命，让产品难以规划、构建和测试。
除去代码层次上的整洁，系统上的整洁同样重要</p>
<ol type="1">
<li><p>如何建造一个城市 &gt;
其实可以发现，建造一座城市，一个人不能熟知所有的细节，也不能完成所有的工作。每个城市在运转时形成了由一组组人管理不同的部分，彼此互相合作。</p></li>
<li><p>将系统的构造和使用分开</p>
<ul>
<li>系统的构造和使用，也可以说是启动过程和启动之后，也就是编译和运行。
在启动过程中构建应用对象，会存在相互纠结的依赖关系</li>
<li>一个坏的例子 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// class</span></span><br><span class="line"><span class="keyword">private</span> Service service;</span><br><span class="line"><span class="function"><span class="keyword">public</span> Service <span class="title">getService</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (service == <span class="keyword">null</span>) &#123;</span><br><span class="line">        service = <span class="keyword">new</span> MyServiceImpl(...)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> service;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>问题 &gt;
这里使用了延迟初始化/赋值的技术，问题就在编译器在解释时，需要把MyServiceImpl的代码全部解析为源代码。而且测试部分想要测试时，必须对该部分进行测试，加大了测试的难度。没有做到测试部分的独立性。实际上我们的期望是运行时构建即可，分别进行测试。
<ul>
<li>延迟初始化这种技术不好?</li>
</ul></li>
<li>如何做？
<ul>
<li>一种最初步的想法就是将全部构造搬迁到main函数中，负责管理构造过程，而且将其他部分认为都是构建好的</li>
<li>使用工厂方法分离构造过程， 系统的构造和具体工厂的实现细节分开。
何时创建对象</li>
<li>一种更高效的方法： 依赖注入</li>
</ul></li>
</ul></li>
<li><p>依赖注入</p>
<ul>
<li>一种基本的想法就是把控制也看成一种职责，交给特定的类来管理。专业术语：控制翻转</li>
<li>例子： Spring, Java DI容器, XML配置文件其实也是用的这个</li>
<li>相关问题：
<ul>
<li>系统如何扩容？ 当对系统提出更高层次的要求时，系统如何进行扩展
<ul>
<li>EJB做法 &gt;
EJB采用传统的继承来做，非常不好，一个类中会出现太多的竖向和方法</li>
<li>横贯式关注面 面向方面编程 AOP &gt;
也就是对整个架构来讲，利用多个切面的组合来管理系统。
这个方面的划分往往是根据某种共有的特性来划分。
<ul>
<li>AOP如何用代码实现? &gt; 系统将每个类外面都套了一层，装饰者模式，
客户以为与实际对象打交道，实际上是先跟方面进行打交道。 &gt;
方面其实也就是一个系统管理者的身份 &gt; Spring
简化了方面编程，使用了描述性语言来做</li>
</ul></li>
<li>something else: 同AOP一样使用的是字节码技术， 即getattr() &gt;
字节码操作库：在运行层面来操作代码，动态（运行过程中）指定类和方法的库。可以由Java或者其他语言写；
代码和复杂度是两大弱点</li>
<li>纯Java AOP框架</li>
</ul></li>
</ul></li>
<li>相关概念
<ul>
<li>POJO: 普通的javabean</li>
<li>EJB: 企业级javabean规范</li>
</ul></li>
<li>好处：
<ul>
<li>测试驱动系统架构 &gt;
将代码层面与架构关注面分离开，可以用测试来驱动架构。</li>
<li>优化决策： 实现了分散化管理和决策</li>
<li>模块化(尽量使用大概可工作的最简单方案)+关注面：
各部分独立，关注于自我的部分，进一步可以开发该模块领域特定语言</li>
</ul></li>
</ul></li>
</ol>
<h2 id="n.-迭进">N. 迭进</h2>
<blockquote>
<p>这章题目有点晦涩，也就是教怎么做到整洁开发？</p>
</blockquote>
<p>整洁开发四个重要性由高到低的考虑顺序 - 运行所有的测试 &gt;
只有可验证才能保证可靠性 - 重构 -
不可重复：即指类不能重复，同时也可以指方法的实现应该避免重复。模板方法是重用的方法，把非重复的内容交给实际去做。
- 表达力： 好名称、好类名和好函数名。 只有通过不断尝试才能达到 -
尽可能少的类和方法 &gt;
上面的概念不可过度使用；也不可因为教条主义使得类又大又长</p>
<h2 id="o.-并发编程">O. 并发编程</h2>
<p>对象是过程的抽象，线程是调度的抽象</p>
<blockquote>
<p>要认识到并发设计是一件超级难的事情</p>
</blockquote>
<blockquote>
<p>私以为，多线程编程其实是想借助并行，即同时运行多个程序来提高效率。但是，者多个线程之间难免会涉及到临界区，临界区往往还会涉及到数量的问题，因此需要对临界区的互斥访问。</p>
</blockquote>
<ol type="1">
<li><p>为什么要并发？</p>
<ul>
<li>并发是什么？
<ul>
<li>并发也是一种解耦策略，它帮助我们把做什么（目的）和何时（时机）做分解开</li>
<li>单线程应用中，目的与时机紧密耦合，只需要根据堆栈跟踪即可断定应用程序的状态</li>
</ul></li>
<li>并发的目的
<ul>
<li>并发主要是解耦，解耦目的和时间主要是为了改变应用程序的吞吐量和结构，响应时间</li>
</ul></li>
<li>并发的场景
<ul>
<li>Servlet, 一个页面请求的资源被多个所共享</li>
<li>单线程聚合信息，需要访问多个web网点</li>
<li>考虑某个解释大量数据集，但只在处理完全部数据后给出一个完整解决方案的系统。
数据集并行处理</li>
</ul></li>
<li>注意
<ul>
<li>并发并不总是能改进性能。并发需要系统在多个CPU之间切换以及维护互斥访问的开销。所以相对来说，并发会在性能和编写额外代码上增加一些开销。同时，并发带来的好处只在多个线程或者处理器之间能够分享大量等待时间的时候，可以充分地利用等待时间。</li>
<li>正确的并发是复杂的，对简单的问题同时如此</li>
<li>并发常常需要对设计策略的根本性改变</li>
</ul></li>
</ul></li>
<li><p>理解并发的关键</p>
<ul>
<li>Just-In-Time 编译器如何对待生成的字节码? &gt;
Java字节码是Java虚拟机执行的一种指令格式。感觉上也就是指令吧</li>
<li>Java内存模型认为什么东西具有原子性？ &gt;
区分原子性的东西，即多个线程会同时执行到。</li>
</ul></li>
<li><p>并发防御原则</p>
<ul>
<li>单一职责原则： 应该分离并发代码和非并发代码 &gt;
一种可行的方案是在并发代码和非并发代码的边界使用POJO来封装，因此在测试时可以分离测试</li>
<li>限制数据作用域 &gt;
在Java中唯一的解决方案就是采用synchronized关键字。
限制临界区的数量非常重要
<ul>
<li>不好的后果
<ul>
<li>忘记保护一个或多个临界区</li>
<li>花很多时间保证一切受到保护</li>
<li>很难找到错误源，判断错误源</li>
</ul></li>
</ul></li>
<li>推论：使用数据副本
<ul>
<li>避免数据共享的好方法就是一开始就避免共享数据。复制对象只可以通过只读方式对待，如果需要修改对象，则从多个线程收集所有复本的结果，并在单线程中进行合并</li>
<li>balance:
使用对象复本避免了锁定而省下的价值是否有可能补偿得上额外的创建成本和垃圾收集开销</li>
</ul></li>
<li>线程应尽可能独立</li>
<li>了解Java库 Java5
<ul>
<li>使用类库提供的安全群集</li>
<li>使用executor框架执行无关任务</li>
<li>尽可能使用非锁定解决方案</li>
<li>有几个类是非线程并发的 &gt; 获取、释放锁， 计数器锁，
指定数量事件发生锁</li>
</ul></li>
</ul></li>
<li><p>了解执行模型</p>
<ul>
<li>基础定义
<ul>
<li>限制资源，固定尺寸或数量的资源</li>
<li>互斥： 每个时刻仅有一个线程能访问共享资源或共享数据</li>
<li>线程饥饿： 一个或一组线程长时间内或者永久被禁止</li>
<li>死锁：多个线程互相等待执行结束</li>
<li>活锁： 多次尝试起步，却总是失败</li>
</ul></li>
<li>执行模型
<ul>
<li>生产者-消费者模型： 固定数量的共享资源，一方提供，一方使用</li>
<li>读者-写着模型： 共享数据， 读者读取使用， 写者进行数据更新 &gt;
https://blog.csdn.net/yanfeivip8/article/details/12527047</li>
<li>哲学家问题： 竞争式系统。 多个系统同时争夺共有资源 &gt;
https://zh.wikipedia.org/wiki/%E5%93%B2%E5%AD%A6%E5%AE%B6%E5%B0%B1%E9%A4%90%E9%97%AE%E9%A2%98</li>
</ul></li>
<li>工具：
<ul>
<li>信号变量mutex, 专门负责互斥使用</li>
<li>计数变量，对一定数量进行统计 &gt;
一般地，对于共享资源的访问，以及计数变量的更改都要求使用信号变量;</li>
</ul></li>
<li>设计关键： 对入口和出口的限制进行准确的分析</li>
<li>实战： todo</li>
</ul></li>
<li><p>警惕同步方法之间的依赖 &gt;
如果多个方法都是同步，并且产生依赖确实是一件头大的事。
建议使用一个共享对象的多个方法</p>
<ul>
<li>如何使用一个共享对象的多个方法?
<ul>
<li>基于客户端的锁定：
客户端代码在调用第一个方法前锁定服务端，确保锁的范围覆盖了调用最后一个方法的代码</li>
<li>基于服务端的锁定，在服务端内创建服务端的方法，调用所有方法，然后解锁，让客户端代码调用新方法</li>
<li>适配服务端： 创建执行锁定的中间层</li>
</ul></li>
</ul></li>
<li><p>保持同步区域微小</p></li>
<li><p>很难编写正确的关闭代码 &gt;
编写永久运行和编写运行一段时间后平静地关闭的系统是两码事 &gt;
在多线程中，平静关闭往往很难做到，常见问题与死锁有关，线程一直等待永远不会到来的信号。
&gt; 1. 一个系统从父进程中分出多个子进程，当某个子进程发生死锁时 &gt; 2.
生产者消费者模型中，生产者已经按照父进程要求迅速关闭，然后消费者会一直迟迟地等待着资源不能关闭</p></li>
<li><p>测试线程代码 &gt;
编写最有潜力暴露问题的测试，在不同的编程配置、系统配置和负载条件下频繁运行。如果测试失败，跟踪错误。别因为后来测试通过后来的运行就忽略失败</p>
<ul>
<li>将偶然发生的失败看成线程失败</li>
<li>先使非线程代码可工作</li>
<li>编写可插拔的线程代码： 编写可在数个配置环境下运行的线程代码
<ul>
<li>单线程与多个线程在执行时不同的情况</li>
<li>线程代码与实物或者测试替身互动</li>
<li>用运行快速、缓慢或有变动的测试替身执行</li>
<li>将测试配置为能运行一定数量的迭代</li>
</ul></li>
<li>编写可调整的线程代码： 即线程的数量可调整</li>
<li>运行多于处理器数量的线程</li>
<li>在不同的平台上运行</li>
<li>装置试错代码，试图用随机方法来测试平时无法覆盖的路径。
Object.wait(), sleep(), yield() 和 priority(), 改变代码的执行顺序。
<ul>
<li>如何装置？
<ul>
<li>硬编码：手工插入这些语句</li>
<li>自动化： 使用Aspect-Oriented Framework,
ASM之类工具通过编程来装置代码。 专门使用单个类来做。</li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<h2 id="p.-逐步改进一个关于args的实例">P.
逐步改进：一个关于Args的实例</h2>
<ol type="1">
<li><p>准则：
编程如同写作文，不可能一开始就写得非常好，是逐步进行迭代的。
对于程序来说，目标首先一开始是能工作，但是最后一个一定要是一个完美的状态。</p></li>
<li><p>可以感觉到的是Args的源码有着非常好的设计，体现在以下几个方面：</p>
<ul>
<li>将一个大的函数按简洁代码的要求拆分为足够小的函数</li>
<li>每个类的书写都符号规范</li>
<li>代码的设计很好地符合了设计模式的指导，即高内聚、低耦合；
活用继承和接口</li>
<li>异常的处理也非常合理</li>
</ul></li>
<li><p>实际指导意义 &gt;
首先不可能从最原始的想法开始推，但一般开发来说，不要求很复杂，我们只需要首先开发出第一个可行的版本，然后再秉承着“测试通过，不重复，短小的类”的原则进行更新</p></li>
</ol>
<h2 id="q.-junit内幕">Q. JUnit内幕</h2>
<h2 id="r.-重构serialdate">R. 重构SerialDate</h2>
<h2 id="s.-味道与启发">S. 味道与启发</h2>
<h2 id="附录-并发编程ii">附录： 并发编程II</h2>
]]></content>
      <categories>
        <category>code</category>
        <category>technology</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>technology</tag>
      </tags>
  </entry>
  <entry>
    <title>course-algorithm lecture2</title>
    <url>/2019/course-algorithm-lecture2-8d2f51eeb29f/</url>
    <content><![CDATA[<h2 id="l2.-asympototic">L2. Asympototic</h2>
<h3 id="growth-rate-of-functions">1. growth rate of functions</h3>
<ol type="1">
<li>用关键操作的数量来进行衡量</li>
</ol>
<figure>
<img
src="C:\Users\Dell\AppData\Roaming\Typora\typora-user-images\1558515224097.png"
alt="1558515224097" />
<figcaption aria-hidden="true">1558515224097</figcaption>
</figure>
<blockquote>
<ol type="1">
<li><p><span class="math inline">\(f \in O(g) \Leftrightarrow f(n) \leq
kg(n)\)</span></p>
<blockquote>
<p>这里 <span class="math inline">\(lim_{n \rightarrow \infty}
\frac{f(n)}{g(n)} &lt; \infty\)</span>
注意可以<strong>不存在</strong>或者等于0</p>
</blockquote></li>
</ol>
</blockquote>
<p><font color='red'>注意对于O来说，极限可以不存在；对于</font></p>
<ol start="2" type="1">
<li>增长率级别的一个概念</li>
</ol>
<blockquote>
<p>由小到大：<span class="math inline">\(logn, n, nlogn, n^k, 2^n,
n!\)</span></p>
</blockquote>
<ol start="3" type="1">
<li>一些经验数据，数量级与时间和空间的感觉</li>
</ol>
<h3 id="brute-force的思考">2. Brute Force的思考</h3>
<p>例子1： Swapping array elements: 交换数组中的所有元素</p>
<p>&lt;time, space&gt;</p>
<ol type="1">
<li><p>BF1 &lt;O(n^2), O(1)&gt;</p>
<blockquote>
<p>冒泡的思想，即把第一个元素不断冒泡冒泡到最后一个元素去。</p>
</blockquote></li>
<li><p>BF2 &lt;O(n), O(n)&gt;</p>
<blockquote>
<p>对辅助空间进行处理</p>
</blockquote></li>
<li><p>？ &lt;O(n), O(1)&gt;</p>
<blockquote>
<p>不断对元素进行交换的思想</p>
</blockquote></li>
</ol>
<p>例子2： Maximum subsequence sum: 寻找最大子序列和</p>
<ol type="1">
<li><p>BF1 <span class="math inline">\(O(n^3)\)</span></p>
<blockquote>
<p>最朴素的思想： 定最左边的限度，在动态寻找右边的限度，再计算片段和</p>
<figure>
<img
src="C:\Users\Dell\AppData\Roaming\Typora\typora-user-images\1558538541074.png"
alt="1558538541074" />
<figcaption aria-hidden="true">1558538541074</figcaption>
</figure>
</blockquote></li>
<li><p>BF2 <span class="math inline">\(O(n^2)\)</span></p>
<blockquote>
<p>定左边的限度后，对于右边实际上不用定完限寻找片段和。</p>
<figure>
<img
src="C:\Users\Dell\AppData\Roaming\Typora\typora-user-images\1558538558913.png"
alt="1558538558913" />
<figcaption aria-hidden="true">1558538558913</figcaption>
</figure>
</blockquote></li>
<li><p>分治 <span class="math inline">\(O(n\log{n})\)</span></p>
<figure>
<img
src="C:\Users\Dell\AppData\Roaming\Typora\typora-user-images\1558538619802.png"
alt="1558538619802" />
<figcaption aria-hidden="true">1558538619802</figcaption>
</figure></li>
<li><p>线性</p>
<figure>
<img
src="C:\Users\Dell\AppData\Roaming\Typora\typora-user-images\1558538654841.png"
alt="1558538654841" />
<figcaption aria-hidden="true">1558538654841</figcaption>
</figure></li>
</ol>
<h2 id="l3.-recursion">L3. Recursion</h2>
<h3 id="recursion">1. Recursion</h3>
<p>特别想说明的就是，通过学习了计算模型导引后的感觉就是对于任何的函数都可以写成递归式，如以下几种方式：</p>
<ol type="1">
<li>本原函数：零函数、后继函数、投影函数</li>
<li>复合算子，减法，u算子，max算子</li>
</ol>
<p>最终写成带参递归方式，即</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">h(x,0) = f(x)</span><br><span class="line">h(x,y+1)=g(x,y,h(x,y))</span><br><span class="line">// 其中x可以为向量</span><br></pre></td></tr></table></figure>
<p>但是在算法中的常见形式为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">M(1) = 1</span><br><span class="line">M(n) = 2M(n-1)+1</span><br></pre></td></tr></table></figure>
<p>然后对于该算法分析就可以用解生成函数的方法来解。</p>
<h3 id="divide-and-conquer">2 . Divide and Conquer</h3>
<ul>
<li><p>Divide: Divide the "big" problem to smaller ones</p></li>
<li><p>Conquer: Solve the "small" problems by recursion</p></li>
<li><p>Combine: Combine results of small problems, and solve the
original problem</p>
<blockquote>
<p><font color='red'>对于我来说，这块常常是我的难点。问题在于务必请想清楚这里原问题的解和这里合并的解是否相同</font></p>
</blockquote></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">divectlySolve(I) &#123;&#125;</span><br><span class="line"></span><br><span class="line">combine(S1，..., Sk) &#123;&#125; // 时间复杂度为f(n)</span><br><span class="line"></span><br><span class="line">// k--- the number of divide parts, 设为c</span><br><span class="line">// the number of subquestions: size(I)/size(Ii)，设为b</span><br><span class="line"></span><br><span class="line">solve(I) &#123;</span><br><span class="line">	n = size(I)</span><br><span class="line">	if (n &lt;= smallSize)</span><br><span class="line">		solution = directlySolve(I);</span><br><span class="line">	else</span><br><span class="line">		divide I into I1, ..., Ik</span><br><span class="line">		for each i \in &#123;1, ..., k&#125;</span><br><span class="line">			Si = solve(Ii);</span><br><span class="line">		solution = combine(S1, ..., Sk)</span><br><span class="line">	return solution</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>算法分析的常见形式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">T(n) = bT(n/c) + f(n)</span><br><span class="line">T(1)可以在常数时间解决</span><br></pre></td></tr></table></figure>
<h3 id="对比">3. 对比</h3>
<ul>
<li><p>Recursion,</p>
<blockquote>
<p>粒度： n, n-1, n-2,...</p>
</blockquote></li>
<li><p>Divide and Coqueer</p>
<blockquote>
<p>粒度： n, n/2, n/4, ...</p>
</blockquote></li>
</ul>
<p>递归形式都可以统一为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">T(n) = bT(n/c) + f(n)</span><br><span class="line">T(1)可以在常数时间解决0</span><br></pre></td></tr></table></figure>
<p>求解时间复杂度：</p>
<ol type="1">
<li>解递归方程</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">最小阶看作0，其余看作x的多少次方，然后待定系数法。再根据常数时间做出来。</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>先猜，然后数学归纳法进行证明。</li>
</ol>
<p>特别地，<font color='red'>Master定理</font>, 令<span
class="math inline">\(E = log_c b\)</span></p>
<figure>
<img
src="C:\Users\Dell\AppData\Roaming\Typora\typora-user-images\1558532639381.png"
alt="1558532639381" />
<figcaption aria-hidden="true">1558532639381</figcaption>
</figure>
<h3 id="examples">4. Examples</h3>
<ul>
<li>Maxima 找最大的数</li>
<li>Frequent element 找出现次数最多的数</li>
<li>Multiplication 大整数相乘</li>
<li>Nearest point pair 最邻接点</li>
</ul>
<p>Recursion vs Induction 归纳与演绎</p>
<p>Smooth functions: 非负非减函数，对于此类函数满足<span
class="math inline">\(f(bn) \in O(f(n))\)</span></p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>nju-course</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>nju-course</tag>
      </tags>
  </entry>
  <entry>
    <title>daily cplus thinking</title>
    <url>/2019/daily-cplus-thinking-f792bd59e5ea/</url>
    <content><![CDATA[<h2 id="c-多文件组织">C++ 多文件组织</h2>
<h3 id="问题">1. 问题</h3>
<p>之前大学学习的时候也是这个问题一直在困扰自己没有得到解决。
主要想思考着将计算机系统基础所学知识联系起来思考。 首先，两个问题： 1.
多个cpp中调用同一个.cpp, 或者重复调用一个.h, 或者变量重复怎么办 2.
头文件中有那个#ifdef定义的怎么用</p>
<blockquote>
<p>现在已经知道的就是c++在编译的过程中是先将cpp文件进行编译（有时间再复习计算机基础的知识，结合起来进行思考）。</p>
</blockquote>
<h3 id="想法">2. 想法</h3>
<p>gcc编译过程有静态链接和动态链接的过程。对于动态链接就是增加已经预先编译好的东西。</p>
<p>一般来说，编译器会做以下几个过程： 1. 预处理阶段 2.
词法与语法分析阶段 3.
编译阶段，首先编译成纯汇编语句，再将之汇编成跟CPU相关的二进制码，生成各个目标文件(obj文件)
4.
连接阶段，将各个目标文件中的各段代码进行绝对地址定位，生成跟特定平台相关的可执行文件</p>
<p>注意，1主要是处理源文件中的宏、变量、函数声明、嵌套的头文件包含等东西，然后重新生成C文件。
2和3通常为一起，此时已经产生了符号表。已经将全局符号和局部变量分开了。而且在操作系统中，建立了对应的符号表以及将定义位置和引用都联系好了。同时，已将将全局变量还有程序转入了对应的程序的位置区段。</p>
<p>哪些已经编译好的内容是指直接只差操作系统指定将代码放在哪里了，只要操作系统指定位置，那么就可以指定按行行动，然后产生文件了？
&gt;
刚刚看了维基百科，其实这里所表述的链接也很正常，易于理解。实际上就是所想的那样的。dll提出的初衷也就是为了复用，比如window窗口部件。直接复用就可以调用同样的功能。</p>
<h4 id="静态编译">2.1 静态编译</h4>
<p>首先，不管是IDE还是命令行，IDE不过是命令行的一个集成，帮你把什么东西都设置快捷了，让你来进行操作。
gcc .cpp .cpp
它会把每个cpp进行编译成.o文件，再由.o文件一起生成可执行文件。
main.cpp一定是在最后。 ##### 为什么有.h和.cpp文件？
.h文件一般是放说明的，而.cpp一般是对应的实现；（同名警告！？
是会给编译过程带来好处吗？）</p>
<p>如果一个.h中声明太多，需要两个.cpp来书写可以吗，如果允许，这样感觉同名潜规则没必要。不允许，编译器规定死了，相关声明只能从相关同名文件中去找。然后，如果其他.cpp声明要用到该环境直接用即可。</p>
<p>所以一般来说，那我们再构建其他文件时，只需要include
.h文件就可以了啊，没有必要引入其他文件。</p>
<p>对啊，因为你生成的是cpp文件，所以这里每个cpp对应的是.o，
它会在对应的表上记录。
那么对应的cpp与源文件存在依赖关系，所以这里就涉及到依赖关系。 &gt;
依赖关系，这里就是图的拓扑排序。还有一个问题，记得计算机系统基础中有讲过gcc
后面的参数对表的构建其实也是有影响的</p>
<p>同时，又可以回答一个问题，在cpp中引用stdio.h也是没有问题的啊。因为这些不过是标志着它会去找文件，所以完全就没有关系。最终不过是生成.o文件是，它会把对应的库中的文件进行替换而已。</p>
<h5 id="一些关键字作用的思考">一些关键字作用的思考</h5>
<ol type="1">
<li><p>incline ？incline声明的会先一步静态编译到程序中。
extern感觉上更多的用法是在一个cpp文件中使用的是另一个文件中的，然后却并不会指出是在哪个文件中定义又初始化的，不安全，不建议使用该关键字。</p></li>
<li><p>define #
define关键字的使用也相当明了了。我们的目的是什么，就是每个.h文件应该管理自己特有的变量和函数声明这样我们就能使程序避免变得杂乱无章。而且像<code>#define
FILE_H</code>这种操作，只能在file.h中做啊，其他情况你为什么要这么做。而加
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#ifndef CPLUS_LAB1_STACK_H</span><br><span class="line">#define CPLUS_LAB1_STACK_H</span><br><span class="line">stack.h特有的</span><br><span class="line">#endif //CPLUS_LAB1_STACK_H</span><br></pre></td></tr></table></figure> 不过是避免犯错，编译特有的。</p>
<p>思考define的第二种用法，首先在命令行或者某个场合环境下，你需要说明你现在是什么环境，或者代码里定义环境。然后，在代码里使用对应的条件判断语句也就很轻易的判断出是哪个了。
##### 多文件组织
多个.h之间的依赖，有什么例子吗？如果是结构体，比如有个queue的操作，现在我又要新建一个优先级queue的操作，所以可以用到queue的操作。那么就涉及到进阶的知识即抽象为类，以及类之间的关系表示。</p></li>
</ol>
<p>一般来说书写.h文件的话没有必要那么多和复杂。而且一般是直接引用两个相对独立的.h,
共同使用它们的函数。然后其实一个cpp也可以调用多个.h的，那么这样的话，按前面的想就明了。
有反常情况吗？</p>
<p>还有一个问题可以创建文件的问题，至少在clion中，因为MakeFile是自己书写，所以只用把文件路径点名即可，照样可以操作，对。</p>
<h4 id="动态链接">2.2 动态链接</h4>
<p>.dll未明朗解决</p>
<h3 id="进一步思考和建议">3. 进一步思考和建议</h3>
<p>MakeFile相关的东西 整理以及实践的结果</p>
<p>一点额外的东西：
一般情况下，程序并不关心栈的具体分配情况，但进行混合语言编程时，则要考虑不同语言在栈使用上的差别。
&gt; 1. 还需要考虑哪些？</p>
<h3 id="再理解的内容">4. 再理解的内容</h3>
<ul>
<li><a
href="https://blog.csdn.net/u010167037/article/details/19680877">关于如何将多个Cpp组织起来
-jamesheros</a></li>
<li><a
href="https://blog.csdn.net/candcplusplus/article/details/53326368">菜鸟攻略-C语言多文件编程初探
-流沙的刺客</a></li>
<li><a
href="https://blog.csdn.net/lee244868149/article/details/39341751">头文件与同名源文件的关系-奔跑的路</a></li>
<li><a
href="https://blog.csdn.net/xhbxhbsq/article/details/78955216">C语言中，头文件和源文件的关系</a></li>
<li>计算机系统基础, 袁春风</li>
<li>程序员的自我修养-链接、装载与库 &gt; 只是被推荐，未读</li>
</ul>
]]></content>
      <categories>
        <category>daily</category>
        <category>thinking</category>
      </categories>
      <tags>
        <tag>thinking</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>daily note 11-28</title>
    <url>/2019/daily-note-11-28-69bb52eae150/</url>
    <content><![CDATA[<h2 id="a.-今日遗留任务">A. 今日遗留任务：</h2>
<ol type="1">
<li>查看GAT代码，思考是否能够直接用tensorflow multiplication来表示。
回看GGCN论文 https://github.com/Diego999/pyGAT/blob/master/layers.py
GAT论文还提出一个很有意思的点，就是tensorflow只能做batch类似的操作，不能做graph并行化</li>
</ol>
<ul>
<li><p>pytorch torch.mul(a,b): 元素相乘 torch.mm(a,b): 矩阵相乘 self.W =
(in_features, out_features) self.a = (2*out_fatures, 1) pytorch
检查成功</p></li>
<li><p>tensorflow 没有检查成功！ import tensorflow as tf node1 =
tf.Tensor node2 = tf.Tensor addr = node1 + node2 sess = tf.Session()
print(sess.run(addr))</p></li>
</ul>
<ol start="2" type="1">
<li>已经安装了eigen, C++数学计算库，计划在vscode中实现
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sparse/mat_mul_op.cc
https://blog.csdn.net/wilsonass/article/details/90754525
多线程，相乘的感觉，没有看到具体的算法 g++ -I /path/to/eigen/
my_program.cpp -o my_program</li>
</ol>
<p>C++ 模板程序也能理解，好像直接将这个放在对应的源文件目录下就可以
https://blog.svenhetin.com/c-ju-zhen-yun-suan-ku/</p>
<p>或许应该先了解稀疏矩阵的乘法是怎么？
https://www.cnblogs.com/wangkundentisy/p/9267764.html</p>
<p>进阶：思考如何进行</p>
<ol start="3" type="1">
<li><p>再思考tensorflow中能够做什么 &gt;
其实tensorflow和pytorch中所表示的都是矩阵的运算，不过所给的卷积操作，还是其他的
&gt; NeuGraph中提到Certain algorithms不能直接用Tensorflow multiplication
operations来表达是什么意思？ 实际上感觉就是矩阵操作。
所以说初步结论：就是tensorflow中没有直接的函数，即矩阵相乘的运算可以一步到位。
需要借助repeat, reshape的运算。 再运用乘法</p></li>
<li><p>阅读GraphSage论文，思考框架 Inductive 归纳 deuctive 演绎
tranductive 转导的</p></li>
</ol>
<p>transductive 特殊到特殊，测试数据也是未来出现的一部分 inductive
learning: 测试数据只用与训练，需要归纳到一般
https://www.zhihu.com/question/68275921</p>
<p>纠正一个错误：之前PPT上说inductive自己说错了。 应该是侧重于用途</p>
<p>感觉inductive像是一个某类问题的模板，比如排序 without task-specific
transductive像是一个具体的算法，求最大值？</p>
<p>tocheck 6. 重点：讨论AliGraph,
再细看AliGraph论文，以及后面的实验部分！
NeuGraph思考的是如何在GPU上进行加速
AliGraph是针对自己的平台的多个特性按需扩展 skip-gram论文？ word2vec
word2vec: 关键问题，如何对一个词进行表示？</p>
<p>power layer 原则，实际上的做法是</p>
<ol start="7" type="1">
<li><p>阅读how to read a paper, sparse</p></li>
<li><p>回顾NeuGraph
neugraph，重点：如何解决点划分，进而带来的每个块的负载均衡问题。
采用了两个策略：1</p></li>
</ol>
<h2 id="b.-现有框架的缺点">B. 现有框架的缺点：</h2>
<p>NeuGraph: 1. 图结构一旦确定，不能改变，不支持动态 2. 不支持GAT 3.
效果真的会比GraphSage好吗？ 看实验部分！！！ 未认真看</p>
<h2 id="paper-lists">1. Paper Lists</h2>
<h3 id="deep-learning-supported-dataflow-frameworks">1.1 Deep Learning
Supported Dataflow Frameworks</h3>
<p>TensorFlow[13], PyTorch[14], MXNet[15], CNTK[16]</p>
<h3 id="graph-processing-systems">1.2 Graph Processing Systems</h3>
<p>Pregel[1], GraphLab[2], PowerGraph[3], GraphX[4]</p>
<h3 id="graph-neural-networks">1.3 Graph Neural Networks</h3>
<p><strong>1. Survey</strong> A Comprehensive Survey on Graph Neural
Networks[25]</p>
<p><strong>2. Graph Convolution Networks</strong> 1stChebNet[26],
GGNN[27]</p>
<p><strong>3. Others</strong> CommNet[28]</p>
<h3 id="gnns-modeling-frameworks">1.4 GNNs Modeling Frameworks</h3>
<p>GraphSAGE[17], MPNN[18], GNBlock[19]</p>
<h3 id="gnns-parallel-systems">1.5 GNNs Parallel Systems</h3>
<p>NeuGraph[29], AliGraph[30]</p>
<h3 id="non-gnns-parallel-works">1.6 Non-GNNs Parallel Works</h3>
<p>AMPNet[23], BPT-CNN[24]</p>
<h3 id="optimizations">1.7 Optimizations</h3>
<p><strong>1. Graph Layout, Sequential Data Access, and Secondary
Storage</strong> GraphChi[5], Grace[6], FlashGraph[7], XStream[8],
Chaos[9]</p>
<p><strong>2. Ditributed Shared Memory</strong> Grappa[10]</p>
<p><strong>3. NUMA-Awareness, Scheduling, and Graph
Partitioning</strong> PowerLyra[11], BiGraph[12]</p>
<p><strong>4. Sparse Works</strong> Sparse Deep Neural Network Graph
Challenge[22]</p>
<h3 id="others">1.8 Others</h3>
<p><strong>1. Bridge the Gap between Graph and Traditional Machine
Learning Computation</strong> TuX2[20]</p>
<p><strong>2. Introduce the Vertex-Centric Programming Model into
Dynamic Neural Networks</strong> Cavs[21]</p>
<h3 id="aligraph">1.9 AliGraph</h3>
<h2 id="references">2. References</h2>
<p>[1] Elmagarmid, A. K., Agrawal, D., &amp; Association for Computing
Machinery. Special Interest Group on Management of Data. (n.d.). Pregel:
A System for Large-Scale Graph Processing. [2] Low, Y., Gonzalez, J.,
Kyrola, A., Bickson, D., Guestrin, C., &amp; Hellerstein, J. M. (2150).
Distributed GraphLab: A Framework for Machine Learning and Data Mining
in the Cloud. [3] Gonzalez, J. E., Low, Y., Gu, H., Bickson, D., &amp;
Guestrin, C. (n.d.). PowerGraph: Distributed Graph-Parallel Computation
on Natural Graphs (Vol. 12). [4] Flinn, J., Levy, H., ACM Special
Interest Group in Operating Systems., USENIX Association, &amp; ACM
Digital Library. (n.d.). GraphX: Graph Processing in a Distributed
Dataflow Framework. [5] Kyrola, A., Blelloch, G., &amp; Guestrin, C.
(n.d.). GraphChi: Large-Scale Graph Computation on Just a PC. [6]
Prabhakaran, V., Wu, M., &amp; Weng, X. (2012). Managing Large Graphs on
Multi-Cores With Graph Awareness Design for a Graph Management System.
USENIX Annual Technical Conference. [7] Zheng, D., Mhembere, D., Burns,
R., Vogelstein, J., Priebe, C. E., &amp; Szalay, A. S. (2014).
FlashGraph: Processing Billion-Node Graphs on an Array of Commodity
SSDs. [8] Roy, A., Mihailovic, I., &amp; Zwaenepoel, W. (2013).
X-Stream: Edge-centric graph processing using streaming partitions. SOSP
2013 - Proceedings of the 24th ACM Symposium on Operating Systems
Principles, 472–488. [9] Roy, A., Bindschaedler, L., Malicevic, J.,
&amp; Zwaenepoel, W. (2015). Chaos: Scale-out graph processing from
secondary storage. SOSP 2015 - Proceedings of the 25th ACM Symposium on
Operating Systems Principles, 410–424. [10] Nelson, J., Holt, B., Myers,
B., Briggs, P., Ceze, L., Kahan, S., &amp; Oskin, M. (2015).
Latency-Tolerant Software Distributed Shared Memory. USENIX Annual
Technical Conference (ATC) [11] Chen, R., Shi, J., Chen, Y., Zang, B.,
Guan, H., &amp; Chen, H. (2018). PowerLyra: Differentiated graph
computation and partitioning on skewed graphs. ACM Transactions on
Parallel Computing, 5(3). [12] Chen, R., Shi, J. X., Chen, H. B., &amp;
Zang, B. Y. (2015). Bipartite-Oriented Distributed Graph Partitioning
for Big Learning. Journal of Computer Science and Technology, 30(1),
20–29. [13] Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean,
J., … Zheng, X. (2016). TensorFlow: A system for large-scale machine
learning. [14] PyTorch. http://pytorch.org, Retrieved January,2019. [15]
Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., … Alberta, M. U.
(n.d.). MXNet: A Flexible and Efficient Machine Learning Library for
Heterogeneous Distributed Systems. [16] Yu, D., Eversole, A., Seltzer,
M., Yao, K., Huang, Z., Guenter, B., … Slaney, M. (2015). An
Introduction to Computational Networks and the Computational Network
Toolkit. In Microsoft Technical Report. [17] Hamilton, W. L., Ying, R.,
&amp; Leskovec, J. (2017). Inductive representation learning on large
graphs. Advances in Neural Information Processing Systems,
2017-Decem(Nips), 1025–1035. [18] Gilmer, J., Schoenholz, S. S., Riley,
P. F., Vinyals, O., &amp; Dahl, G. E. (2017). Neural message passing for
quantum chemistry. 34th International Conference on Machine Learning,
ICML 2017, 3, 2053–2070. [19] Battaglia, P. W., Hamrick, J. B., Bapst,
V., Sanchez-Gonzalez, A., Zambaldi, V., Malinowski, M., … Pascanu, R.
(2018). Relational inductive biases, deep learning, and graph networks.
1–40. [20] Xiao, W., Xue, J., Miao, Y., Li, Z., Chen, C., Wu, M., …
Zhou, L. (2017). Tux2: Distributed Graph Computation for Machine
Learning. Nsdi ’17, 669–682. [21] Xu, S., Zhang, H., Neubig, G., Dai,
W., Kim, J. K., Deng, Z., … Xing, E. P. (2018). Cavs: An Efficient
Runtime System for Dynamic Neural Networks. 2018 {USENIX} Annual
Technical Conference ({USENIX} {ATC} 18), 937–950. [22] Kepner, J.,
Alford, S., Gadepally, V., Jones, M., Milechin, L., Robinett, R., &amp;
Samsi, S. (n.d.). Sparse Deep Neural Network Graph Challenge. [23]
Gaunt, A. L., Johnson, M. A., Riechert, M., Tarlow, D., Tomioka, R.,
Vytiniotis, D., &amp; Webster, S. (2017). AMPNet: Asynchronous
Model-Parallel Training for Dynamic Neural Networks. [24] Chen, J., Li,
K., Member, S., Bilal, K., Zhou, X., Li, K., &amp; Yu, P. S. (n.d.). A
Bi-layered Parallel Training Architecture for Large-scale Convolutional
Neural Networks. [25] Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C.,
&amp; Yu, P. S. (2019). A Comprehensive Survey on Graph Neural Networks.
X(X), 1–22. [26] Kipf, T. N., &amp; Welling, M. (n.d.). SEMI-SUPERVISED
CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS. [27] Li, Y., Tarlow,
D., Brockschmidt, M., &amp; Zemel, R. (2015). Gated Graph Sequence
Neural Networks. (1), 1–20. [28] Sukhbaatar, S., Szlam, A., &amp;
Fergus, R. (2016). Learning multiagent communication with
backpropagation. Advances in Neural Information Processing Systems,
2252–2260. [29] Ma, L., Yang, Z., Miao, Y., Xue, J., Wu, M., Zhou, L.,
&amp; Dai, Y. (2019). NeuGraph: Parallel Deep Neural Network Computation
on Large Graphs. 2019 USENIX Annual Technical Conference (USENIX ATC
19), 443–458. [30] Zhu, R., Zhao, K., Yang, H., Lin, W., Zhou, C., Ai,
B., … Zhou, J. (2018). AliGraph: A comprehensive graph neural network
platform. Proceedings of the VLDB Endowment, 12(12), 2094–2105.</p>
]]></content>
  </entry>
  <entry>
    <title>daily thinking</title>
    <url>/2019/daily-thinking-7d135d21c29f/</url>
    <content><![CDATA[<p>感觉不及时写写自己的想法，自己可能会对自己所犯的错误记得不够牢靠</p>
<h2 id="一点想法">一点想法</h2>
<h3 id="问题">问题</h3>
<ol type="1">
<li><p>前段时间，没头没脑地看似很认真地同时并行地学习tensorflow，结果发现笔记也有很多。其实还是给忘的差不多了，仍然不会；
&gt; ! 某段时间应该集中在一件事情上，事情不在多，在精</p></li>
<li><p>用来三天时间搭博客，前面看一些教程，东看看西看看，结果一遇到bug啥都不会。资料不是最新的，不是学习的官方的资料
&gt; ! 一定要自己对大纲了解，以及学习最官方的资料</p></li>
<li><p>关于论文的梯度公式看了很多篇文章以及进行推导，结果实现却花了很多时间仍未完成。
&gt; !
一开始学习的途径不对，计算机最大的特点就是在于实践！每做一件事情时请务必动手</p></li>
<li><p>论文太多，太杂? 感觉看不过来 &gt; ! 学会慢慢地分类</p></li>
<li><p>比如画出一个图形，其实用matplotlib很好画，可就是没想通？ &gt;
记住别人的设计是面向对象的，图灵机，一切都是由最简单的堆叠而成</p></li>
<li><p>代码迟迟不想下手 &gt;
记住！代码这件事，只有不断地练习；谨记！永远不要期望第一版的代码有多好，重点是自己的想法实现了才是最重要的；
而且当你做了之后才发现自己哪些地方问题特别大</p></li>
<li><p>时间应该花在最基本的东西的学习和了解上! &gt;
最基础的东西应该要反复过才行，不要贪多</p></li>
<li><p>现在的时间自己仍然不可控 &gt; !
现在最重要的是能把自己的想法做完和事情做完，其他地慢慢就会会了
<span id="more"></span></p></li>
</ol>
<blockquote>
<p>更新! 2019-9-12
今天真的做了超级多的无用功，发现其实根本是自己论文中有些东西都没读清楚，还有源代码都没有学会怎么做，就开始动手写！真的太惨了,
就此说明，好的论文一定要不断地读，不懂的话就再读·</p>
</blockquote>
<h3 id="总结">总结</h3>
<p>感觉中适合我的学习方法就是: 1. 审定这件事情自己需要了解到什么程度
&gt;
以前总是执着于这个点，总感觉学得东西反正都会有用的，所以都学下总是好的。可以认真细想下来会发现，互联网的技术等东西真的是太多了，而且随着社会的进步，要有社会的洞察力，很多东西很多工作别人做得很好了就没必要投入。准则：</p>
<pre><code>- 这件事情是否是自己的刚需， 一定要做吗？ 收益有多大？
- 目标是什么？怎么学？需要花费多少时间？是否会破坏现有的计划？
- 从某种角度出发，也是按需出发了
- 时间花在培养自己不变的，最基础的能力上</code></pre>
<ol start="2" type="1">
<li>看全局，系统地所有的介绍，并做到心中有数。 &gt;
比如，前几天自己搭建博客时，东看看，细看看，看一下现有的东西，结果发现，做完后自己一点记忆点都没有。最终还是得从头来，把最基本的了解了
<ul>
<li>途径： 名校基础课，行业标杆，名始，名人上对齐，google搜索</li>
<li>知乎： 先树立好整体的框架</li>
<li>时间： 20%</li>
</ul></li>
<li>初步计划，并对计划中的事情大概有着心中时间的拟定。 &gt; 做的不好，
待定； 该步计划后面会发现没啥用</li>
<li>早动手，动态调整计划 &gt;
当只有对已经做过的事情积累了足够多的经验，对现实世界了解后。才能对以后的时间规划更为合理</li>
<li>学会舍弃一些不要的东西，或者避开，不要忘了你的目标</li>
<li>过程中抽出框架，总结！一定要总结</li>
<li>良好的作息，身体！</li>
</ol>
]]></content>
      <categories>
        <category>daily</category>
        <category>summary</category>
      </categories>
      <tags>
        <tag>thinking</tag>
        <tag>daily</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title>deep learning study</title>
    <url>/2019/deep-learning-study-68ede45a5372/</url>
    <content><![CDATA[<h2 id="tensorflows">1. tensorflows</h2>
<p>tensorflow 数据流图 用于数值计算单开源软件库</p>
<p>Nodes : 数学操作 &gt; 特别地，有数据输入和数据输出的节点，
或者是读取、写入持久变量的终点 &gt; persistent</p>
<p>edges: 多维数据数组， tensor &gt; 根据不同的计算, 张,
即数据的大小可变size</p>
<p>特征 - 高度的灵活性，可自己写C++ - 可以在CPU, GPU, Docker等，
Portablilty 可移植性 - 科研和产品 - 自动求微分 &gt;
只需要添加数据和目标函数，可以自动计算相关的微分导数 - 多语言支持 -
支持线程、队列、异步操作的支持，可以自由第将TensorFlow中的计算元素分配到不同的设备中</p>
<span id="more"></span>
<h3 id="什么是tensorflow">1.1 什么是tensorflow</h3>
<p>能够在几行代码之内构建模型，能够在几十或几百个机器的簇是哪个进行训练，从而用该模型进行非常低的延迟预测</p>
<p>模型会以图的形式展现出来，可以推迟或删除不必要的操作，甚至重用部分结果，还可以很轻松地实现的一个过程叫做反向传播。
基于所见的样本以及计算的误差。来更新模型中的链接强度，这整个过程就是反向传播</p>
<p>因为模型表现为操作图而不是代码，因此会自动地计算以及应用这些迭代更新。</p>
<p>可以用一行代码声明，我想这部分图在这里运行，另一部分分布式运行在不同的机器上。</p>
<p>注重数学的在GPU上运行，与此同时，数据输入的代码在CPU运行。专门的硬件TPU</p>
<p>tensorflow可以在ios安卓、甚至树莓派等设备上加载。</p>
<p>TensorBoard可视化哦工具</p>
<h3 id="tensorflow可以做什么">1.2 tensorflow可以做什么</h3>
<p>谷歌在多种应用上应用了tensorflow</p>
<h3 id="tensorflow入门指南">1.3 tensorflow入门指南</h3>
<ul>
<li><p>边: Tensor &gt; 把所所有都看作张量 &gt; 属性 - 数据类型
tf.float32, tf.complex32 ? 怎么表示, tf.int32, tf.string, tf.bool - 形状
list: [1,2,3,4] &gt; 操作 - 获取阶 tf_tensor1_ndim = tf.rank(tf_tensor1)
- 切片 tensor[:,1] ?是否是引用 - 返回numpy数组 tf.eval(tensor) &gt;
分类</p>
<ul>
<li>每次运行都一样
<ul>
<li>1维 tf.constant(tf.type)</li>
</ul></li>
<li>每次运行都不一样 &gt; 占位input_node = tf.placeholder(tf.int32) +
输入 sees.run( , feed_dict={input_node: 2})</li>
<li>每次运行中都发生变化，比如模型中的参数 &gt; 如果设置变量
<ul>
<li>tf_var = tf.get_variable(name, shape=, initializer=tf.costant())
<ul>
<li>name唯一标志，不可重复，下文可直接使用？一般两个名字一样？ &gt;
理解: name主要有两个用法：1.保存时可以直接使用变量保存 2.
tensorboard时用来使用 &gt; why?
因为这里name实际上是tensorflow中自己存储的命名空间，而py文件中的名字是python中的命名空间，所以当脚本运行终止后将不复存在</li>
<li>shape:[1,2], []表示标量</li>
<li>initializer: 默认值 arry-like &gt;
如果默认所有变量都使用默认值启动，那么tf.global_variables_initializer()
&gt; 当发生变化时，判断是否合理
<ul>
<li>取值
<ul>
<li>tf.constant</li>
<li>tf.zeros_initializer, tf.glorot_uniform_initializer</li>
</ul></li>
</ul></li>
<li>变量检查 assign_node = tf.assign(tf_var, default_node) default_node
= tf.constan(arr) 为true表示成功</li>
<li>运行时靠什么启动? sess.run(assign_node), sess.run(tf.var)</li>
</ul></li>
<li>tf_var = tf.Variable(initializer=arr_like_list, tf.type, name=,
traninable=Fals.e, collections=[]) collections表示可能的类型 &gt; 获取值
sess.run(tf_var.initializer) sess.run(tf_var)</li>
<li>进阶：考虑作用域问题，将问题转换为作用域问题 &gt;
用途主要在RNN循环神经网络的构建中会使用到 with
tf.variable_scope(scope_name, reuse=False): v1 = get_variable('x', [1])
&gt; 技巧： 把每个层看作一个单元 scope_name为str, 直接进行改变名称即可;
当指定reuse=True时，可以进行变量复用</li>
</ul></li>
</ul></li>
<li><p>节点： operation</p></li>
<li><p>架构</p>
<ul>
<li>sess = tf.Session()
<ul>
<li>sess.run(args)
<ul>
<li>args(0): list(nodes) 需要输出的节点</li>
<li>feed_dict={} : 为前面tf.placeholder(tf.int32)占位的数据输入数据</li>
</ul></li>
</ul></li>
<li>机器学习过程
<ul>
<li>设计抽象模型
<ul>
<li>构建网络结构 x= tf.placeholder y=tf.placeholder m=tf.var
b=tf.var</li>
<li>模型表达式 y_guess = mx + b</li>
<li>损失定义 loss = tf.square(y-y_guess)</li>
<li>指定梯度下降方法 optimizer =
tf.train.GradientDescentOptimizer(lambda): 学习率</li>
<li>train_op = optimizer.minimize(loss) 训练模型</li>
</ul></li>
<li>开始训练
<ul>
<li>loss, _ = sess.run([loss, train_op], feed_dict={input_placehold: ,
output_placehold: }) &gt; _占位, 表示train_op. &gt;
这样直接完成一轮训练？并没有说迭代终止条件啊！！！ &gt;
input_placeholder应该是支持数组的吧？
还有应该默认就把var看作模型的参数，每次梯度下降进行更新吧？每个变量tf.Variable.init()中有可选方法，
traninable来选择是否使用到Optimizer,
不过这应该是不会在模型中使用到吧</li>
</ul></li>
<li>debug
<ul>
<li>print_sum_node = tf.Print(node1,list(nodes)) //
表示自己想要的node</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="其它">1.4 其它</h3>
<p>tensorflow使用数据流图将计算表示为独立的指令之间的依赖关系，这可生成低级别的编程模型。
首先定义低级别的编程模型，在改模型中，首先定义数据流图，然后创建tensorflow会话。</p>
<p>why？ 数据流图 &gt;
数据流是一种用于并行计算的常用模型。tf.matmul操作对应于单个节点 -
并行处理。通过使用明确的边缘来表示操作之间的依赖关系 -
分布式执行。通过使用明确的边缘来表示操作之间流动的值，可以将程序划分到不同机器的多种平台
- 编译.
XLA编译器可以使用数据流图中的信息生成更快的代码，例如将相邻的操作融合到一起
- 可移植性。不依赖与模型的代码表示法</p>
<p>tf.Graph结构 -
图结构：图的节点和边缘，表示各个操作组合在一起的方式，但不规定它们的使用方式
- tf.Operation: 节点. - tf.Variable(0) - tf.matul(x,y) -
tf.constant(42,0) - tf.train.Optimizer.minmize():
执行的最后，该操作在执行时将返回一个tf.Operation.
该操作在运行时将这些梯度用到一组变量上。 &gt;
一般地，直到拥有表示整个计算（例如梯度下降法的一步）的tf.Tensor或tf.Operation,才使用Session计算
- 图集合: 在图中存储了元数据集合的通用机制。 &gt; 如Variable,
collections, 分全局变量和可训练变量</p>
<p>？如何保存整个图，保存整个图的关键就在于保存节点和边，所以在tensorflow中就是如何保留节点和边。
即Tensor, Operation &gt; 不保留Operation,
每个Tensor都有自己的名称。特别地是，在保存时，Tensor命名为"生成它的操作：索引"？？？,
是否有name</p>
<ul>
<li><p>将操作放置到不同的设备</p>
<ul>
<li>设备规范：<code>/job:&lt;JOB-NAME&gt;/task:&lt;TASK-INDEX&gt;/device:&lt;DEVICE_TYPE&gt;:&lt;DEVICE_INDEX&gt;</code>
&gt; 其中device_type即决定CPU还是GPU</li>
<li>并行化？
<ul>
<li>这里的并行化从编程的角度的感觉就是指定每个device安排哪些工作而已。
&gt; ? 总的操作应该是合起来看的吧？
<ul>
<li>任务并行 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">with tf.device(&quot;/job:ps/task:0&quot;):</span><br><span class="line">    weights_2 = tf.Variable(tf.truncated_normal[]) </span><br><span class="line">with tf.device(&quot;/job:ps/task:1&quot;):</span><br><span class="line">    weights_1 = </span><br></pre></td></tr></table></figure></li>
<li>数据并行 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">with tf.device(tf.train.replica_device_setter(ps_task=3)):</span><br><span class="line">    w_0 = tf.Varible  // task:0</span><br><span class="line">    b_0 = tf.Varible  // task:1</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>类张量对象</p>
<ul>
<li>tf.Tensor</li>
<li>tf.Varible</li>
<li>numpy.ndarray</li>
<li>list</li>
<li>标量Python数据类型 &gt;
注意！在写代码时最好将所有的类张量都转换为tf.Tensor.
否则，每次使用时都会创建新的Tensor, 会爆内存</li>
</ul></li>
<li><p>会话 tf.Session &gt; 推荐 <code>with tf.Session() as sess:
#..</code> &gt; 会话是拥有物理资源如GPU和网络连接的 &gt;
tf.train.MonitoredTrainingSession或tf.estimatorEstimator?
将会自动创建和管理Session</p>
<ul>
<li>tf.Session.init三个参数
<ul>
<li>target: 默认将使用本地机器中的设备，也可以指定棋子。</li>
<li>graph: 会默认捆绑到当前的图</li>
<li>config: 配置设备、机器以及优化</li>
</ul></li>
<li>tf.Session.run(): 执行动作，会强调需要执行哪些子图.
在执行最终节点之前，务必注意需要将所有的变量的初始化操作完成
<ul>
<li>fetches: list, 指定必须要执行哪些操作</li>
<li>feed_dict: dict为图的元素赋予值</li>
<li>options</li>
<li>run_metadate</li>
</ul></li>
</ul></li>
<li><p>直观展示图</p>
<ul>
<li>tf.summary.FileWriter(save_path, sess.graph): 在with tf.Session() as
sess之后，即将图已经建好之后 &gt; 发现一个事情？
sess.run在写代码时，感觉到一个点就是，每个点是单独算的。然后进行梯度更新的，然后图神经网络是这样没有问题的，但是一般的算法也是这样搞的吗？</li>
</ul></li>
<li><p>保存和恢复</p>
<ul>
<li>变量保存 saver = tf.train.Saver(), saver.save(sess, "model.ckpt");
tf.reset_default_graph() saver.restore(sess, "model.ckpt") &gt;
注意这里的保存方式就是之前讨论的保存方式。然后还有一点就是默认会保存全部的变量
checkpoint file &gt; 特殊定制化： saver.save(var_name, var)</li>
<li>模型保存 tf.saved_model.simple_save</li>
</ul></li>
<li><p>debug 待扩展</p></li>
<li><p>性能</p>
<ul>
<li>输入流水线 &gt;
输入流水线会从一个位置提取数据，对数据进行转换，然后将数据加载到加速器上进行处理。
&gt; https://zhuanlan.zhihu.com/p/43356309
推荐大数据100MB以上使用tf.data,小数据集使用feed_dict
<ul>
<li>create <code>.tfrecords</code> file, 思路即通过迭代器来做</li>
<li>read '.rfrecords` as input, 整个过程使用迭代器来完成</li>
</ul></li>
<li>RNN: 动态和静态的RNN, 会将内存从GPU切换到CPU</li>
<li>针对CPU预处理: 配置线程数或者编译器版本mkg ### 1.5 tensorboard
tensor神经网络可视化 &gt; 有多个可视化的点
https://zhuanlan.zhihu.com/p/36946874</li>
</ul></li>
</ul>
<h3 id="keras-高级接口">1.6 keras 高级接口</h3>
<p>训练神经网络中最基础的三个概念： 1. epoch:
使用训练集的全部数据对模型进行一次完整训练，成为一代训练 2. batch:
使用训练集中的一小部分样本对模型权重进行一次反向传播的参数更新，这一小部分样本称为一批数据
3. Iteration:
使用一个Batch数据对模型进行一次参数更新的过程，称为一次训练</p>
<p>tf.keras高阶API - 方便使用 - 模块化和可组合 - 易于扩展</p>
<p>包括特定功能 - Eager Execution - tf.data - Estimator</p>
<p>序列模型：这里说的就是搭积木的意思，即自己一层一层地建立神经网络的连接
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mode = tf.keras.Sequential()  </span><br><span class="line">// 线性模型，这里，那么后面的Dense中的参数64是怎么是定的</span><br><span class="line">mode.add(layers.Dense(64, activation=&quot;relu&quot;))</span><br><span class="line">mode.add(layers.Dense(64, activation=&quot;relu))</span><br></pre></td></tr></table></figure></p>
<p>tf.keras.layer - activation:
设置层的激活函数。此参数由内置函数的名称指定 "relu", tf.relu -
kernel_initializer 和bias_initializer:
创建层权重（核和偏差）的初始化方案。默认"Glorot uniform" -
kernel_regularizer和biar_regularizer:
应用层权重的正则化方案，例如L1或L2正则化</p>
<p>keras文档</p>
<blockquote>
<p>https://blog.csdn.net/sinat_26917383/article/details/72857454</p>
</blockquote>
<p>具体思路： Dense这里不过表示深度学习中某一层的全连接层而已</p>
<p>https://blog.csdn.net/sinat_26917383/article/details/72857454
https://tensorflow.org/guide/keras</p>
<p>下一步，探讨需要什么环境？</p>
<p>RNN是涉及到具体的链接层的。这里的层是进行抽象的，keras tf.Dense():
应该是没有参数定义实际上应该怎么运算？
也就是说对于图神经网络的结构只能用tensorflow底层接口来做。</p>
<h4 id="一个完整的pipeline">1) 一个完整的pipeline</h4>
<ol type="1">
<li>构建简单的模型
<ul>
<li>序列模型
<ul>
<li>两种初始化方法
<ul>
<li>model = Sequential() model.add(layer)</li>
<li>model = Sequential([layer1, layer2, ..])</li>
</ul></li>
</ul></li>
<li>配置层 &gt;
layer即配置层的含义，在这里可以指多个层。对于深度神经网络而言，dropout的实现不过就是在需要的地方加上一层dropout
<ul>
<li>Dense配置的东西
https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense &gt;
Dense(32, input_shape(16, )) # input array of shape (<em>, 16); output
arrays of shape (</em>, 32) 一般*为batch_size的大小
<ul>
<li>units: dimensionality of the output space</li>
<li>activation: 激活函数</li>
<li>user_bias: boolean, 是否使用bias向量 ???
意思是输入是向量，而不是矩阵？？</li>
<li>initializer: kernel, bias</li>
<li>regularize: kernel, bias</li>
<li>constraint: kernel, bias</li>
</ul></li>
<li>关于layer的配置,</li>
</ul></li>
</ul></li>
<li>训练和评估
<ul>
<li>model.compile()
<ul>
<li>optimizer: tf.train.AdamOptimizer, tf.train.RMSPropOptimizerm
tf.GradientDescentOptimizer</li>
<li>loss, 在优化期间最小化的函数，常见均方误差mse,,
categorical_crossentropy binary_crossentropy</li>
<li>metrics, 用于监控训练，字符串或者可调用对象, 比如准确率</li>
</ul></li>
<li>mode.fit()
<ul>
<li>data</li>
<li>labels</li>
<li>epochs: 总共运行几次训练</li>
<li>batch_size: 一次训练使用多少个样本</li>
<li>validation_split: 0~1, 交叉验证集占训练集的比例</li>
<li>validation_data = (val_data, val_labels)), 与上面的二选其1进行 &gt;
该命令执行后直接会运行</li>
</ul></li>
<li>model.evaluate(data, labels, batch_size=32)
对未知数据集和预测结果进行评价 // 每个batch_size为一个评价单元</li>
<li>model.predict(data, batch_size) 模型预测</li>
</ul></li>
</ol>
<h4 id="构建高级模型">2）构建高级模型</h4>
<h5 id="函数式api">函数式API</h5>
<ul>
<li>多输入</li>
<li>多输出</li>
<li>具有共享层(同一层被调用多次)</li>
<li>具有非序列数据流的模型（剩余连接）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">inputs = tf.keras.Input(shape=(32,))  # Returns a placeholder tensor</span><br><span class="line"></span><br><span class="line"># A layer instance is callable on a tensor, and returns a tensor.</span><br><span class="line">x = layers.Dense(64, activation=&#x27;relu&#x27;)(inputs)</span><br><span class="line">x = layers.Dense(64, activation=&#x27;relu&#x27;)(x)</span><br><span class="line">predictions = layers.Dense(10, activation=&#x27;softmax&#x27;)(x)</span><br><span class="line"></span><br><span class="line">model = tf.keras.Model(inputs=inputs, outputs=predictions)</span><br><span class="line"></span><br><span class="line"># The compile step specifies the training configuration.</span><br><span class="line">model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),</span><br><span class="line">              loss=&#x27;categorical_crossentropy&#x27;,</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br><span class="line"></span><br><span class="line"># Trains for 5 epochs</span><br><span class="line">model.fit(data, labels, batch_size=32, epochs=5)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用了函数式编程接口，tensor为输入变量，返回结果也为tensor</p>
</blockquote>
<h5 id="模型子类化">模型子类化</h5>
<blockquote>
<p>通过对tf.keras.Model进行子类化并定义自己的前向传播来构建完全可自定义的模型。在__init__中创建层并将它们设置为类实例的属性。在call方法中定义前向传播
通过继承keras中已有Model,
还是根据本身已有的数据，还是调用原本的功能，不过会进行添加一些新功能</p>
</blockquote>
<h5 id="自定义层">自定义层</h5>
<p>tf.keras.layer.Layer进行子类化并实现以下方法自定义层
只需要实现以下接口 - build: 创建层的权重 add_weight方法添加权重 &gt;
shape = tf.TensorShape() self.kernel = self.add_weight() super(MyLayer,
self).builf(input_shape) - call: 定义前向传播 &gt; return
tf.matmul(inputs, self.kernel) - compute_output_shape:
指定在给出形状的情况下如何计算层的输出相撞 &gt; shape =
tf.TensorShape(input_shape).as_list() &gt; shape[-1]=self.output_dim
return tf.TensorShape(shape) - 或者，实现get_config方法序列化层,
from_config; 因为需要涉及到存储 &gt; base_config = super(MyLayer,
self).get_config() &gt; base_config['output_dim']=self.output_dim &gt;
return base_conofig &gt; <span class="citation"
data-cites="classmethod">@classmethod</span> &gt; def from_config(cls,
config): return cls(**config)</p>
<p>？？ python 如何进行继承，是方法抽象吗？ 还有抽象方法呢？ <span
class="citation" data-cites="关键字">@关键字</span> 全局变量呢</p>
<h2 id="pandas">2. pandas</h2>
<p>https://www.pypandas.cn/</p>
<p>pandas: 处理表格和混杂数据 numpy: 处理统一的数值数据 scipy:
数值计算工具 分析库：scikit-learn 和 statsmodels 数据化可视库:
matplotlib</p>
<ul>
<li>数据结构
<ul>
<li>Series:
类型与一维数组的对象，它有一组数据（各种numpy数据类型）以及一组一直相关的数据标签即索引组成。
&gt;
索引可以为字符串，在使用numpy函数或者类似num朋友的运算，如布尔型数组的过滤、标量乘法、应用数学等都会保留索引值的链接
&gt; np.exp(Series), 即可以直接传入series &gt;
Series可以看作是一个定长的<strong>有序</strong>字典，因为它是索引值到数据值的一个映射,
索引是key, 可以用in
<ul>
<li>init初始化: 深复制
<ul>
<li>dict: ser1 = pd.Series(dict)</li>
<li>list: ser2 = pd.Series(list1, index=list2)</li>
<li>array: ser2 = pd.Series(arr1, index=list1)</li>
</ul></li>
<li>index： list('abcdef') // 超级简单的方法
<ul>
<li>index本身就是属性, RangeIndex, Index两种</li>
<li>ser2.index=list3 // 直接修改</li>
</ul></li>
</ul></li>
<li>DataFrame &gt;
表格性的数据结构，它包含一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame即有行索引，也有列索引。
&gt; 可以看作是由Series组成的字典，共用同一索引 &gt;
Dataframe中的数据是以一个或多个二维快存放的。
虽然是二维结构保存数据的，但可以很轻松地表示为更高维度的数据
<ul>
<li>属性
<ul>
<li>df1.index.name / df1.columns.name</li>
<li>df1.values</li>
<li>df1.index: 不可改变，切片也不可改变；为不可变对象; Index类型,
因为是序列，所以允许重复元素 &gt; 一些操作
<ul>
<li>append, difference, intersection, union, sin, delete, drop,
insert(i, ) isunique, unique</li>
</ul></li>
</ul></li>
<li>init
<ul>
<li>dict: df1 = pd.DataFrame(dict): dict.key是等长的list,
将key映射为列名；列顺序未被指定 &gt; 注意元组会被当成一个值</li>
<li>2d_arr: df1 = pd.DataFrame(2d_arr, columns=list1, index=list2) //
注意columns是指定列名， 并且指定了列顺序; index指定行名</li>
</ul></li>
<li>索引： 一旦给定就确定下来，不会发生任何改变
<ul>
<li>Series: df1[column_name], df.column_name</li>
<li>Value: df1[column_name][index_name]</li>
<li>Object行, df1.loc[index_name]<br />
</li>
</ul></li>
<li>添加、修改 &gt; 按照类型赋值
<ul>
<li>按索引的方式添加，添加等于修改
<ul>
<li>df1[column_name] = Series: 不够的值，没有的值会赋np.NaN</li>
<li>df1.loc[index_name]=list1: 必须匹配，否则报错</li>
<li>df1[colume_name][index_name]=1</li>
</ul></li>
</ul></li>
<li>删除
<ul>
<li>删除列 del df1[column_name]</li>
<li>删除全部 del df1</li>
<li>批量删除 drop
<ul>
<li>df1.drop(colums_list)</li>
<li>df1.drop(index_list)</li>
<li>df1.drop(list1, axis): 按默认来，0为x轴</li>
</ul></li>
</ul></li>
<li>取切片的都属于浅复制, 即改变任何一个的元素都会引起另一个的改变。
&gt; 注意这里是末端包含式切片 &gt; 特别地,
当删除frame中的serie时，新的serie还存在, 为变化之前的值 &gt; <code>ser1
= pd1['value'],   pd1['value'][2]=1, del
dp1['value'];  ser1仍存在</code>
<ul>
<li>杂项
<ul>
<li>范围 pd1[columnN: columnM]: 因为是序列数据，所以直接取范围;
可用int</li>
<li>特定项 pd1[[column1, colum3, colum4]]， Series可用int做,
默认从0开始</li>
<li>obj[cond]</li>
</ul></li>
<li>通法
<ul>
<li>pd1.loc[val, val2] 标签</li>
<li>pd1.iloc[i, j] 整数</li>
</ul></li>
</ul></li>
<li>特殊值处理
<ul>
<li>空值 "" isnull()</li>
<li>缺失值 nan或naT isna()</li>
<li>两种手段
<ul>
<li>删除对应行和列： df.dropna()</li>
<li>填充 df.dropna() // 细粒度地填充, inplace=True在原来上操作</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>基本功能
<ul>
<li>重新索引
<ul>
<li>row ser1.reindex(new_index, method="ffill") // 使用前向值进行填充;
fill_value: 替代缺失值; limit最大填充量</li>
<li>columns pd.reindex(columns=new_columns)</li>
</ul></li>
<li>算术运算和数据对齐 &gt; 必须行名，列名相同才好使 &gt;
非对齐使用nan填充
<ul>
<li>会用到吗？
<ul>
<li>add, radd: r表示reverse版本，即将两个操作数的位置交换</li>
<li>sub, rsub</li>
<li>div, rdiv</li>
<li>floordiv, rfloordiv</li>
<li>mul, rmul</li>
<li>pow, rpow</li>
</ul></li>
</ul></li>
<li>DateFrame和Series: 广播运算，对每一行都做</li>
<li>pd1.apply(func, args=): 特别好用 +
lambda表达式，作用在每个元素级别</li>
<li>排序和排名
<ul>
<li>sort by index: pd.sort_index(axis=0)</li>
<li>sort by value
<ul>
<li>ser1.sort_value() //nan在尾部</li>
<li>pd1.sort_value(by=[col1,col2])</li>
</ul></li>
<li>rank obj.rank(ascending=false, axis= , method= )
<ul>
<li>method: 相同排名的处理问题; first 按索引的第一个; max, 最大; min;
average</li>
</ul></li>
</ul></li>
<li>汇总和计算描述统计-&gt;基于列的Series
<ul>
<li>df.sum(axis=, skipna=)</li>
<li>df.idxmax() 索引位置 max() 索引值</li>
<li>df.cumsum() &gt; count, mean, std, min, max</li>
</ul></li>
<li>唯一值，值计算及成员资格
<ul>
<li>ser1.unique()</li>
<li>ser1.value_counts() // 计算重复出现的值</li>
<li>ser1.isin(ser2)</li>
<li>ser1.match(ser2) 对齐数据, 比较返回真假值</li>
</ul></li>
</ul></li>
<li>数据加载、存储和文件格式
<ul>
<li>读写
<ul>
<li>read_csv( seq=',')</li>
<li>read_table(seq=')</li>
</ul></li>
<li>处理
<ul>
<li>索引</li>
<li>类型推断和数据转换</li>
<li>日期解析</li>
<li>迭代</li>
<li>不规整数据问题</li>
</ul></li>
</ul></li>
</ul>
<h2 id="matplotlib">4. matplotlib</h2>
<p>matplotlib 更详细的内容
https://www.matplotlib.org.cn/api/overview/index.html</p>
<ul>
<li>基本API入门 <code>import matplotlib.pyplot as plt</code> &gt;
只要返回对象是figure的，就会在jupyter中产生图 &gt;
在py文件中，则是使用plt.show()产生图
<ul>
<li>多个子图
<ul>
<li>fig = plt.figure()
<ul>
<li>ax1 = fig.add_subplot(2,2,1) //(length, width, rank) rank从1开始
&gt; 此时ax1 就可用作 plt</li>
</ul></li>
<li>fig, axs = plt.subplots(2,3) &gt; axs[0,1]获取子图
<ul>
<li>plt.subplots(args) 参数
<ul>
<li>nrows, ncols</li>
<li>sharex, sharey 是否共享x，y轴</li>
<li>subplot_kw 各subplot的关键字字典</li>
</ul></li>
<li>fig.subplots_adjust(wspace=0.3, hspace=0.5) &gt;
这里可以直接使用plt, 因为matplotlib会自动引用新添加的子组件的对象
<ul>
<li>wspace, hspace, 图与图之间的间隙中宽度为子图的多少倍,
即一般为0.3之类, 为百分比</li>
</ul></li>
</ul></li>
</ul></li>
<li>图的类型
<ul>
<li>plot(x[,y]) 折线图，x默认索引</li>
<li>hist(y) 条形图，x默认索引</li>
<li>scatter(x,y) 散点图</li>
</ul></li>
<li>操作图
<ul>
<li>调整子图周围的间距 wspace, hspace</li>
<li>plot(args) 参数
<ul>
<li>fmt_str "{marker}{line}{color}" 或者
<code>[color][marker][line]</code>
<ul>
<li>marker
<ul>
<li><code>.</code>: point</li>
<li><code>o</code>: 实心circle</li>
<li><code>v</code>, <code>^</code>, <code>&gt;</code>,
<code>&lt;</code>: 各个方位的实心三角形</li>
<li>1, 2, 3, 4: 箭头，下、上、左、右</li>
<li>|,_: vline, hline</li>
<li>s: square; *: start; D: diamond,; p: 多边形; +,x</li>
</ul></li>
<li>linestyle
<ul>
<li><code>-</code>: 实线</li>
<li><code>--</code>:虚线</li>
<li><code>-.</code>: 非规整虚线</li>
<li><code>:</code>: 小点小点的线</li>
</ul></li>
<li>color
<ul>
<li>b: blue, g:green, r:red, c:cyan, y:yellow, k:black, w:white</li>
</ul></li>
</ul></li>
<li>lable: 设置图标说明</li>
<li>drawstyle: 点到点的其它路径画法</li>
<li>xlim, yli: x,y的界限</li>
<li>grid: 网格线是否打开</li>
</ul></li>
<li>set方式设置参数 &gt; plt.set(dict) 全局设置 &gt; plt.legend()
用于增加图裂
<ul>
<li>设置刻度标签，为刻度赋予自己的意义 &gt; tricks =
ax.set_xtricks([0,250,500,750,1000]); &gt; labels =
ax.set_xticklabels(list('abcdf'))</li>
<li>图的标题 title &gt; ax.set_titile("")</li>
<li>图的x轴lable &gt; ax.set_xlabel()</li>
<li>图解，标注某个点 &gt; ax.annotate(label, xy=(x,y))</li>
<li>保存文件 &gt; plt.savefig(".png")</li>
</ul></li>
</ul></li>
<li>全局配置，字体什么的 plt.rc(); pandas本身ser.plot(),
df.plot()就可以进行绘图</li>
</ul></li>
<li>应用
<ul>
<li>画等高线图
<ol type="1">
<li>取特定个点 np.linspace(start, end, number), np.arange(start, end,
step)</li>
<li>画网格 xx, yy=np.meshgrid(x,y) xx表示n个x轴的数据
yy表示m个y轴的数据</li>
<li>plt.contour(x,y,f(x,y)) // 绘制等高线</li>
</ol></li>
<li>动画animate
<ul>
<li>animation.FuncAnimation(fig=fig, func=animate, init_func=,
frames=length, interval=60ms频率, blit=True是否更新所有的点) &gt;
line.set_data([],[]) point.set_data([],[])
<ul>
<li>def animation(i): line.set_ydata((np.sin(x+i/100)))</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>tools</category>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>tools</tag>
        <tag>numpy</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning dropout</title>
    <url>/2019/deeplearning-dropout-48098b712722/</url>
    <content><![CDATA[<p>dropout的总结
https://blog.csdn.net/stdcoutzyx/article/details/49022443</p>
<p>bias &gt; output += bias</p>
]]></content>
      <categories>
        <category>deeplearning</category>
        <category>dropout</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>dropout</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning cs231n</title>
    <url>/2019/deeplearning-cs231n-560b20fcf310/</url>
    <content><![CDATA[<h1 id="introduction">1. Introduction</h1>
<ol type="1">
<li>A brief history of computer vision
<ul>
<li>creatures -&gt; vision</li>
<li>camera</li>
<li>what is the vision processing
<ul>
<li>Original picture</li>
<li>differntiated picture</li>
<li>Feature points selected</li>
</ul></li>
<li>MIT research <img
src="asserts/1-stagesOfvisualRepresentation.png" />
<ul>
<li>Inpute image
<ul>
<li>preceived intensities</li>
</ul></li>
<li>Edge image
<ul>
<li>zero crossing, blobs, edges, bars, ends, virtual lines</li>
</ul></li>
<li>2 1/2-D sketch
<ul>
<li>local surface orentation</li>
</ul></li>
<li>3D</li>
</ul></li>
<li>how to recognize and represent the world</li>
<li>image segmentation: Jitendra Malik</li>
<li>face detection</li>
<li>1999-2000, momentum动量, ML, adaBoost algorithm to do real-time face
detection, 2001</li>
<li>2006, digital camera a real-time face detector</li>
<li>SIFT feature: match and the entire object due to camera angles,
occlusion, viewppoint, lighting</li>
<li>Spatial pyramid matching: from different parts of the image and in
different resolutions and put them together in a feature</li>
<li>HoG Histogrm of Gradients</li>
<li>imagenet</li>
<li>SVM, AdaBoost, overfiting: not enought training data, cannot
generalize. benchmarking WordNet</li>
<li>2009 ImageNet Large-Scale Visual Recognition Challenge</li>
</ul></li>
<li>CS231n overview
<ul>
<li>Aims
<ul>
<li>image classification</li>
<li>object detection</li>
<li>action classification</li>
<li>image captioning</li>
</ul></li>
<li>Convolutional Neural Neteworks</li>
<li>object relationships</li>
<li>object attributes</li>
<li>Our philosophy
<ul>
<li>Thorough and Detailed</li>
<li>Practical</li>
<li>State of the art</li>
<li>Fun</li>
</ul></li>
</ul></li>
</ol>
<h1 id="image-classification-pipeline">2. Image Classification
pipeline</h1>
<p>python numpy tutorial</p>
<p>https://github.com/cs231n/cs231n.github.io/blob/master/python-numpy-tutorial.md</p>
<p>gce~tutoria ? google compute engine</p>
<ol type="1">
<li><p>cluster</p></li>
<li><p>attempts have been made</p>
<ul>
<li>find edges</li>
<li>find corners -&gt;, &lt;-, &gt; not scalerable</li>
</ul></li>
<li><p>Neareast Neighbor</p>
<ul>
<li>train: memorize all data and labels O(1)</li>
<li>predict: predict the label of the most similar training image O(N)
&gt; noisy spurious <img data-src="asserts/2-1nn.png" /> &gt; just training
data, 把所有测试数据可能的分类填上去 &gt; k-nearest neighbors <img
src="asserts/2-knn.png" /> &gt; the white place
可能选哪个都可以，随机才</li>
</ul></li>
</ol>
<p>L1: coordinate system is important &gt; you know what the coordinate
system meaning</p>
<p><img data-src="asserts/2-knn-distance_metric.png" /> numpy的基本运算</p>
<p>http://vision.stanford.edu/teaching/cs231n-demos/knn/</p>
<p>why 图像是那样的???? &gt; PRML必读</p>
<ul>
<li>Setting Hyperparameters</li>
</ul>
<p>pick the best training hyperparameters performs on validation? and
run once on the test data, then write in the paper</p>
<p>cross valildation Useful for small datasets, but not used too
frequently in deep learning</p>
<p>有个点自己理解错了，其实是看交叉验证集上的损失怎么样？如果交叉验证集上的损失没有连续操作多少次上升？
或者达到终止条件，则选择该超参数</p>
<p>不过，k-cross-validation的意思是用同样的超参数训练多次，然后得到验证集的平均损失，然后更新一次吗？</p>
<p>因为本身更新公式是作用在损失函数上的</p>
<p>validation to check how well</p>
<p>same methodology for collecting the data, go and partition it
randomly</p>
<p>时间序列分割 shift the problem</p>
<p><img data-src="asserts/2-k-cross-validation.png" /></p>
<p>L2 distance is really not doing a very good job</p>
<p>cover space densely exponential growth traning examples?</p>
<p>knn不适用与图像分类
https://blog.csdn.net/chaipp0607/article/details/77915298</p>
<ul>
<li>很差的测试效率</li>
<li>整个图像的水平距离度量可能非常不直观</li>
</ul>
<blockquote>
<p>计算距离的对象不可能是像素值，因为他不能从本质上反映出人对图像的认知，比如把一张图进行位移，人觉得是一类，但是计算结果距离很大。
所以knn计算的应该是一些描述子生成的特征。</p>
</blockquote>
<p>knn总结 1. 对于样本不平均问题，knn相比于其他监督学习算法容忍度更低。
2. 计算和存储开销大，在线学习效率低。</p>
<p>改进 1. 解决样本不平衡问题 2. 提高分类效率</p>
<p><img data-src="asserts/2-hard-cases-for-alinearclassifier.png" /></p>
<p>mutlimodal data: different regions of space</p>
<p>229</p>
<h1 id="some-concepts">3. some concepts</h1>
<h2 id="loss">3.1 loss</h2>
<ul>
<li>SVM loss: <span class="math inline">\(L_i = \sum_{j \ne y_i} max(s_j
- s_{y_i} +1)\)</span> <span class="math inline">\(L = \frac{1}{N}
\sum_{i=1}^N L_i\)</span></li>
</ul>
<p><span class="math inline">\(max(1-yf(x))\)</span>:
在分类分割线附近进行鼓励 &gt; care the correct is much greater than the
incorrect scores</p>
<p>loss function; how bad are different mistakes square: bad, very, very
bad hinge: a litte wrong, a better wrong</p>
<p>损失函数总结 https://zhuanlan.zhihu.com/p/58883095</p>
<blockquote>
<p>设置W, 来查看Loss</p>
</blockquote>
<p>W, 2W the zero loss</p>
<h2
id="regularization-term-encourages-the-model-to-somehow-pick-a-simple-w-rw">3.2
regularization term: encourages the model to somehow pick a simple W
<span class="math inline">\(R(W)\)</span></h2>
<p><img data-src="asserts/3-regularization.png" /></p>
<p>L1 encouraging sparsity in this matrix W. w1: 0.4, 0, 0.4, 0 w2: 0.2,
0.2, 0.2, 0.2 x:1,1,1,1</p>
<p>L1:w1 L2:w2 &gt;
正则化项是在原本目标得到的函数的基础上，按照你想要的某种特性去构造</p>
<p>minimize -log P(Y=yi| X=xi) multi-SVM: softmax loss &gt; min=zero,
max is infinity</p>
<blockquote>
<p>当出现错误的数据，如何处理？ 0应该处理为一个非常小的数 debuging:
minus log of one over C</p>
</blockquote>
<ul>
<li>hinge-loss vs softmax loss &gt; SVM-loss: margin between different
classes, if the data point over the bar, they don't care about it
anymore if they are correct. &gt; softmax-loss: drive probabiltity mass
all the way to one, pile the all classes, because log loss, it tends to
push correct class to 0, imcorrect classes to infinity. continually to
improve the correct classes.</li>
</ul>
<h2 id="optimization">3.3 Optimization</h2>
<ol type="1">
<li>A first very bad idea solution: Random search</li>
</ol>
<p>cifar-10 15.5%</p>
<ol start="2" type="1">
<li>fllow the slope &gt; scalar 标量</li>
</ol>
<p>如何计算梯度？ - 前向传播，然后计算一个新值，然后得到 dW <img
src="asserts/3-gradient.png" /></p>
<blockquote>
<p>debugging</p>
</blockquote>
<p>https://vision.stanford.edu/teaching/cs231n-demos/linear-classify</p>
<p>calclus 微分</p>
<p><img data-src="asserts/3-gradient-ex.png" /></p>
<p>add gate: gradient distributor max gate: gradient router mul gate:
gradient switcher</p>
<p>back to a node is add</p>
<p><img data-src="asserts/3-Jacobian.png" /> 4096*4096? Jacobian matrix:
diagonal matrix</p>
<p>step 1 <img data-src="asserts/3-gradient-vectorized-ex.png" /></p>
<p>step 2 <img data-src="asserts/3-gradient-vectorized-ex-2.png" /> &gt;
Always check: the gradient with respect to a variable should have the
same shape as the variable.</p>
<p><img data-src="asserts/3-forward_backward-api.png" />
https://github.com/BVLC/caffe/blob/master/src/caffe/layers/clip_layer.cpp
&gt; caffer layers</p>
<h2 id="layers-kinds">3.4 layers kinds</h2>
<p>http://tutorial.caffe.berkeleyvision.org/tutorial/layers.html</p>
<ul>
<li>vision layers
<ul>
<li>convolution</li>
<li>pooling</li>
<li>local response normalization(lrn)</li>
<li>im2col</li>
</ul></li>
<li>loss layers
<ul>
<li>softmax</li>
<li>sum-of-squares/euclidean</li>
<li>hinge/margin</li>
<li>sigmoid cross-entropy</li>
<li>accuracy and top-k</li>
</ul></li>
<li>Activation/Neuron Layers
<ul>
<li>ReLU/Rectified-Linear and Leaky-ReLU</li>
<li>Sigmoid <span class="math inline">\(y = \frac {1}{1 +
e^{-x}}\)</span> &gt;
https://github.com/BVLC/caffe/blob/master/src/caffe/layers/sigmoid_layer.cpp</li>
<li>TanH/Hyperbolic Tangent</li>
<li>Absolute Value</li>
<li>Power</li>
<li>BNLL</li>
</ul></li>
<li>Data Layers
<ul>
<li>In-Memory</li>
<li>HDF5 Input</li>
<li>Images</li>
<li>Windows</li>
<li>Dummy</li>
</ul></li>
<li>Common Layers
<ul>
<li>Innner Product</li>
<li>Splitting</li>
<li>Flattening</li>
<li>Concatenation</li>
<li>Slicing</li>
<li>Elemetwise Oprations</li>
<li>Argmax</li>
<li>Softmax</li>
<li>Mean-Variance Normalization</li>
</ul></li>
</ul>
<p>examples <img data-src="asserts/3-svm.png" /></p>
<p>summary <img data-src="asserts/3-summary.png" /> &gt; upstream gradient
multipy local gradient</p>
<blockquote>
<p>左乘优先 non-linearities</p>
</blockquote>
<p>question: templates, in fact, you don't have to care about it, the
only thing you concerned is the scores</p>
<p><img data-src="asserts/3-neural_networks.png" /></p>
<blockquote>
<p>Assignment2: Writing a 2-layer net</p>
</blockquote>
<h2 id="activation-functions">3.5 Activation functions</h2>
<p><img data-src="asserts/3-activation_functions.png" /></p>
<blockquote>
<p>callled 2-layer neural net</p>
</blockquote>
<p>matrix form, matrix-vector form</p>
<p>Summary - arrange neurons into fully-connected layers - the
abstraction of layer has the nice property that it allows us to use
efficient vectorized code(e.g. matrix multiplies) - neural networks are
not really neural - next time: convolutional neural networks</p>
<h1 id="convolutional-neural-networks">4. Convolutional Neural
Networks</h1>
<p>Deep Learning history - 1957: Perceptron, Frank Rosenblatt - 1960:
Adaline/Madaline &gt; stack these linear layer to multi-layers, no
back-propagation or other rules - 1986: Rumelhart et al. First time
back-propagation became popular - 2006: Reinvigorated research in Deep
Learning &gt; carefully-initialized pre-training stage - 2012, first
strongest results using for speech recognition</p>
<p>A bit of history: CNN - 1959 electrical signal from brain &gt;
topographical mapping 地形学 - Hierarchical organization: &gt; simple
cells -&gt; complex cells -&gt; hypercomplex cells - 1980 complex
cells-&gt;perform pooling - 1998 gradient-base document recognition -
2012, AlexNet - Detection, Segmentation R-CNN reinforcement learning</p>
<p>notation should rorate 180 how to slide this over all the spatial
locations &gt; 卷积层得到的结果是什么<br />
&gt; 3 filter??, 6 filters?? over the image spatially we're sampling the
edges and corners less than the other localtions</p>
<blockquote>
<p>试图去理解每一步的过程还有每一个公式的含义</p>
</blockquote>
<p>one filter-&gt; one activation map</p>
<p>we call these <img data-src="asserts/4-convolutional.png" /></p>
<p><img data-src="asserts/4-output_size.png" /></p>
<p>Output size: (N-f)/stride + 1</p>
<blockquote>
<p>if we use common to zero pad the border, we will get 7*7 output</p>
</blockquote>
<p><img data-src="asserts/4-outputsize-ex.png" /> &gt; what will channels do?
5<em>5</em>3 + 1=76 params(+1 for bias) =&gt; 76*10=760 params</p>
<p><img data-src="asserts/4-outputsize_summary.png" /></p>
<blockquote>
<p>概念辨析 - 向量的乘法 点集，标量积得到内积； 叉乘，结果为向量，向量积
- 矩阵乘法 multiply: 普通的乘法 Hadamard product, 逐点乘法 Kronecker
product: tensor product</p>
</blockquote>
<p>conv layer in torch &gt; spatial convolution ----- torch, pytorch
&gt;
torch能够放在GPU中加速计算，前提是有合适的GPU时，使用起来跟numpy来说差别不大</p>
<ul>
<li><p>torch
https://github.com/torch/nn/blob/master/doc/convolution.md#nn.SpatialConvolution</p></li>
<li><p>caffe
http://caffe.berkeleyvision.org/tutorial/layers/convolution.html</p></li>
</ul>
<hr />
<h1 id="training-neural-networks">5. Training Neural Networks</h1>
<p>Overview: 1. one time setup - activation functions - preprocessing -
weight initilization - regularization - gradient checking 2. Training
dynamics - babysitting the learning process parameter updates -
hyperparameter optimization 3. Evaluation - model ensembles</p>
<h2 id="activation-functions-1">5.1 Activation Functions</h2>
<ol type="1">
<li>sigmoid
<ul>
<li>introduction
<ul>
<li>squashes numbers to range[0,1] &gt; [-5,
5]变化明显，其他位置变化就有问题了 [-10, 10]=0 &gt; df = f(1-f) &gt;
梯度就是函数图像的直线，永远不要忘了最直观的理解</li>
<li>historycally popluar since they have nice interpretation as a
saturating "firing rate" of a neuron</li>
</ul></li>
<li>problem
<ul>
<li>Saturated neurons "kill" the gradients</li>
<li>Sigmoid outputs are not zero-centered &gt;
因为对x的范围的限制，所以不对称，同理也不能在全positive的数据上表现的很好；
always the sign of the upstream gradient coming down. inefficient weight
update</li>
<li>exp() is bit compute expensive</li>
</ul></li>
</ul></li>
</ol>
<p><img data-src="asserts/5-sigmoid.png" /></p>
<p><img data-src="asserts/5-sigmoid-pic.png" /> &gt; avoid allways a
direction</p>
<ol start="2" type="1">
<li>tanh 1991</li>
</ol>
<ul>
<li>Squashes numbers to range[-1,1]</li>
<li>zero centered (nice)</li>
<li>still kills when saturated :( <img data-src="asserts/5-tanh.png" /></li>
</ul>
<ol start="3" type="1">
<li>relu 2012 rectified linear unit</li>
</ol>
<p><img data-src="asserts/5-relu.png" /></p>
<ul>
<li>not zero-center output</li>
<li>any annoyance hint: what is the gradient when x&lt;0 ?</li>
</ul>
<blockquote>
<p>it is fine at the begining, then at some point, it became bad and it
died.</p>
</blockquote>
<p><img data-src="asserts/5-relu-problem.png" /></p>
<blockquote>
<p>data cloud is just your training data. wx1 + wx2上进行影响啊 people
like to initialize relu neurons with slightly positive biaes(e.g.
0.01)</p>
</blockquote>
<ol start="4" type="1">
<li><p>leaky relu <img data-src="asserts/5-prelu.png" /></p></li>
<li><p>elu <img data-src="asserts/5-erelu.png" /> &gt; how the <span
class="math inline">\(\alpha\)</span> is defined</p></li>
<li><p>Maxout Neuron <img data-src="asserts/5-max-neuron.png" /></p></li>
</ol>
<p><img data-src="asserts/5-practice.png" /></p>
<h2 id="data-preprocess">5.2 data preprocess</h2>
<p>original data -&gt; zero-centered data -&gt; normalized data</p>
<blockquote>
<p>to do at the test data, too <img
src="asserts/5-2_preprocess_data-1.png" /></p>
</blockquote>
<p><img data-src="asserts/5-2_pcaAndWhitening.png" /></p>
<p><img data-src="asserts/5-2_preprocess_data-practice.png" /></p>
<blockquote>
<p>per-channel RGB do this for entire train data, once before training.
don't do this per batch</p>
</blockquote>
<blockquote>
<p>how sigmoid need the zero-centered data, it only servers for the
first layer.</p>
</blockquote>
<h2 id="weight-intilization">5.3 Weight Intilization</h2>
<p>Q: what will happen if W is zero? &gt; 1. will disappear &gt; !!they
will all do the same thing</p>
<ul>
<li>First idea: small random numbers (gaussian with zero mean and 1e-2
standard deviation) <code>W = 0.01 * np.random.randn(D, H)</code> &gt;
works okay for small networks, but problems with deeper networks.</li>
</ul>
<p>pic1 see the hidden data is pic2: see the data distribution &gt;
zero</p>
<blockquote>
<p>All activations become zero!!</p>
</blockquote>
<p>What will W look like?</p>
<p>because X is small, so the W is getting more small, they're basically
not updating.</p>
<ul>
<li>forward doing</li>
<li>have gradient flows coming down &gt; for each line, we chain these
weight</li>
</ul>
<p>cs231n: 深度视觉识别课程P6</p>
]]></content>
      <categories>
        <category>deeplearning</category>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>stanford</tag>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning learn</title>
    <url>/2019/deeplearning-learn-dc64da181b72/</url>
    <content><![CDATA[<blockquote>
<p>参考: 吴恩达深度学习视频和网上教程</p>
</blockquote>
<p>https://www.zybuluo.com/hanbingtao/note/433855</p>
<p>隐藏层大于2的神经网路叫做深度神经网络</p>
<p>一个仅有隐藏层的神经网络可以拟合热河一个函数，但是它需要很多很多的神经元。
而深度网络就是考虑用少得多的神经元就能拟合同样的函数。</p>
<p>为了拟合一个函数，要么使用浅而宽的网络，要么使用深而窄的网络。 &gt;
后者给节约资源</p>
<h2 id="感知器">1. 感知器</h2>
<p><img data-src="ganzhiqi.png" /></p>
<h2 id="组成">1.1 组成</h2>
<ul>
<li>输入权值 <span class="math inline">\(w_i\)</span></li>
<li>激活函数, 比如阶跃函数，<span class="math inline">\(f(x) =
z&gt;0?1:0\)</span></li>
<li>输出，整个感知器的公式 <span class="math display">\[f(w \cdot x +
b)\]</span></li>
</ul>
<p>如此，表示的就是一元函数。因为权值的不同取值，由此可以表达出不同的函数</p>
<h2 id="表示能力">1.2 表示能力</h2>
<ul>
<li><p>and函数: <span class="math inline">\(w_1 = 0.5, w_2=0.5,
b=-0.8\)</span> <img data-src="and.png" alt="and function" /> <span
class="math display">\[y = 0.5x_1 + 0.5x_2 -0.8\]</span></p></li>
<li><p>or函数： <span
class="math display">\[y=0.5x_1+0.5x_2-0.3\]</span></p></li>
<li><p>线性分类 &gt; 因为它的数学表示实际上就是一条直线
<font color="red">不能表示一维以上的，比如异或运算</font> ## 1.3
训练</p></li>
</ul>
<blockquote>
<p>训练的主要想法就是进行更新权值</p>
</blockquote>
<blockquote>
<p>更新 <span class="math inline">\(w_i, w_0=b\)</span></p>
</blockquote>
<p>深度学习： 反向传播是否可以保证收敛？？ 强化学习：探索和利用</p>
<p>budget: 总共评估多少个节点 随机深林</p>
<p>算法</p>
<p>Q-learning &gt; 蒙特卡罗 + 动态规划</p>
<h2 id="深度学习应用总结">1. 深度学习应用总结</h2>
<p>分类 - Standard NN - CNN - RNN - Customl / Hybrid</p>
<ol type="1">
<li>structured vs unstructured
<ul>
<li>结构化数据： 组织为表格形式，每个维度都在人类的意义下具有解释性</li>
<li>非结构化数据：例如图像或者音频，每个细小的单位是像素点。 &gt;
从历史的角度来看，计算机很难解释非结构化数据。但是深度学习引入后，对非结构化数据也能解释的很好</li>
</ul></li>
<li>why 深度学习现在火起来？
<ul>
<li>大量数据的产生</li>
<li>越来越深的神经网络的规模的上限会表现得越来越好 &gt;
在小规模数据上，算法的优劣性不好比较。但是在大规模数据上，深度学习是远远领先的</li>
</ul></li>
<li>发展
<ul>
<li>Data</li>
<li>Computation</li>
<li>Algorithms:
<ul>
<li>特别地，从sigmoid函数到ReLu函数的改变，因为sigmoid函数在最低端和最上端点的梯度变化非常缓慢，不利于学习。可以是梯度下降得更快</li>
</ul></li>
</ul></li>
</ol>
<p>神经网络类比于人的大脑有点过度了，没有必要，因为从某种深度学习只是人的大脑一个非常简化的近似</p>
<h3 id="神经网络与深度学习">1.1 神经网络与深度学习</h3>
<ul>
<li>二分类</li>
<li>Logistic Regression &gt; 目标改变了，是从概率上来约束，即希望<span
class="math inline">\(P(y=1|x)\)</span>最大，此时认为该算法是最优的</li>
</ul>
<h3 id="序列模型-sequence">1.5 序列模型 Sequence</h3>
<p>https://mooc.study.163.com/learn/2001280005?tid=2001391038&amp;<em>trace_c_p_k2</em>=a561339e0cbf45b491dd9e12104a8641#/learn/content?type=detail&amp;id=2001771052</p>
<blockquote>
<p>序列模型是什么？
其实，从某种意义上说，定义很简单。就是输入和输出的是序列。
从某种意义上感觉，就是原本的数据是输入有很多维特征，而现在是这些维特征从另一个角度进行解释。即比如自然语言处理，输入为一个句子。
每个单词作为输入的特征，但是这些特征并不是相互独立的。
机器学习中好像有要求特征必须相互独立把</p>
</blockquote>
<blockquote>
<p>在这里好像又从新起了一个名字？</p>
</blockquote>
<blockquote>
<p>在这里看来，每维特征姑且叫做特征吧。
这些是相关联的，有点像层次分析法，所以必须要使用神经网络来做。
这些是序列的
序列意味着什么？意味着之间的关系性，前后具有联系，不能割开看。
如何做标记？ 这里认为<span
class="math inline">\(x^{(i)}\)</span>表示第i个样本，<span
class="math inline">\(x^{(i)&lt;t&gt;}\)</span>表示第i个样本的第t个特征，y同理。<span
class="math inline">\(T_x^{(i)}\)</span>表示<span
class="math inline">\(x^{i}\)</span>的长度？？？ -
于是意味着x的输入还可以处理为不一样？？</p>
</blockquote>
<pre><code>&gt; 所以后面有说到，可以填充或者零填充使得每个输入语句达到同样的长度</code></pre>
<p>如何来表示这些词？
这里的一个想法是用字典(这里通常是最常见的词，不在其中的词使用UNK来表示)，使用One-hot编码来做</p>
<h4 id="rnn在nlp中的应用">1.1.1 RNN在NLP中的应用</h4>
<ul>
<li>任务： 输入一个句子，对句子做情感分析，比如评分。
比如：输入的x是一个句子，那么怎么感觉学习过程的有效性呢？
首先必须思考神经网络结构是基于什么做的？比如在图中，是基于图的整个结构做的。
而在NLP中这里针对的就是一个句子。</li>
</ul>
<p>那么，在自然中，多个句子之间是会存在相同的单词。
所以，当对上一个单词训练结束后，再使用下一个单词进行训练就可。此时模型</p>
<blockquote>
<p>特别注意，深度学习是分领域的，等于说如果这里没有给定在哪个领域内是很难的。像在这里，邻域实际上决定了学习目标是什么。
而这里的学习目标，以及输入，输出是什么，神经网络模型需要学习的是什么就显得非常重要了。所以这里需要特别思考</p>
</blockquote>
<ul>
<li>RNN &gt; 这里理解的角度和自己的想象方式，从某种角度上还是出现了偏差
&gt;
这里的时间步，说的是上一个x训练的模型的参数，然后再影响到下一个x输入的模型的参数。
？ 合理循环之说呢？ 不对！错误，这里看错了标记<span
class="math inline">\(x^{&lt;t&gt;}\)</span>只的是第t步的特征，所以这里网络结构的输入依然是一个x。不可网络结构变得非常不一样，不再是每一维特征都有复杂的到最终的关系。</li>
</ul>
<p><span class="math display">\[a^{&lt;1&gt;} = g(W_{aa} a^{&lt;00&gt;}
+ W_{ax} x_{&lt;1&gt;} + b_a\]</span></p>
<p><span class="math display">\[y^{&lt;1&gt;} = g(W_{ya} a^{&lt;1&gt;} +
b_y\]</span> &gt; 其中<span
class="math inline">\(a^{&lt;0&gt;}\)</span>是初始化的，<span
class="math inline">\(a^{&lt;1&gt;}\)</span>是循环神经网络<span
class="math inline">\(x^{&lt;1&gt;}\)</span>到<span
class="math inline">\(x^{&lt;2&gt;}\)</span>传递的参数</p>
<p>假设输入向量的维度为x，循环体的全连接层神经网络的输入大小为h+x.</p>
<blockquote>
<p>做深度学习时，最重要的想法就是能够转换为矩阵运算，然后记得通过检查维度来确定正确性</p>
</blockquote>
<blockquote>
<p>RNN只用到了之前的信息。即只使用了序列前面的信息，未使用序列后面的信息</p>
</blockquote>
<h4 id="section">1.2</h4>
<p>梯度下降优化</p>
<blockquote>
<p>如果对于凸函数，是具有全局最优解的 为什么凸函数具有全局最优解？ <span
class="math inline">\(f(y)-f(x) \leq f&#39;(x) (y-x)\)</span>
注意最凸优化中，把权重矩阵看成是x的参数，目标是看何时x能够降到最低点；直观上看就是，梯度下降的方向就是去往最低点的地方。因为全局只有一个最低点。</p>
</blockquote>
<ul>
<li>凸函数的快速判断
<ol type="1">
<li>判断的性质 &gt; 一阶条件，即满足一阶不等式的公式，即证明不等式 &gt;
二阶条件，直接对二阶求导公式需要大于等于0.
对于矩阵来说，探究的就是矩阵的二阶导矩阵，此时称为Hessian矩阵。</li>
<li>常见的1维凸函数
<ul>
<li>放射函数 <span class="math inline">\(ax+b, a,b \in R\)</span></li>
<li>指数函数</li>
<li>对数函数 <span class="math inline">\(logx\)</span></li>
<li>幂函数 <span class="math inline">\(x^a\)</span>，绝对值幂函数</li>
<li>负熵 xlogx</li>
</ul></li>
<li>常见的d维凸函数有：
<ul>
<li>仿射函数</li>
<li>范数</li>
</ul></li>
<li>凸函数运算
<ul>
<li>非负加权求和: 所以这一点在神经网络中不能保证，所以就不是最优解</li>
<li>与放射函数复合</li>
<li>最大值或者上确界</li>
</ul></li>
</ol></li>
</ul>
<h2 id="各种优化器">2. 各种优化器</h2>
<p>二阶Hessian矩阵：各个的偏导数</p>
<p>一阶倒数刻画切线的斜率，二阶倒数刻画的是切线的斜率的变化率。</p>
<p>二阶函数能刻画函数的凹凸性</p>
]]></content>
  </entry>
  <entry>
    <title>deeplearning tensorflow study</title>
    <url>/2019/deeplearning-tensorflow-study-c596b3b82490/</url>
    <content><![CDATA[<h1 id="一个pipeline">一个pipeline</h1>
<blockquote>
<p>一层封装，但还是仍然比较繁琐
https://blog.csdn.net/u012896627/article/details/72874678</p>
</blockquote>
<ol type="1">
<li>建立一个sess=tf.Session &gt; 交互式会话跟全局会话有什么区别 &gt;
tf.Session.init()
<ul>
<li>tf.Session vs tf.InteractiveSession &gt;
原本每个张量的计算，以及最后的取值都需要在默认的Session中，而且最终的运行也离不开Session.run();
采用InteractiveSession后， 本身就为默认的session,
此时距直接tensor.eval() 即可运行， vai.init.run()即可运行</li>
</ul></li>
<li>中间涉及到的张量Tensor, 主要相关的其实就是矩阵运算
<ul>
<li>tensor类型
<ul>
<li>tf.placeholder() // 通常用于小数据集的输入, 在后面的feed_back={}
将进行制定</li>
<li>tf.Variable(name=, intilizer=) // 可用于梯度 更新的内容</li>
<li>tf.constant(name= , shape=)</li>
</ul></li>
<li>tensor初始化
<ul>
<li>获取指定分布的值
<ul>
<li>random_normal 正态分布 random_uniform 聚云分布 truncated_normal</li>
</ul></li>
</ul></li>
<li>区分不同作用域的变量
<ul>
<li>with tf.variable_scope(scope_name, resue=): v1=""</li>
</ul></li>
<li>小技巧
<ul>
<li>tensor.eval() // 查看tensor的numpy矩阵</li>
<li>tensor.shape // 查看形状</li>
<li>v.assign() assign( )</li>
<li>tf.get_variable(name): 获取指定名称的var</li>
</ul></li>
</ul></li>
<li>Tensor之间的运算, 即边 &gt;
https://blog.csdn.net/u012896627/article/details/72874678
<ul>
<li>矩阵变换, 这个本身可以用numpy来做？
<ul>
<li>tf.expands_dims(arr, 1), 在指定的轴，
比如axis=1，增加一维，原数据不变？ 如其名，</li>
<li>tf.concat(arr1, arr2, axis=1) 在某一维上将两个向量合并。
(2,3)-&gt;(2,6), (4,3) 发现对于0来说是倒着来的</li>
<li>tf.sparse_to_dense()</li>
<li>tf.random_shuffle() 按照axis=0, 进行制定shuffle</li>
<li>tf.argmax/ arg.min 找到最大最小所对应的的位置</li>
<li>tf.equal 判断两个tensor是否每个元素都相等，返回bool的tensor</li>
<li>tf.cast 将x的数据格式转化为dtype</li>
<li>tf.matul 用来做举证乘法</li>
</ul></li>
<li>神经网络
<ul>
<li>tf.nn.embedding_lookup
将一个数字序列转化为embedding序列表示？举证</li>
<li>tf.trainable_variables 返回多个有训练的变量</li>
<li>tf.gradients 用来计算导数</li>
<li>tf.nn.dropout 防止过拟合</li>
</ul></li>
<li>普通操作
<ul>
<li>tf.linrange() tf.range()</li>
</ul></li>
<li>规范化
<ul>
<li>tf.variable_scope</li>
<li>tf.getvariale_scope</li>
</ul></li>
<li></li>
</ul></li>
<li>变量的初始化操作
<ul>
<li>Session.run(vari.initilizer) // 进行变量的初始化</li>
<li>tf.initialize_all_variables().run()</li>
</ul></li>
<li>损失函数和梯度下降
<ul>
<li>损失函数为图的最后一个tensor</li>
<li>优化器. optimizer = tf.train.GradientDesecentOptimizer(0.5)</li>
<li>train = ptimizer.minimize(cross_entropy)</li>
</ul></li>
<li>tensorflow运行
<ul>
<li>sess.run(fetches, feed_dict, options) //
<ul>
<li>fetches: tensor_node</li>
<li>feed_dict</li>
<li>return: fetches中的值</li>
</ul></li>
</ul></li>
<li>预测
<ul>
<li>tf.equal(tf.argmax(a, 1), tf.argmax(g,1))</li>
<li>accuary = tf.reduce_mean()</li>
</ul></li>
<li>tensor.close()</li>
</ol>
<blockquote>
<p>另外，所谓的tf.Graph; 每个tensor都可以产生一个graph;
或者定义一个graph, 之后都在该作用域下进行声明tensor</p>
</blockquote>
<p>tf快捷配置命令行参数 &gt; 并不是技术，用在了很多方面
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 声明</span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line">tf.app.flags.DEFINE_string(props_str, default_str) // DEFINE_TYPE</span><br><span class="line"></span><br><span class="line">// 使用</span><br><span class="line">FLAGS.props</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>查看GPU nvidia-smi</p></li>
<li><p>以后计划任务，务必注意查看需要花费的时间</p></li>
</ul>
<p>什么是skip-gram算法？
skip-gram算法是什么，在给出目标单词的情况下，预测它的上下文单词，这里会给定指定窗口大小。
思想：https://zhuanlan.zhihu.com/p/29305464 &gt;
没看懂，还是没明白第一个矩阵W是V*d,
是当前矩阵的什么。还有就是用到邻接矩阵的向量？？</p>
<p>https://zhuanlan.zhihu.com/p/27234078</p>
<p>扩展，一点想法，代理是什么？ 代理服务，代理协议，代理端口
首先代理服务，有邮件 代理协议就是像常见的http/https协议等等
代理端口也就是所用的代理端口的感觉</p>
<p>两个问题：现在已经测试了可以开启代理服务器的方式允许各种方式的网络配置。
已经测试了同局域网下可以访问，如何允许私网段以及不同局域网访问呢？按理说是能做到的</p>
<p>ssh连接远程访问也可以通过代理服务器来做，也就是说如果解决了不同局域网的访问，那么就可以访问到集群</p>
<p>很多配置相关的文件都在~/.ssh下</p>
<p>现在所配置的代理不过都是私网地址，即局域网内允许使用的地址
另外有一种情况就是NAT，地址映射协议，由某一地址统一管理。如果其他计算机需要访问的话，需要首先在主节点上进行说明。</p>
<ul>
<li>docker是什么？有什么用？ 相关概念：虚拟机，操作系统
http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html
虚拟机是在一个操作系统之上再嵌套一个操作系统。</li>
</ul>
<p>对于虚拟机来说，它管理很多方面，有着很多方面的高效性。就是一个操作系统，并且能够提供各种服务，比如文件服务、网络</p>
<p>而docker是进行进程的模拟，所以提供的服务会很快。启动快，占用资源少
有什么用？ 提供一次性的环境， 提供弹性的云服务， 组件微服务架</p>
]]></content>
      <categories>
        <category>tools</category>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>design pattern summary</title>
    <url>/2019/design-pattern-summary-939a5b5b5373/</url>
    <content><![CDATA[<p>参考书籍： head first 之设计模式</p>
<p>相关实现代码： https://github.com/AugF/DesignPatterns</p>
<h2 id="a.-概览">A. 概览</h2>
<ol type="1">
<li>OO基础
<ul>
<li>抽象 &gt; 基类，类的定义</li>
<li>继承 &gt; 在设计模式中体现，父类和子类的多态</li>
<li>封装 &gt; 类本身的定义，类封装或者函数封装</li>
<li>多态 &gt; 参数，返回值多态
<ul>
<li>运算符多态</li>
</ul></li>
</ul></li>
<li>类代码可控制的点
<ul>
<li>访问控制 &gt; 保护，公有，私有</li>
<li>单例方法，类的方法
<ul>
<li>静态变量</li>
<li>单件模式</li>
</ul></li>
<li>多态
<ul>
<li>函数参数多态</li>
<li>函数返回值多态</li>
<li>操作符多态</li>
</ul></li>
<li>变量类型
<ul>
<li>引用</li>
<li>常量</li>
<li>setter, getter类</li>
</ul></li>
</ul></li>
<li>OO原则
<ul>
<li>封装变化</li>
<li>多用组合，少用继承</li>
<li>针对接口编程，不针对实现编程</li>
<li>为了松耦合而设计</li>
<li>类应该对扩展开放，对修改关闭（开闭原则）</li>
<li>要依赖抽象，不要依赖具体类（依赖倒置原则） &gt;
不要让高层组件依赖于低层组件</li>
<li>最少知识原则，只和你的密友谈话，和Law of Demeter一样的意思</li>
<li>好莱坞原则：别调用我们，我们会调用你们</li>
<li>一个类应该只有一个引起变化的原因（单一原则） &gt;
还有一个概念叫内聚，用来度量一个类或者模块紧密地达到单一目的或责任。
单一原则要求高内聚</li>
</ul></li>
<li>原则总结
<ul>
<li>类本身
<ul>
<li>单一职责</li>
<li>封装变化</li>
<li>对扩展开放，对修改关闭</li>
</ul></li>
<li>类之间的关系的目标
<ul>
<li>松耦合</li>
<li>最少知识(和很少的类交互)</li>
</ul></li>
<li>类之间关系的设计
<ul>
<li>思想
<ul>
<li>多用组合，少用继承</li>
<li>针对接口，不针对实现</li>
</ul></li>
<li>物理
<ul>
<li>依赖抽象，不依赖具体类</li>
<li>掌握主动性, 主动发出，而不是被动接受</li>
</ul></li>
</ul></li>
</ul></li>
<li>OO方法
<ul>
<li>策略模式: 接口实现动态的方法 &gt;
定义算法族，分别封装起来，让它们可以互相替换，此模式使得算法的变化独立于使用算法的客户.
委托即接口</li>
<li>订阅者模式: 出版者和订阅者 &gt;
在对象之间定义一对多的依赖，这样当一个对象改变状态时，依赖它的对象会收到通知，并自动更新
&gt; 窗口添加监听对象</li>
<li>装饰器模式: 开闭原则的唯一实现?? &gt;
动态地将责任附加到对象上。想要扩展功能，装饰器提供有别于继承的另一种选择
&gt; 永远都不会实例化对象</li>
<li>工厂方法模式：完成多种类别的对象创建的封装 &gt;
定义了一个创建对象的接口，但由子类来决定要实例化的类是哪一个。工厂方法让类把实例化推迟到子类。
&gt; 输入目标返回实例</li>
<li>抽象工厂模式：创建一个家族 &gt;
提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类</li>
<li>单件模式: 有益于随时随地地使用全局变量 &gt;
确保一个类只有一个实例，并提供一个全局访问点 &gt; 使用vilatile static
Singleton uniqueInstance，
vilatile关键字要求当uniqueInstance初始化为Singeleton时，多个线程需要正确处理它</li>
<li>命令模式： 封装命令的具体形式,
日志的记录，其他的操作实际上就是写入文件, 面板的按钮引起操作 &gt;
将“请求”封装成对象，以便使用不同的请求，队列或者日志来参数化其他对象，命令模式也支持可撤销操作
&gt; 具体实现就是，User中, sendCommand(command),
buttonPressed事件触发command.execute();
Command将对其他的一些复杂操作完全包括在自身execute中 &gt;
单独将方法抽出来成为一个类</li>
<li>适配器模式: 接口解耦 &gt;
将一个类的接口，转换为客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。</li>
<li>外观模式：操作的简易化封装 &gt;
提供了一个统一的接口，用来访问子系统的一群接口。外观定义了一个高层接口，让子系统更容易使用。</li>
<li>模板方法模式： 封装算法 &gt;
在一个方法中定义了一个算法的骨架，而将一些步骤延迟到子类中。模板方法可以在不改变算法结构的情况下，重新定义算法中的某些步骤</li>
<li>迭代器模式： 封装集合，顺序访问接口 &gt;
提供一种方法顺序访问聚合对象中的各个元素，而又不暴露其内部的表示。</li>
<li>组合模式： 同等方式对待整体和部分中的每一个元素 &gt;
允许你将对象组合为树形结构来表现“整体/部分”层次结构，组合能让客户以一致的方式处理个别对象以及对象组合。
<ul>
<li>两个版本： 透明式和不透明式</li>
</ul></li>
<li>状态模式：通过引用不同的状态对象，将不同行为委托给所对应的（当前的）对象。
&gt; 允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类
&gt; !
内部状态改变时，改变它的行为实际是就是将将行为委托给状态。因为本身引用到多个不同的状态，所以可以来类好像产生了改变，实际上是由行为引起转向了不同的状态对象</li>
<li>代理模式: 用于输入对象的过滤. Proxy代替RealSubject处理外界输入 &gt;
为另一个对象提供一个替身或占位符以控制对这个对象的访问 &gt;
使用代理模式创建代表对象，让代表对象控制某对象的访问。被代理的对象可以是远程的对象、创建开销大的对象或者需要安全控制的对象。
&gt; transient A a; 声明类中a属性不用序列化 &gt;
虚拟代理的例子中，加载图片涉及到新开一个线程
<ul>
<li>特性 &gt; 代表对象和以及处理相比于对象更多的东西 &gt;
只允许访问部分接口</li>
</ul></li>
<li>复合模式 &gt;
复合模式结合两个或两个以上的模型，组成一个解决方案，解决一再发生的一般性问题
&gt; 注意！
简单的叠加不叫复合模式，复合模式是一个对象同时参与到多个模式中。</li>
</ul></li>
</ol>
<h2 id="b.-常见模式总结">B. 常见模式总结</h2>
<ol type="1">
<li>全局变量： 单件模式 &gt; 实现： 变量标志，关键字控制多线程，即模板
<ul>
<li>测试： 全局只有一个锅炉</li>
</ul></li>
<li>接口不匹配： 适配器模式
<ul>
<li>类适配器 &gt; 原本的类没有，只有新类 &gt;
Adapter实现目标类Duck的接口, Adapter构造参数为要替代的类Turkey,
然后实现Duck的接口 &gt; 实际使用时用Adapter当做Duck使用</li>
<li>对象适配器 &gt;
实现目标类的接口或抽象类，不过只需要覆盖方法即可</li>
<li>测试： 火鸡的接口来冒充鸭子的接口</li>
</ul></li>
<li>可变子类太多： 装饰器模式 &gt; 抽象接口,
两类扩展接口，一种是基本的元素类（必需品）,
一种是可扩充品，参数为该接口本身, 添加一些东西，对要计算的值再计算;
<ul>
<li>测试： 面包的可加的料有很多，而且可加的次数不受限</li>
</ul></li>
<li>类之间的通信： 订阅者模式 Java Observable &gt;
被订阅者拥有订阅者列表，可对该列表进行添加等操作,
当自身的某些东西改变时, 触发订阅者列表中的每个的set接口改变新的值 &gt;
订阅者有统一的接口, 订阅者有被订阅者作为构造参数,
构造同时使用被订阅者方法加入自己。 &gt; 订阅者根据被订阅者set自己的方法
<ul>
<li>应用：窗口部件在初始化的同时注册许多</li>
<li>测试： 温度计，被多个显示屏所订阅</li>
</ul></li>
<li>要初始化的类太多,初始化太繁琐: 工厂模式 &gt; 超级简单！ &gt;
产品类接口，然后一些产品的实现。 &gt;
工厂将接口作为参数，然后声明方法，通过指定的参数，即指示创建类的名称，然后拥有对应的动作
<ul>
<li>测试： 工厂创建各种各样的面包</li>
</ul></li>
<li>有多个功能相似（有重叠）的类： 抽象工厂模式 &gt;
在工厂的基础上，工厂再作为接口，每个具体的工厂用于多个多个不同的产品。
&gt; User类在使用时，直接可选择性地创建工厂
<ul>
<li>测试：不同的面包店，提供不一样的买的东西</li>
</ul></li>
<li>接口太复杂： 外观模式 &gt; 非常简单的事情 &gt;
主体包含很多部分控件，封装主体的操作，每个操作对应到一组组件的动作
<ul>
<li>应用：应用总窗口的创建操作</li>
<li>测试：party房间绝对房间中的一切状态</li>
</ul></li>
<li>方法的步骤很多，以及处理种类各异: 命令模式 Java &gt;
声明中间Command接口, 对应很多的实体, execute &gt;
命令方发出setCommand(), 动作然后对应的Command被触发 &gt;
对应的Command实体可以是操纵一些方法，也可以是操纵一些类
<ul>
<li>应用: 对于窗口部件的多个触发事件</li>
<li>测试： 餐厅服务员的例子</li>
</ul></li>
<li>算法的封装： 模板模式 &gt; 抽象类作为高层,
写好了算法的绝大部分，只留下一小部分 &gt;
实现方法，抽象类封装具体的算法过程，具体的一小部分由继承实现
<ul>
<li>应用: Arrays.Sort()</li>
<li>测试：不同的餐厅菜单，试图实现对应的问题</li>
</ul></li>
<li>方法的多样性，选其一： 策略模式 &gt;
User类的某个组件为接口，并且该接口会对应很多具体的实现
<ul>
<li>测试：比如英雄可以选择多样的武器，并发出动作，每个武器的动作不一样</li>
</ul></li>
<li>封装集合，不同的物理实现； 迭代器模式 &gt;
首先迭代器一个接口，然后每种物理的储存抽象为迭代器，扩展自迭代器接口。
&gt;
具体的迭代器实现传入目标类为构造参数。目标类有createIterator调用迭代的方法，创建迭代器
&gt; 使用时直接使用迭代器接口即可
<ul>
<li>测试: 建立多个不同物理集合方式的类，然后进行遍历</li>
</ul></li>
<li>同等方式对待整体和个体的元素： 组合模式 &gt; 首先具有统一的接口 &gt;
对于方法，不过某些只能叶子实现，某些只能组合实现。 &gt;
对于组合来说，会维护一个数组，表示其拥有的元素；每个组合，一个print可以完全展示其所有元素
&gt; 扩展使用，组合+迭代器，如何实现的? &gt; Iterator接口，
CompositeIterator() 组合迭代器，本身会维护一个栈,
当new时，会push进入元素。 &gt;
CompositeIterator()的next(),hasNext()实现有讲究；
取next时，会递归地将成分解析!!!,
当发现真正的叶子时，进行加入，并返回该元素;
hasNext()的判断过程也是一个递归的过程 &gt; hard!! menu
createIterator(menuComponents.iterator) meanComponents为数组元素 &gt;
NullIterator, false, null; 供叶子使用;
<ul>
<li>测试： 由menu接口来做, menuComponent来共同生成，menu作为组合，
menu可以添加menu, 或者menuItems, 测试遍历输出结果如何</li>
</ul></li>
<li>对象更易于分割为各个状态，而且更简单： 状态模式 &gt;
每个状态接口，不同状态进行扩展，每个状态会实现这些的方法，而且这些类中的这些方法一般会包含状态的转换
&gt;
对于主类，常见的操作是这些各种类实际是组成部分，当然会有一些简易的初始化步骤
<ul>
<li>测试： 完全一系列主类的动作，通过主类当前的状态的输出进行查看</li>
</ul></li>
<li>对象的访问控制： 代理模式
<ul>
<li>远程代理 &gt; 实际上是远程通信 &gt;
实现一个远程代理接口(注意返回值和参数都是可序列化对象，并抛出异常)，该接口继承自具体的Remote;
&gt; 实现远程代理接口的具体类（需要继承UnicastRemoteObject，
同时要求有个午餐的构造器），实际上是具体的服务。因为涉及到远程，所以这里首先注册rmi
rmiregistry产生对应代理辅助对象 &gt;
开启服务端，服务端创建一个对象，然后使用Naming.rebind("name", new
MyRemoteImpl())注册。 &gt; 服务端运行，
并且在存根产生目录rmiregistry运行辅助对象 &gt; 客户端请求
直接使用MyRemote接口，然后使用Naming.lookup("rmi://localhost" +
name)得到远程对象。 &gt; 然后得到的这个对象即可直接使用。
<ul>
<li>测试：直接输出远程对象的方法</li>
</ul></li>
<li>动态代理 &gt; 使用java自带的Proxy &gt;
例子：实现一个类的访问权限控制。 &gt; 首先，一个类接口，一个具体类 &gt;
一个关于类的代理 implements InvocationHandler, 构造函数参数为类接口。
&gt; 根据 Proxy.newProxyInstance(classloader, interfaces(), new
Handler(a))方法返回一个原类 &gt;
实现invoke()方法，即对可使用的方法进行过滤，对参数进行过滤；一起进行重新分配
<ul>
<li>测试： 使用返回回来的原类进行测试，是否实现了过滤</li>
</ul></li>
</ul></li>
</ol>
<blockquote>
<p>如何能够更快速，简便地画图？
思考，现在打字只是为了记住一些东西，但是记录的东西意义性值得考虑</p>
</blockquote>
<ol start="15" type="1">
<li>复合模式之MVC &gt; MVC: model, view, control
view和contrl都是view的观察者, model改变后会直接告诉contrl,
control做出对应逻辑的改变，或许产生view的变化 contrl是view的策略模式
view内部的组件实际上是组合模式。控制器只要与顶层组件进行交互即可</li>
</ol>
]]></content>
      <categories>
        <category>java</category>
        <category>design_pattern</category>
        <category>summary</category>
      </categories>
      <tags>
        <tag>summary</tag>
        <tag>java</tag>
        <tag>design_pattern</tag>
      </tags>
  </entry>
  <entry>
    <title>design pattern details</title>
    <url>/2019/design-pattern-details-403772281a6e/</url>
    <content><![CDATA[<p>参考书籍： head first 之设计模式</p>
<p>相关实现代码： https://github.com/AugF/DesignPatterns</p>
<h2 id="设计模式入门">1. 设计模式入门</h2>
<p>知道封装、抽象、继承、多态这些概念，并不会马上让你变成好的面向对象设计者。设计大师关心的是建立弹性的设计，可以维护，可以应付改变</p>
<p>面向对象，鸭子对象。只要认为实现了鸭子对应的方法就是鸭子</p>
<p>首先，实现基类鸭子会叫，其他鸭子都是基于基类的继承
某天出现了会飞的鸭子，怎么办？在基类中添加飞的接口，？但是，并非所有鸭子都会飞
1. 使用继承，？代码量太大 2.
使用飞和叫两个接口，每个鸭子基于接口的实现，？没有鸭子都需要进行重写内容，无法做到代码复用</p>
<p>设计原则 - 找出应用中可能需要变化之处与其他稳定的代码相分离 -
针对接口编程，而不是针对实现编程</p>
<blockquote>
<p>与原本不一样的是，这里的想法是针对接口编程，实际上就是针对超类型编程。即将需要变化的用户的行为进行两步抽象，第一步首先为接口，第二步为具体的各种实现，然后具体的类使用的是具体的实现。这里针对接口编程其实也可以看作是抽象类型编程。</p>
</blockquote>
<p><font color='red'>多态！将子类型的实现绑定到父类型上，然后直接用父类型接口的所有方法来做事</font>
有种感觉即是把鸭子的行为委托给了别人。
接口是局部版的抽象，又跟抽象不一样，很奇妙！！ <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">interface FlyBehavior&#123;&#125;</span><br><span class="line"></span><br><span class="line">FlyWithWings&#123;  fly()&#123;// action&#125;  &#125;</span><br><span class="line">FlyNoWay&#123; fly()&#123;//no way&#125;  &#125;</span><br><span class="line"></span><br><span class="line">interface QuackBehavior&#123;&#125;</span><br><span class="line"></span><br><span class="line">Duck implements FlyWithWings &#123; //？   extends FlyWithWings   错误</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class Duck &#123;</span><br><span class="line">    QuackBehavior quackBehavior; // 每只鸭子在构造函数中都会进行实现接口</span><br><span class="line"></span><br><span class="line">    public void performQuack()&#123; </span><br><span class="line">        quackBehavior.quack();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class MallardDuck extends Duck &#123;</span><br><span class="line">    public MallardDuck() &#123;</span><br><span class="line">        quickBehavior = new Quack(); // 指定接口的行为</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>? 先做系统还是然后再分离和封装 需要进行自己预估 ?
如果飞行的行为不止对应的方法，还对应着变量， 怎么处理？ &gt; ?
考虑使用方法来管理对象 ? Duck不应该设计为接口吗 &gt;
不，需要变化的地方已经做到；继承最大的好处是可以共用共有的东西，所以直接将Duck实例为一个对象即可。</p>
<p>就目前来说，在构造函数中其实还是面对的具体编程，即指定了某个特定的行为。那么如果在运行时使用多台的行为，使得在行为时可以动态改变呢？
setattr() 方法</p>
<p>??
一个很妙的思路，现在虽然将我们所关心的接口分离了，但是的话，还是单个只能表示单个。
如何是一个目标是可以动态改变的呢？
一种想法是设置一个傀儡类，也可以称为模板类，先在构造函数中指定默认的接口实现。并且对外界提供修改该属性值的方法，从而获得修改行为的方式。
&gt;
这里是通过将行为另类地表示为属性，从而根据属性的动态挂定从而获得好的结果</p>
<p>所以需要在运行时改变鸭子的行为，只需要调用鸭子的setter方法即可</p>
<h3 id="关系">关系</h3>
<ul>
<li>Is-A</li>
<li>Has-A</li>
<li>implements</li>
</ul>
<blockquote>
<p>这里，前面的想法其实所有的一切都是将是一个变为了有一个，其实关键原因在于代码中本身有多个可以变化的东西。如果是是一个的话很难改变，所以我们通常期望的就是是有一个。</p>
</blockquote>
<p>于是，得到第三个设计原则 多用组合，少用继承。</p>
<blockquote>
<p>以上即为策略模式！！！
简单来说，主体的类有多个作为属性的接口，这些接口可以各自进行实现。然后各种各样的人物可以通过继承来实现。</p>
</blockquote>
<p>运用 &gt;
对于动作冒险游戏中，各个游戏角色可以使用任意的武器，做任意的动作。</p>
<p>共享词汇的好处，可以高效</p>
<h3 id="总结">总结</h3>
<ol type="1">
<li>OO基础
<ul>
<li>抽象</li>
<li>封装</li>
<li>多态</li>
<li>继承</li>
</ul></li>
<li>OO原则
<ul>
<li>封装变化</li>
<li>多用组合，少用继承</li>
<li>针对接口编程，不针对实现编程</li>
</ul></li>
<li>OO特性
<ul>
<li>可复用</li>
<li>可扩充</li>
<li>可维护</li>
</ul></li>
</ol>
<h2 id="观察者模式">2. 观察者模式</h2>
<p>让你的对象知悉现状，不会错过该对象感兴趣的事情。对象设置在运行时可决定是否要继续被通知。观察者模式是JDK中运用最多的模式。
松耦合，一对多的关系。</p>
<p>问题：如何实时地显示和更新气象站得到的湿度、温度、气压等信息</p>
<p>一种想法就是设置一个measurementsChanged()方法，当监控到元数据更改时，就进行整体更新数据。</p>
<h3 id="简介">2.1 简介</h3>
<p>出版者和订阅者=观察者模式 &gt;
即主体对象是出版者，当出版者进行更新时，直接通知订阅者即可；而不是每个订阅者进行实时监听所有的情况。
&gt; ？
将订阅者列表作为类的属性，然后可以通过set和get进行添加和删除。然后，根据订阅者列表所关注的信息，如果关注的信息发生改变，那么就进行通知。
关注的信息是什么？</p>
<blockquote>
<blockquote>
<p>进一步回答，这里注意到观察者是主动进行添加订阅者的。这里有两个点：</p>
</blockquote>
</blockquote>
<ol type="1">
<li>为什么要将订阅者的三个行为作为抽象？
两个接口之间的关系，实际上因为发布者会管理订阅者的状态，所以使用了订阅者作为函数参数。
抽象为接口是为了方便有更多的订阅者状态管理和订阅者更多的显示功能以及用其他的表示的不合适</li>
<li>关注的信息是如何做到的？
这里其实就是首先具体实现的主题中会封装一个通知所有订阅者的方法，然后一般来说观测的内容是作为类的属性的。当使用某种方法进行类的属性更改时，记得调用通知所有订阅者的方法即可实现当方法改变时通知了所有的订阅者</li>
<li>实际上订阅者是仅仅与发布者相关的，所以订阅者必须知道发布者的消息，所以一般来说订阅者会将发布者作为类的属性，然后调用它来订阅自己，依此这样就可以完成订阅。
&gt; 等于说订阅者有发布者的指针</li>
</ol>
<p>再思考java中的接口设计 &gt; 接口可以封装一些共同的方法</p>
<p>这里的想法是，观察者作为接口, 状态改变时进行更新;
然后接口主题对应于多个观察者，具体的主题是基于接口的实现；可以get,set观察者。
notifyObserves()专注于查看状态改变时更新所有的观察者。 &gt; ?
主题应该才是主题 &gt; ? 怎么实现多个的。</p>
<p>主题只知道观察者实现了某个接口？</p>
<p>!!!
主题唯一的依赖是一个实现了Observe接口的对象列表，可以进行随时增加观察者</p>
<p><font color='red'>为了交互对象之间的松耦合设计而努力</font></p>
<p>理解为什么起作用，因为register注册后是将观测者加入到了订阅列表中的，而且当消息更新时，消息更新时是遍历每个观测者并且调用了各自的更新函数的。</p>
<p>其实这种方法与另一种是对立的，即从某种意义上来说为什么不直接发布者提供getter方法呢，每个订阅者直接获取需要的数据。
这样是有问题的，破坏了发布者本身数据的隐私性。
但是，会导致发布者给订阅者需要传送一大波状态。</p>
<h3 id="java内置的观察者模式">2.2 Java内置的观察者模式</h3>
<blockquote>
<p>观察者模式的运用范围还是超级广的</p>
</blockquote>
<p>观察者如何接收通知？？ arg应该只是通知参数 &gt;
一个特别有意思的东西就是实现了Changed参数，即可以从某种范围来进行约束。如果手动应该怎么设计</p>
<p>java.util.Oberverable是一个类是有问题的，使用</p>
<p>//
注意接口和类的区别，接口没有成员变量，所有方法必须是抽象方法，支持多继承。抽象类可以有方法实现，只要有一个抽象类即认为为抽象类</p>
<p>在界面设计中最为频繁。
当设计出一个新的部件时，通常会问是否增加对应的亲听着，以及对应的倾听者发出什么样的行为。
每个倾听者倾听的是不同的行为，然后把所有的事件也进行了一定程度的封装。</p>
<p>大量运用GUI框架中</p>
<h2 id="装饰者模式">3. 装饰者模式</h2>
<p>使用对象组合的方式，在运行时装饰类 讲对象包装起来，赋予新的组合</p>
<p>问题引入：在星巴克咖啡中，如何实现多种种类的咖啡的支付？</p>
<ol type="1">
<li>直接针对每种实现：组合爆炸</li>
<li>针对原料进行继承实现，当原材料发生变化时会出现问题</li>
</ol>
<p><font color='red'>类应该对扩展开放，对修改关闭</font></p>
<p>初步印象：
有一个对象，然后可以有各种对象可以按任何顺序来装饰它，然后最后的总能记住前面的顺序是如何达到的，从而可以准确地计算出对应对象的价格</p>
<p>分析： 1. 被装饰者和装饰者一直始终拥有相同的超类型 2.
可以用一个或者多个，装饰器可以替代原本，庄思琪可以在所委托的前后加上自己的行为？？？所以前面那么艰巨的任务是通过这样来实现的？
3. 对象可以在任何时候装饰</p>
<p>尽量不改变原本的设计，所以原本是抽象类也可，当然如果是接口也可。
总共设计到这几方面： 1. 抽象订单 Basic 2. 基本原料，
由Basic继承而来，无参数 3. 可添加接口，
继承自Basic，为什么这样做是为了保持前后加持的行为的统一，又称为装饰器；使用的是继承，所以可以来自于其他装饰器之间的组合关系
4. 可添加原料实现，默认参数为Basic类型，因此可以动态地无穷无尽地进行添加
&gt;
因为一定包含参数，所以这里利用的不是父类的属性，而是基于其他对于父类的基本实现，是一种很牛逼的做法，很厉害了</p>
<p>这就是装饰者模式牛逼的地方所在，不用继承；而使用了一个继承的性质，做到了多种进行叠加的继承的效果，牛逼！！</p>
<h3 id="应用范围">应用范围</h3>
<p>当针对特定种类的具体组件是这样的设计将不再有效果。
装饰器方法适用于组件会发生动态变化的情况 装饰器增加行为到被包装对象上。
&gt;
如何窥探装饰链上的每一个装饰者，getDescription()的返回值为ArrayList()类型即可</p>
<p>会带来大量的小类!!! ### 实际应用</p>
<p>Java IO 使用对流的管理，从而来组合各种输入流装饰者来符合用途</p>
<h3 id="缺点">缺点</h3>
<ol type="1">
<li>很难轻易理解</li>
<li>类型问题，往往一些代码依赖于特定的类型，当导入装饰器时会出现问题？（不是继承吗？怎么回事？）</li>
<li>代码复杂度问题，实例化组件时非常麻烦 ## 4. 工厂模式与抽象工厂模式
### 4.1 工厂方法模式 除了使用new之外，还有很多制作对象的方法。
使用工厂模式批量地制作对象</li>
</ol>
<p>当某一个类的派生子类出现的情况越来越多时，此时我们就需要考虑使用工厂模式来做了，将所有制作的参数来封装。只需要引入某个类型参数即可创建对应的需要的对象。</p>
<p>静态工厂：
仅仅只管理各种不同的类的创建，因此不需要创建对象的方法来实例化对象。</p>
<p>但是，一般来说工厂可能还会封装一些其他属性以及方法，因此就不能通过继承来改变创建方法的行为了。</p>
<p>感觉上都是运用了父类对象可以直接访问到子类对象的多态来做的</p>
<p>实现一个接口，即实现一个超类型</p>
<p>由工厂进一步扩大的要求，不止有建工厂的需求，还希望能够管理加盟店。加盟店还要给下面的店一些自己操作的空间，那么将不变的封装在加盟店中，将改变的部分给下面的店进行继承实现。
&gt; 如果加盟店为一个抽象类，那么如何展示这个店的所有权呢？
因为，所有加盟店体现为加盟店的所有子类，所以所有子类可以整个看成是加盟店，这样就特别自然</p>
<h4 id="组成">4.1.1 组成</h4>
<ul>
<li>创建者类
<ul>
<li>工厂方法,
抽象类，将关键的创建方法设置为abstact,由具体的子类来决定如何创建</li>
<li>具体的加盟店，定义具体的创建方法</li>
</ul></li>
<li>产品类
<ul>
<li>具体的产品，实际可以供选择创建的产品</li>
</ul></li>
</ul>
<h4 id="评价">4.1.2 评价</h4>
<p>将生产知识封装进了创建者，使得剥离了很多。
特别有意思的东西就是实际上的想法是通过抽象类之间方法的调用从而实现了工厂方法。</p>
<p>OO一个原则是针对接口编程，不针对实现编程。工厂方法所在的思想是将创建兑现的代码集中封装在一个对象或方法内。从某种意义上说，此时就不是具体的类的创建，而是根据参数创建对应的类，从某种意义实现了面对接口编程。但是，对于对象的创建是现实的，不可能永远不创建对象，否则就无法建立java程序，所以不要走向极端。</p>
<h4 id="辨析">4.1.3 辨析</h4>
<p>简单工厂 vs 工厂方法
简单工厂只是将创建方法进行提取，工厂方法是将创建方法重新作为了一个类的方法
简单工厂把全部的事情在一个地方处理完了，而工厂方法却是提供了一个框架，让子类决定要如何实现</p>
<p>? 字符串传入参数化的类型有点危险
可以通过创建代表类型的对象或者enum类型 ? 工厂方法和创建者是否总是抽象的
不，可以定义一个默认的工厂方法来产生某些具体的产品，这样一类，即使创建者没有任何子类，依然可以创建子类。</p>
<h3 id="抽象工厂模式">4.2 抽象工厂模式</h3>
<p>其实，要实现工厂模式，我们还有一个简单的版本，即实现一个具体类，这个具体类中有函数createPizza(style,
type), 但是这有一个问题，这个具体类会依赖于大量的类。</p>
<p><font color='red'>要依赖抽象，不要依赖具体类</font></p>
<p>？为什么要依赖一个抽象类呢，感觉上是因为抽象类一般都是包含固定的实现或者接口，是不会改变的地方，比起具体的类而言。</p>
<p>在高层和低层组件之间加上一个抽象类，很完美地体现了依赖倒置原则。</p>
<p>依赖倒置设计指导原则 1.
变量不可以持有具体类的引用：如果使用new，就会持有具体类的引用，可以改用工厂来改变这样的做法
2. 不要让类派生自具体类，有派生必然产生依赖，请派生自一个抽象或接口 3.
不要覆盖基类中已实现的方法。</p>
<p>依赖倒置设计原则的应用环境：
所依赖的具体类是一个极易改变的类，当依赖的是一个不会改变的类时没有必要遵循依赖倒置原则</p>
<p>扩展：设计原料工厂
这里扩展了一个原料工厂的接口，它是单独的，不受任何依赖。然后具体的pizza会拥有原料工厂作为属性，在自己进行创建时经过原料工厂的手来进行创建。
然后，pizza具体工厂会在函数中拥有原料工厂的变量，即在创建时以便将原料工厂传给具体的pizza作为参数</p>
<p>其实，这里原料工厂用来管理各种原料的生产和前面pizza工厂用来管理各种不同的pizza的创建的想法是一样的。这里称为抽象工厂模式。</p>
<p>提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。
&gt; 抽象工厂方法用来创建一种特定的具体的产品，具有某种属性的东西</p>
<h4 id="辨析-1">4.2.1 辨析</h4>
<p>抽象工厂模式:
与工厂方法相比来看，抽象工厂定义了一系列的步骤，产品的操作，每个产品都有createProductA()方法。
而每个createProduct()方法的实现实际上是考虑了工厂方法的。即将其交给各自的具体的实现类来管理使用哪种原料。
而原料工厂提供给pizza工厂的接口就是自己
原料工厂提供给pizza的操作就是各种的createProduct方法 &gt;
在这里其实每个原料工厂是进行了封装了多种特定的方法。暂时代码没有能够实现多个原料工厂的混搭，从某种意义上上层再建一层抽象或者参数给传递多一点可以实现</p>
<p>抽象工厂 vs 工厂方法
创建对象上，抽象工厂使用的是组合；工厂方法使用的是继承
对于抽象工厂来说，如果扩展这组相关产品，必须要修改接口
抽象工厂是被用来创建整个产品家族的，工厂方法不过是创建一个产品。</p>
<p>抽象工厂：创建产品家族和想让制造的相关产品集合起来是
工厂方法：将客户代码从需要实例化的具体类中解耦 ## 5. 单件模式
确保一个类只有一个实例，提供全局访问点</p>
<h3 id="前沿">5.1 前沿</h3>
<p>以下情况我们只需要一个对象，线程池、缓存、对话框、处理偏好设置和注册表中的对象、日志对象、充当打印机、显卡等设备的驱动程序的对象。</p>
<p>全局变量的缺点：如果将对象赋值给一个全局变量，那么必须在程序一开始就创建好对象，然而，如果这个对象非常耗费资源，在程序中一直没用到它，就会造成资源的浪费。
JVM: 在用到的时候才创建对象。</p>
<p>如果有多个同时出现，此时就会发生操作系统中学习到的多个进程同时发生的问题了
### 5.2 实现 !!! 居然是通过私有的构造器 + getInstance来实现的 &gt;
不过这样一想也非常合理，如果是共有的必然new会进行不断创建</p>
<blockquote>
<p>? 不会出现后面给static标志为null的情况了吗？ 问题：
多线程运行时会发生同时进入的问题，导致可能分配到不同的对象？ 方法： 1.
将getInstance()方法前加入synchronized,
迫使每个进程在进入这个方法之前，必须等候别的线程离开该方法。
但是，同步其实只需要在第一次保证即可，后面的情况不再需要，因此会严重降低性能。
如果不重要可忽略 2. 在一开始就创建好实例 3. 双重检查加锁，代码加P182</p>
</blockquote>
<blockquote>
<p>可以扩展为控制实例的个数为指定个</p>
</blockquote>
<p>? 为何不直接将所有方法和变量都定义为静态的 &gt;
如果类自给自足，不依赖于复杂的初始化可以这么做，否则静态初始化在java手上可能导致混乱。建议使用对象的单件而不是类的单件
? 类加载器 !!注意不同的类加载器会创建多个单件模式</p>
<p>? 单件模式适合继承吗？
不，因为单件模式的核心是通过私有化构造函数实现的，所以不适合继承。因为子类会进行破坏单件的内容。任何现有的类，都轻易地加上一些代码支持单件模式，但是，单间模式不一定适合设计进入一个库。使用情况并不多</p>
<p>单件模式 vs 全局变量 &gt;
在Java中全局变量就是对对象的静态引用，全局变量有一个很大的缺点就是急切实例化，而且全局变量可以提供全局访问，但是不能确保只有一个实例。
单件模式，有点像静态变量static,
不过声明的时间和位置可以任意，这点超级棒！ ## 6. 命令模式
外界显示的接口为命令模式，即将实际的方法进行进一步的封装。将方法调用封装起来。
&gt;
思考这样一种场景，顾客下了一份订单，订单经过服务员然后交给厨师长，然后厨师长进行做菜。其中服务员无须知道订单内容是什么，只需要接收订单并传递给厨师长即可。于是服务员和厨师长之间就彻底解耦了，服务员只需要将订单给厨师长，厨师长则只需要按订单来做</p>
<p>又如前面的问题，让用一个遥控器实现所有设备的自动打开什么之类的。此时遥控器的实现要求不能知道太多细节，有点像订单？</p>
<p>模型是发出请求的对象和接收与执行这些请求的对象解耦</p>
<blockquote>
<p>然后想到这里的服务员其实只有两个动作，一是接收命令setCommand(这里使用了Light作为参数)，表示添加了一个接收者，二是触发动作。
? 订阅者模式。 不对！有区别。
这里是一个可能有着多条不同的命令，从命令的模式进行封装。这里就把服务员
直接抽象为命令。于是就形成了各种命令，一下子所有问题变得非常简单了。</p>
</blockquote>
<p>//
等于说Command有多种不同的变体，然后client做到了解耦，即只需要关心所有Command共有的两个操作即可。而所有的Command的具体实现对具体的Receiver进行了封装。</p>
<p>扩展？ 如何做撤销 如何实现队列、日志和支持撤销的操作</p>
<p>为了避免检查，很多时候会考虑设置空对象来做。可以更方便地表示!!!!</p>
<p>实现undo操作，在类中设置一个变量用来跟踪最后一个命令。</p>
<p>? 如何控制不再是一个的操作
将RemoteContrl的参数变为数组类型，即所谓的宏命令；或者另一种方式，硬编码；但是第一种宏命令更为灵活
? 为何命令对象不直接实现execute()方法细节
这样就不够傻瓜，换句话说达不到想要的解耦的效果 ?
如何保存多层次的撤销记录
不再使用变量，而是考虑使用一个堆栈来做到保存所有的历史记录</p>
<h3 id="扩展">6.1 扩展</h3>
<p>如何实现线程池？即收集多个队列的线程请求，然后有效地把输出限定在固定数目的线程中进行。
&gt; 1.
如何控制每次线程数目是一定的？比如说总共只有4个线程。可以考虑在RemoteContrl中设置属性记录线程的数目，使得线程的个数不会超过指定个数
&gt; 2. 如何存储请求？将请求按单元存储在队列中</p>
<p>日志请求 &gt;
某些大项数据机构的动作的应用无法在每次改变发生时被快速地存储，那么就需要使用记录日志，将上次检查点之后的所有操作记录下来，如果系统出现故障，则从上次的检查点从做。
&gt;
某些应用需要我们将所有的动作都记录在日志中，并能在系统死机之后，重新调用这些动作恢复到之前的状态。这里通过新增两个方法store(),
load().
在Java中，可以利用对象的序列化实现这些方法，但是一般认为序列化最好还是只用在对象的持久化上。
如何做呢？
如何做？这里的感觉就是栈式保存检查点的信息，或者直接将其写入文件，通过对文件内容的解析从而达到目的啊。
## 7. 适配器模式与外观模式 ### 7.1 适配器模式
将底层可被调用的类的接口转变为目标类的接口，依此实现不同的接口。
将对象包装起来以简化其接口。</p>
<p>装饰器可以把一个方块放进一个圆洞里面
面向对象的适配器像交流电适配器，用于在中间将客户的请求转变为厂商能理解的请求。
&gt;
简单理解就是一层封装，即把系统的接口封闭起来，向外提供的接口是用户感兴趣的接口</p>
<p>一个例子，需要鸭子，鸭子可以飞，而且可以呱呱叫。但是没有鸭子，只有火鸡，火鸡可以飞和咯咯叫，现在想办法用适配器来冒充提供鸭子的接口</p>
<p>适配器实现了目标接口即鸭子，并且持有被适配器的实例</p>
<p>? 适配器需要做多种适配的工作
如果不采用适配器的话，需要话很多力气来做大量的调查工作和代码改写工作。相比之下，提供一个适配器类，将所有的改变都封装在一个类中，是比较好的做法。
? 一个适配器只封装一个类吗
不，现实情况下，被适配器有很多种，比如同种需求往往有种多种实现，而且后面可能进行增加和删除实现，所以提出了适配器需要适配多个被适配者，就是下面介绍的外观模式。
? 如果既有新的适配要求，又有旧的适配要求怎么办
实现双向的适配器，于是该适配器都可以用，怎么写????</p>
<h4 id="对象适配器和类适配器">7.1.1 对象适配器和类适配器</h4>
<p>类适配器使用的是继承适配类和被适配类得到的，而对象适配器是通过组合得到的。
对象适配器可以适配某个类及其所有子类。
对象适配器只需要组合的对象是子类即可。
类适配器的好处在于代码少，可以覆盖被适配者的行为，而且可以直接继承自适配器</p>
<h4 id="真实世界的适配器">7.1.2 真实世界的适配器</h4>
<p>在Java中elements()方法会返回一个Enumeration来，这个接口可以逐一地遍历集合中每一个元素，而不需要知道在集合内是如何被管理的。
迭代器的实现也可以看作是适配器。</p>
<h4 id="适配器-vs-装饰器">7.1.3 适配器 vs 装饰器</h4>
<p>适配器允许客户使用新的库和子集合，无须改变“任何”代码。一定会进行接口的转换。
装饰器只是扩展所包装对象的行为或责任，而且绝对不会进行接口的转换 ### 7.2
外观模式 Facade-Pattern
改变接口的新模式，改变接口的原因不过只是为了简化接口
外观只是提供你更直接的操作，并来讲原来的子系统组个起来。如果你需要子系统类的更高层功能，还是可以使用原来的子系统。</p>
<p>如何不要赢得太多的朋友和影响太多的对象 只调用以下范围的方法 -
该对象本身 - 被当做方法的参数而传递进来的对象 -
此方法所创建或者实例化的任何对象 - 对象的任何组件 &gt;
如果某对象是调用其他的方法返回的结果，不要调用该对象的方法</p>
<p>实际世界中并不总是满足这个原则的，比如System.out.println??;
因为这样设计会导致非常多的包装类，加大复杂度和开发时间 ## 8.
模板方法模式 ### 8.1 模板方法模式
主要是为了封装公有算法而产生的，使得对于类型都适配</p>
<p>例子：设计封装煮咖啡和茶的算法。如何做？设计一个接口，分别包含茶和咖啡的所有公共部分的操作，然后算法直接调用它，咖啡和茶则继承自它。
这里接口也可以是抽象类</p>
<p>对模板方法进行挂钩，钩子实际上是一个默认的方法实现。有了钩子，通过自己决定是不是需要覆盖方法，如果不提供自己的方法，抽象类会提供一个默认的实现</p>
<p>? 什么时候使用抽象方法，什么时候使用钩子 &gt;
当子类必须是某个实现时使用抽象方法。
使用钩子的场景：钩子是用来让子类实现算法中可选的部分，或者狗仔对子类的实现并不重要的时候；以及让子类有机会对模板方法中某些即将发生的步骤做出反应</p>
<h3 id="好莱坞原则">8.2 好莱坞原则</h3>
<p>防止依赖陷阱，别打电话给我，我会打电话给你们
允许低层组件挂钩到高层组件上，但是高层组件会决定什么时候和怎样使用这些低层组件</p>
<p>模板方法中的体现，抽象类为高层，Tea,Coffee为低层，如果Tea和Coffee没有先被调用，绝不会调用抽象类？
&gt;
抽象类作为高层，只有当Tea先被调用时才可能调用自己，这就由高层决定了什么时候使用，不过这不本身就是多态允许的吗??</p>
<h3 id="应用">8.3 应用</h3>
<ol type="1">
<li>排序算法
sort()方法是Arrays类的一个静态方法，然后由用户自己设计类，并实现CompareTo接口，利用对象数组即可实现排序。这也是模板方法模式的一种变形。
&gt;
注意到并没有使用一般的继承来做到，实际上的做法是利用了数组。然后和静态方法来做</li>
</ol>
<p>模板方法模式 vs 策略模式 &gt;
在策略模式中，所组合的类一定是实现了整个算法，而对于模板方法模式，所实现的算法并不完整
&gt;
策略模式定义了一个算法家族，这些算法都可以进行互换，正因为每一个算法都被封装起来了，所以客户可以使用不同的算法。</p>
<ol start="2" type="1">
<li>写一个SWing的窗口程序
JFrame本身不做任何事情，当你继承它后，并覆盖它的paint类就可以做一些事情了</li>
</ol>
<h2 id="迭代器与组合模式">9. 迭代器与组合模式</h2>
<p>迭代器模式，将集合的实现进行封装起来，仅给用户提供遍历的接口。
对象职责？ 创建对象超集合？</p>
<blockquote>
<p>封装集合</p>
</blockquote>
<p>不封装的坏处，必须知道各个部分的物理实现方式，知道的细节多，同时也非常不利于代码维护</p>
<p>本身可以是各种各样的数据结构，例如：列表、数组、散列表等等，无论什么方式存储，一律可以视为集合，有时也称作聚合</p>
<ul>
<li>hasNext()</li>
<li>next()</li>
<li>remove() ! 多线程下小心，如果是这种具有写操作类似的感觉。即remove,
那么可能会发生多个迭代器引用同一个对象集合，从而会产生冲突</li>
</ul>
<p>架构： Iterator,
ConcreteIterrator一个具体的迭代器，然后再关联一个具体的类ConcreteAggregate(由createIterator()来函数返回值关联)。
ConcreteAggregate同时扩展自Aggreate(createIterator())接口的类。 所以
Clint 只需要使用Aggreate接口即可访问任意的ConcreteAggreate &gt;
评价，首先通过第一次接口的使用，屏蔽了具体的类型；第二次接口，屏蔽了具体的存储实现。所以，迭代器模式很完美地做到了解耦！！</p>
<p>? 内部迭代器和外部迭代器 &gt;
迭代器模式是外部迭代器，内部迭代器由迭代器自己控制。 ?
元素读取的顺序问题，如散列表 &gt; 看实现，没有假设有顺序，是无顺序的 ?
Enumeration &gt; Enumeration是一个有次序的迭代器</p>
<p>如何评价高内聚?? 单一职责?</p>
<p>Java 5: for( in ) &gt; 不再需要迭代器模式了</p>
<h3 id="组合模式">9.1 组合模式</h3>
<p>树形结构，能够按顺序访问到所有的叶子节点 !
忽略对象组合和个别对象之间的差别 &gt; 就是一种变形的迭代</p>
<p>结构: &gt; 组合包含组件，组件有两种：组合和叶节点元素</p>
<p>? 在组合中用到了迭代器 &gt;
其实说到底的感觉不过就是接口，然后接口有些方法其他地方不用去实现 ?
共同接口, 一个类两个功能，从某种意义上说违反了单一原则 &gt;
但这是设计上的抉择，这样做失去了一些"安全性“,但是透明性transparency更好。，另一种想法是使用两个接口，单功能来表示，但是失去了透明性，客户的代码必须用条件语句和instanceOf操作符处理不同类型的节点</p>
<blockquote>
<p>有些时候为了保证透明性，不得不去牺牲一些其他的特性</p>
</blockquote>
<p>? 应用 &gt;
用户界面来说，一个顶层的组件（Frame或Pane)包含着其他组件（菜单、文字面板、滚动条、按钮），所以你的GUI包往往包含了若干部分，但是但你显示它的时候，你认为它是一个整体，由顶层组件显示所有相关的部分
? 有些对象没有的特性 &gt; null或者false, 具体看需求。 ?
为何不对孩子节点也设置getChild(), 不过返回为null &gt;
失去了本身的一些特征，会产生一些没有意义的调用，失去了组合模式的感觉 ?
结构特性 &gt;
孩子不会反指向父亲；需要注意孩子遍历的顺序的问题；当组合结构很复杂，遍历代价很高时，可以考虑焕春
## 10. 状态模式 状态模式 vs 策略模式</p>
<p>策略模式是围绕可以互换的算法的创建成功业务的。
状态模式依赖的是状态以及状态之间的改变</p>
<p>自动糖果机</p>
<blockquote>
<p>一个类一个状态? 一个类一个状态机?</p>
</blockquote>
<p>如何思考? - 首先，得到所有的状态 -
分析出所有状态之间的转换关系，注意一些陷阱 - 设置标志变量 -
分析每个状态之间的转换过程，并对其他的过程进行分析</p>
<p>初试设计，每个状态实际上一个方法，现在考虑扩展方法 1.
扩展，10%的概率奖励购买的人，如何做？ &gt;
标志变量需要扩展，标志变量实际上这里可以看作是类本身的属性</p>
<p>感觉，改进了什么？ &gt;
将有问题多判断以及不好管理和扩展的if语句，改为了对象的形式</p>
<h3 id="策略模式-vs-状态模式">策略模式 vs 状态模式</h3>
<blockquote>
<p>从类图上看，这两者的类图完全一致，但两者有很大区别 1.
状态模式，往往直接将主体分为状态，把行为附加到状态上；所有的状态模式都会一起相互作用，在主体context下完成工作，是和的作用;
适用于context中多太多的条件判断的替代 2.
策略模式，仅仅是某一步的行为或属性，可以有多种替代方式。策略模式，只要求选其一即可;适用于仅仅继承某个行为的类的优化方式。</p>
</blockquote>
<p>? 如何决定下一个状态的 &gt;
这种设计模式必然带来了会在具体的类和context类中共同改变状态，所以产生了很强的依赖，这里的改进就是应用getter方法而不是硬编码的形式把依赖降到了最小。</p>
<p>? 客户会直接和状态交互吗？ &gt; 不会</p>
<p>? context有多个实例，如何共享对象 &gt;
这里考虑的方法是利用context引用来做，状态对象不能持有自己的内部状态，否则不能共享?</p>
<h3 id="some-question">some question</h3>
<p>? 会带来类的数目的增加 &gt; 对，显然的！可维护性和扩展性的折中</p>
<p>? 为什么要WinnerState, 不直接放在SoldState中 &gt;
确实代码上很多重复，这里我们依据的想法是一个类一个责任，即OO原则之单一职责原则</p>
<p>? 如何清掉重复代码以及将糖果机用到其他机器上 &gt;
接口改为抽象类，封装外部可见和内部可见的一些知识</p>
<h2 id="代理模式">11. 代理模式</h2>
<p>白黑脸游戏，你是一个白脸，很友善地为别人服务，但你不希望每个人都叫你做事；于是你找了个黑脸，来控制对你的访问。这就是代理所做的事情：控制和管理访问，为某些懒惰的对象做一些事情</p>
<p>当你的重心在糖果机上时，其实是在接受外部消息时，对你的通信线路强插一脚，过滤调用和访问的内容。
&gt;
所以这里就好像在糖果机上套了一个监视器，当实际一细想，是谁在使用糖果机，用户啊?
而目标在于设计糖果机监视器。该视角太难，所以想到转变视角，在糖果机监视器的角度想。</p>
<blockquote>
<p>然后就产生了很神奇的东西，对于糖果监视器，用户直接使用我，我来处理一些东西，然后我再远程调用糖果机，做真正的处理。所以，远程调用就对用户来说透明了!!!</p>
</blockquote>
<p>RMI: 远程调用 &gt; 实际上的做法感觉上其实就是 被调用方变成可调用方法
&gt;
然后，会有一个平台进行实时监控。当收到调用方的调用命令时，然后调用调用方法返回给调用者。
&gt;
也可以不是实时通信，像邮件系统投递一样，调用方和被调用方都有辅助对象。说起来有点像观察者模式中消息传递的感觉</p>
<p>RMI - stub客辅助对象 - 服务辅助对象skeleton</p>
<h4 id="服务端">服务端</h4>
<p>三步走 - 总览 - 制作远程接口 MyService.java - 实现具体的远程类
MyServiceImpl.java - 使用rmi, 产生该具体类的stub, skeleton - 启动rmi
registry 注册表 - 开始远程服务，本地得有一个具体的远程类的一个实例，
将实例加到注册表中</p>
<ol type="1">
<li>制作远程接口
<ul>
<li>interface MyRemote extends java.util.Remote{}: 接口可以继承接口</li>
<li>声明所有的方法都会抛出RemoteException异常</li>
<li>确定变量和返回值都是原语类型或可序列化对象 &gt;
原语类型，即java本身自带的类型，即基本类型。可序列化对象，即实现了Serializable接口</li>
</ul></li>
<li>制作远程实现
<ul>
<li>实现远程接口, 并且对象具有某些远程的功能 &gt; public class
MyRemoteImpl extends java.rmi.server.UnicastRemoteObject implements
MyRemote</li>
<li>设计一个不带变量的构造器</li>
<li>用rmi
registry注册该远程接口的实例化对象。使用java.rmi.Naming的静态rebind()方法
&gt; Naming.rebind("RemoteHello", service)
当绑定具体对象时，rmi会把服务换成stub注册在registry,
因此远程客户就能很轻易找到</li>
</ul></li>
<li>产生stub和skeleton &gt; rmic MyRemoteImpl. 将会产生_stub.class,
_skel.class两个对象 &gt; 命令行需要先编译为class文件 &gt;
注意要在targets/classes中执行，加包的名称 &gt; !!!
现在不再产生_skel类了<br />
</li>
<li>执行rmiregistry &gt; 开启一个终端，启动remiregistry,
确定目录必须有可以访问你的类 &gt; 命令找不到
https://stackoverflow.com/questions/26197749/cant-find-rmi-registry &gt;
http://www.voidcn.com/article/p-ajxdfmab-ux.html 一种另外的方式 &gt;
需要在target/proxy中进行启动， 即所在目录，启动方式为类当前目录</li>
<li>启动服务 &gt; 开启另一个终端，启动服务 java MyRemoteImpl &gt;
直接使用idea中运行！！</li>
</ol>
<h3 id="客户端">客户端</h3>
<ol type="1">
<li>在rmi registry中寻找</li>
<li>rmi registry 返回stub对象</li>
<li>调用服务stub, 此时stub看起来就好像是真正的服务</li>
</ol>
<h3 id="评价-1">评价</h3>
<blockquote>
<p>这种方式其实有点低级，相当于首先一个窗口执行rmiregistry表示开始了中间的监听，然后一个窗口执行服务器端程序。
现在来说，更普遍的方式为“动态类下载”，利用动态类下载，序列化的对象被贴上一个url保险。只需要一个简单的web服务器来提供这些类文件即可。
### 注意 1. 启动rmiregistry 2. 服务端，参数和返回值都必须可序列化 3.
记得产生stub类</p>
</blockquote>
<h3 id="应用设计gumball的代理模式">应用：设计Gumball的代理模式</h3>
<ol type="1">
<li>transient 关键字, jvm不需要序列化这个关键字 &gt; can't find the
.._stub.class ??</li>
</ol>
<p>由此可见，通过调用代理的方法，远程调用可以扩月网络，返回字符串、整数和State对象。而此时GumballMonitor并不知道是使用了代理。
&gt; !要特别注意处理远程异常</p>
<p>类图组成 &gt;
注意观察就可以发现，这里的类图组成实际上就是一个接口，然后有两个继承类，一个RealSubject,
一个Proxy,
Proxy持有Subject的引用，所以必要时它可以请求转发给Subject.</p>
<h3 id="进一步应用虚拟代理">进一步应用：虚拟代理</h3>
<ol type="1">
<li>远程代理 &gt; 远程代理可以作为另一个JVM对象的本地代表。</li>
<li>虚拟代理 &gt;
RealSubject创建开销大，所以在创建的时候，先用一个代理来接收请求委托，当创建好了后再进行显示
&gt;
很常见的例子就是网络在加载一个大的视频的时候，通常会由一个正在缓冲的图片来代理显示
&gt; ? 未请求到图片，也没有错误信息</li>
</ol>
<h3 id="question">question</h3>
<p>? vs 装饰器 &gt;
目的不同，装饰器是为对象增加行为，而代理是控制对象的访问，可以代表对象，而且处理比对象更多的内容，代理将用户和RealSubject解耦了;
&gt; 装饰器还有一个很大的点就是装饰器永远都不会实例化对象</p>
<p>? 如何让客户使用代理，而不是真正的对象 &gt;
常用的技巧是提供一个工厂接口，实例化返回主题，实例化的工作由工厂来做</p>
<p>? 能不能把加载过的图像放在缓存中 &gt; 可以的，即缓存代理Caching
Proxy;
缓存代理会维护之前创建的对象，当收到请求时，在可能的情况下返回缓存对象。</p>
<p>? vs 适配器 &gt;
保护代理有点类似。适配器肯定接口不一样，代理则随意</p>
<h3 id="动态代理">动态代理</h3>
<ul>
<li>动态代理 &gt; java.lang.reflect
java反射机制其实本身就是代理的彻底体现 &gt;
大概的感觉这里就是java本身为你实现了各种的代理proxy,但是代理的工作现在我放在哪里呢？
所以java设计了InvocationHandler接口invoke()方法，你只需要实现该接口即可。使用该接口的具体类感觉上就是是代理的方法调用一样的感觉</li>
</ul>
<p>how to do?</p>
<ol type="1">
<li>InvocationHandlerImpl, 构造函数参数为Target， handler()方法</li>
<li>使用时, 通过Target = (Target)
Proxy.newProxyInstance(object.getClass().getClassLoader(),
object.getClass().getInterfaces(), new
InvocationHandlerImpl(object))得到</li>
</ol>
<p>! 动态指的是运行时才将类给创造出来，代码开始执行时是不存在的 ?
如何判断是否是代理类 &gt; isProxyClass()方法</p>
<p>? newProxyInstance()类型有什么限制吗 &gt;
只能有接口，并且属于同一个package? 具体看javadoc</p>
<p>! 改变 &gt;
java5的RMI和动态代理搭配使用，不需要stub,skeleton都不要了，rmic也不需要了</p>
<ul>
<li>保护代理</li>
</ul>
<blockquote>
<p>一个约会软件的例子。 PersonBean有两个访问权限：1.
别人不可以修改自己的特别信息 2. 自己不可以修改别人对自己的评分
其实说到底感觉更像是一种访问权限的控制的事情</p>
</blockquote>
<h3 id="代理使用启示">代理使用启示</h3>
<ol type="1">
<li>防火墙代理</li>
<li>智能引用代理：当主题被引用时进行额外的动作，比如计算一个对象被引用的次数</li>
<li>缓存代理：
为开销大的运算结果提供暂时存储?，常在Web服务器代理，以及内容管理和出版系统中出现</li>
<li>同步代理Synchronization:
在多线程的情况下为主题提供安全的访问，被发现出没于JavaSpaces,
为分散式环境内的潜在对象集合提供同步访问控制</li>
<li>复杂隐藏代理：用来隐藏一个类的复杂集合的复杂度，并进行访问控制。外观代理。就是可能直接访问接口太多，代理的话可以只显示一些东西。与外观模式不一样，外观模式只提供一组接口，并不能对原本的对象产生影响。而且远简单于该方式。</li>
<li>写入时复制代理:
用来控制对象的赋值，方法是延迟对象的赋值，知道客户真的需要为止，lazy计算</li>
</ol>
<h2 id="复合模式">12. 复合模式</h2>
<p>!!!, 模式之间进行一起使用</p>
<p>鸭子，不同行为的鸭子； 混入鸭子的鹅， 适配器模式 统计鸭子的叫声，
装饰器模式 统计鸭子叫声的工厂， 工厂方法模式
一个鸭子接口可以控制所有鸭子叫，组合模式 +
迭代器模式（一般是默认实现好的，所以这里就直接用即可）
需要跟踪某个鸭子实时的叫声，即监听，订阅者模式 !!! &gt;
关于组合的订阅者??</p>
<p>? 上面就是复合模式吗 &gt; 不只是模式的组合而已</p>
<p>!!! 不要为了使用模式而使用模式 &gt;
上面的例子只是为了演示而已，一定要避免陷入里面去</p>
<h3 id="复合模式之王-mvc">复合模式之王: MVC</h3>
<p>视图：
模型：应用系统存在的理由，设计的对象包含了数据、逻辑和其他在你的应用领域出现的问题</p>
<p>视图：用来显示和编辑的部分</p>
<p>控制器：模型和视图之间的数据流动</p>
<p>用户查看视图，获得的试图的结果传给控制器。控制器做两步工作，第一步，改变显示。第二步，改变数据的状态。
然后，显示是订阅了模型的内容的，所以问询问模型，模型一旦更新完毕。显示进行对应的更新。</p>
<blockquote>
<p>模型可能要求视图产生变化</p>
</blockquote>
<p>? 控制器可以便曾模型的观察者吗？ &gt; 可以的</p>
<p>?
控制器主要就是作为模型和视图之间的交互，那么为什么不直接把这样的代码放在视图中，1，这样会使视图的代码变得复杂，视图就具有了两个功能，管理用户界面和处理如何控制模型的逻辑。2.
这么做会造成模型和视图之间紧耦合。</p>
<p>设计模式解析 &gt;
模型利用观察者模式使得控制器和视图可以随着最新状态更新而更新 &gt;
视图为一个对象，可以被调整为不同的策略，而控制器提供了策略。 &gt;
视图的显示，包含了窗口、面板、按钮、文本标签等，每个显示组件使用了组合模式。当视图进行更新时，只需告诉视图顶层的组件即可。</p>
<p>Java Dj view</p>
<p>代码之间的关系</p>
<ul>
<li>model: 负责数据模型部分, 主要是Observable</li>
<li>controller, 构造参数为model, 拥有view, 同时初始化view;
为view的策略模式部分。</li>
<li>view: 主管视图，以及定义乡音接口</li>
<li>测试： new model, new controller(model)</li>
</ul>
<h3 id="mvc-与-web">MVC 与 Web</h3>
<p>Web中浏览器/服务器模型也很适用于MVC模型 主要涉及</p>
<ul>
<li>客户</li>
<li>控制器Servlet</li>
<li>视图</li>
<li>Bean模型</li>
<li>DB数据库操作层</li>
</ul>
<p>关系</p>
<ol type="1">
<li>客户发送http请求给控制器，控制器操作jsp视图，http回应给客户</li>
<li>jsp视图，控制器， bean三者关系即MVC</li>
</ol>
<p>优点</p>
<ol type="1">
<li>实现了设计上的组件分割，也提供了制作责任的分割。 &gt;
单一责任有利于专业的人做专业的事</li>
</ol>
<ul>
<li>进一步可以做的事，在手机上进行扩展
<ol type="1">
<li>修正模型完全不需要</li>
<li>创建Servlet控制器，一个简单的Servlet,接收http请求，并对模型执行一些操作。它需要做的是停止、开始和改变BPM
&gt; 其实也就是用户希望能够操作的控制</li>
<li>创建html视图。它会从控制器收到一个JavaBean,从这个Bean就可以得知它所有需要显示的东西。
&gt; 这里的Bean的感觉其实就是给前端的模型对象的接口</li>
</ol></li>
<li>步骤
<ol type="1">
<li>模型 &gt;
模型对视图和控制器一无所知。模型只需要知道，有一些观察者需要它通知。这就是观察者模式美妙的地方所在</li>
<li>控制器Servlet</li>
<li>建立视图 &gt; 关于idea部署 &gt; 1.
https://juejin.im/post/5b440ba05188251aad20f5dd java &gt; 2.
https://blog.csdn.net/qq_27093465/article/details/63683873 maven,
暂时看来不能混用： &gt;
tomcat下载安装https://blog.csdn.net/zhouzezhou/article/details/52450810
中间四之前需要 service.bat install &gt; idea 目录机构 &gt;
https://blog.csdn.net/l00149133/article/details/78984083 &gt;
idea配置java
web项目，太原始，问题未得到解决！请试图用比较现代的方式。这里的Servlet和form的路径可以由来表示，但是怎么说起来还是有问题的</li>
</ol></li>
<li>总结 &gt;
对比前面的浏览器模型，视图不再是经典意义上模型的观察者，它没有向模型注册以接收状态噶变通知。而是当模型改变时，视图间接地从控制器收到了相当于通知的东西。控制器甚至把Bean送给视图，允许视图可以取得模型的状态。
&gt;
其实考虑到浏览器模型，视图在http响应返回浏览器只需要一个状态信息的更新，随时通知没有意义。只有当页面被创建和返回时，创建视图并结合模型状态才有意义。
&gt; 1. 策略: 在这里策略对象依然是控制器Servlet,
但它不想传统的做法那样直接和视图结合，而是，策略对象为视图实现行为，当我们想要有不同的行为时，可以直接把控制器换掉
&gt; 2. 组合: Swing
GUI中视图是利用许多图形组件一层一层叠加起来的。但是在这里，则是由网页浏览器呈现html描述。尽管如此，内部还是很类似一个形成组合的对象系统</li>
</ul>
<h3 id="问题">问题</h3>
<p>? 组合模型在MVC中， 在！</p>
<p>? 控制器会实现应用逻辑吗 &gt;
不，控制器为视图实现行为。它将来自视图的动作转换为模型的动作。应用逻辑是指管理与操纵你的模型中的数据的代码</p>
<p>? 控制器是中介者模式吗 &gt;
中介者意图是封装两个对象的交互，不让对象之间互相显式引用，是双方的。控制器只是单方的</p>
<p>? 视图与控制器之间的对应关系 &gt;
通常情况下，运行时一个视图搭配一个控制器；也可搭配多个</p>
<p>? 视图不应该操纵模型，实例代码中并没有设限，这样不危险吗? &gt;
非常对，作者只是为了简单而已。应该这么做，可以使用代理模式，只对部分接口开放</p>
<h2 id="与设计模式相除">13. 与设计模式相除</h2>
<p>真实世界中的模式</p>
<p>模式是什么? &gt; 在某情境下，针对某问题的某种解决方案 广义之，
如果你发现自己处于某种情境下，面对着所要达到的目标被一群目标约束影响着的问题。然而，你可以用这个设计，克服这些约束并达到该目标，将你引领到某个解决方案
特别注意的是这个问题应该是重复出现的问题，因为始终需要衡量的一个东西就是成本。</p>
<p>? 模式的秒速是否由一个问题，一个情境以及一个解决方案构成？ &gt;
不止这些，模式类目的细节：模式类目描述某个模式的意图、动机、可能应用该模式的地方、解决方案的设计以及使用后果</p>
<p>? 首尾改变模式的结构符合我的设计，可以吗 &gt;
模式只是指导方针，可以改变模式来符合你的需求。真实世界的许多实例，都不符合经典的设计模式。不过在文档中最好注明两者之间的差异</p>
<p>? 从哪里取得模式类目 &gt;
设计模式：可复用面向对象软件的基础。23个基本的模式，还有其他将焦点放在不同领域：企业软件、并发系统、业务系统的模式类目</p>
<p>一种新鲜的解说：
实际的问题实际上就是力。世界上所有的问题包含了一组目标和一组约束。取得平衡的方向是光明的方向，约束是黑暗的方向，只有当两者取得平衡时才是你的目标</p>
<ul>
<li>如何学习？
<ol type="1">
<li>首先对于模式，知道的越多越好。然后，在实际应用中，一旦三个开发人员认同你的看法，你就成功了</li>
<li>一个条目所包含的内容
<ul>
<li>Intent</li>
<li>Motivation</li>
<li>Applicablity</li>
<li>Structure</li>
<li>Participants</li>
<li>Collaboration</li>
<li>Consequences</li>
<li>Implementation/Sample Code</li>
<li>Known Uses</li>
<li>Related Patterns</li>
</ul></li>
</ol></li>
<li>模式分类
<ol type="1">
<li>创建型:
涉及到将对象实例化，这类模式都提供一个方法，将客户从所需要实例化的对象中解耦
&gt; Singleton, Builder, Prototype, Abstract_Factory,
Factory_Method</li>
<li>行为型：涉及到类和对象如何交互分配职责 &gt; Template_Method,
Visitor, Mediator, Iterator, Memento,, Interpreter, Observer,
Chain_Of_Responsibility, State, Strategy</li>
<li>结构型： 把类或对象组合到更大的结构 &gt; Decrator, Composite,
Facade, Proxy, Flyweight, Adapter</li>
</ol></li>
</ul>
<p>架构模式: 建筑物 应用模式： MVC 领域特定模式： J2EE 业务流程模式:
组织模式： 用户界面设计模式：</p>
<h2 id="剩下的模式">14. 剩下的模式</h2>
<ul>
<li>桥接 Bridge Pattern &gt; 不止改变你的实现，也改变你的抽象 &gt; ?
不是很详尽，大概的改机是，一个遥控器，一个电视，每个不同型号的遥控器应该都有自己的实现。实际上的做法就是RemoteControl接口，ConcreteControl是抽象类,可以改变，然后TV接口接具体的实现
&gt; 两者的关系是RemoteContrl拥有TV, TV为成员变量 &gt; 应用 :
?需要用不同的方式改变接口和实现时</li>
<li>生成器 Builder Pattern &gt; 封装一个产品的构造过程，并允许按步骤构造
&gt; 例子：度假计划，每一天都可以由用户自我进行构造；
想法，实现一个AbtractBuilder, 具体生成器隐藏具体的构造过程</li>
<li>责任链Chain of Responsibility Pattern &gt;
当你想让一个以上的对象有机会能够处理某个请求的时候，就使用责任链模式
&gt; 例子：自动将邮件分发到不同的部门 &gt;
Handler此时就像switch语句的编译实现一样，Handler有多个具体的实现，如果当前Handler解决不了，会一直向后进行自动传递。
&gt; 优点： 将请求的发送者和接受者解耦; 可以简化结构，不必知道链的实现;
通过改变链内成员或调动他们的次序，允许你动态地新增或者删除责任。 &gt;
应用： 经常被使用在窗口系统，处理鼠标和键盘之类的事件;
并不保证请求一定会被执行，如果没有任何对象处理它，会落到链尾端。不容易观察运行时的特征。</li>
<li>蝇量 FlyWeight &gt;
如果想让某个类的一个实例能用来提供许多虚拟实例，就使用该模式 &gt;
并不实际建立类，比如TreeManager,treeArray来代表所有类的状态，所以存储的只是需要某个内容，比如说显示，只存储位置，而不进行建树
&gt; 缺点：
一旦实现了它，那么单个的逻辑实现将无法拥有独立而不同的行为</li>
<li>解释器? Interpeter Pattern &gt; 使用解释器为语言创建解释器 &gt;
这里的重点好像就是把每条语法设置为类。首先，本身的设计是什么？即首先词法分析，词法分析后进行比对语法分析。所以这里是处理上下文。把每个类当做节点，如果当前节点成功就进行下个语句的解析的意思是吗？</li>
<li>中介者 Mediator Pattern &gt;
使用中介者模式来集中相关对象之间复杂的沟通和控制方式 &gt;
使用中介者来管理两个对象之间的相互交互 &gt; 常用来协调相关的GUI组件??
如何做的</li>
<li>备忘录 MemontPottern &gt;
当你需要让对象返回之前的状态时，就使用备忘录模式 &gt;
出发点是为了保存进度 &gt; 存储系统关键对象的重要状态 &gt;
维护关键对象的封装</li>
<li>原型 ProtoType &gt;
当创建给定类的实例的过程很昂贵或很复杂时，就使用原型模式 &gt;
原型允许你通过复制现有的实例来创建新的实例，在Java中意味着clone方法。从某种程度上说，一要求某类提供静态方法。二要求能够查找正确的复制对象</li>
<li>访问者 Visitor &gt;
当你想要为一个对象的组合增加新的能力，且封装并不重要时，就使用访问者模式
&gt; !!!
很精彩，访问者可以参观组合中的每个元素，由它来管理外界对该组合的访问。由此，外界需要使用该组合时，可以直接考虑使用访问者。如此，当想在组合中增加一些对象时，只需要在访问者接口中进行相应的注册即可</li>
</ul>
<blockquote>
<p>怎么从类图看依然还是不会</p>
</blockquote>
<p>思考：</p>
<ol type="1">
<li>解决什么问题？什么条件</li>
<li>一般的解决方法是</li>
<li>如果过渡到设计模式</li>
<li>设计模式是什么，类图关系，如何做到解耦的?</li>
<li>优点和缺点分析</li>
<li>实际场景介绍</li>
</ol>
]]></content>
      <categories>
        <category>java</category>
        <category>design_patterns</category>
        <category>details</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>design_patterns</tag>
        <tag>details</tag>
      </tags>
  </entry>
  <entry>
    <title>easy offer details</title>
    <url>/2019/easy-offer-details-f4221b619b04/</url>
    <content><![CDATA[<p>总结</p>
<ol type="1">
<li><p>找出数组中重复的数字
注意这里的题目给的长度为n的数组，数组所有的数字都在0~n-1范围内
找出重复的元素，一种非常简单的思想就是hash，看hash位置上是否对应元素出现了两次。
而这里给的题明显有针对性，就是探讨能否在原数组上做hash之类的工作，于是想到了可以不断填坑。当遇到了非对应的那个坑但是有重复元素则退出</p></li>
<li><p>不修改数组找出重复的数字
注意到这里的题给的也有意思，数组的长度为n+1, 所有的数均在1~n.</p></li>
</ol>
<p>这里是二分法非数组索引的应用，对于数值来说，中位数的一边一定存在实际的计数大于所在的坑位</p>
<p>这里二分法就是一个递归的过程</p>
<ol start="3" type="1">
<li><p>二维数组的查找 分治也可以做，但是比较麻烦</p></li>
<li><p>从尾到头打印链表 查看vector一些常用的东西</p></li>
<li><p>重建二叉树 层次遍历怎么实现的？</p></li>
<li><p>二叉树的下一个节点 循环的再次理解</p></li>
</ol>
<p>while(p-&gt;left){</p>
<p>} 通常需要对p再进行输出处理，p是有实际含义的值</p>
<p>while(p){</p>
<p>}
通常对p判断是否为空，来查看里面的循环的执行情况；而真正的返回值的情况应该在括号内</p>
<p>理解这两个之间的不同！！！</p>
<ol start="7" type="1">
<li><p>用两个栈实现队列 队列需要什么功能？
入队，出队，返回top元素，所以这里我们就只需要考虑这些情况就可以了 &gt;
入栈，当要压入元素时直接进行压入；当要处理末尾元素时，考虑怎么处理，后如的再压栈，那么栈顶就是队首元素</p></li>
<li><p>旋转数组的最小数字 算法步骤：</p></li>
</ol>
<ul>
<li>如果长度不合法，返回不正确的结果</li>
<li>如果尾部等于头结点的元素</li>
<li>排除掉不存在解的情况 while(n&gt;0 &amp;&amp; nums[n]=nums[0]) n-- //
这里为什么是n&gt;0, 很有讲究的！！！</li>
<li>使用二分法查找问题的解</li>
</ul>
<ol start="9" type="1">
<li>矩阵中的路径 是否有某个解</li>
</ol>
<ul>
<li>首先找到起始元素，即找到某个连通分支图的起点。
可能图中有多个连通分支</li>
<li>dfs(matrix, str, len, x,y){ // 使用这个框架，每个点不能往回走 //
<ul>
<li>不等， 返回true</li>
<li>达到尺寸，返回false</li>
<li>对可能的情况进行枚举，并且进一步进行求解， 递归每个点 }</li>
</ul></li>
</ul>
<ol start="10" type="1">
<li><p>机器人的运动范围 机器人能到达多少格子？ BFS, 标志状态位，
对分支的限制函数的加法</p></li>
<li><p>剪绳子 数学知识， 分为多个3的做法</p></li>
<li><p>二进制1中的做法
注意，统计1的时候负数不可，直接对无符号数进行统计即可 待做：</p></li>
<li><p>数值的整数次方 记得负数进行取倒数即可</p></li>
<li><p>在O(1)时间删除链表节点 直接进行交换链表的值即可</p></li>
<li><p>删除链表重复的节点 双指针算法，而且注意给出虚拟头指针。
i指向上一个的头，j指向下下一个的开始</p></li>
<li><p>正则表达式匹配 &gt;
说明一个问题，啥问题？凡是字符串匹配都可以用这种动态规划的思想来思考</p></li>
</ol>
<p>s=aa p=a.*</p>
<p>f[i][j] 所有s[1-i], p[1-j]是否匹配，布尔值 集合划分 f[i][j] 以p为标准
- p[j]='.':f[i][j] = f[i+1][j+1] - p[j]==s[i] f[i][j] = f[i+1][j+1] -
p[j+1] = * f[i][j] = f[i][j+2]（匹配0个） || f[i+1][j](匹配多个) &gt;
这里用了递归的思想</p>
<p>f[n][m] = true;</p>
<p>f[0][0]</p>
<ol start="17" type="1">
<li><p>表示数值的字符串！！！ 分情况讨论的顶点</p></li>
<li><p>调整数组顺序使奇数位于偶数前面
快排思想的运用，一次划分两个不同性质的集合
二分法，找到两个不同不相交性质的中点</p></li>
<li><p>树的子结构 递归理解的经典版本
https://www.acwing.com/problem/content/35/ &gt;
判断一棵树是否是另一棵树的子结构，怎么判断？
如果该点是，返回；否则，对左孩子和右孩子进行判定</p></li>
<li><p>二叉树的镜像</p></li>
<li><p>对称的二叉树</p></li>
<li><p>顺时针打印矩阵 方向的运用</p></li>
<li><p>包含min函数的栈 单调栈</p></li>
<li><p>栈的压入、弹出序列 模拟</p></li>
<li><p>不分行从上往下打印二叉树 &gt;
感觉队列不能存储空节点，而dfs很轻易做到；但是可以标记一下的</p></li>
<li><p>分行从上往下打印二叉树 nullptr</p></li>
<li><p>之字形从上往下打印二叉树 flag=fasle; flag=!flag;</p></li>
<li><p>二叉树搜索树的后序遍历序列
给定一个整数数组，判断该数组是否为某二叉搜索树的后序遍历结果
[1,2,3,43,3,3] &gt;
同前面给定前序遍历或者中序遍历数组一样，首先是关键要找到一个代表元素，然后找到切分位置
思路: <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">ans = <span class="built_in">dfs</span>(nums, <span class="number">0</span>, s.<span class="built_in">size</span>()<span class="number">-1</span>);</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">dfs</span><span class="params">(nums, l, r)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(l&gt;=r) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">int</span> root=nums[r];</span><br><span class="line">    <span class="keyword">int</span> k=l; <span class="comment">// 找到分界点</span></span><br><span class="line">    <span class="keyword">while</span>(k&lt;=r &amp;&amp; nums[k] &lt; root) k++;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=k;i &lt; r;i++)</span><br><span class="line">        <span class="keyword">if</span>(nums[i] &lt; root) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">dfs</span>(nums, l, k<span class="number">-1</span>) &amp;&amp; <span class="built_in">dfs</span>(nums, k, r);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>二叉树的和为某一值的路径 dfs判断路径是否符合,
进行值减去即可</p></li>
<li><p>复杂链表的复刻
在原链表的基础上每个节点还有一个额外的指针指向链表中随机的节点</p></li>
<li><p>二叉搜索树与双向链表 通过二叉搜索树建立一个双向链表</p></li>
<li><p>序列化二叉树</p></li>
<li><p>数字排列
输入一组数字（可能包含重复数字），输出其具有的所有排列方式</p></li>
<li><p>数组中出现次数超过一半的数字 O(n), O(1)
注意就是代码的复杂度.分情况讨论，当</p></li>
<li><p>最小的k个数</p></li>
<li><p>数据流中的中位数</p></li>
<li><p>连续子数组的最大和</p></li>
<li><p>从1到n整数中1出现的次数</p></li>
<li><p>数字序列中某一位的数字</p></li>
<li><p>把数组排成最小的数</p></li>
<li><p>把数字翻译成字符串</p></li>
<li><p>礼物的最大价值</p></li>
<li><p>最长不含重复字符的子字符串</p></li>
<li><p>丑数</p></li>
<li><p>字符串中第一个只出现一次的字符</p></li>
<li><p>字符流中第一个只出现一次的字符</p></li>
<li><p>数组中的逆序对数</p></li>
<li><p>两个链表的第一个公共结点</p></li>
<li><p>数字在排序数组中出现的次数</p></li>
<li><p>0到n-1中缺失的数字</p></li>
<li><p>数组中数值和下标相等的元素</p></li>
<li><p>二叉搜索树的第k个节点</p></li>
<li><p>二叉树的深度</p></li>
<li><p>平衡二叉树</p></li>
<li><p>数组中只出现一次的数字</p></li>
<li><p>和为S的两个数字</p></li>
<li><p>和为S的连续正数序列</p></li>
<li><p>翻转单词顺序</p></li>
<li><p>左旋转字符串</p></li>
<li><p>滑动窗口的最大值</p></li>
<li><p>骰子的点数</p></li>
<li><p>扑克牌的顺子</p></li>
<li><p>圆圈中最后剩下的数字</p></li>
<li><p>股票的最大利润</p></li>
<li><p>计算1+2+..+n</p></li>
<li><p>不用加减乘除做加法</p></li>
<li><p>构建乘积数组</p></li>
<li><p>把字符串转换为整数</p></li>
<li><p>树中两个节点的最低公共祖先</p></li>
</ol>
<h2 id="总结">总结</h2>
<ul>
<li>复习栈、队列和</li>
</ul>
<p>变量重名，大忌！！ 注意检查这个错误 函数参数名一般不要为i,j</p>
<p>c++运算符优先级</p>
<p>大致感觉 1 :: 2 a++ () {} [] . -&gt; 3 ++a ! ~ <em>a &amp;a sizeof
new 4 .</em> -&gt;<em> 5 </em> / % 6 + - 7 &lt;&lt; &gt;&gt; 8 &lt;=
&gt;= 9 &amp; 9.5 == != 10 ^ 11 | 12 &amp;&amp; 13 || 14 +=</p>
<p>再思考用栈模拟递归 ## 递归的精妙之处</p>
<p>快排 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void quick_sort(int l,int r) &#123;</span><br><span class="line">    if(l&gt;=r) return; // basic</span><br><span class="line">    int x=a[l],i=l,j=r;</span><br><span class="line">    while(i&lt;j)&#123; // 这里为什么是i&lt;j</span><br><span class="line">        while(a[i]&lt;x) i++;</span><br><span class="line">        while(a[j]&lt;x) j--;</span><br><span class="line">        if(i&lt;j) swap(a[i],a[j]);</span><br><span class="line">    &#125;</span><br><span class="line">    quick_sort(l,i);</span><br><span class="line">    quick_sort(i+1,r);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>归并 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">merge_sort(int l,int r)&#123;</span><br><span class="line">    if(base) //base;</span><br><span class="line">    merge_sort(1);</span><br><span class="line">    merge_sort(2);</span><br><span class="line">    combine;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>扩展欧几里得算法 ax+by=d,<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int exgcd(int a,int b,int &amp;x,int &amp;y)&#123;</span><br><span class="line">    if(!b)&#123;</span><br><span class="line">        x = 1, y= 0;</span><br><span class="line">        return a;</span><br><span class="line">    &#125;</span><br><span class="line">    int res = exgcd(b, a%b, y, x);  </span><br><span class="line">    y -= a/b *x; // 合并结果对结果进行改进</span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>递归分治和DFS之间的感觉 分治强调范围的缩小 &gt;
也可以理解为特殊的DFS,
层数是通过区间长度为base来限制。划分技巧定的，导致每次一个点到其他点的方法都是确定，即确定的区间划分策略
&gt; 二叉树的遍历则可以认为物理确定了划分策略就为左右子树 &gt;
递归则可以看作划分的不均匀，也就是单位1和剩余，不过降低了规模而已。比如，路径缩短一点。
&gt; 动态规划是一种本身就有拓扑路径的结构</p>
<blockquote>
<p>循环也是一种递归，条件写在最前面，前后更新等等都有很多种讲究
DFS则是层数限制，每层展开是每个点的可行路径</p>
</blockquote>
<p>BFS-队列</p>
<p>递归-栈 &gt;
栈不断压入当前根节点等内容，直到最基本的情况，然后用解决最基本的情况，不断倒着解决，直到解决原本的问题，基本问题有解。需要回溯计算压存的解的计算公式，有特殊的返回值</p>
<p>DFS-栈 &gt;
DFS感觉有点不一样的就是，每层的东西都可以算，一定不断得到结果，到最后一层于是就得到了最终结果；然后，如果没有，则回溯再找解。
DFS到达根节点的感觉就是无返回值返回的感觉</p>
<p>两者相同的点最终都是返回原问题的解</p>
<p>中序遍历 左,中，右-栈 &gt;
是递归的感觉，相当于不是一次压栈结束的，到达了底层的一个节点又需要返回，然后再压数据，再找一次底层；这里底层的标志就是是否为空</p>
<p>二叉树的中序遍历等多种遍历方式的刷题</p>
<p>所谓循环：base, k, dfs()</p>
<p>调试代码的几种方法： 1. printf大法，输出所有东西</p>
<ol start="2" type="1">
<li>没有东西的时候，注释代码，或者删代码法，知道没有错误为止</li>
</ol>
<p>RunTime Exlimit:
其他语言有注释的，即有堆栈显示哪里出现了错误，所以可以得到直接更改</p>
<p>注意，DFS中节点有特别重要有意思的一点就是节点的状态是可以进行用二进制数来表示，进行优化的</p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>easy-offer</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>easy-offer</tag>
      </tags>
  </entry>
  <entry>
    <title>english todo</title>
    <url>/2019/english-todo-1349869961d4/</url>
    <content><![CDATA[<h2 id="英语学习">英语学习</h2>
<h3 id="目的是什么">目的是什么？</h3>
<ol type="1">
<li>为了提高自己的发音</li>
<li>为了无字幕听懂英语演讲，英语歌曲</li>
<li>为了英语论文写作</li>
<li>为了能说出正确的句子，写出正确的话</li>
<li>为了脑袋里有正常的英语单词反应</li>
</ol>
<h3 id="前沿发音">1. 前沿：发音</h3>
<ol type="1">
<li>掌握音标的读音</li>
</ol>
<ul>
<li><p>阶段1 元音、辅音发音PPT，反复看</p>
<blockquote>
<p>注意这些发音的技巧，记住这些发音</p>
</blockquote></li>
<li><p>阶段2 B站发音巩固：关键词（BBC发音）<a
href="https://www.bilibili.com/video/av14396376?from=search&amp;seid=16167892933239657823"
class="uri">https://www.bilibili.com/video/av14396376?from=search&amp;seid=16167892933239657823</a></p></li>
</ul>
<ol start="2" type="1">
<li>学会单词音标拼读</li>
</ol>
<blockquote>
<p>单词音标拼读可能需要的技巧：</p>
<p><a
href="https://www.bilibili.com/video/av42990246/?spm_id_from=333.788.videocard.5"
class="uri">https://www.bilibili.com/video/av42990246/?spm_id_from=333.788.videocard.5</a></p>
</blockquote>
<ol start="3" type="1">
<li><p>学习自然拼读法*</p>
<blockquote>
<p>掌握常见音的发音技巧</p>
</blockquote></li>
<li><p>使用记单词软件，记常见单词的发音</p></li>
</ol>
<h3 id="口语">2. 口语</h3>
<h4 id="笔记">笔记</h4>
<p>Task 3 - In the reading passage, the school announces(student
proposes) that ... - Because 1. first 2. second - In the coversation,
the M/W agree/disagree with ... - Because 1. first 2. second</p>
<p>Task 5 ready: 20s <br> time: 1 min - In the coversation, the M/W got
a problem..., but... There are .. - 2 possible solutions 1. she/he can,
<positive points>, <negtive points> 2. she/he can, <positive points>,
<negtive points> - I would recommend the M/W to do 1. why 1 is good, and
2 is bad.</p>
<p>Task 4 - Def - RG is ... that ... - when ...., we call it ... -
过渡句： In the lecture, the prof use .... to ... - eg/exp:</p>
<p>Task 6 - Begining: In the lecture, the prof. uses ... to .. -
subtopic1. the 1st strategy is ... for example - subtopic2. the 2nd
strategy is ... for example</p>
<h4 id="单词">单词</h4>
<p>behaviors and attitudes imtate Chinese New Year Lunar New Year</p>
<p>cousins ants uncles</p>
<p>fresh man sophmore junar senior</p>
<p>graduate</p>
<p>persvasive strategies ## 课外 考试前2星期，每隔2天一套TPO。
大脑习惯</p>
<h3 id="app">APP</h3>
<p>小但？ 托福考满分</p>
]]></content>
      <categories>
        <category>todo</category>
        <category>english</category>
      </categories>
      <tags>
        <tag>english</tag>
        <tag>todo</tag>
      </tags>
  </entry>
  <entry>
    <title>english pronuncation</title>
    <url>/2019/english-pronuncation-6323d5ac4b92/</url>
    <content><![CDATA[<p>音标复习</p>
<p><img data-src="pronuncation.jpg" /></p>
<h1 id="单元音">1. 单元音</h1>
<h2 id="section">1</h2>
<p><img data-src="listen-basic-1.png" /></p>
<table style="width:7%;">
<colgroup>
<col style="width: 6%" />
</colgroup>
<thead>
<tr class="header">
<th>## 2 <img data-src="listen-basic-2.png" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>## 3 <img data-src="listen-basic-3.png" /></td>
</tr>
</tbody>
</table>
<h2 id="section-1">4</h2>
<p><img data-src="listen-basic-4.png" /></p>
<table style="width:7%;">
<colgroup>
<col style="width: 6%" />
</colgroup>
<thead>
<tr class="header">
<th>## 5 <img data-src="listen-basic-5.png" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>## 6 <img data-src="listen-basic-6.png" /></td>
</tr>
</tbody>
</table>
<h2 id="section-2">7</h2>
<p><img data-src="listen-basic-7.png" /></p>
<h1 id="双元音">2. 双元音</h1>
<h2 id="section-3">1</h2>
<p><img data-src="listen-basic-di-1.png" /></p>
<table style="width:7%;">
<colgroup>
<col style="width: 6%" />
</colgroup>
<thead>
<tr class="header">
<th>## 2 <img data-src="listen-basic-di-2.png" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>## 3 <img data-src="listen-basic-di-3.png" /></td>
</tr>
<tr class="even">
<td># 3. 辅音1 ## 1 <img data-src="listen-basic-f-1.png" /></td>
</tr>
</tbody>
</table>
<h2 id="section-4">2</h2>
<p><img data-src="listen-basic-f-2.png" /></p>
<table style="width:7%;">
<colgroup>
<col style="width: 6%" />
</colgroup>
<thead>
<tr class="header">
<th>## 3 <img data-src="listen-basic-f-3.png" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>## 4 <img data-src="listen-basic-f-4.png" /></td>
</tr>
</tbody>
</table>
<h2 id="section-5">5</h2>
<p><img data-src="listen-basic-f-5.png" /></p>
<table style="width:7%;">
<colgroup>
<col style="width: 6%" />
</colgroup>
<thead>
<tr class="header">
<th>## 6 <img data-src="listen-basic-f-6.png" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>## 7 <img data-src="listen-basic-f-7.png" /></td>
</tr>
</tbody>
</table>
<h2 id="section-6">8</h2>
<p><img data-src="listen-basic-f-8.png" /></p>
<h1 id="辅音2">4. 辅音2</h1>
<h2 id="section-7">1</h2>
<p><img data-src="listen-basic-f2-1.png" /></p>
<table style="width:7%;">
<colgroup>
<col style="width: 6%" />
</colgroup>
<tbody>
<tr class="odd">
<td>## 2 <img data-src="listen-basic-f2-2.png" /></td>
</tr>
</tbody>
</table>
<h2 id="section-8">3</h2>
<p><img data-src="listen-basic-f2-3.png" /></p>
]]></content>
      <categories>
        <category>english</category>
        <category>pronuncation</category>
      </categories>
      <tags>
        <tag>english</tag>
        <tag>pronuncation</tag>
      </tags>
  </entry>
  <entry>
    <title>errors in c++</title>
    <url>/2019/errors-in-c-dbd4f74843ee/</url>
    <content><![CDATA[<h2 id="bugs">bugs</h2>
<ol type="1">
<li><p>Segmentation Falut 删代码法, 段错误，溢出；
就是for循环没写对的问题 深搜里面爆栈了，进入了死循环</p></li>
<li><p>Complic Error</p></li>
<li><p>Memory Limit Exceeded 内存超限 &gt; 发现是i &lt; a.size() ||
b.size() 这里的操作出错</p></li>
</ol>
<p>图论问题TLE很大的一个问题可能就是邻接表忘记初始化了memset(h),
还有一个就是无向图M双倍，不要忘了</p>
<ol start="4" type="1">
<li><p>结果是多个一模一样的值，多半是数组越界的问题。就是输入数据的问题</p></li>
<li><p>Float Point Exception 表示除0错误</p></li>
</ol>
<h2 id="其他">其他</h2>
<p>为什么用static? 防止每次调用函数时重新分配内存，效率会更高</p>
<p>https://zhuanlan.zhihu.com/p/57512786</p>
<p>如果对于邻接链表的结构出现 Time Limited 检查h[N]忘记了初始化为-1</p>
<p>如果大部分数据已经过了，1,2个数据没过，说明边界问题没处理好 ##
else</p>
<p>csp考试准备</p>
<ol type="1">
<li>编译环境准备</li>
<li>时间熟悉，考场熟悉</li>
<li>题型熟悉</li>
<li>考试资料熟悉
<ol type="1">
<li>stl, 算法</li>
<li>acwing复习课</li>
</ol></li>
</ol>
<p>重定向 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;fstream&gt; </span><br><span class="line">#include &lt;cstring&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int n, m;</span><br><span class="line">int w[10][10];</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">	ifstream in(&quot;in.txt&quot;);</span><br><span class="line">	ofstream out(&quot;out.txt&quot;);</span><br><span class="line">	streambuf *cinbuf = cin.rdbuf();</span><br><span class="line">	streambuf *coutbuf = cout.rdbuf();</span><br><span class="line">	</span><br><span class="line">	cin.rdbuf(in.rdbuf());</span><br><span class="line">	cout.rdbuf(out.rdbuf());</span><br><span class="line">	</span><br><span class="line">	cin &gt;&gt; n &gt;&gt; m;</span><br><span class="line">	</span><br><span class="line">	for (int i = 1; i &lt;= n; i ++)</span><br><span class="line">		for (int j = 1; j &lt;= m; j ++)</span><br><span class="line">			cin &gt;&gt; w[i][j];</span><br><span class="line">			</span><br><span class="line">	for (int i = 1; i &lt;= n; i ++) &#123;</span><br><span class="line">		for (int j = 1; j &lt;= m; j ++)</span><br><span class="line">			cout &lt;&lt; w[i][j] &lt;&lt; &#x27; &#x27;;</span><br><span class="line">		cout &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	cin.rdbuf(cinbuf);</span><br><span class="line">	cout.rdbuf(coutbuf);</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="c-新特性">c++ 新特性</h2>
<p>dev c++ 5.4.0</p>
<p>tools -&gt; complier options -&gt; add following commands when
calling the complier: -std=c++11</p>
<p>新特性 for (auto x: nums) cout &lt;&lt; x &lt;&lt; endl;</p>
<p>设置autosave</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">str常见操作</span><br><span class="line"></span><br><span class="line">string -&gt; char[]</span><br><span class="line">char *c;</span><br><span class="line">string s = &quot;1234&quot;;</span><br><span class="line">c = s.c_str(); // c_str()返回的是指针</span><br><span class="line"></span><br><span class="line">char c[20];</span><br><span class="line">string s &quot;1234&quot;;</span><br><span class="line">strcpy(c, s.c_str());</span><br><span class="line"></span><br><span class="line">char[] -&gt; str</span><br><span class="line">char b[8]=&#123;&#x27;a&#x27;, &#x27;b&#x27;&#125;;</span><br><span class="line">string str(b); //()一般是初始化</span><br><span class="line"></span><br><span class="line">str += substr</span><br></pre></td></tr></table></figure>
<p>注意除了，初始化不能进行{}赋值</p>
<p>c++: replace(start_pos, len, replace_str) // 指定长度
replce(line.beigin(), line.begin()+6, replace_str); //
迭代器从开始到结束</p>
<p>特别地，需要注意关于字符串这部分的内容</p>
<p>思考下stdlib.h下有没有好用的一些东西 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int atoi(const char *str) 将字符串转换为整数</span><br><span class="line">double atof(const char *str)</span><br></pre></td></tr></table></figure></p>
<p>刷题经常用的库 algorithm - swap, sort, count(f,f+n,value),
reverse()</p>
<p>cstring stoi, stof</p>
<p>int.to_string</p>
]]></content>
  </entry>
  <entry>
    <title>gnn-parallel-gnn-overview-paper-summary</title>
    <url>/2019/gnn-gnn-parallel-gnn-overview-paper-summary-163378634a76/</url>
    <content><![CDATA[<p>[TOC] # 1. 序言 图有着复杂的关系和交互依赖</p>
<p>2D卷积: 邻居的决定由filter size w = 平均，
邻居有序，可以按照一定的序列来看且有固定的尺寸</p>
<p>Graph卷积： 邻居无序，价值等同，数量不一</p>
<p>Random Walk??? 随机游走，有概率计算方法还有要理解？</p>
<p>图网络表示： 1. 编码 2. 随机游走 3. 矩阵因式分解</p>
<h1 id="框架">2. 框架</h1>
<p>Node-level: MLP+softmax: 见pooling结构 Edge-level:
额外的函数将两个节点的表示作为边 Graph-level: 就是pooling</p>
<p>半监督: 只能适用于node-level 监督学习: 适用于graph-level 无监督：
graph-embedding &gt; 编码器+译码器 负采样</p>
<h1 id="正文">3. 正文</h1>
<h2 id="gcn">3.1 GCN:</h2>
<p>? stack多层可以学到更多的东西. 对！注意这里的输入是整个图
如果堆叠多层的话，实际上就可以不断的获得更远的信息</p>
<p>basic &gt; 这里每个的输出应该不会只是一个值吧？？ Relu修正线性函数：
当大于x时为本身，小于x时为0</p>
<p><font color="red">ReLU</font>
ReLU可以将模型实现稀疏话更好地挖掘相关特征
就激活函数而言，在深度网络中，由于非负区间的梯度为常数，所以不存在梯度消失问题，使得模型的收敛速度维持在一个稳定状态。
https://blog.csdn.net/cherrylvlei/article/details/53149381</p>
<p>pooling</p>
<p>一个图经过GCN加pooling得到一个子图，然后给下一个模型。如此最后不断地得到更高级别的表示，最后一层是MLP
+ softmax</p>
<p><font color="red">MLP</font> MLP: 多层感知机 vs 支持向量机 SVM &gt;
多层感知机其实就是多层网络结构，但是一般是向前的，不会有后退的，然后关键就是设定一个偏差评价函数，以及某种策略，当出现错误时可以向后调节参数</p>
<p><font color="red">softmax</font>
softmax函数：逻辑函数的推广，归一化指数函数。</p>
<p><span class="math display">\[\delta(z)_j = \frac
{e^{z_j}}{\sum_{k=1}^K e^{z_k}}\]</span></p>
<blockquote>
<p>将任何一个元素都压缩到了指数域，并满足归一化,并且保证了归一化结果在[0,1]之间
将原数压缩为指数来做有什么感觉</p>
</blockquote>
<p><font color="red">sigmoid</font> sigmoid函数，数学表达式 <span
class="math display">\[f(x) = \frac {1}{1 + e^{-x}}\]</span>
优点：可以把任何值映射到[0,1]之间；导数的计算公式方便<span
class="math inline">\(f&#39;(x) = f(x) (1-f(x))\)</span>
https://blog.csdn.net/saltriver/article/details/57531963</p>
<p>扩展：<a
href="https://blog.csdn.net/saltriver/article/details/55105285">指数分布族</a>
### 3.1.1 spectral-based</p>
<p>spectral CNN: 直接将filter设置为了参数 ChebySheve:
重新改进了公式，定义了filter的计算，并使得公式的更新的复杂度降低，而且只需要用到空间中的局部信息
1阶：沟通两类, 在batch-learning时会指数级增加开销 AGCN:
扩展了Laplacian矩阵的适用范围，为每个图重定义了一个剩余矩阵，即完成有向图到无向图的转换</p>
<blockquote>
<p>所以这里的黑盒实际上就是数学表达式计算</p>
</blockquote>
<p>原本2D卷积是filter设置的是尺寸，而这里的filter有什么含义呢？ &gt;
就是从信号的角度，过滤得程度吧？？</p>
<p>所以说这里的GCN是有很多参数，然后反馈参数修正是当end时再来修正参数，对吗?</p>
<p>filter为什么是domin dependent,
比如两个不同的domin,人和物品，显然感觉不能吧</p>
<h3 id="spatial-based">3.1.2 spatial-based</h3>
<p>GNNs,GRU, SSE MMNN, GraphSage</p>
<p>recurrent GCN全一样 composition GCN全不一样</p>
<h4 id="recurrent">1) recurrent</h4>
<p>GNNs:
每个GCN考虑当前节点的属性，相关边的属性，邻居在上一步的表示，邻居的属性
GRU: 每个GCN将上一步的状态和邻居节点当前的状态放在GNU中进行考虑 SSE：
每个GCN,
随机地选取t个节点，进行更新表示然后随机第选取P个已经更新？的节点来更新梯度</p>
<ol type="1">
<li>GNNs
全是用的一个把所有因素都进行考虑的函数，唯一的点就是要保证这个函数收敛
循环神经网络</li>
<li>GRU 门控神经网络：
循环神经网络在时间步数较大或时间步数较小时，循环神经网络的梯度会衰减和爆炸</li>
</ol>
<p><font color="red">RNN</font> 循环神经网络 RNN
神经网络可以看作任意函数的黑盒子，目的是为了解决时序数据中存在的对应关系。
中间因为出现循环，所以某个状态会对应T步，但是还是基本的权重更新公式 &gt;
这里待推导！！！ &gt; 所以这里有个时间t原来是这么回事 &gt;
这里的时间步数就是关联程度的感觉
https://zhuanlan.zhihu.com/p/30844905</p>
<p>https://zybuluo.com/hanbingtao/note/541458</p>
<p><font color="red">GRU</font>
实际上的感觉就是认为RNN那样直接进行步长来更新（因为该步也要考自己来设置），这样可能导致问题，衰减或爆炸，所以这里的想法就是加入了门控，即在中间可以根据隐藏状态和当前出现的值来决定是否进一步计算还是改变当前值进行另一种计算。
https://zh.d2l.ai/chapter_recurrent-neural-networks/gru.html</p>
<ol start="3" type="1">
<li>SSE</li>
</ol>
<p>随机异步更新节点的表示，考虑历史状态和所有新状态 &gt; 神奇？
暂未涉猎， 直觉上会收敛</p>
<blockquote>
<p>这里统一的<span
class="math inline">\(h_v^t\)</span>是指v在第t个GCN所得到的值，注意这里的t是全局所设置的网络结构</p>
</blockquote>
<h4 id="composition-based">2) Composition Based</h4>
<p>MPNN： 每一步的GCN综合上一步的信息和邻居节点的更新操作集合的信息
GraphSage: one
batch在线学习的特点，根据域，聚集当前的邻居信息，使一个点成为最终状态；然后，为每个邻居进行更新；最后，知道所有的节点都成为了最终状态</p>
<ul>
<li>MPNN</li>
</ul>
<p>message passing: 信息函数，信息更新函数
这里的信息函数考虑到了上一步的信息，和关于邻居节点的所有更新操作
更新函数考虑到了自己的上一步的表示，邻居节点的表示和边的权重 readout
关于最后的值的读取函数</p>
<ul>
<li>GraphSage
看公式的话是每个位置有个权重，并且将上一次的点的状态和邻居节点的状态进行了考虑。</li>
</ul>
<p>过程？？ 不是很清楚？ 一种观点：</p>
<p>这里的节点是怎么选取的？ &gt;
它说的是保证各种聚集参数是对的，但是并未说其他的啊？？</p>
<p>首先对一个节点进行更新，然后根据邻居节点产生该节点的状态，然后使用中间节点的最终状态来预测和反馈错误。</p>
<p>也就是说先考虑一个点，然后传递错误到其他点，但是我会进行标记这个点已经不可再取。
而且当新的数据来临时，也可以采用直接训练的想法</p>
<h4 id="杂项">3) 杂项</h4>
<p>DCNN(缩小图的转移举证) PATCHY-SAN(先全局排序，CNN)
LGCN(得到邻接节点的特征矩阵处理排序后，CNN+子图搜索)
MMN(建议考虑边的权重，使用高斯核来学习)</p>
<ul>
<li>DCNN
模拟压缩图的扩散过程，所以这里除了权重，函数f应该具有缩小尺寸的功能
但是需要存储转移矩阵，耗费内存</li>
<li>PATCHY-SAN
先将节点排序，然后后面的所有做法就是选取特定的值，然后使用标准的CNN来做</li>
<li>LGCN * node level
在每次做的时候，对特征矩阵进行分析，选取特征矩阵的前多少行来做。
子图训练</li>
<li>MMN
*考虑了空间位置关系，即便的权重，建议使用标准的高斯核来学习参数调节边的权重
&gt; 绝大部分采用CNN,也有用GCN的</li>
</ul>
<h3 id="总结">3.1.3 总结</h3>
<p>recurrent 节点的稳定状态 composition 可能获得高级别的信息</p>
<p>但是要放隐藏状态，内存</p>
<p>子图训练： GraphSage确定一个的最终状态先,SSE完全随机的思想</p>
<p>复杂的网络结构取得成果 1. 增加深度和宽度 2. 多图维护信息 3.
超参数学习接收域的大小</p>
<h3 id="池化">3.1.4 池化</h3>
<p>chebNet首先进行池化，使得一开始的结构得到了改进，进一步取得了更好的效果
DGCNN 池化进行预处理排序 DIFFPOOL 使用两个GCN, 一个embed, 一个pool,
用来整合异质的GCN。</p>
<p>基于空间的在效率上可以使用batch和smapling提高效率，在泛化性上可以共享权重;在灵活性上，可以处理多源输入
## 3.2 GAN</p>
<ul>
<li><p>GAT 就是考虑所有邻居节点的表示和考虑邻居节点的权重 &gt;
不同的子空间是指的，随着当前所处的不同位置，可能得到的数据不同，所以就把所有子空间的邻居节点的位置堆叠吗。感觉是这样的
&gt; 这里的子空间也可以看做是某个模型</p></li>
<li><p>GAAN 在聚集不同子空间中的信息时，考虑不同的权重</p></li>
<li><p>GAM
不考虑所有的情况，考虑其中一段一段的状态，因为LSTM非常好用，就用它</p></li>
<li><p>AW 目标是node embedding,
即为了学习转移矩阵。操作的想法是，构造转移矩阵，并且当前的共现矩阵为所有转移矩阵之和的某种表示
&gt; ? 如何体现，应该是转移矩阵的参数体现吧</p></li>
</ul>
<p><strong>总结</strong></p>
<ul>
<li>注意力为邻居赋予权重</li>
<li>整合多个模型</li>
<li>指导random walks</li>
</ul>
<p>GCN每个聚集时，直接按照某种特定的属性进行聚集 GAN:
首先会通过一个神经网络结构来获得权重指派，等于说多加了一层网络结构</p>
<h2 id="gae">3.3 GAE</h2>
<p>编码：得到最终的编码结果</p>
<p>GAE: GCNs, 评价调节 AGRA: GCN产生，GAN训练 NetRA: 序列到序列，random
walks DNGR: 堆叠矩阵+噪声，基于统计数据 SDNE:
使用指标，评价邻居，评价结果，正则化项 DRNE: 重建节点，LSTM聚集函数</p>
<ul>
<li><p>GAE GCNs, 然后定义评价函数</p></li>
<li><p>AGRA GCN产生，GAN评价,
产生时服从某一先验分布，评价时选出服从分布的</p></li>
<li><p>混合变体</p>
<ul>
<li>NetRA: 通过序列到序列结构的random walks来重建序列</li>
<li>DNGR:
用堆叠的降噪的自动编码器来重建矩阵。具体做法是通过统计同时出现的数量与单独出现数量的比值的最大值来决定最终的共现矩阵的值。因为是直接根据数据特性来统计，所以所学得的东西应该是非线性的。另外一点就是，在做的时候随机增加了噪声</li>
<li>SDNE:
使用了两个指标，一个是隐藏节点表示与邻居节点隐藏表示之间的距离；一个是节点的输入与重新构造之间的距离（这里考虑了惩罚项）；最后，优化目标即为三个项+正则化项</li>
<li>DRNE:
直接考虑重建节点，设置损失函数，定义为所有邻居节点表示值与聚集函数(LSTM)的差</li>
</ul></li>
</ul>
<p>DNGR+SDNE：仅考虑拓扑结构 邻接矩阵的稀疏性： GAE: 重新赋予权重；
NetRA线性化；DNGR密集矩阵; SDNE: 惩罚</p>
<p>A+X经过Encoder, 再经过GCN,
得到一种简单的表示，然后经过非线性激活函数？
就可以由decoder重构出邻接举证吗？ &gt;
这前后是不是应该有严格的数学来做？加一层GCN，训练得到的参数是否还满足性质</p>
<h2 id="ggn">3.4 GGN</h2>
<p>重新生成图</p>
<ul>
<li><p>MolGAN
分布-&gt;Generator-&gt;密集邻接矩阵tensor(张量)-&gt;sample产生Graph-&gt;
GCN-&gt; Disciminator产生反馈和进行调节 &gt;
需要预知分布，共同产生边和节点</p></li>
<li><p>DGMG
采用加点和边的方式，有一个停止的标准；当decision为假时，加边；为真时，评估将加入的节点连接到已存在的节点的可能分布，然后随机选择一个点。当一个新的节点和它的连接都被加入图中，更新图的表示。
&gt; 需要预知分布，采用序列化的方式来做 &gt;
图的表示用来计算前面的decision,
所以该方法又称为根据图的表示产生图的节点和边</p></li>
<li><p>杂项</p>
<ul>
<li>GraphRNN
两个RNN，对于graph和level，操作在二进制序列上。如何添加根据假设分布来做。对于graph为了训练，用BFS线性化为序列
&gt; 采用序列化的方式来做，利用了统计数据？</li>
<li>NetGAN 产生器LSTM产生合理的random walks,
测试器GAN挑选，最后获得共现矩阵 &gt; 利用统计数据？
同时产生节点和边</li>
</ul></li>
</ul>
<p>序列化的方式在于，长序列会带来问题？？ 其他方式维护全局属性难
最近的采用变化的自动编码器做，增加输出空间
没有方法有很好的大规模可扩展性</p>
<p>产生+训练</p>
<h2 id="gsn">3.5 GSN</h2>
<p>DCRNN能处理长时间 CNN-GCN有效取决于1DCNN
ST-CNN考虑瞬时流作为节点的边，导致邻接矩阵平方增长，会导致计算图卷积层的开销增大，但是要堆叠很多次
Strutural-RNN需要先验知识来分割语义组</p>
<p>空间+瞬时</p>
<h1 id="其他">4. 其他</h1>
<h2 id="建议">4.1 建议</h2>
<p>go deep 感受野 扩展性： 什么时候具有扩展性？？
快采样（在线算法）和子图训练。不够
动力学和异质性：图的结构固定，节点和边不一定来源相同 ## 4.2 batch
learning vs stochastic learning</p>
<p>batch learning: 批量学习，是一种离线的学习方法 &gt;
离线学习，输入数据时不处理数据；训练数据时才处理数据 &gt;
总是全局最优的，但是耗时</p>
<p>stochastic learning: 随机学习，在线学习 &gt;
每输入一种数据都进行修正，这里默认的单位为1，即有一个样本时就进行修正
&gt;
那么问题的关键就在于这个样本是否有问题，即该模型就容易搜到噪声的影响，有问题的数据称为噪声；
但也有好处，能够节省时间。 &gt; 易陷入局部最优</p>
<p>深度网络的实现中都采用了两种方法的结合，即每次训练使用10个或者别的合适数目的样本，即可以稍微消除噪声的影响，又可以进行在线学习</p>
<p>https://blog.csdn.net/Buyi_Shizi/article/details/51454549</p>
<h2 id="无结构化数据-vs-结构化数据">4.3 无结构化数据 vs 结构化数据</h2>
<p>结构化数据即数据能够用二维表结构来逻辑表达实现的数据，通常每行和每列都有具体的含义</p>
<p>无结构数据即不能用数据二维逻辑来表现的数据，比如所有格式的办公文档、文本、图片、HTML等等</p>
<p>无结构化数据更难被计算机理解</p>
<p>https://zhuanlan.zhihu.com/p/29856645</p>
<h2 id="dropout">4.4 dropout</h2>
<p>为了解决过拟合现象，也就是用小数据集训练过于复杂的网络
训练深度神经网络，总会遇到两大问题：过拟合+费时，一定程度可以达到正则化的效果。</p>
<p>dropout就是在训练深度神经网络中，每次训练中，忽略一半的特征检测器（让一半的隐层节点值为0），这样可以明显地减少过拟合现象。</p>
<p>简单地说就是让某个神经元以一定的概率停止工作
https://zhuanlan.zhihu.com/p/38200980</p>
<h2 id="cross-entropy-loss">4.5 cross entropy loss</h2>
<p>回归问题常用的损失函数是均方误差MSE 分类问题常用的损失函数是交叉熵
&gt; 描述了两个概率分布之间的距离 &gt;
预测函数得出的结果应该是分为每一类的概率</p>
<p>在得到概率之前，softmax函数经常在交叉熵前面，用于把结果处理为[0,1]之间的概率</p>
<p>首先，如果用实际分类错误率来做，太粗略 为什么不用MSE？因为softmax +
MSE会产生非凸函数，不具有好的性质。 &gt; 这里自己可以进行分析</p>
<p>所以最终用的是交叉熵，softmax+交叉熵会产生凸函数，结果具有凸函数的性质。
&gt; 损失函数也会参与反馈传递误差的过程吗？</p>
<p><span class="math display">\[H_y(y) = - \sum_i y&#39;_i
log(y_i)\]</span> 为什么回归问题不用交叉熵?
因为<code>log-1.5</code>没有意义。 &gt;
MSE是在欧式距离为误差度量的情况下，由系数矩阵所张成的向量空间内对于观测向量的最佳逼近点</p>
<p>结论： traning中需要用最反映实际情况的，即分类问题用交叉熵 &gt;
交叉熵用在training这里是体现训练误差的，损失函数的设置是用来指导如何进行梯度下降的。</p>
<p>validation/testing中，关注的就是分类的错误率，所以用分类错误率即可。</p>
<p>https://blog.csdn.net/xg123321123/article/details/80781611</p>
<p>https://www.cnblogs.com/pinard/p/5970503.html</p>
<h1 id="简要">5. 简要</h1>
<h2 id="gcns">5.1. GCNS</h2>
<h3 id="spectral-based">5.1.1 spectral-based</h3>
<p>spectral CNN: 直接将filter设置为了参数 ChebySheve:
重新改进了公式，定义了filter的计算，并使得公式的更新的复杂度降低，而且只需要用到空间中的局部信息
1阶：沟通两类, 在batch-learning时会指数级增加开销 AGCN:
扩展了Laplacian矩阵的适用范围，为每个图重定义了一个剩余矩阵，即完成有向图到无向图的转换</p>
<h3 id="spatial-based-1">5.1.2 spatial-based</h3>
<ul>
<li><p>recurrent GNNs:
每个GCN考虑当前节点的属性，相关边的属性，邻居在上一步的表示，邻居的属性
GRU: 每个GCN将上一步的状态和邻居节点当前的状态放在GNU中进行考虑 SSE：
每个GCN,
随机地选取t个节点，进行更新表示然后随机地选取P个已经更新？的节点来更新梯度</p></li>
<li><p>Composition Based MPNN：
每一步的GCN综合上一步的信息和邻居节点的更新操作集合的信息 GraphSage: one
batch在线学习的特点，根据域，聚集当前的邻居信息，使一个点成为最终状态；然后，为每个邻居进行更新；最后，知道所有的节点都成为了最终状态</p></li>
<li><p>杂项 DCNN(缩小图的转移举证) PATCHY-SAN(先全局排序，CNN)
LGCN(得到邻接节点的特征矩阵处理排序后，CNN+子图搜索)
MMN(建议考虑边的权重，使用高斯核来学习)</p></li>
</ul>
<h3 id="池化-1">5.1.3 池化</h3>
<p>chebNet首先进行池化，使得一开始的结构得到了改进，进一步取得了更好的效果
DGCNN 池化进行预处理排序 DIFFPOOL 使用两个GCN, 一个embed, 一个pool,
用来整合异质的GCN。</p>
<h2 id="gan">5.2. GAN</h2>
<p>GAT:
考虑邻居及诶点的表示和邻居节点的权重。并且考虑子空间，不过每个子空间都是相同的权重
GAAN: 不同的权重 GAM: 考虑用的因素不再全部，而是一段一段 AM: 目标是node
embedding, 直接学习转移矩阵，由注意力指导random walks</p>
<h2 id="gae-1">5.3. GAE</h2>
<p>GAE: GCNs, 评价调节 AGRA: GCN产生，GAN训练 NetRA: 序列到序列，random
walks DNGR: 堆叠矩阵+噪声，基于统计数据, 统计出来的结果 SDNE:
使用指标，评价邻居，评价结果，正则化项 DRNE: 重建节点，LSTM聚集函数</p>
<h2 id="ggn-1">5.4. GGN</h2>
<p>MolGAN: 基于分布 ，产生图和点，然后产生Graph,GCN,再调节 DGMG:
获得一个图的表示后，做一个决定，根据决定来加边，或从分布中加点,操作在序列上
GraphRNN: 两个RNN, 一个graph训练，一个edge由分布来做 NetGAN:
LSTM产生合理的random walks, 测试器筛选，最终获得共现矩阵</p>
<h2 id="gsn-1">5.5. GSN</h2>
<p>DCRNN: 出度入度-空， DCGRU-瞬时 CNN-GNN: GCN空间，1DCNN-瞬时 ST-CNN:
瞬时流作为边，同时考虑。用邻接举证距离的和作为最终接地那的值
Strutual-RNN: 语义组，GCN瞬时；nodeRNN接edgeRNN输出空间</p>
]]></content>
      <categories>
        <category>gnn-parallel</category>
        <category>gnn</category>
      </categories>
      <tags>
        <tag>gnn-parallel</tag>
        <tag>gnn</tag>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>git using</title>
    <url>/2019/git-using-4af7f078a057/</url>
    <content><![CDATA[<p>更全面的请参考
http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html</p>
<h2 id="绪论">绪论</h2>
<p>Workspace：工作区 Index / Stage：暂存区 add
Repository：仓库区（或本地仓库） commit/fetch Remote：远程仓库</p>
<p>git reflog 查看当前分支的最近几次提交 git log
查看所有commit的记录</p>
<h2 id="开始git之旅">开始git之旅</h2>
<ol type="1">
<li>github上新建reposity，假设仓库名为Inbox</li>
<li>本地化
<ul>
<li>配置 <br> git config --global user.name "yourname" <br> git config
--global user.email "youremail" <br> <font color='red'>git config
--global core.editor vim</font> <br> &gt;
这一点很重要，可以摆出Git自带的愚蠢的GNO的困扰</li>
<li>两种方式
<ul>
<li>git init <br>
<ul>
<li>git remote add origin <code>http://website://repo.git</code> <br>
&gt; https://github.com/AugF/DesignPatterns.git</li>
<li>git push -u origin master</li>
<li>git push origin master -f</li>
</ul></li>
<li>git clone <code>http://website://repo.git</code> ## 多人开发思路：
git branch查看分支</li>
</ul></li>
</ul></li>
</ol>
<p>git checkout -b fpm， 创建分支并转到分支 git checkout -d fpm,
删除分支</p>
<p>所有的修改操作都在fpm分支上 master负责merge远程分支</p>
<ol type="1">
<li>希望master分支更新fpm分支上的内容
<ul>
<li>git checkout master</li>
<li>git merge fpm</li>
<li>git branch 查看分支</li>
<li><blockquote>
<p>fpm 分支并不会消失</p>
</blockquote></li>
</ul></li>
<li>希望fpm更新到master分支上的内容
<ul>
<li>git checkout fpm</li>
<li>git rebase master</li>
</ul></li>
<li>希望能够显示本地分支的情况</li>
<li>merge前和push前需要检查本地内容有没有提交，请注意一件事就是先提交</li>
<li>更新本地分支
<ul>
<li>git pull注意不过不带参数是直接覆盖</li>
<li>git pull origin next:master
取回origin主机的next分支与本地的master分支合并 !!! &gt; 或者git pull
origin master &gt; 一种思路可以将代码全部拉到本地某个分支 &gt; git fetch
origin + git merge origin/next</li>
<li>git branch --set-upstream master origin/next
自动为本地master追踪分支</li>
</ul></li>
<li>远程分支操作
<ul>
<li>查看远程分支： git branch -r</li>
<li>创建运程分支： git push origin [name]</li>
<li>删除远程分支： git push origin :[name]</li>
</ul></li>
</ol>
<h2 id="对别人的项目做贡献">对别人的项目做贡献</h2>
<ol type="1">
<li>非Collaborators
<ul>
<li>git remote add upstream</li>
<li>git fetch upstream</li>
<li>git merge upstream/master</li>
</ul></li>
</ol>
<h2 id="对远程仓库名进行查看">对远程仓库名进行查看</h2>
<ol type="1">
<li>git remote show <code>&lt;主机名&gt;</code> :
查看远程主机，不包含地址</li>
<li>git remote add <code>&lt;主机名&gt;</code>: 添加远程主机</li>
<li>git remote rm <code>&lt;主机名&gt;</code>: 删除远程主机</li>
<li>git remote rename <code>&lt;主机名&gt;</code>: 改名</li>
<li>git remote -v: 连带查看地址 ## 标签 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 列出所有tag</span><br><span class="line">$ git tag</span><br><span class="line"></span><br><span class="line"># 新建一个tag在当前commit</span><br><span class="line">$ git tag [tag]</span><br><span class="line"></span><br><span class="line"># 删除本地tag</span><br><span class="line">$ git tag -d [tag]</span><br><span class="line"></span><br><span class="line"># 查看tag信息</span><br><span class="line">$ git show [tag]</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="常见错误">常见错误</h2>
<ol type="1">
<li><p>You have not concluded your merge (MERGE_HEAD exists). Exiting
because of unfinished merge 之前的提交没有merge &gt; git reset
--merge</p></li>
<li><p>无法推送一些引用到 'https://github.com/wangyunpan/nlp-zh-NER.git'
&gt; git pull &gt; git push</p></li>
<li><p>报错 fatal: 远程 origin 已经存在。 &gt; git remote rm origin
删除远程分支</p></li>
<li><p>如果我本地一顿猛操作，然后需要更新文件，然后应该怎么办？
不能直接git pull, 再git push, 这样会覆盖本地的文件？？</p></li>
<li><p>! [rejected] master -&gt; master (non-fast-forward) error: failed
to push some refs to 'https://github.com/AugF/DesignPatterns.git' hint:
Updates were rejected because the tip of your current branch is behind
&gt; git push origin master -f</p></li>
<li><p>OpenSSL: error:1409442E:SSL routines:ssl3_read_bytes:tlsv1 alert
protocol version &gt; 向pasa gitbucket提交出现该bug &gt;
按照stackoverflow上
https://stackoverflow.com/questions/53151456/openssl-error1409442essl-routinesssl3-read-bytestlsv1-alert-protocol-versio
&gt; 修改 wget --secure-protocol=TLSv1_2 仍然未解决</p></li>
<li><p>如何强制将远程代码覆盖到本地 &gt; git pull
并没有得到远程最新的代码 &gt; 使用 git fetch --all &amp;&amp; git reset
--hard origin/master &amp;&amp; git pull 强制覆盖本地代码</p>
<ul>
<li>git branch --set-upstream-to=origin/master branch</li>
<li>git pull 远程主机名 远程分支名:本地分支名</li>
</ul></li>
<li><p>如何将现有代码分支push到远程指定分支 &gt; git push --set-upstream
origin current_branch</p></li>
<li><p>fatal: protocal 'https' is not supported &gt; 1. use ssh &gt; 2.
在git安装目录中找到libcurl-4.dll的文件位置，并移动到其他地方</p></li>
<li><p>error: Your local changes to the following files would be
overwritten by merge: graph/images/GRU_dot.png</p></li>
</ol>
]]></content>
      <categories>
        <category>tools</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel-AliGraph-paper-read</title>
    <url>/2019/gnn-parallel-AliGraph-paper-read-785c163859e1/</url>
    <content><![CDATA[<h2 id="引用论文列表">引用论文列表</h2>
]]></content>
      <categories>
        <category>gnn</category>
      </categories>
      <tags>
        <tag>gnn</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel-GRU</title>
    <url>/2019/gnn-parallel-GRU-9a9ca13e91f9/</url>
    <content><![CDATA[<p>2015 ## 1. Abstract 机器翻译。 encoder + decoder encoder: a
fixed-lenght representation decoder: a correct translation from this
representation</p>
<p>RNN Encoder-Decoder gated recusive rconvolutional neural network</p>
<p>the neural machine translation performs relatively well on short
sentences without unknown words. but degrades rapidly as the lengthe of
the sentence and the number of unknown words.</p>
<p>gated recursive convolutional networks learns a grammatical
struture</p>
<h2 id="introduction">2. Introduction</h2>
<p>SMT仅仅记忆一小部分内容 GRU可以记忆500MB内容</p>
<p>没有工作来分析这些模型的属性以及表现</p>
<p>understand the properties and behavior</p>
<p>grConv is able to learn, without supervision, a kind of syntactic
struture over the sourece language. &gt; rnn, cnn paper</p>
<p>不懂概率的形式 &gt; K是class labels 数量</p>
<p>p(x): joint distribution</p>
<hr />
<p>以上抛弃</p>
<p>Learning Phrase Representations using RNN Encoder–Decoder for
Statistical Machine Translation</p>
<p>其实所谓的概率模型<span class="math inline">\(p(x_1, x_2, ...,
x_n)\)</span>，
其实是链式法则，直接看最后一层即可，这也就是RNN实际的含义。</p>
<p>RNN其实的目标是 maximize the conditional log-likelihood.</p>
<hr />
<p>LSTM</p>
<ol type="1">
<li>the problem, with conventional "Back-Propagation Through TIme).
<ul>
<li>blow up</li>
<li>vanish</li>
</ul></li>
</ol>
<p>直接已经有的知识那么用</p>
<p>为什么RNN不能记忆知识？ 反向传播时，&lt;1.0的数引起梯度消失，
&gt;1.0的数引起梯度爆炸</p>
<p>LSTM: 输入、忘记、输出</p>
<p>主线剧情由输入分线进行控制</p>
<p>输入的内容会写入主线，然后忘记的内容会影响到输入的内容</p>
<p>RNN到底是什么？</p>
<p>network对于sequence序列问题解决的很好 上一个状态和当前状态</p>
<p>lstm使得其中cell的运算变得复杂</p>
<p>https://www.youtube.com/watch?v=EC3SvfW0Z_A</p>
<p>https://blog.csdn.net/FlyingLittlePig/article/details/72229041 &gt;
非常好，有代码实现部分</p>
<p>https://www.yunaitong.cn/understanding-lstm-networks.html &gt;
这篇也有意思</p>
<p>https://www.youtube.com/watch?v=8HyCNIVRbSU &gt; 好像有乘积符号</p>
<blockquote>
<p>传统RNN: <span class="math display">\[h = tanh(W_x \cdot x_t + W_h
\cdot h_{t-1} + b)\]</span></p>
</blockquote>
<blockquote>
<p>LSTM: 1. forget gate layer <span class="math inline">\(f_t =
\delta(W_i \cdot [h_{t-1}, x_t] + b_i)\)</span> 2. input gate layer $
i_t = (W_i + b_i) $ $ = tanh(W_C + b_C) $ 3. the current state $ C_t =
f_t C_{t-1} + i_t $ &gt; <span class="math inline">\(f_t,
i_t\)</span>分别表示forget gate的权重， input gate所占的权重 &gt;
根据维度进行猜想，那么这里实际上就不是元素的乘法了？？？ 4. output layer
$ o_t = (W_o + b_o)$ $ h_t = o_t tanh(C_t)$ 5. predict $ y_t =
softmax(W_y h_t + b_t）$</p>
</blockquote>
<blockquote>
<p>GRU: <span class="math inline">\(z_t = \delta (W_z \cdot [h_{t-1},
x_t])\)</span> <span class="math inline">\(r_t = \delta(W_r \cdot
[h_{t-1}, x_t])\)</span> <span class="math inline">\(\tilde{h}_t =
tanh(W \cdot [r_t \odot h_{t-1}, x_t])\)</span> <span
class="math inline">\(h_t = (1-z_t) \odot h_{t-1} + z_t \odot
\tilde{h}_t\)</span> &gt; LSTM的变体，主要的改变在于， forget gate <span
class="math inline">\(f_t\)</span>和input gate <span
class="math inline">\(i_t\)</span>用了一个update gate <span
class="math inline">\(z_t\)</span>来替代. &gt; 然后， current
state的变化再加了一层， <span class="math inline">\(\tilde{h}_t = tanh(W
\cdot [r_t \odot h_{t-1}, x_t])\)</span>, 这里引入了一个<span
class="math inline">\(r_t\)</span>叫做reset gate. &gt;
其次就是没有了output layer层，直接输出 计算开销更小</p>
</blockquote>
<blockquote>
<p>参考 1. https://zhuanlan.zhihu.com/p/32481747 2.
https://www.yunaitong.cn/understanding-lstm-networks.html 3.
https://blog.csdn.net/FlyingLittlePig/article/details/72229041 4.
https://www.youtube.com/watch?v=EC3SvfW0Z_A</p>
</blockquote>
<p>GGNN propgagation model</p>
<ol type="1">
<li><p>初始化 <span class="math inline">\(h_v^{(1)} = [x_v^T,
0]^T\)</span></p></li>
<li><p>图操作 <span class="math inline">\(a_v^{(t)}= A_{v:}^T
[h_1^{(t-1)T} ... h_{|V|}^{(t-1)T}]^T + b\)</span></p></li>
<li><p>GRU <span class="math inline">\(z_v^t = \delta (W^z a_v^{(t)} +
U^z h_v^{(t-1)})\)</span> <span class="math inline">\(r_v^t = \delta
(W^r a_v^{(t)} + U^r h_v^{(t-1)})\)</span> <span
class="math inline">\(\hat{h}_v^{(t)} = tanh(W a_v^{(t)} + U (r_v^t
\odot h_v^{(t-1)}))\)</span> <span class="math inline">\(h_v^{(t)} = (1
- z_v^t) \odot h_v^{(t-1)} + z_v^t \odot
\hat{h}_v^{(t)}\)</span></p></li>
</ol>
<h2 id="new">new</h2>
<ol type="1">
<li>初始化 <span class="math inline">\(H^{(0)} = [X_v, P]\)</span> <span
class="math inline">\(A_v = [A_{in}, A_{out}]\)</span> <br></li>
<li>图操作 <span class="math inline">\(T^{(t-1)} = A_v (H^{(t-1)}
W^{A})\)</span> <br></li>
<li>节点操作 $H^{(t)} = $ <font color='red'><span
class="math inline">\(\delta(T^{(t-1)}W^{z_a})\)</span></font> <span
class="math inline">\(\odot\)</span> <font color='red'><span
class="math inline">\(tanh(T^{(t-1)}W_{h_a})\)</span></font> $ + $
<font color='red'><span
class="math inline">\(\delta(T^{(t-1)}W^{z_a})\)</span></font> <span
class="math inline">\(\odot\)</span> <font color='red'><span
class="math inline">\(tanh\{\delta[(T^{t-1)}W^{r_a} \odot
H^{(t-1)})W^h]\}\)</span></font><span class="math inline">\(+\)</span>
<font color='red'>$ (T<sup>{(t-1)}W</sup>{z_a})$</font> $  tanh{+
H^{(t-1)}} + $ <font color='red'>$
tanh(T<sup>{(t-1)}W</sup>{h_a})$</font> $  (H<sup>{t-1}W</sup>{z_h}) + $
<font color='red'>$tanh{} $</font> $ (H<sup>{(t-1)}W</sup>{z_a}) +\
(H<sup>{(t-1)}W</sup>{z_h}) tanh{- H^{(t-1)} } + H^{(t-1)}$</li>
</ol>
]]></content>
      <categories>
        <category>gnn</category>
      </categories>
      <tags>
        <tag>gnn</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel-NeuGraph-paper-read</title>
    <url>/2019/gnn-parallel-NeuGraph-paper-read-b5cd69a0bf99/</url>
    <content><![CDATA[<p>NeuGraph: Parallel Deep Neural Network Computation on Large
Graphs</p>
<p>深度学习四大框架</p>
<p>tensorflow keras pytorch caffee2 mxnet cntk</p>
<p>deep graph library</p>
]]></content>
      <categories>
        <category>gnn-parallel</category>
      </categories>
      <tags>
        <tag>gnn-parallel</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel-ggsnn-code-read</title>
    <url>/2019/gnn-parallel-ggsnn-code-read-41f35521ee50/</url>
    <content><![CDATA[<h2 id="torch-lua">1. torch lua</h2>
<p>th test.lua to test all the modules in the ggnn and run libraries</p>
<ol type="1">
<li>go into "babi/data", run'bash get_10_fold_data.sh" to get 10 folds
of bAbI data for 5 tasks (4, 15, 16, 18, 19) and do some
preprocessing</li>
<li>go into 'babi/data/extra_seq_tasks', run'bash
generate_10_fold_data.sh' to get 10 folds of data for the two extra
sequence tasks</li>
<li>go back to 'babi/' and use 'run_experiments.py' to run the
GGNN/GGS-NN</li>
<li>Use 'run_rnn_baselines.py babi18 lstm' runs LSTM on bAbI task 18 for
all 10 folds of data</li>
</ol>
<h3 id="目录结构">目录结构</h3>
<ul>
<li>run_rnn_baselines babi18 lstm</li>
<li>run_experiments / bash generate_10_fold_data.sh</li>
<li>get_10_fold_data.sh: do some preprocessing预处理</li>
</ul>
<h3 id="实际执行">实际执行</h3>
<ul>
<li>babi4
<ul>
<li>run_q4()
<ul>
<li>babi_train.lua
<ul>
<li>paras
<ul>
<li>nsteps: number of propagation iterations</li>
<li>learnrate: learning rate 0.01</li>
<li>momentum: ? for adam ？</li>
<li>mb: minibatch size</li>
<li>maxiters: maximum number of weight updates 100</li>
<li>printafter: save checkpoint after this amount of weight updates</li>
<li>saveafter: save checkpoint after this amount of weight updates
100</li>
<li>optim: adam</li>
<li>statedim: dimensionality of the node representations</li>
<li>evaltrain: evaluate on training set during training if set to 1</li>
<li>nthreads: set the number of threads to use with this process</li>
<li>ntrain: number of training instances 50</li>
<li>nval: number of validation instances 50</li>
<li>annotationdim: dimensionality of the node annotations
节点annotations的维度</li>
<li>outputdir: output directory</li>
<li>mode: {selectnode, classifygraph, seqclass, shareprop_seqclass}
selectnode</li>
<li>datafile: should contain lists of edges and questions in standard
format</li>
<li>seed: random seed. <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">preprocess其实就是edges上的属性，点的属性</span><br><span class="line">color = require &#x27;trepl.colorize&#x27;</span><br><span class="line">babi_data = require &#x27;babi_data&#x27;</span><br><span class="line">eval_util = require &#x27;eval_util&#x27;</span><br><span class="line">ggnn = require &#x27;,,/ggnn&#x27;</span><br><span class="line">1. prepare data</span><br><span class="line">math.randomseed(opt.seed)</span><br><span class="line">torch.manualSeed(opt.seed)</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul></li>
</ul></li>
<li>eval_q4()
<ul>
<li>babi_eval.lua</li>
</ul></li>
</ul></li>
</ul>
<p>todo: 看具体是怎么做的?</p>
<h3 id="数据预处理">数据预处理</h3>
<pre><code>python rnn_preprocess.py processed_$fold/train/$&#123;i&#125;_graphs.txt processed_$fold/rnn/train/$&#123;i&#125;_tokens.txt --mode graph --nval 50</code></pre>
<h3 id="babi使用">bAbi使用</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">babi-tasks PathFinding --path-length 3 --decoys 1</span><br><span class="line">babi-tasks Size --steps 3</span><br><span class="line"></span><br><span class="line"> ./babi-tasks $i 1000 --symbolic true &gt; symbolic_$fold/train/$&#123;i&#125;.txt</span><br><span class="line"></span><br><span class="line">--symbolic true </span><br></pre></td></tr></table></figure>
<h2 id="pytorch">2. pytorch</h2>
<p>论文中总共4个数据集 task 4 task 15 task 16 task 18 只有0.3386</p>
<ul>
<li>main.py
<ul>
<li>grid(opt)
<ul>
<li>main(opt)
<ul>
<li>run(opt)
<ul>
<li>net = GGNN (model.py)</li>
<li>train_loss = train(epoch, train_dataloader, net, criterion,
optimitzer, opt)</li>
<li>test_loss, numerator, denomitor = test(test_dataloader, net,
criterion, optimizer, opt)</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>model.py
<ul>
<li>GGNN
<ul>
<li>incoming and outgoing edge embedding</li>
<li>propogation model</li>
<li>output model</li>
</ul></li>
</ul></li>
</ul>
<p>task4 基本数据集 - edge_types - labels.txt: true or false -
node_ids.txt: - question_types.txt: - graphs.txt - n1 e6 n2 - ? n1 n2 2
数据主要从graphs.txt中提取 graphs.txt中的数据 n_edges_type 2 n_tasks 4
问题的类型 n_node 4</p>
<p>item[1] = {task_type, _, task_output} annotation = np.zeros([n_nodes,
n_annotation_dim]) # [4, 1] annotation[target][0] = 1 &gt;
这里的annotation是怎么设置的？ 这样设置有什么用？</p>
<p>task_data_list[task_type-1].append([edge_list,annotation,task_output])
&gt; 每次只使用一种类型的task_id进行训练</p>
<p>一些提前设置的参数 -D: denmensions 50 -H: hidden layer size 50</p>
<p>然后进行变换的参数是 bAbIDataloder(train_dataset, batch_size,
shuffle, num_workers) batch_size = 1, num_workers = 2</p>
<h3 id="pytorch数据处理的通路">pytorch数据处理的通路</h3>
<p>基于task4</p>
<ol type="1">
<li>原始含义-&gt;graphs.txt
<ul>
<li>单条数据 &gt; 1 1 2: node_1 e_type node_2 fact &gt; 3 1 1 fact &gt;
? 1 1 2: ? qustion_node qustion_type(&lt;=edge_type)
question_target</li>
<li>根据quetsion_type, 每次指示某个task_type进行运行GGNN模型</li>
<li>统计数据
<ul>
<li>n_edges_type 2</li>
<li>n_node 4</li>
<li>n_tasks 4</li>
</ul></li>
<li>返回结果
<ul>
<li>edges: (node_1, edges, node_2)</li>
<li>annotation: [n_nodes, n_annotation_dim] &gt;
这里n_annotation_dim由用户自己指定，这里为1 &gt; question_node对应位为1
&gt; 这里值得注意 n_annotation_dim=2, 结果为<code>[[1, 0, 0, 0], [0, 0,
0, 0]]</code>, 只指示<code>[question_node - 1][0]</code>为1</li>
<li>target: question_target &gt;</li>
</ul></li>
</ul></li>
<li>dataset -&gt; dataloader(batch_size=1, shuffle=True, num_workers=2):
&gt; 猜想是转换为邻接矩阵，或者其他？ 介绍的是 产生multi-process
iterable
<ul>
<li>dataset <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> &lt;class &#x27;list&#x27;&gt;: [[[1, 1, 2], [3, 1, 1]], array([[1.],</span><br><span class="line">[0.],</span><br><span class="line">[0.],</span><br><span class="line">[0.]]), 2]</span><br><span class="line">&lt;class &#x27;list&#x27;&gt;: [[[3, 1, 2], [1, 1, 3]], array([[0.],</span><br><span class="line">[0.],</span><br><span class="line">[1.],</span><br><span class="line">[0.]]), 2]</span><br></pre></td></tr></table></figure></li>
<li>dataloader &gt; num_samples 15??? <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[[[0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],</span><br><span class="line"> [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span><br><span class="line"> [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],</span><br><span class="line"> [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]</span><br><span class="line"> // [1, 4, 16]</span><br><span class="line"> [[[1.],</span><br><span class="line"> [0.],</span><br><span class="line"> [0.],</span><br><span class="line"> [0.]]]</span><br><span class="line"> </span><br><span class="line"> [1]</span><br></pre></td></tr></table></figure>
<ul>
<li>adj_matrix: (1, 4, 16): [A_in, A_out]</li>
<li>annotation (1, 4, 1) &gt; 这里前面的1是与那个有关</li>
<li>target: 按索引开始排列，-1, 从0开始 (1,)</li>
</ul></li>
<li>train.py对代码使用
<ul>
<li>padding: (n_nodes, n_nodes, opt.state_dim - opt.annotation_dim) (1,
4, 3) &gt; len(): 取的一直都是第一位 &gt; ? 有什么用 &gt; opt.state_dim:
论文中有提到的关于每个节点要设置多少个的东西 &gt;
所以这个是关于前面的补充？？</li>
<li>init_input = (annotation, padding)</li>
<li>output = net(init_input, annotation, adj_matrix) &gt; shape: [1, 4],
估计里面存储的是softmax值
<ul>
<li>GGNN mode: Select node???
<ul>
<li>forward(prop_state, annotation, A)
<ul>
<li>prop_state: (1,4,3)</li>
<li>annotation: (1,4,1)</li>
<li>A: (1, 4, 16) &gt; A的猜测对了，但是in_states,
out_states还没检查</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>main.py中相关参数
<ul>
<li>opt.state_dim: default 4</li>
<li>opt.n_steps: propogation: 4</li>
</ul></li>
</ul></li>
</ol>
<p>pytorch用法小结 torch.cat((x, x, x), 1) torch.stack((x, x, x), 2)
进行数据的封装 transpose(x, 0, 1) 进行转置 &gt;
https://zhuanlan.zhihu.com/p/64551412 &gt; view(1,6)
按照所想的内容进行填充 &gt; view(-1, 1, 2):
如果为-1表示这个位置由其他位置的数字来推断 nn.Linear(): 权重自己给定 ##
torch</p>
<ol type="1">
<li>ggnn.NodeSelectionGGNN(state_dim, annotation_dim, prop_net_h_sizes,
output_net_h_sizes, n_edge_types)
<ul>
<li>state_dim = opt.statedim 4</li>
<li>annotation: opt 1</li>
<li>prop_net_h_sizes: {}</li>
<li>output_net_h_sizes: {state_dim} 4 &gt; 输出的每个节点的大小</li>
</ul></li>
</ol>
<h2 id="something-new">something new</h2>
<ol type="1">
<li>学习方式的问题</li>
</ol>
<p>测试集和训练集分开的。 测试集和训练集</p>
<p>测试集上是全部关于一个图的局部的训练数据。</p>
<p>所以实际上对于每个图的获取方式都不一样</p>
<p>训练数据是原本图上的一部分</p>
<ol start="2" type="1">
<li>edge-type训练还是question_type训练</li>
</ol>
<p>edge-type不对，这里是边类型直接进行处理了</p>
<p>question_id 进行训练</p>
<p>这里question_id实际上是边的type类型，跟之前的理解是一样的</p>
<ol start="3" type="1">
<li><p>sequence 观测点的想法: 对的，刚刚看了下论文，发现确实是这样的！
应该是中间的标注能够知道。</p></li>
<li><p>是否有初始维度之说。 对的，没错！！！</p></li>
<li><p>训练模式 &gt;
这又回到了传统的训练方式，不过是借助了图的模型而已。还是进行一个图形一个图形地进行训练</p></li>
<li><p>跟原始的有什么区别，原始的一大串进行考虑，结果发现怎么根据边来传播，发现这样做是最成功的
## 思考</p></li>
<li><p>普通的机器学习 vs 图神经网络</p></li>
</ol>
<p>普通机器学习过程即学习一个函数，然后有很多数据都是关于这个函数的。
然后，用一个数据会产生loss, 然后根据loss进行反向传播，更新梯度。
然后，不断地用多组数据不停地进行训练。</p>
<p>图神经网络 一部分图的数据，一部分图的标签来模拟常见操作。</p>
<p>不对是一组数据进行学习的过程。</p>
<ol start="2" type="1">
<li>导数更新
对于传统的机器学习。导数更新实际上是由公式算出来的导数，然后导数更新公式上赋值上一堆权重。问题就是如何进行更新。</li>
</ol>
<p>对于一般情况来说，如果是一个训练数据直接使用一个数据进行训练即可。如果是多个训练数据，则loss来进行更新</p>
<ol start="3" type="1">
<li>分析 相比于传统的图数据处理方式，GNN,
GG-NN等模型可以有效地利用图的拓扑结构信息。</li>
</ol>
<p>这些模型在每个传播时间步都需要展开所有的节点，因而这些模型也可以用于处理各种图（包括有向图、无向图、有环图、无环图等）。</p>
<p>而且有以下问题： &gt; 1. 在每个时间步都要展开图中所有节点，效率降低；
&gt; 2. GG-NN将传播时间固定，可能只会得到有效的信息。</p>
<ol start="4" type="1">
<li>总结 &gt;
实际是每步即根据出度和入度矩阵进行标签传播，然后每一步都是在图上，从一个节点走到另外的节点。但是这样图上的信息传输也因此受到了约束。
&gt;
而且只是对特定的点给予信息，这意味着只能这些点的信息进行向前传播</li>
</ol>
<h2 id="总结">10.28总结</h2>
<p>对GGNN总结主要如下： 所谓的A_in,
实际上就是每个节点新一轮的表示是按照当前边的in边，将in边的节点的值进行加和，从而得到最终的结果。
&gt; 详细可见矩阵相乘的运算</p>
<p>关于训练集和验证集、测试集的思考：
经过实践发现，其实训练集和验证集是一直用的。 然后</p>
]]></content>
      <categories>
        <category>gnn-parallel</category>
      </categories>
      <tags>
        <tag>gnn-parallel</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel-communication_neural_network-read</title>
    <url>/2019/gnn-parallel-communication-neural-network-read-4a90a35cefcb/</url>
    <content><![CDATA[<h2 id="abstract">Abstract</h2>
<p>很多任务在Ai中都需要多个智能体之间的交互。特别地，这些相互交互的协议往往是提前手动特化好的，不能随着训练而改变。
在这篇文章， 提出一个简单的神经模型 CommNet,
用于全合作的任务之间的连续的交流
这个模型包含多个智能体，而且他们之间的交流信息可以依据policy来进行学习得到。
我们应用这个模型到一些列的任务中，使他们自安静相互学习，最终提高他们在非交流智能体和baselines中的表现。
在某些例子中，最好的效果甚至可以根据智能体所产生的语言来做出好的策略 ##
1. Introduction
Communication是智能体一个很basic的方面，特别是在真实环境中的复杂任务。但是大多都有着有限的能力limited
capabilities或者对环境的不足的可见性visibility。
实际中的例子包括电梯控制，sensor networks,
Communication是一个很重要的因素在robot
soccer中。在某些特别的环境中，Communication交流甚至比智能体个人Individual的表现更为重要。然而，现有Reinforcement
learning中， specification and format of Communication 是
pre-determined.</p>
<p>在这篇work中，我们提出了一种模型，在做出actions之前可以通过agents之间的cooperating来进行学习。Each
agent 被一个deep feed-forward network控制, 通过一个continuous vector.
通过这个channel, 他们可以获得来自于其他智能体的summed
transmissions。然而，每个agent传递的信息不是a-prioir,而是学习得到的。
因为学习是continuous, 所以模型可以通过back-propagation来进行训练，
所以他们可以与标准的single agent RL algorithms或者supervised
learning方法相结合。
这个模型是简单而且多才多艺的，它允许应用于只能partial visibility of the
environment,
智能体可以学习task-specific交流通过他们之间的表现。更进一步，
模型可以动态变化， the number and type of agents.</p>
<p>我们考虑设置了J个agents, 所有的一起合作去最大化reward R在某些环境中。
我们做了一个assumption, 每个agent获得R独立于contribution. 这就意味着，
each agent有他们各自的控制器或者可以把他们看作a pieces of a larger
model一大个训练的模型。
从另一个观点来看，我们的控制器将每个agent的input映射到他们的actions. ?
input, 每个agent参加在a subset of units?<br />
一个特别的在layer之间的结构就是 a. 实例化通信的channe b.
传播agent的state</p>
<p>我们扩展了这个模型在一系列任务上，在某些方面， supervision
用来提供每一步动作， 偶尔地给别人提供? In the former case,
对于每个agent多续联的控制器， backpropagation the error signal 通过
connectivity structure，确保智能体学习到如何communication?
(学习函数)来最大化目标。 In the latter case,
RL会用于一个额外的步骤来提供训练信号，在每个时间步里?
等于说训练数据是通过它提供的?</p>
<h2 id="communication-model">2. Communication Model</h2>
<p>我们表述了一个模型用来计算 the distribution over actions <span
class="math inline">\(p(\mathbf{a}(t)|\mathbf{s}(t),
\theta)\)</span>即在给定时间步t下的行动的概率分布。 <span
class="math inline">\(s_j\)</span>作为<span
class="math inline">\(j_{th}\)</span>的agents在环境中获取的state. ? ==
input? yes controller 's input 是所有的state拼接而成的向量<span
class="math inline">\(\mathbf{s}={s_1, s_2, ..., s_J}\)</span>,
output是all actions的拼接 <span class="math inline">\(\mathbf{a} = {a_1,
a_2, ..., a_J}\)</span> &gt;
?controller每个agent都有一个，然后output是所有的，输出的是直接概率吗？
distribution又是如何得到的</p>
<p><span class="math inline">\(\Phi\)</span>即a single controller
包括individual controllers for each agents, 和communication对于agents.
&gt; ? ### 2.1 Controller Struture <span
class="math inline">\(\Phi\)</span>是有modules<span
class="math inline">\(f^i\)</span>得到的， <span class="math inline">\(i
\in \{0,...,K\}\)</span>, K是沟通的时间步</p>
<p><img
src="gnn-parallel-communication-neural-network-read/eq1&amp;2.png" /></p>
<p>每个<span class="math inline">\(f_i\)</span>对agent j有两个输入<span
class="math inline">\(h_j\)</span>和<span
class="math inline">\(c_j\)</span> &gt; 注意到的<span
class="math inline">\(c_j\)</span>这里是收集的不包含自身</p>
<p><span class="math inline">\(h^{i+1} = \delta(T^i h^i)\)</span> &gt;
这里考虑到了进一步将权重进行简化 &gt; 需要说明的是这里<span
class="math inline">\(T^i\)</span>具有permutation invariant,
即排列不变性 &gt; 这里<span
class="math inline">\(c^{i+1}\)</span>允许其他的形式,
所以agent的数量可以发生改变</p>
<p>另外 1. first layer: encoder funciton, problem
dependent问题独立性相关的。 &gt; <span class="math inline">\(h^{0} =
r(s_j)\)</span>, 一般地， <span class="math inline">\(c^0 = 0\)</span>
2. end layer: decoder funciton <span class="math inline">\(a_j =
q(h_j^K)\)</span></p>
<ol start="3" type="1">
<li>the whole model <img
src="gnn-parallel-communication-neural-network-read/fig1_whole_model.png" />
&gt; 解释： <span class="math inline">\(\Phi\)</span>是整个过程？,
这个应该不是单个吧？ 灰色阴影是agent, 还是agent group?
<ul>
<li>用了所有agent的状态? 需要吗？</li>
<li>使用等式1和2</li>
<li>根据decoder, 采样出所有的agents的行动</li>
</ul></li>
</ol>
<h3 id="model-extensions">2.2 Model Extensions</h3>
<ol type="1">
<li>Local Connectivity: 在<span
class="math inline">\(c^i\)</span>计算中， 可以选择特别数量的来做</li>
<li>Skip Connection: <span class="math inline">\(h^{i+1} = f^i(h^i, c^i,
h^0)\)</span>, 在f中添加其他T的h的印象</li>
<li>Temporal Recurrence: 一直循环某一个<span
class="math inline">\(f^i\)</span>。 ## 3. Related Work</li>
</ol>
<h2 id="experiments">4. Experiments</h2>
<h3 id="baselines">4.1 Baselines</h3>
<ol type="1">
<li><p>独立的控制器： 每个控制器都是独立的一部分，它们之间没有任何交流。
在这里直接认为<span class="math inline">\(\mathbf{a} = (\Phi(s_1),
\Phi_(s_2), ..., \Phi_(s_J))\)</span>完全是独立的。
这样的优点其实在于分子性和灵活性，可以很好地选择进入或者退出</p></li>
<li><p>全连接的控制器： 认为<span
class="math inline">\(\Phi\)</span>是一个全连接层的神经网络,
softmax使用multiple output softmax heads?.
简单的理解就是所有的agent全进行参与</p></li>
<li><p>离散的交流： 一个agents可替代的communicate方式就是通过discrete
symbols（感觉就是一些信号量）。 因为<span
class="math inline">\(\Phi\)</span>包含了离散的操作，所以不可微分，RL可以用来训练。
特别地，一个agent可以在每个communication step产生离散的信号。
但是，如果这里有internal 时间段，我们可以直接应用policy gradient?
如何做， 见下文 <span class="math inline">\(w_j^i ~
softmax(Dh_j^i)\)</span>,
这里D是模型的参数。在我们广播的操作中，在下一个<span
class="math inline">\(c^{i+1}\)</span>的运算即变成了离散的操作之间与，或关系。</p></li>
</ol>
<h3 id="simple-demonstration-with-a-lever-pulling-task">4.2 Simple
Demonstration with a Lever Pulling Task</h3>
<p>我们设计一个游戏，需要agent之间相互communicate来win.
这个包括了m个levers(杠杆？ 有什么用？), a pool of N agents. 在each
round中， 从N个agents中随机地取m个agents, 他们每个必须选择一个lever to
pull(?), 同时与其他m-1个agents进行交互，在每轮结束时(每轮都选？) &gt;
每一轮都选m个agent, 每个agent每轮确定一个lever. 每个lever如何初始化？
这个游戏的目标是让它们每个都选择一个不同的lever?, 这是目标？ &gt;
lever是什么？ 同时，所有的agents按照获取的不同的levers的比列来获得奖励。
每个agent可以看到自己的身份, <span class="math inline">\(s_j =
j\)</span> &gt; 所以这是一个间谍游戏，level也是混在其中？？</p>
<p>我们扩展这个游戏m=5, N=500. 使用CommNet拥有两个交流步K=2和skip
connections from (4)来进行实验。 1. encoder是一个N entries of
128D的查找表 2. <span
class="math inline">\(f^i\)</span>是一个两层的神经网络，以ReLU非线性的结构，
<span class="math inline">\(f(h^i, c^i, h^0)\)</span>, 输出128D的向量。
3. decoder是一个linear layer plus softmax, 产生关于m layer的一个分布
&gt; decoder就是<span class="math inline">\(p(a|s, \theta)\)</span>,
这里行动action用来选择lever 4. sample来决定使用哪一个</p>
<p>同时与Indepent controller进行对比，所有结构相同，只有c为0.
我们同时扩展了两组实验Supervised和RL - Supervised: 使用排序agents IDs,
每个agent pull the lever根据当前m agents中的相对顺序 - RL:
另一篇论文</p>
<p><img data-src="gnn-parallel-communication-neural-network-read\res.png" />
&gt; m=5, 500 trials, 5000 batches of size 64 during traning &gt;
metrics = # distinct / # levers</p>
<h3 id="multi-turn-games">4.3 Multi-turn Games</h3>
<p>两项任务： 1.
控制通过交通路口的汽车进入，最大化流量的同时，最大程度减小碰撞 2.
控制多个代理击败敌人</p>
<p>使用前馈神经网络MLP, <span
class="math inline">\(f^i\)</span>是一个single layer network, K=2
communication steps. 对于RNN module, 我们需要一个<span
class="math inline">\(f^i\)</span>, 使用共享权重。 最后对<span
class="math inline">\(f^t\)</span>使用LSTM, 在所有的模块中，hidden layer
is 50, MLP使用skip connections. 训练300 epochs, 每一轮进行100 weight
updates 使用RMSProp在mini-batch有288论的训练。 在训练中会经过~8.6M</p>
<p>a few days #### 4.3.1 Traffic Junction</p>
<p><img
src="gnn-parallel-communication-neural-network-read/fig2_traffic_junction.png" /></p>
<blockquote>
<p>left: 观察到车时，可能有的三种行进路线 middle: 有限的视野，
不能看见己方机器人，目标是攻击对方机器人 right:
当视野扩大时，实验对比。</p>
</blockquote>
<p>包含了4-way junction on 14*14 grid.
在每个时间步里，以某个概率p在四个方向放入车辆，车辆的总共数量为10.
每个car在有限的视野下，选择两种操作，前进或者不动。</p>
<p>当两个车位置重叠时即发生碰撞，此时reward=-10.
不影响以其他方式模拟？</p>
<p>为了缓解交通事故，会给每个时间步安排一个<span
class="math inline">\(Tr_{time}\)</span>, 于是可以得到总共的时间步:</p>
<p><img
src="gnn-parallel-communication-neural-network-read/eq_traffic_junction.png" /></p>
<p>each car {n, l, r}, 视野范围为3*3, 所以维度为 <span
class="math inline">\(3^3 * n * l * r\)</span></p>
<p><img
src="gnn-parallel-communication-neural-network-read/table2.png" /></p>
<p>将f()使用不同的结构时所带来的失败概率上的问题 #### 4.3.2 Analysis of
Communication Communication的分析</p>
<p><img
src="gnn-parallel-communication-neural-network-read/fig3.png" /></p>
<blockquote>
<p>left: 在traffic
junctiontask中，两个主要的成分的交流向量c在多轮运行中的结果。</p>
</blockquote>
<h4 id="combat-task">4.3.3 Combat Task</h4>
<p>对抗任务，15<em>15， m=5 agents, 5</em>5 初始化位置</p>
<p>视野3*3, 电脑方可以共享位置。</p>
<p>攻击一下就减1，总共生命值3， 只要在视野内即可攻击。</p>
<p>失败条件： 所有agents生命值为0， 达到最终轮数</p>
<p>？</p>
<h3 id="babi-tasks">4.4 bAbI Tasks</h3>
<p>读一段故事回答问题。</p>
<h2 id="discussion-and-future-work">5. Discussion and Future Work</h2>
<p>MARL在多种任务中表现超过没有交流，
全连接，模型利用离散交流信息的模型，我们去的了很好的效果。</p>
<p>另一方面，可扩展的 1. 异构agent types 2. large numbers of agents.</p>
]]></content>
      <categories>
        <category>gnn-parallel</category>
        <category>cnn</category>
      </categories>
      <tags>
        <tag>gnn-parallel</tag>
        <tag>paper</tag>
        <tag>cnn</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel-ggsnn-code-realize</title>
    <url>/2019/gnn-parallel-ggsnn-code-realize-72209def8480/</url>
    <content><![CDATA[<h2 id="待做">待做</h2>
<ol type="1">
<li><p>表示复杂的梯度计算图 &gt; 根据计算图来表示，计算图有两种类型</p>
<ul>
<li>节点表示操作，边表示数据，如Tensorflow</li>
<li>节点表示数据，边表示操作，如计算图
https://blog.csdn.net/zxl55/article/details/83537144</li>
</ul></li>
<li><p>将所有复杂的公式转变为矩阵操作，然后直接使用Tensorflow类似的想法，不过感觉上可以做得更具体点</p></li>
<li><p>剥离输入输出，模型照抄 &gt;
为什么远程登录是用到Anaconda中的python</p></li>
</ol>
<h5 id="一些常量说明">一些常量说明</h5>
<ul>
<li>H(t-1): 上一轮的状态</li>
<li>H(t): 最终状态</li>
<li>Hz(t): 当前计算的状态</li>
<li>Wa: 初始化对H(t-1)做的操作</li>
<li>Wz, Wh, Wr: Z(t), Hz(t), R(t)关于Av(t-1)的权重</li>
<li>Uz, Uh, Ur: Z(t), Hz(t), R(t)关于H(t-1)的权重</li>
<li><span class="math inline">\(Av=[A_{in}, A_{out}]\)</span></li>
</ul>
<h5 id="图上的操作">图上的操作</h5>
<p><span class="math inline">\(Av(t-1) = A_{v:} (H(t-1)Wa)\)</span>
##### GRU单元 <span class="math inline">\(Z(t) = \delta (Av(t-1)Wz +
H(t-1)Uz)\)</span> <span class="math inline">\(R(t) = sigmoid(Av(t-1)Wr
+ H(t-1)Ur)\)</span> <span class="math inline">\(Hzt(t) = tanh(Av(t-1)Wh
+ (R(t) \odot H(t-1))Uh)\)</span> <span class="math inline">\(H(t-1) =
(1-Z(t))\odot H(t-1) + Z(t) \odot Hzt(t)\)</span></p>
<h5 id="原论文公式">原论文公式</h5>
<p>$<em>v^{t} = </em>{v:}^T [<em>1^{(t-1)T} ... </em>{|V|}^{(t-1)T}]^{T}
+ $ <span class="math inline">\(\mathbf{z}_v^t = \mathbf{\delta} (
\mathbf{W}^z \mathbf{a}_v^{t} + \mathbf{U}^z
\mathbf{h}_v^{t-1})\)</span> <span class="math inline">\(\mathbf{r}_v^t
= \delta ( \mathbf{W}^r \mathbf{a}_v^{t} + \mathbf{U}^r
\mathbf{h}_v^{t-1})\)</span> <span class="math inline">\(\mathbf{h}_v^t
= tanh ( \mathbf{W} \mathbf{a}_v^{t} + \mathbf{U} ( \mathbf{r}_v^t \odot
\mathbf{h}_v^{t-1}))\)</span> <span class="math inline">\(\mathbf{h}_v^t
= (1 - \mathbf{z}_v^t) \odot \mathbf{h}_v^{t-1} + \mathbf{z}_v^t \odot
\mathbf{h}_v^t\)</span></p>
<h5 id="代码-pyg">代码 pyg</h5>
<p><span class="math inline">\(\mathbf{h}_j^{0} = \mathbf{x}_i
\mathbf{\parallel} 0\)</span> <span
class="math inline">\(\mathbf{m}_i^{l+1} = \sum_{j \in \mathcal{N}(i)}
\mathbf{\Theta} \mathbf{h}_j^{l}\)</span> <span
class="math inline">\(\mathbf{z}_i^{l+1} = \mathbf{\delta} (
\mathbf{W}^z \mathbf{m}_i^{l+1} + \mathbf{U}^z
\mathbf{h}_i^{l})\)</span> <span
class="math inline">\(\mathbf{r}_i^{l+1} = \delta ( \mathbf{W}^r
\mathbf{m}_i^{l+1}+ \mathbf{U}^r \mathbf{h}_i^{l})\)</span> <span
class="math inline">\(\mathbf{h}_i^{l+1} = tanh ( \mathbf{W}
\mathbf{m}_i^{l+1} + \mathbf{U} ( \mathbf{r}_i^{l+1} \odot
\mathbf{h}_i^{l})))\)</span> <span
class="math inline">\(\mathbf{h}_i^{l+1} = (1 - \mathbf{z}_i^{l+1})
\odot \mathbf{h}_i^l + \mathbf{z}_i^{l+1} \odot
\mathbf{h}_i^{l+1}\)</span></p>
<p>$^{l+1} = ^{l} $ <span class="math inline">\(\mathbf{Z}^{l+1} =
\mathbf{\delta} (\mathbf{M}^{l+1} \mathbf{W}^z + \mathbf{H}^{l}
\mathbf{U}^z)\)</span> <span class="math inline">\(\mathbf{R}^{l+1} =
\delta ( \mathbf{M}^{l+1} \mathbf{W}^r + \mathbf{H}^{l}
\mathbf{U}^r)\)</span> <span class="math inline">\(\mathbf{H}_t^{l+1} =
tanh ( \mathbf{M}^{l+1} \mathbf{W} + (\mathbf{R}^{l+1} \odot
\mathbf{H}^{l})\mathbf{U}))\)</span> <span
class="math inline">\(\mathbf{H}^{l+1} = (1 - \mathbf{Z}^{l+1}) \odot
\mathbf{H}^l + \mathbf{Z}^{l+1} \odot \mathbf{H}_t^{l+1}\)</span></p>
<p>以算<span
class="math inline">\(\mathbf{W}^r\)</span>的权重矩阵梯度为例，我们需要将上面公式拆分为以下小公式，
$_1 = ^{l+1} ^r $ <span class="math inline">\(\mathbf{T}_2 =
\mathbf{T}_1 + \mathbf{H}^{l} \mathbf{U}^r\)</span> <span
class="math inline">\(\mathbf{R}^{l+1} = \mathbf{\delta}
(\mathbf{T}_2)\)</span> $_3 = ^{l+1} ^l $ <span
class="math inline">\(\mathbf{T}_4 = \mathbf{T}_3 \mathbf{U}\)</span>
<span class="math inline">\(\mathbf{T}_5 = \mathbf{M}^{l+1} \mathbf{W} +
\mathbf{T}_4\)</span> <span class="math inline">\(\mathbf{H}_t^{l+1} =
tanh(\mathbf{T}_5)\)</span> <span class="math inline">\(\mathbf{T}_6 =
\mathbf{Z}^{l+1} \odot \mathbf{H}_t^{l+1}\)</span> <span
class="math inline">\(\mathbf{H}^{l+1} = (1 - \mathbf{Z}^{l+1}) \odot
\mathbf{H}^l + \mathbf{T}_6\)</span></p>
<p>从而，反向传播，通过链式法则，<span
class="math inline">\(\mathbf{W}_r\)</span>的梯度就为： <span
class="math inline">\(\frac{\partial loss} {\partial \mathbf{W}_r} =
\frac {\partial loss}{\partial\mathbf{H}^{l+1}} \cdot \frac
{\partial\mathbf{H}^{l+1}} {\partial\mathbf{T}^6} \cdot \frac {\partial
\mathbf{T}_6}{\partial\mathbf{H}_t^{l+1}} \cdot \frac
{\partial\mathbf{H}_t^{l+1}}{\partial\mathbf{T}_5} \cdot \frac
{\partial\mathbf{T}_5}{\partial\mathbf{T}_4} \cdot \frac
{\partial\mathbf{T}_4}{\partial\mathbf{T}_3} \cdot \frac
{\partial\mathbf{T}_3}{\partial\mathbf{R}^{l+1}} \cdot \frac
{\partial\mathbf{R}^{l+1}}{\partial\mathbf{T}_2} \cdot \frac
{\partial\mathbf{T}_2}{\partial\mathbf{T}_1} \cdot \frac
{\partial\mathbf{T}_1}{\partial\mathbf{W}_r}\)</span> ## 问题总结</p>
<ol type="1">
<li>RuntimeWarning: overflow encountered in exp &gt;
https://www.cnblogs.com/zhhy236400/p/9873322.html</li>
</ol>
<p>实现说明
由于该算法初始输入要求输入维度小于隐藏层的维度，所以在实现时，在Input
Layer后进行了特征到隐向量维度的转换，在Prediction Layer前进行</p>
]]></content>
      <categories>
        <category>gnn</category>
      </categories>
      <tags>
        <tag>gnn</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel-ggsnn-paper-read</title>
    <url>/2019/gnn-parallel-ggsnn-paper-read-d28823966db5/</url>
    <content><![CDATA[<h2 id="摘要">摘要</h2>
<p>图结构广泛出现在化学、自然语言语义、社交网络和知识结构中。
在这篇工作中，我们学习了关于图结构输入的特征学习方法。
我们开始的起点是2009年的GNN的工作，我们使用gated recurrent
units和现代化优化手段，并且扩展到输出序列。
结果是灵活的并且广泛对于神经网络，结果相对于纯粹基于序列的模型具有很好的归纳偏差?，尤其是图结构的模型。(LSTM)
&gt; https://zhuanlan.zhihu.com/p/38740843,
归纳偏差简单的理解就是模型的偏好是什么？
我们描述了模型在bAbI任务上的能力和图的算法学习任务。接下来，我们展示了程序验证中的问题的应用效果，其中子图可以抽象为数据结构</p>
<h2 id="introduction">1. Introduction</h2>
<p>很多现实的图结构任务。
我们想在学习任务中将图作为输入。标准的方法对于问题来说包括对于一个输入图的工程自定义特征，
graph kernel. 方法用来定义图的特征通过在图上random walks，
更多的靠近我们目标的是先从图中进行学习特征中能包括GNN, spectral
networks以及在图足迹分类，化学分子表示上的方法</p>
<p>我们的主要贡献在于关于GNN在输出sequences上。之前在特征学习的工作主要集中在产生图的单个输出，比如grah-level分类任务，但是很多关于图的许多问题需要输出sequences。
例子包括在图上的路径，具有理想节点的枚举，以及图分类任务的序列。比如， a
start and end node. 我们不确定现有的工作是否能够很好的解决这个问题
我们的动机来自于程序验证，需要输出logical formulas，
我们把它形式化为一个序列化输出问题。
第二个贡献是GNN是一个广阔的神经网络模型可以应用再现阶段的很多领域</p>
<p>这里有两种关于图的特征学习的设定： 1. 学习关于输入图的表示 2.
学习在产生序列输出的interal state的表示</p>
<p>其中，1主要在GNN的工作里面。我们对这个框架做了调整，比如使用modern
practices 有关Recurrent Neural Networks.
2是我们期望从图结构问题中输出的，这不仅仅是individual classfication.
因此，这要的挑战就在于如何在图中学习特征，并且encode
已经产生的partial输出序列（比如path so far if outputting a
path），以及还需要被产生的（the remaining path）。 我们同时也展示了GNN
framework can be adapted to these settings,
从而获得一个新的关于基于图的神经网络模型，GGS-NNs</p>
<p>我们阐述了这个模型在bAbI tasks和图算法，在学习模型的能力上。
然后我们展示关于程序验证的应用。
当需要试图验证内存安全是，一个核心的问题是如何发现关于程序中运用的关于数据结构的数学描述。
我们 phrased这个机器学习任务，在我们需要map from a set of input graphs,
代表运用的内存，用来获取关于是咧的数据结构的logical descripton.
另外有一篇论文依赖于大量的手写工程的特征，我们展示了可以使用GGS-NN来替代该系统。</p>
<h2 id="graph-neural-networks">2. Graph Neural Networks</h2>
<p>在这段中，我们review GNNs, 并且介绍了整个过程用到的notation and
conecpts</p>
<p>GNNs 是一个普遍的神经网络结构根据图来定义， G=(V, E), 其中v为Nodes,
e为edges. 我们主要集中在directed graph上，所以(v, v')表示一个directed
edge, 但是我们发现这个框架可以easily to adapyed to undirected graphs,
see Scarselli et al.(2009). The node vector(node representation or node
embedding) for node v 是<span class="math inline">\(h_v\)</span>,
图也可以包含关于摸个节点的标签, edge labels <span
class="math inline">\(h_S\)</span>中S是a set of nodes <span
class="math inline">\(l_S\)</span>中S是a set of edges <span
class="math inline">\(IN(v)\)</span>表示v节点的祖先 <span
class="math inline">\(OUT(v)\)</span>表示v节点的后继 <span
class="math inline">\(NBR(v)=IN(v) U OUT(V)\)</span>表示v的邻居 <span
class="math inline">\(Co(v)\)</span> 所有经过顶点v的边</p>
<p>GNNs将graphs map到outputs通过两步： 1. propagation
step计算每个节点的表示 2. <span class="math inline">\(o_v =
g(\mathbf{h}_v, l_v)\)</span>
从node的表示和对应的labels中学习，来获取关于每个节点的一个输出。
在对于g的notation，
我们留下了关于参数的隐式的依赖，然后我们继续做这件事。 this
system是differentiable from end-to-end,
所以所有参数都可以通过gradient-based optimization学习</p>
<h3 id="propagation-model">2.1 Propagation Model</h3>
<p>在这里是关于一个迭代过程传播节点的表示。初始化节点的表示<span
class="math inline">\(h_v\)</span>可以设置为arbitary
values(任意的值)，然后node
representation根据下面的节点表示进行更新，直到convergence.</p>
<p><span class="math display">\[h_v^{(t)} = f^*(l_v, l_{Co_{(v)}},
l_{NBR(v)}, h_{NBR(v)}^{(t-1)})\]</span>
很多变量被提及，所以Scarselli建议decompsing函数f为一个关于每个对应的变得相加</p>
<p><span class="math display">\[f(l_v, l_{(v&#39;,v), l_{v&#39;},
h_{v&#39;}^{(t)}}) = A h_{v&#39;}^{(t-1)}+b\]</span></p>
<h3 id="output-model-and-learning">2.2 Output Model and Learning</h3>
<p>输出模型定义在每个节点上， g函数是可微的，可以maps到输出。
这仅仅是一个linear or neural network mapping.
在这个模型中每个节点将获得一个最终的表示。
如果是为了处理graph-level分类任务，他们的建议是使用一个dummy 'supper
node, which is connected to all other nodes by a special type of edge."
学习过程 ALmeida-Pineda算法已经完成
然后基于梯度的计算直到收敛解决最终问题。 评价： 1. advantage:
不需要存储中间状态来计算梯度。 2. disadvantage: 参数必须首先的，
所以传播步骤是一个收缩map。这需要来确保收敛，因为它可能限制模型的表达能力。</p>
<p>鼓励使用一个关于1-norm的Jacobian作为惩罚项。 Appendix
A是一个例子，给出了收缩银蛇的直觉难以在图中长时间传播信息</p>
<h2 id="gated-graph-neural-networks">3. Gated Graph Neural Networks</h2>
<p>我们提出了GG-NNs, 适用于non-sequential puputs.
关于GNNs的最大调整是我们使用了Gated Recurrent Units，并且unroll(展开)
一个循环的重复的神经步，使用backpropagation 来计算梯度。
这需要更多的内存相比于GNN算法，但是不需要限制参数来确保收敛convergence.
我们同时扩展了隐藏层的表示和输出模型</p>
<h3 id="node-annatations">3.1 Node Annatations</h3>
<p>在GNNs中， 这里没有明显的点来初始化节点的表示因为收缩图map
constraint来确保，者使得我们不需要与其他的节点label作为额外的输出。为了分辨这些节点用作输入和之前介绍的节点。
node annotations 并且使用向量x来denote这些表示。
为了产生他们怎么用，考一个简单的任务，训练图神经网络来预测接地那t如何到达节点s在一个给定的图上。在这个问题中有来哥哥问题相关的
节点，s 和t， [1,0] [0,1]. 在可到达的例子中，
可简单来看春波模型如何来传播节点的annotation(注解)，使得它们的第一位变为1.
output step
classifier可以轻易地辨别nodel是如何从s到达t的通过查看安歇节点有非零的实体在前两维上
&gt; 这个过程好像标签传播</p>
<h3 id="propagation-model-前向传播模型">3.2 Propagation Model
前向传播模型</h3>
<p><img data-src="gnn-parallel-ggsnn-paper-read/ggnn-equations.png" /></p>
<p>MatrixA决定了节点在图的communicate中如何进行交流。
稀疏的结构和参数在A中图图1所示。 eq 1是初始化步骤，copy node
annotions到隐藏层的第一位，并把剩余维度清零。 eq
2是在不同节点间通过出度和入度的边来春波参数，这些参数独立于边的种类和方向。
<span class="math inline">\(a_v^{(t)}\)</span> &gt; ?
输入x是什么？是对应的邻接矩阵信息吗? 注意维度，这里是二维的</p>
<p>剩余的就是GRU的部分 https://zhuanlan.zhihu.com/p/32481747</p>
<p>https://zh.d2l.ai/chapter_recurrent-neural-networks/gru.html</p>
<p><span class="math inline">\(z_t\)</span>用于门控的更新， <span
class="math inline">\(r_t\)</span>用于门控的重置</p>
<p><span class="math inline">\(h^{(t-1)} = h^{(t-1)} . r\)</span> &gt;
理解，<span class="math inline">\(H_t\)</span>是更新门，
最终结果是对上一时间步的隐藏层和当前时间步的候选隐藏状态<span
class="math inline">\(H_t\)</span>做组合 <span class="math inline">\(Z_t
* H_{t-1}\)</span> 表示对上一层的遗忘，忘记上一层的某些东西 <span
class="math inline">\((1-Z_t) *
H_{t}\)</span>表示对当前候选隐藏层的状态进行记忆。 这里z是门控喜好，
门控信号越接近1表示记忆得越多，越接近0表示遗忘得越多？？ &gt;
需要看乘法是怎么做的？</p>
<blockquote>
<p>不要管z和r怎么看，都是有w的超参数，实际上就进行理解为z是用来学习分配更新的，r是用来产生中间隐藏候选状态的中间变量</p>
</blockquote>
<p>结果表示GRU-like 前向传播步骤更有效果</p>
<h3 id="output-models">3.3 Output Models</h3>
<p>这里有one-step outputs，我们可以用来产生各种的情形。首先GG-NNs node
selection任务为门戈节点的输出进行打分，并且因公softmax在node 分数上 &gt;
意思是node selection其实它会中间输出表示，按理说维度应该和类别一样。
&gt; 其实这里就是中间观察的结果</p>
<p>对于graph-level outputs,我们的定义如下</p>
<p><img data-src="gnn-parallel-ggsnn-paper-read/eq7.png" /></p>
<blockquote>
<p>这里<span class="math inline">\(\delta\)</span>使用的是soft
attention机制? 来决定是否哪些节点与当前的tgraph-level任务相关。
i和j是神经网络。使用<span
class="math inline">\(h_v^{(T)}\)</span>和<span
class="math inline">\(x(v)\)</span>$作为input和ouputs的real-valued
vectors. tanh可以被替代
这里说的就是如何产生中间观察结果，记得之前有学习过一个模型！ 不理解？ ##
4. Gated Graph Sequence Neural Networks 在这里GGSNNs</p>
</blockquote>
<p>对于k-th 输出步骤，我们描述了node annotations as <span
class="math inline">\(X^{(k)}\)</span>, 我们用了两个 GG-NNs <span
class="math inline">\(F_o^k\)</span>和<span
class="math inline">\(F_x^k\)</span>来从<span
class="math inline">\(X\)</span>中预测o. 以及<span
class="math inline">\(F_X\)</span>用来从<span
class="math inline">\(X_k\)</span>预测<span
class="math inline">\(X_{k+1}\)</span>,
两个都是包括了一个前向模型和输出模型。在前向模型中，我们使用了节点向量作为t层的前向步骤和k层的输出步骤。
在之前的每一步，我们设置 &gt; 这两个模型一个输出x， 一个用来输出o；
在之前我们把<span
class="math inline">\(H^{k-1}\)</span>初始化为0-extending的<span
class="math inline">\(X_{k}\)</span>.
这种简单的变体是能够很快用来训练和评估的，在很多case种，整个模型可以达到相同的表现。但是在某些case中，两个的表现效果不一样，所以这种变体不能work得很好
&gt; ? 为什么 我们介绍了node annotation ouput用来从H预测X。
这个预测对于每个节点都可以很简单地用一个神经网络j来连接h和x作为输入和输出，从而得到一个真实的分数
&gt; ?</p>
<p>这里有两种关于GGS-NNs的设定： specifying all intermediate annotation
Xk, 或者训练所有模型，仅仅给X1, graphs and target sequence.
前者可以提高表现力，但我们有邻居只是在知道节点的信息在哪些 &gt;
取得节点达摩鞋特征。 第二种更为普遍</p>
<ol type="1">
<li>Sequence outputs with observed annotations 考虑任务来做整个，
图的序列预测，每个预测只是包括图的一笑部分。为了确定每个部分都有一个输出，每个节点只有一位就过来，表示我们已经解释了。
&gt; 子图训练？？</li>
</ol>
<p>在某些设定中，少量的annotations足够来预测。我们可以扩展多个模型，这些模型都有注释地可做
&gt; one idea, 可以用不同的邻域，来结合多个相同模型！！！
还有模型的组合</p>
<p>单步domain预测，这实际上和所有是一样的 2. Sequence outputs with
latent annotations 一般地，当中间不可用时，作为隐藏层，后向传播训练</p>
<h2 id="explanatory-applications">5. Explanatory Applications</h2>
<h3 id="babi-tasks">5.1 bAbI Tasks</h3>
<p>这里我们简述了如何使用GGS-NNs. 我们主要集中在bAbI任务上。</p>
<p>bAbI tasks是Facebook提出的一个AI任务集，
第一组发布的bAbI包括20个任务。若要查看这些任务的详细信息， 请移步<a
href="https://arxiv.org/abs/1502.05698">bAbI tasks</a>.
在bAbI数据集中，每一篇文本对应于一个故事。本文将每个故事映射成了一个简单的图（节点对应于实体，边对应于关系）。
每个问题(eval)由问题类型（类似于谓词，如"has_fear")与一些参数（对应于图中一个或多个节点）构成。当任务具有多种问题类型时，需要对每种类型都训练一个独立的模型。在本文中，仅处理类型未二元一阶谓词的问题。</p>
<p>例如，对于问题“eval E&gt;A true”, 那么问题的类型为"&gt;",
图中的节点E将会被（初始化）标注为<span class="math inline">\(x_E = [1,
0]^T\)</span>, 节点A将会被标注为<span class="math inline">\(x_A=[0,
1]^T\)</span>, 其他节点将会被标注为<span class="math inline">\([0,
0]^T\)</span></p>
<h4 id="单输出任务">单输出任务</h4>
<p>单输出任务实验基于bAbI的四个任务： Task4: Two Argument
Relations(选用D=4)； Task15: Basic Deduction(D=5); Task16: Basic
Induction(D=6); Task 18: Size Reasoning(D=3) &gt; D是什么？</p>
<p>在bAbI任务集的四个任务上的实验结果为（括号内为使用的训练样本数，下同）</p>
<p><img data-src="gnn-parallel-ggsnn-paper-read/bAbI_res.png" /></p>
<h4 id="序列输出任务">序列输出任务</h4>
<p>序列输出任务基于bAbI Task19: Path Finding(D=6). 其实验结果如下：</p>
<p><img data-src="gnn-parallel-ggsnn-paper-read/bAbI_res2.png" /></p>
<h3 id="learning-graph-algorithms">5.2 Learning Graph Algorithms</h3>
<h2 id="程序验证问题-ggs-nns">6 程序验证问题 GGS-NNs</h2>
<p>在GGS-NNs的工作主要来自于实际program verification. 在automatic
program verification中最关键的一步就是program invariants的推论，
它用来近似评估在一次execution中一些程序状态是否可达。
发现数据结构中的不变量是一个open problem. 在这里，C函数为例
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node* concat(node* a, node* b) &#123;</span><br><span class="line">    if (a==NULL)  return b;</span><br><span class="line">    node* cur=a;</span><br><span class="line">    while (cur.next != NULL)</span><br><span class="line">        cur = cur-&gt;next;</span><br><span class="line">    cur-&gt;next = b;</span><br><span class="line">    return a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 为了证明这个问题two lists
a和b确实是concatnates连接的，所有指针取消引用都是合法的。我们需要characterize程序在每一次迭代的循环中的help。
在这里我们用了separation logic(分隔的逻辑符号)， 它使用inductive
predicates归纳谓词来描述, 抽象数据结构。 举个例子，
一个分段的list定义为todo1, todo2
意味着x指向一个内存区域，它包括了数据结构有两个域， val和next，
它们的值保存在v和n中， * connective是合并的布尔连接法，
但是额外需要它操作指导"separate" parts of the heap. ls(cur, NULL)
于是这cur要么是null,要么指向heap中的两个值v、n, 这里n用ls描述。
公式todo3 是一个循环的不变式。
使用它，我们可以证明，不会失败，因为不会引用一块未分配的内存地址。
这个函数进一步使用Hoare-style验证方式的确连接了两个lists.
关于整个流程最困难的地方在于产生描述数据结构的公式。在这里我们使用到机器学习。在给定的程序中，我们跑了很多次并且提炼了内存的状态（重新表示为graph)在相关程序位置，接着预测了分离逻辑公式。静态的程序分析工具可以检查一个候选的公式是否是充足地去证明它需要的属性。
&gt; 这里考虑的是使用Machine Learning来描述data struture,
然后预测相关的separation logic formula??? 怎么能保证正确性啊？
惊奇！！！</p>
<blockquote>
<p>Input这里边上的权重0表示什么意思？ ### 6.1 Formalization</p>
</blockquote>
<ol type="1">
<li>Representing heap state as a graph:<br />
作为输入，我们考虑有向图，可能是循环图来表示一个程序的heap.
这些图可以自动地构建程序的对状态。
每个图的节点都对应着内存中一块内存地址，在这块地址中，v0, ...,
vk已经存储。 图的边反映了指针值，即v具有标记为0, ..., k
分别指向了节点v0, ..., vk &gt; ?? node 和 edge 还需要再理解。
实际上只指向一块地址，但是node可能多个地方对这块地址有引用？
地址一块，一块链接存储，像链表一样，每个节点都对应独特的一块内存空间？
&gt; 边的属性表示什么意思？</li>
</ol>
<p>A subset of nodes are labeled as corresponding to program
variables.</p>
<p>一个输入图的例子as "Input" in Fig.3. In it, 节点展示在节点里面。node
id(i.e., memory address), 边的labels表示特殊的域？，e.g. 0对应于previous
section中的下一个指针。 对于binary trees, 这里有两种类型的指针left,
right分别指向树节点的left和right节点。 2. Output Representation
我们的目标是数学表示heap的形状。在我们的模型中，我们限制了分离限制的语法版，
formulas的形式是，<span class="math inline">\(\exists x_1, ..., x_n, a_1
* ... * a_m\)</span>， 这里每个atomic formula <span
class="math inline">\(a_i\)</span>或者ls(x, y), tree(x), 或者none(x)(no
data struture at x).
存在量词是用于给描述形状所需的堆节点命名，而不给一个程序的变量命名。
举例， 为了描述“人手清单”（a list that ends in a cycle）, 第一个list
element需要被描述。 在separation logic, 被表示为 <span
class="math inline">\(\exists t. ls(x, t) * ls(t, t)\)</span></p>
<ol start="3" type="1">
<li>Data
我们为了这个问题产生合成的（标记的）数据集。自此，我们还修复了一些谓词，比如ls和tree(扩展名可以考虑双向链标的列表段，多树)以及它们的递归定义。然后，我们列举了实例化分离逻辑公式我们的谓词使用的程序变量集
&gt; 程序变量集，变量v, address</li>
</ol>
<p>最后，对于每个公式，我们列举满足该公式的堆图，结果是一个数据集包括我们heap
graphs and associated formulas that are used by our learning
procedures.</p>
<h3 id="formulation-as-ggs-nns">6.2 Formulation As GGS-NNs</h3>
<p>通过数据迭代产生的过程来获得节点的中间表示。所以，我们训练一个不变量GGS-NN使用观察的annotations(observed
at training time) &gt; 这里关注的点是什么？为什么要这么做</p>
<p>使用un-obeserved GGSNN
variant来做end-to-end学。这个过程将会使得separation logic formula拆分为
a sequence of steps.
我们首先决定了来宣称了哪个必要的变量，如果可以的话，选择对应的节点来表示变量。<code>??</code>
一旦我们有了宣称的必要的变量，我们迭代所有变量的名字，然后产生一个separation
logic formula以当前变量所对应的的节点未根来描述数据结构。
完整的算法如下所示。</p>
<p>我们使用了三个明显的node annotation部分，namely is-named(heap node
labeled by program variable or declared existentially quantified
variable(量化的))， 被命名的， active(cf. algorithm) 和
is-explained(heap node is part of data struture already predicted).
初始化的节点标记可以直接从input graph中计算得到。
is-named是对于程序变量的编辑。 active和is-explained总是off.</p>
<p>评论的行在扩展中都使用的是GG-NN。 Alg.1 是一个GGS-NN model的instance.
一个简要的关于算法运行的一开始的算法在Fig3,
每一个斗鱼算法的每一行相关</p>
<p><img data-src="gnn-parallel-ggsnn-paper-read/alg1.png" /> &gt; Separation
logic formula prediction procedure <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Input:  Heap graph G with named program variables.</span><br><span class="line">X: compute initial labels from G    // 做了些什么</span><br><span class="line">H: initialize node vectors by 0-extending X</span><br><span class="line"></span><br><span class="line">while exists quantifier needed do // 当需要存在量词的时候  Graph-level Classification</span><br><span class="line">    t: fresh variable name</span><br><span class="line">    v: pick node    // Node selection.</span><br><span class="line">    X: turn on &quot;is-named&quot; for in X</span><br><span class="line">    print &quot;exists t&quot;  // 不懂什么意思</span><br><span class="line">end while</span><br><span class="line"></span><br><span class="line">for node v_l with abel &quot;is-named&quot; in X do</span><br><span class="line">    H: intialize node vectors, turn on &quot;active&quot; label for v_l in X</span><br><span class="line">    pred: pick data structure predicate // Graph-level  Graph-level Classification 好抽象， 随便来抽取数据结构还是怎么会使</span><br><span class="line">    if pred = ls then</span><br><span class="line">        l_&#123;end&#125;: pick list end node  // Node selection</span><br><span class="line">        print &quot;ls(l, l_&#123;end&#125;)  // 这里的print实际上就是输出上面想要分析的表达式</span><br><span class="line">    else </span><br><span class="line">        print &quot;pred(l)*&quot;  // 没有tree等其他情况，等于说</span><br><span class="line">    end if</span><br><span class="line">    X: update node annoatations in X  // Node Annotation</span><br><span class="line">end for</span><br></pre></td></tr></table></figure> &gt;
所以是这里每一步的评论都会用到GGS-NN模型？ &gt; is-named, active,
is-explained等于说是变量的三个状态，
于是heap中的变量的状态就是？，不过依然看不懂fig3</p>
<p><img data-src="gnn-parallel-ggsnn-paper-read/fig3.png" /></p>
<h3 id="model-setup-details">6.3 Model Setup Details</h3>
<p>我么使用了full GGS-NN model， <span
class="math inline">\(F_o^k\)</span> 和 <span
class="math inline">\(F_X^k\)</span>有着separate propagation models.
对于所有GG-NN成分，在GGS-NN pipeline中的， 我们展开传播过程为10 time
steps. GGS-NNs与step(|)(决定是否更多存在两次变量需要声明) 和 step(||)
(辨别哪些节点需要声明为存在量词)， 通过使用D=16维的节点表示。 对于all
other GGS-NN成分， D=8使用，Adam优化器用来优化，模型被训练在20
graphs的minibatches， 优化直到训练错误率非常低。
对于图级别的分类任务，我们认为平衡地分类，每一小皮量中甚至都有even
number of examples. 所有的GGS-NN成分包含了少于5k paras, 并且 no
overfitting被观察到，在训练过程中。</p>
<h3 id="batch-predication-details">6.4 Batch Predication Details</h3>
<p>在实际中，一系哦啊部分heap graphs将会被给与input and a single output
formula is expected to describe, 并且与所有的input graphs一直。
不同的heap graphs可以是程序执行过程中不同状态点，
或者运行在相同程序的不同输入。 我们称这个"batch prediction" setup
与描述在主要的paper中的single graph prediction相互对比。</p>
<p>为了得到batch predictions, 我们运行一次GGS-NN对于each graph同时的。
For each prediction step, 所有GGS-NNs的outputs at the step across the
batch of graph被聚集。</p>
<p>对于node selection outputs, 普遍的命名为variables link
nodes在不同的图上，它是聚集prediction in a
batch的关键。我们计算particular named variable t as <span
class="math inline">\(o_t = \sum_g o^g_{V_g(t)}\)</span>, 其中<span
class="math inline">\(V_g(t)\)</span>maps 变量t到图中的一个节点。 <span
class="math inline">\(o^g_{V_g(t)}\)</span>是named variable t in graph
g中的 output score. 当使用一个softmax对于所有names using <span
class="math inline">\(o_t\)</span> as scores, 这个与计算<span
class="math inline">\(p(toselect=t)=II_g
p_g(toselect=V_g(t))\)</span>相同。</p>
<p>对于graph-level 分类输出，我们增加一个特别的类的scores across the
batch of graphs., 或者相等的计算<span
class="math inline">\(p(class=k)=II_gp_g(class=k)\)</span>, Node
annoation outputs作为不同的图在每个图中独立地被更新，有着完全不同的set
of nodes. 然后，当算法尝试更新annotation of one named variable, the node
相关联的所有节点也被更新。在训练中， 所有标记 intermediate
steps对于我们是可获得的，从data generation process, 所以training
process能够在一次的降解到single output single graph training.
一个更complex的情景允许nested（嵌套的）数据结构(list of lists)被讨论。
我们也成功地扩展了GGS-NN model到这个例子，更多的细节在Appendix C.</p>
<h3 id="experiments">6.5 Experiments</h3>
<p>在这篇文章中，我们产生了327 formulas的数据集，包含了三个程序变量，
498 graphs per formula, 产生了大约160,000 formula/heap graph
combinations.
为了评估，我们分隔数据到训练集、验证集和测试集按6:2:2的比例(测试集不会用在训练集上)。我们测试了准确率，是否formula预测在测试时间在逻辑上等于基本事实
等价通过规范化来近似公式的名称和顺序，然后进行比较以求完全相等。</p>
<p>我么比较了我们的GGS-NN 模型和Brockschmidt中提到的方法。
更早的方法把每一个验证不都对待为一个标准的分类任务，并且要求complex,
manual, problem-specific feature engineering,
来达到89.11%的准确率。作为对比，我们的新模型no feature
engineering和少量的domain knowledge来达到了89.96%的准确率。</p>
<p>一个heap graph 的例子和对应的logic formula从我们GGS-NN
model中发现的如fig4所示。 <img
src="gnn-parallel-ggsnn-paper-read/fig4.png" /> &gt;
比较了两个命名变量arg1, arg2. one isolated NULL node, nodel 1.
所有的边指向NULL没有进行显示。
边上的数字暗示了不同的边的类型。我们的GGS-NN模型成功地找到了正确的formul</p>
<p>这个例子还包括了nested data structures和the batching
extension在之前的section中提到的。</p>
<p>我们还成功的用我们的模型在程序验证的framework,
提供所需将定理证明给定理证明这，以证明列表操作集合的正确性比如插入排序等算法。
一下table
4展示了一组基准列表操作程序和由GGS-NN模型找到的分离逻辑公式不等式，分别是在验证框架中成功使用以证明相应程序的正确性。</p>
<p><img data-src="gnn-parallel-ggsnn-paper-read/table4.png" />
一个未来的扩展已经展示成功的证明了更复杂的程序比如排序程序，以及各种l其他list操作的程序。</p>
<h2 id="相关工作">7. 相关工作</h2>
<p>最相关的工作是GNNs, 我们之前讨论过。
Micheli建议了另一个紧密相关的模型，它不同于GNNs，主要在输出上。
GNNs被应用在许多领域，但是他们没有广阔地在ICLR社区传播。我么的部分目的publicize
GNNs是一个useful and interesting neural network variant.</p>
<p>一个比喻可以秒速我们从GNNs到GG-NNs的掉成， the work of Domke and
Stoyanov在strutured prediction setting.
这里的信念传播（这里必须运行在能够convergence,
以取得好的梯度）被替代为truncated(截断的)信念传播更新。然后这个模型被训练，所以truncated
iteration produce good results在一些迭代次数后。同样地，RNN扩展到了Tree
LSTM也相似与我们使用GRU来更新GG-NNs而不是使用标准的GNN，目的在于提高长时间的信息在graph
struture中的前向传播。 the general
idea表现在paper中的是组装特定问题的神经网络学习成分已经有一个很长的历史，可以追溯到the
work of Hinton， 用神经网络来根据家族数结构预测人与人之间的关系。 Graph
kernel能够被用于一系列的kernel-based learning tasks使用graph-strutured
inputs， 但是我们不知道learn the kernel 和outputs sequences.
Perozzi转化graph为sequences通过following random walks在图上，学习node
embedding 使用sequence-based的方法。 Sperduti map graphs to graph
vectors 然后output neural
network来分类这里有多种模型使用同样的节点表示的前向传播在图结构上。
他们的工作和GNNS的不同点在于卷积和recurrent networks.
Duvenaud认为convolutional想在图上的操作，建立一个可学习的，可微的关于graph
feature的变体。
LUsci转换认为的无向图为一定数量的不同的DAGs，然后向内传播节点表示每个根，训练一组模型。在以上所有内容上，重点都放在了一步式问题上。</p>
<p>GNNs和我们扩展具有滋镇网络的许多相同的理想属性。使用节点选择输出层，可以选择输入中的及诶按作为输出。
有两个区别：
首先，在GNN中，图结构是显式的，这使得模型通用性较低，但可以提供更强的泛化能力；第二，指针网络要求每个节点都有属性（比如,
空间中的位置），而GNN可以表示已定义的节点仅通过他们在图形中的位置即可，这使它们在不同维度上更具有通用性。
GGS-NN与软对齐和注意力名有关。有两个方面，第一，eg7中，等式的图形表示，
使用上下文将注意力集中在哪些节点对当前决策很重要；第二，节点程序验证例子中的注释跟踪已注释的哪些节点，因此，它地公馆一种明确的机制来确保输入中的每个节点都已经使用在产生输出的顺序上。</p>
<h2 id="discussion">8. Discussion</h2>
<ol type="1">
<li>What is being learned?
有启发的去思考GG-NNs能学到什么。为此，我们可以在bAbI任务的方式之间类比,
bAbI task15将会通过logical
formulation得到解决。作为一个例子，考虑右边的一个例子中需要回答的行。</li>
</ol>
<p>为了做逻辑推断，我们需要的不仅仅是关于故事中事实的逻辑编码，而且，关于世界的背景知识也编码为一个inference
rules</p>
<p>我们对任务的编码简化了将故事解析为图形形式的过程，但没有提供任何背景知识，可以将GG-NN模型视为学习此方法的结果存储在神经网络权重中。</p>
<ol start="2" type="1">
<li>Discussion
论文的结果表明，GGS-NN在整个过程中都具有理想的感应偏差，一系列具有固有图结构的问题，我们相信在很多问题，在更多情况下，GGS-NN将很有用。但是，有一些限制需要克服这些障碍，使其广泛地应用。我们前面提到的两个显示是bAbI任务翻译未包含输入的时间顺序或三进制或更高解关系。我们可以想象一下接触这些限制的可能性，例如将一个座位会议论文在ICLR2016上发布的一系列GG-NN,
每个边缘有一个GG-NN,
代表更高阶的关系，作为因子图。一个更大的挑战是如何处理结构化的输入表示形式。例如，在bAbI任务中，最好不要使用输入的符号形式。
一种可能的方法是在我们的GGS-NN中合并结构较少的输入和潜在向量。但是，需要进行实验以找到解决这些问题的最佳方法
## Analysis</li>
</ol>
<p>相比于传统的图数据处理方式，GNN、
GG-NN、GGS-NN等模型可以有效地利用图的拓扑结构信息，这也是为什么GGS-NN可以在Path
Finding任务中取得优异效果的原因。另外，由于这些模型在每个实践部都需要展开所有的节点，因而这些模型也可以用于处理各种图（包括有向图、无向图、有环图、无环图等）。但是，这同样也带来了一些问题：
1.
由于在每个实践部都需要展开所有的节点，每个节点还需要使用D维向量进行表示；当图很大且向量表示很大时，模型的效率问题就会变得很重要
2.
在GNN中需要保证凸的整体映射是一个压缩映射，这显然就减小了该模型所能建模的问题空间???(好像的要求时对于寻找压缩映射问题而言的)。为了解决这一问题，GG-NN将传播时间步固定为T,
虽然不需要保证收敛，但是，图上的信息传输却也因此受到了约束(???，信息的传输与时间步有关，因为终止条件不再是收敛，而是具体的时间步)。例如，在可达性预测任务中，在两个时间步后节点1的信息才可以到达节点4.虽然本文中采取了一定的措施来缓解这一问题（即不仅定义了沿边方向的转移举证，还定义了与边相反方向的转移矩阵）。但是只要T的大小有限，节点之间的信息就只能沿着路径传播T步，而不能像GNN那样到模型收敛才停止。换句话说，GG-NN实际上是以损失图中较长路径信息的代价换取了模型可建模的问题空间。</p>
<h2 id="参考文献">参考文献</h2>
<p>https://zhuanlan.zhihu.com/p/28170197</p>
<p>jianshu.com/p/40362662014a
https://github.com/microsoft/tf-gnn-samples</p>
<p>cnblogs.com/wacc/p/5341670.html
https://zhuanlan.zhihu.com/p/38051458</p>
<h2 id="阅读思考">阅读思考</h2>
<p>有空再阅读一遍，通过阅读发现，这里的图神经网络实际上node-selection,以及graph-level,
都是graph-level级别的任务，即得到每个节点的表示，然后由节点进行预测。</p>
<p>该论文和上篇semi-gnn形成鲜明对比 1. 上篇论文是inductive learning,
这篇是transactive learning. 2. 上篇是node-level
分类任务，这篇是graph-level任务，即node-selection.</p>
<p>好像是为了偷懒，所以才用三维，把对应的给空着</p>
]]></content>
      <categories>
        <category>gnn-parallel</category>
      </categories>
      <tags>
        <tag>gnn-parallel</tag>
      </tags>
  </entry>
  <entry>
    <title>semi-gnn, relization progress</title>
    <url>/2019/gnn-semi-gnn-relization-progress-4a32edb8b631/</url>
    <content><![CDATA[<blockquote>
<p>试图用numpy实现</p>
</blockquote>
<p>主要问题 &gt; 模拟自动微分这一块出现的问题</p>
<p>对于softmaxarg()函数来说 目标即寻找一个平滑函数</p>
<p>https://deepnotes.io/softmax-crossentropy</p>
<p>一个softmax的非常好的做法</p>
<p>soft-argmax</p>
<p>https://bouthilx.wordpress.com/2013/04/21/a-soft-argmax/ ##
一些后记</p>
<p>关于cs231n课程代码的一些借鉴</p>
<ol type="1">
<li><p>一个pipeline <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> past.builtins <span class="keyword">import</span> xrange</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  A two-layer fully-connected neural network. The net has an input dimension of</span></span><br><span class="line"><span class="string">  N, a hidden layer dimension of H, and performs classification over C classes.</span></span><br><span class="line"><span class="string">  We train the network with a softmax loss function and L2 regularization on the</span></span><br><span class="line"><span class="string">  weight matrices. The network uses a ReLU nonlinearity after the first fully</span></span><br><span class="line"><span class="string">  connected layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  In other words, the network has the following architecture:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  input - fully connected layer - ReLU - fully connected layer - softmax</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  The outputs of the second fully-connected layer are the scores for each class.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size, output_size, std=<span class="number">1e-4</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Initialize the model. Weights are initialized to small random values and</span></span><br><span class="line"><span class="string">    biases are initialized to zero. Weights and biases are stored in the</span></span><br><span class="line"><span class="string">    variable self.params, which is a dictionary with the following keys:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    W1: First layer weights; has shape (D, H)</span></span><br><span class="line"><span class="string">    b1: First layer biases; has shape (H,)</span></span><br><span class="line"><span class="string">    W2: Second layer weights; has shape (H, C)</span></span><br><span class="line"><span class="string">    b2: Second layer biases; has shape (C,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - input_size: The dimension D of the input data.</span></span><br><span class="line"><span class="string">    - hidden_size: The number of neurons H in the hidden layer.</span></span><br><span class="line"><span class="string">    - output_size: The number of classes C.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    self.params = &#123;&#125;</span><br><span class="line">    self.params[<span class="string">&#x27;W1&#x27;</span>] = std * np.random.randn(input_size, hidden_size)</span><br><span class="line">    self.params[<span class="string">&#x27;b1&#x27;</span>] = np.zeros(hidden_size)</span><br><span class="line">    self.params[<span class="string">&#x27;W2&#x27;</span>] = std * np.random.randn(hidden_size, output_size)</span><br><span class="line">    self.params[<span class="string">&#x27;b2&#x27;</span>] = np.zeros(output_size)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, X, y=<span class="literal">None</span>, reg=<span class="number">0.0</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the loss and gradients for a two layer fully connected neural</span></span><br><span class="line"><span class="string">    network.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: Input data of shape (N, D). Each X[i] is a training sample.</span></span><br><span class="line"><span class="string">    - y: Vector of training labels. y[i] is the label for X[i], and each y[i] is</span></span><br><span class="line"><span class="string">      an integer in the range 0 &lt;= y[i] &lt; C. This parameter is optional; if it</span></span><br><span class="line"><span class="string">      is not passed then we only return scores, and if it is passed then we</span></span><br><span class="line"><span class="string">      instead return the loss and gradients.</span></span><br><span class="line"><span class="string">    - reg: Regularization strength.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    If y is None, return a matrix scores of shape (N, C) where scores[i, c] is</span></span><br><span class="line"><span class="string">    the score for class c on input X[i].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If y is not None, instead return a tuple of:</span></span><br><span class="line"><span class="string">    - loss: Loss (data loss and regularization loss) for this batch of training</span></span><br><span class="line"><span class="string">      samples.</span></span><br><span class="line"><span class="string">    - grads: Dictionary mapping parameter names to gradients of those parameters</span></span><br><span class="line"><span class="string">      with respect to the loss function; has the same keys as self.params.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Unpack variables from the params dictionary</span></span><br><span class="line">    W1, b1 = self.params[<span class="string">&#x27;W1&#x27;</span>], self.params[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2, b2 = self.params[<span class="string">&#x27;W2&#x27;</span>], self.params[<span class="string">&#x27;b2&#x27;</span>]</span><br><span class="line">    N, D = X.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute the forward pass</span></span><br><span class="line">    scores = <span class="literal">None</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Perform the forward pass, computing the class scores for the input. #</span></span><br><span class="line">    <span class="comment"># Store the result in the scores variable, which should be an array of      #</span></span><br><span class="line">    <span class="comment"># shape (N, C).                                                             #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment">#                              END OF YOUR CODE                             #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># If the targets are not given then jump out, we&#x27;re done</span></span><br><span class="line">    <span class="keyword">if</span> y <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute the loss</span></span><br><span class="line">    loss = <span class="literal">None</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Finish the forward pass, and compute the loss. This should include  #</span></span><br><span class="line">    <span class="comment"># both the data loss and L2 regularization for W1 and W2. Store the result  #</span></span><br><span class="line">    <span class="comment"># in the variable loss, which should be a scalar. Use the Softmax           #</span></span><br><span class="line">    <span class="comment"># classifier loss.                                                          #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment">#                              END OF YOUR CODE                             #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass: compute gradients</span></span><br><span class="line">    grads = &#123;&#125;</span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Compute the backward pass, computing the derivatives of the weights #</span></span><br><span class="line">    <span class="comment"># and biases. Store the results in the grads dictionary. For example,       #</span></span><br><span class="line">    <span class="comment"># grads[&#x27;W1&#x27;] should store the gradient on W1, and be a matrix of same size #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line">    <span class="comment">#                              END OF YOUR CODE                             #</span></span><br><span class="line">    <span class="comment">#############################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, grads</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self, X, y, X_val, y_val,</span></span></span><br><span class="line"><span class="params"><span class="function">            learning_rate=<span class="number">1e-3</span>, learning_rate_decay=<span class="number">0.95</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            reg=<span class="number">5e-6</span>, num_iters=<span class="number">100</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            batch_size=<span class="number">200</span>, verbose=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Train this neural network using stochastic gradient descent.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (N, D) giving training data.</span></span><br><span class="line"><span class="string">    - y: A numpy array f shape (N,) giving training labels; y[i] = c means that</span></span><br><span class="line"><span class="string">      X[i] has label c, where 0 &lt;= c &lt; C.</span></span><br><span class="line"><span class="string">    - X_val: A numpy array of shape (N_val, D) giving validation data.</span></span><br><span class="line"><span class="string">    - y_val: A numpy array of shape (N_val,) giving validation labels.</span></span><br><span class="line"><span class="string">    - learning_rate: Scalar giving learning rate for optimization.</span></span><br><span class="line"><span class="string">    - learning_rate_decay: Scalar giving factor used to decay the learning rate</span></span><br><span class="line"><span class="string">      after each epoch.</span></span><br><span class="line"><span class="string">    - reg: Scalar giving regularization strength.</span></span><br><span class="line"><span class="string">    - num_iters: Number of steps to take when optimizing.</span></span><br><span class="line"><span class="string">    - batch_size: Number of training examples to use per step.</span></span><br><span class="line"><span class="string">    - verbose: boolean; if true print progress during optimization.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">    iterations_per_epoch = <span class="built_in">max</span>(num_train / batch_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use SGD to optimize the parameters in self.model</span></span><br><span class="line">    loss_history = []</span><br><span class="line">    train_acc_history = []</span><br><span class="line">    val_acc_history = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> it <span class="keyword">in</span> xrange(num_iters):</span><br><span class="line">      X_batch = <span class="literal">None</span></span><br><span class="line">      y_batch = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="comment"># <span class="doctag">TODO:</span> Create a random minibatch of training data and labels, storing  #</span></span><br><span class="line">      <span class="comment"># them in X_batch and y_batch respectively.                             #</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="keyword">pass</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="comment">#                             END OF YOUR CODE                          #</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># Compute loss and gradients using the current minibatch</span></span><br><span class="line">      loss, grads = self.loss(X_batch, y=y_batch, reg=reg)</span><br><span class="line">      loss_history.append(loss)</span><br><span class="line"></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="comment"># <span class="doctag">TODO:</span> Use the gradients in the grads dictionary to update the         #</span></span><br><span class="line">      <span class="comment"># parameters of the network (stored in the dictionary self.params)      #</span></span><br><span class="line">      <span class="comment"># using stochastic gradient descent. You&#x27;ll need to use the gradients   #</span></span><br><span class="line">      <span class="comment"># stored in the grads dictionary defined above.                         #</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="keyword">pass</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line">      <span class="comment">#                             END OF YOUR CODE                          #</span></span><br><span class="line">      <span class="comment">#########################################################################</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> verbose <span class="keyword">and</span> it % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;iteration %d / %d: loss %f&#x27;</span> % (it, num_iters, loss))</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Every epoch, check train and val accuracy and decay learning rate.</span></span><br><span class="line">      <span class="keyword">if</span> it % iterations_per_epoch == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># Check accuracy</span></span><br><span class="line">        train_acc = (self.predict(X_batch) == y_batch).mean()</span><br><span class="line">        val_acc = (self.predict(X_val) == y_val).mean()</span><br><span class="line">        train_acc_history.append(train_acc)</span><br><span class="line">        val_acc_history.append(val_acc)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Decay learning rate</span></span><br><span class="line">        learning_rate *= learning_rate_decay</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">      <span class="string">&#x27;loss_history&#x27;</span>: loss_history,</span><br><span class="line">      <span class="string">&#x27;train_acc_history&#x27;</span>: train_acc_history,</span><br><span class="line">      <span class="string">&#x27;val_acc_history&#x27;</span>: val_acc_history,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Use the trained weights of this two-layer network to predict labels for</span></span><br><span class="line"><span class="string">    data points. For each data point we predict scores for each of the C</span></span><br><span class="line"><span class="string">    classes, and assign each data point to the class with the highest score.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - X: A numpy array of shape (N, D) giving N D-dimensional data points to</span></span><br><span class="line"><span class="string">      classify.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    - y_pred: A numpy array of shape (N,) giving predicted labels for each of</span></span><br><span class="line"><span class="string">      the elements of X. For all i, y_pred[i] = c means that X[i] is predicted</span></span><br><span class="line"><span class="string">      to have class c, where 0 &lt;= c &lt; C.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    y_pred = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Implement this function; it should be VERY simple!                #</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line">    <span class="comment">#                              END OF YOUR CODE                           #</span></span><br><span class="line">    <span class="comment">###########################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure></p></li>
<li><p>graph架构 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 整个Graph</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ComputationGraph</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        <span class="comment"># 1. [pass inputs to input gates...]</span></span><br><span class="line">        <span class="comment"># 2. forward the computational graph</span></span><br><span class="line">        <span class="keyword">for</span> gate <span class="keyword">in</span> self.graph.nodes_topologically_sorted():</span><br><span class="line">            gate.forward()</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> gate <span class="keyword">in</span> <span class="built_in">reversed</span>(self.graph.nodes_topologically_sorted):</span><br><span class="line">            gate.backward()</span><br><span class="line">        <span class="keyword">return</span> inputs_gradients</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个gate</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultipyGate</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;x, y,z: scalars&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        z = x*y</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, dz</span>):</span></span><br><span class="line">        dx = self.y * dz <span class="comment"># [dz/dx * dL/dz]</span></span><br><span class="line">        dy = self.x * dz <span class="comment"># [dz/dy * dL/dz]</span></span><br><span class="line">        <span class="keyword">return</span> [dx, dy]</span><br></pre></td></tr></table></figure></p></li>
<li><p>前向传播的一个例子</p></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># assume some unit gaussian 10-D input data</span></span><br><span class="line">D = np.random.randn(<span class="number">100</span>, <span class="number">500</span>) <span class="comment"># 100， 500</span></span><br><span class="line">hidden_layer_sizes = [<span class="number">500</span>] * <span class="number">10</span></span><br><span class="line">nonlinearities = [<span class="string">&#x27;tanh&#x27;</span>] * <span class="built_in">len</span>(hidden_layer_sizes)</span><br><span class="line"></span><br><span class="line">act = &#123;<span class="string">&#x27;relu&#x27;</span>: <span class="keyword">lambda</span> x: np.maximum(<span class="number">0</span>,x), <span class="string">&#x27;tanh&#x27;</span>: <span class="keyword">lambda</span> x: np.tanh(x)&#125;</span><br><span class="line"></span><br><span class="line">Hs = &#123;&#125;  <span class="comment"># why?</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(hidden_layer_sizes)):</span><br><span class="line">    X = D <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> Hs[i-<span class="number">1</span>]</span><br><span class="line">    fan_in = X.shape[<span class="number">1</span>]</span><br><span class="line">    fan_out = hidden_layer_sizes[i]</span><br><span class="line">    W = np.random.randn(fan_in, fan_out) * <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">    H = np.dot(X, W)</span><br><span class="line">    H = act[nonlinearities[i]](H)</span><br><span class="line">    Hs[i] = H  <span class="comment"># cache result on this layer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ctrl + enter</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># look at distribution at each layer</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;input layer had mean %f and std %f&quot;</span> % (np.mean(D), np.std(D)))</span><br><span class="line">layer_means = [np.mean(H) <span class="keyword">for</span> i, H <span class="keyword">in</span> Hs.items()] <span class="comment"># ?</span></span><br><span class="line">layer_stds = [np.std(H) <span class="keyword">for</span> i, H <span class="keyword">in</span> Hs.items()]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, H <span class="keyword">in</span> Hs.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;hiddeen layer %d had mean %f and std %f&quot;</span> % (i + <span class="number">1</span>, layer_means[i], layer_stds[i]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot the means and standard deviations</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.plot(<span class="built_in">list</span>(Hs.keys()), layer_means, <span class="string">&quot;ob-&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;layer mean&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.plot(<span class="built_in">list</span>(Hs.keys()), layer_stds, <span class="string">&quot;or-&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;layer std&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot the raw distribution</span></span><br><span class="line">plt.figure()</span><br><span class="line"><span class="keyword">for</span> i, H <span class="keyword">in</span> Hs.items():</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="built_in">len</span>(Hs), i+<span class="number">1</span>)</span><br><span class="line">    plt.hist(H.ravel(), <span class="number">30</span>, <span class="built_in">range</span>=(-<span class="number">1</span>,<span class="number">1</span>)) <span class="comment"># ravel, shape to (1, N)</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>gnn</category>
        <category>semi-gnn</category>
      </categories>
      <tags>
        <tag>numpy</tag>
        <tag>gnn</tag>
        <tag>matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel-gnn-overview-paper-summarygnn summary paper read</title>
    <url>/2019/gnn-parallel-gnn-overview-paper-details-b934e0fb32e6/</url>
    <content><![CDATA[<h1 id="abstract">1. Abstract</h1>
<ol type="1">
<li>深度学习应用很广，特别是在图像分类和视频过程识别以及自然语言理解</li>
<li>这些任务的数据都表示在欧式空间中</li>
<li>有其他对于非欧式空间的需求， 将图表示为复杂的关系和交互依赖</li>
<li>图的复杂性很大</li>
</ol>
<p>文章： 1. 一个调查报告，深度学习在数据挖掘和机器学习领域的运用， 2.
将图的状态设计神经网络的计数分为不同的种类 3. 图的建设性的可替代结构,
包括图注意网络，图自动编码器，图生成网络和图的空间瞬时网络结构 4.
接下来，讨论了图的神经网络在各个领域的应用和找了开源代码和benchmark算法针对不同的任务。
5. 最后，提出了有意思的方向</p>
<h1 id="introduction">2. Introduction</h1>
<p>CNN，LSTM,等的成功</p>
<p>!欧式距离 vs 非欧式距离</p>
<p>？
核心机器学习算法样例之间一般互相独立，但是图数据中节点与节点之间有着相互的关系，比如引用，友元，相互作用</p>
<p>如何降低图的复杂性，最基本的方法还是模拟卷积的思想，即卷积核的大小可以来模拟图的不同权重值</p>
<blockquote>
<p>但是不与图像数据相同的是，图中每个节点的邻居节点是无序的而且大小不确定</p>
</blockquote>
<p><font id="fig1" color="red">fig1</font></p>
<p><img data-src="fig1.png" /></p>
<blockquote>
<p>? 这里说的是进行取平均？但是实际是怎么做的啊？</p>
</blockquote>
<h2 id="gnn过去发展的历史">2.1 GNN过去发展的历史</h2>
<p>第一个就是基于卷积的简单表示[21] 基于光谱图理论 [22],[23],[24]
对图的全局做处理，无法很好地并行化和应对大规模图</p>
<blockquote>
<p>这些方法的思想都是直接通过节点的邻居信息的特点， 加采样来做的</p>
</blockquote>
<h2 id="近期的工作">2.2 近期的工作</h2>
<p>其他人做的不好</p>
<h2 id="graph-neural-network-vs-network-embedding">2.3 graph neural
network vs network embedding</h2>
<p>graph neural network grph embedding</p>
<p>network embedding &gt;
目标是将网络节点表示在一个低维空间，并且保留拓扑和本身的内容信息 &gt;
用途是分类，聚类和推荐系统(支持向量机) &gt; 通常是半监督算法，常见类别有
&gt; - matrix factorization &gt; - random walk &gt; - deep learning</p>
<p><img data-src="fig2.png" /></p>
<h2 id="贡献">2.3 贡献</h2>
<ol type="1">
<li><p>新的分类学，五类 graph convolution networks GCN graph attention
networks GAN graph auto-encoders GAE graph generative networks GGN graph
spatial-temporal networks GSN</p></li>
<li><p>易于理解</p></li>
<li><p>丰富的资源</p></li>
<li><p>未来的方向</p></li>
</ol>
<h1 id="definition">3. Definition</h1>
<p><img data-src="table1.png" /></p>
<h1 id="categorization-and-frameworks">4. Categorization and
frameworks</h1>
<h2 id="种类">4.1 种类</h2>
<p><img data-src="works.png" /></p>
<h3 id="gcn">4.1.1 GCN</h3>
<blockquote>
<p>卷积+池化</p>
</blockquote>
<ol type="1">
<li>basic 通过考虑自己和邻居的特征信息，从而学习到表示该节点的函数</li>
</ol>
<p><img data-src="GCN1.png" /></p>
<ol start="2" type="1">
<li>+pooling <font id="GCN" color="red">GCN</font></li>
</ol>
<p><img data-src="GCN2.png" /></p>
<blockquote>
<p>卷积的理解：卷积核主要的目的是利用卷积核的设计使得能够保留原图像的局部信息；并且实现原图像的；卷积实际是一个抽象函数
<a href="https://zhuanlan.zhihu.com/p/54033473">常见的卷积方法</a></p>
</blockquote>
<blockquote>
<p>池化的理解：当对每个图像做完卷积后，如果直接将特征拿去学习会太消耗；所以会考虑使用池化的方法，即学习这些数据中的聚集特征，比如最值、平均值、众数等等
<a
href="https://blog.csdn.net/chenyuping333/article/details/82531047">常见的池化方法</a>
### 4.1.2 GAN Attention,
加入了注意力机制，思想即关注重要信息；主要的做法是为更重要的节点，路径或者模型安排权重</p>
</blockquote>
<blockquote>
<p>目标与GAN相同，试图学习一种新的结点的表达方式，能够整合邻居节点，随机路径和候选模型</p>
</blockquote>
<ol type="1">
<li>Attention vs Convolution</li>
</ol>
<p><img data-src="GAN.png" /> &gt; ???</p>
<h3 id="gae">4.1.3 GAE</h3>
<p>一种半监督学习的框架
目标在于通过编码器学习到低维表示，并能够通过译码器翻译回去</p>
<p>graph embedding</p>
<p><img data-src="GAE.png" /></p>
<h3 id="ggn">4.1.4 GGN</h3>
<p>目标在于从数据中学习到貌似合理的结构</p>
<p>通过一个图的经验分布来产生模型，本身就极具挑战的一件事</p>
<blockquote>
<p>一般的做法是首先形成产生节点和边，是否可替代，然后应用产生对抗训练进行筛选</p>
</blockquote>
<p>应用在化学成分分析中比较多</p>
<h3 id="gsn">4.1.5 GSN</h3>
<p>目标在于学习未见的模式通过暂时性空间结构的图
应用比如在交通预测和人类活动预测，图的结构往往是变化的
主要的想法就是同时考虑空间依赖和瞬时依赖 &gt; 空间依赖——GCNs来做 &gt;
瞬时依赖——RNN或CNN来做</p>
<p><img data-src="GSN.png" /></p>
<h2 id="框架">4.2 框架</h2>
<p>GCNs试图去复试CNN的成功在图中运用spectral theory和spatial
locality信息</p>
<ul>
<li>输入 图的结构信息和节点的内容信息</li>
<li>输出 不同的图的分析任务
<ul>
<li>Node-level
关于节点的回归或者分类任务，只需要直接给出节点的表示，通常用感知机或者softmax函数作为GCN的最后一层</li>
<li>Edge-level
关于边的分类或者链接预测任务。为了预测关于边的lable/connection的强度，一个额外的函数需要能够将两个节点的表示作为输入</li>
<li>Graph-level
关于图的分类任务，为了获得在图级别的联合表示，pooling需要能够把一个图改为子图来求和或者平均节点的表示</li>
</ul></li>
</ul>
<p><strong>main GCNs methods</strong></p>
<p><img data-src="summary.png" /></p>
<p><strong>end-to-end Traning Frameworks</strong></p>
<blockquote>
<p>这里的end-to-end理解是关注输入到输出吧
这里根据训练任务和标记信息是否可以直接获得可以分为监督、半监督和无监督学习</p>
</blockquote>
<ul>
<li>半监督学习 node-level classification.
首先通过部分有标记的图的节点的网络学习到robust model,
它可以高效地为未标记数据进行分类。
end-to-end框架可以通过堆大量的跟随softmax层用来做多标记学习 &gt;
对！这里会给出一个网络结构只有部分节点有标记</li>
<li>监督学习 graph-level classification
给出整个图数据集，图级别的分类任务旨在预测关于整个图的标记
end-to-end框架可以通过GCNs加polling来完成, 最后加些softmax层, <a
href="#GCN">GCN结构</a></li>
<li>无监督学习 graph embedding
这些算法采取两种角度来开发edge-level的信息
<ul>
<li>编码器+译码器</li>
<li>利用负采样的方法，采样一部分节点作为负pairs，并且已经存在一些节点在图中是正样本了，最后应用一个逻辑回归层
&gt; 负采样？？？</li>
</ul></li>
</ul>
<h1 id="graph-convolution-networks">5. Graph Convolution Networks</h1>
<p>spectral-based &gt;
介绍filters从图信号的角度，将卷积的操作看作消除噪声</p>
<p>spatial-based &gt; 从邻居节点收集特征信息</p>
<p>当GCNS操作在node level, pooling可以交替在GCN
layer之间，从而将图转换为高级别的子结构</p>
<h2 id="基于谱分析">5.1 基于谱分析</h2>
<h3 id="基本套路背景">5.1.1 基本套路（背景）</h3>
<p>然后每个节点利用的是拉普拉斯矩阵，以及特征值分解来做 首先，定义 <span
class="math display">\[L=I_n - D^{-1/2}AD^{-1/2}\]</span> robust
数学表示</p>
<p>实际上 <span class="math display">\[L =
\frac{A_{21}+A_{31}+..+A_{n1}}{A_{11}+A_{21}+A_{31}+..+A_{n1}}\]</span>
然后，该矩阵一定为半正定矩阵，所以得到特征向量U和特征值</p>
<p>那么，由可逆运算就可知 <span class="math inline">\(x=U
(U^Tx)\)</span> 然后如果再对x加上一个filter，那么就有 <span
class="math inline">\(x*_G g_\theta = U(U^T(x) .* U^T(g))\)</span> &gt;
这里.*是一种定义的新的运算，就是矩阵的每个元素进行相乘</p>
<p>化简后结果即为 <span class="math display">\[x*_G g_\theta = U
g_\theta U^T(x)\]</span> ？ &gt;
这里实际上就形成了图的卷积操作，这里的关键就在于如何进行设计<span
class="math inline">\(g_\theta\)</span></p>
<h3 id="实际的方法">5.1.2 实际的方法</h3>
<ol type="1">
<li><p>Spectral CNN <img data-src="equation4.png" /> 假设<span
class="math inline">\(g_\theta = \Theta_{i,j}^k\)</span>是可学习的参数
这里假设了转换前和转换后参数的个数，即又称为channel</p></li>
<li><p>Chebysheve Spectral CNN <span class="math inline">\(g_\theta =
\sum_{i=0}^K \theta_i T_k(\widehat{\Lambda})\)</span> 这里<span
class="math inline">\(T_k是递归函数定义\)</span>
经过化简操作，可以发现？？ <span class="math display">\[x*_G g_\theta =
\sum_{i=0}^{K-1} \theta_i T_i(\widehat{L})x\]</span> 这里<span
class="math inline">\(\widehat{L} = 2L/ \lambda_{max} - I_N\)</span>
&gt; 将时间复杂度从O(N^3)降低到了O(KM) 而且<span
class="math inline">\(T_i(\widehat{L})\)</span>计算时，只需要空间中的局部信息。</p></li>
<li><p>1阶ChebNet K=1, <span
class="math inline">\(\lambda_{max}=2\)</span>
该方法沟通了spectial-based和spatial-method。 在batch
training中，随着层数的数量的增加，计算开销会指数级扩张？？？</p></li>
<li><p>Adaptive Graph Convolution Network
为了扩展Laplacian矩阵的应用范围，因为Laplacian矩阵只能建模在无向图上。定义了一个叫做剩余矩阵的东西，可以用用来衡量两个节点之间的距离
尽管可能计算多余的东西，但是时间复杂度只有<span
class="math inline">\(O(N^2)\)</span></p></li>
</ol>
<h3 id="评价">5.1.3 评价</h3>
<p>Spectral CNN依赖于拉普拉斯矩阵的特征值分解 1.
图的任何一点扰乱将导致特征分解的重做 2. 学习到的filter是domin
dependent???, 意味着他们不能应用再一个不一样的结构中 3.
特征分解需要O(N<sup>3)的时间和O(N</sup>2)的空间</p>
<p>ChebNet and 1st ChebNet
学习到的filters定义在局部的空间，所以可以在图的不同位置进行共享。</p>
<p><strong>总结</strong> 关于该方法需要将所有图加载到内存中进行graph
convolution, 不利于解决大的图???ChebNet</p>
<h2 id="spatial-based">5.2 Spatial-based</h2>
<p><a href="#fig1">Fig1</a> figA,
对于image而言，每个像素点直接与周围的像素点像关联 figB,
为了扩展节点能容纳的深度和宽度，一个常用的方法就是将图的多个卷积层叠加在一起</p>
<p>Recurrent-based: same graph convolution layer来更新隐藏的表示</p>
<p>Composition-based: differnt graph convolution layer</p>
<p>比较</p>
<p><img data-src="rb-cb.png" /></p>
<h3 id="recurrent-based">5.2.1 Recurrent-based</h3>
<ul>
<li>impose constraints on recurrent functions</li>
<li>employ gate recurent unit architectures</li>
<li>update node latent representations asynchronously and
stochastically</li>
</ul>
<h4 id="graph-neural-networks">1) Graph Neural Networks</h4>
<p>递归计算直到收敛，扩散直到相等</p>
<p><span class="math display">\[h_v^t = f(l_v,, l_{co}[v],
h_{ne}^{t-1}[v], l_{ne}[v])\]</span></p>
<p><span class="math inline">\(l_v\)</span>-node v的属性 <span
class="math inline">\(l_{co}[v]\)</span>-node v相关的边的属性 <span
class="math inline">\(h_{ne}^{t-1}[v]\)</span>-v's 邻居在第t步的表示
<span class="math inline">\(l_{ne}[v]\)</span>- v's邻居的属性</p>
<p>为了保障收敛，f函数应该是收缩映射的
f是神经网络，那么对于参数的雅克比矩阵？应该得到惩罚</p>
<p>the Almeida-Pineda algorithm #### 2) Gate Graph Neural Networks gated
recurrent units——循环函数 recurrence循环</p>
<p><span class="math display">\[h_v^t = GRU(h_v^{t-1}, \sum_{u \in N(v)}
W h_u^t)\]</span></p>
<p>与GNN不同的是，GGCN通过时间上的后向传播来传递参数。</p>
<p>好处是不用保证收敛性，缺点会牺牲时间和空间上的效率，需要多次在全部节点上计算recureent函数，以及需要将所有状态都存储在内存中</p>
<h4 id="stochastic-steady-state-embedding">3) Stochastic Steady-state
Embedding</h4>
<p>SSE： 每个GCN,
随机地选取t个节点，进行更新表示然后随机第选取P个已经更新？的节点来更新梯度</p>
<p>为了提高预测效率，SSE随机异步地更新节点的表示。为了保证收敛性，recurrent函数定义为了历史状态和新状态的平均权重</p>
<p><span class="math display">\[h_v^t = (1-\alpha ) h_v^{t-1} +
\alpha  W_1 \delta (W_2[x_v, \sum_{u \in N(v)} [h_u^{t-1},
x_u]])\]</span></p>
<p><img data-src="SSE.png" /></p>
<h3 id="composition-based">5.2.2 Composition Based</h3>
<p>构成</p>
<h4 id="message-passing-neural-networks">1) Message Passing Neural
Networks</h4>
<p>产生已经存在的图卷积神经网络的一个框架。</p>
<p>包括两部分 - message passing phase</p>
<p>通常运行T步的基于空间的图神经网络算法。
图神经网络定义了一个信息函数和一个更新函数</p>
<p><span class="math display">\[h_v^t = U_t (h_v^{t-1}, \sum_{w \in
N(v)} M_t(h_v^{t-1}, h_w^{t-1},e_{vw}))\]</span></p>
<blockquote>
<p><span class="math inline">\(M_t\)</span>信息函数， <span
class="math inline">\(U_t\)</span>更新函数</p>
</blockquote>
<ul>
<li>readout phase</li>
</ul>
<p>通常对应于池化操作，产生基于整个图的一个表示</p>
<p><span class="math display">\[\widehat{y} = R(h_v^T | v \in
G)\]</span></p>
<p><span
class="math inline">\(\widehat{y}\)</span>用来做最终的graph-level的任务</p>
<blockquote>
<p>需要确定不同形式的Ut()和Mt()</p>
</blockquote>
<h4 id="graphsage">2) GraphSage*</h4>
<p>使用聚合的概念定义图的卷积</p>
<blockquote>
<p>?必须保证对节点的聚合值的排序的排列，那么其他的需要保证吗？ 使用mean,
sum, max等函数</p>
</blockquote>
<p><span class="math display">\[h_v^t = \delta(W_t \cdot aggregate_t
(h_v^{t-1}, \{h_u^{t-1}, \forall u \in N(v)\})\]</span></p>
<p>这里不是更新所有节点，而是进行batch-traning,适合扩展，说明是可以扩展到很大的数据集的？</p>
<p>3 steps 1. 对一个节点的k-hop邻居节点进行固定大小的采样 ？ &gt;
这里的采样范围是什么？ 一个圆吧 2.
通过聚集邻居节点的所有信息，最终产生该中心节点的最后状态 3.
使用中间节点的最终状态来做预测和前馈错误</p>
<p><img data-src="GraphSage.png" /></p>
<p>假定<span class="math inline">\(t^{th}\)</span>hop的邻居数量是<span
class="math inline">\(s_t\)</span>, one batch的时间复杂度为 <span
class="math inline">\(O(\prod _{t=1}^T s_t)\)</span>, 指数级别 &gt;
作者发现t=2是GraphSage已经取得很好的成绩</p>
<h3 id="miscellaneous-variants-of-spatial-gcns">5.2.3 Miscellaneous
Variants of Spatial GCNs</h3>
<h4 id="dcnn-扩散卷积神经网络">1) DCNN 扩散卷积神经网络</h4>
<blockquote>
<p>encapsulates 压缩</p>
</blockquote>
<p>通过图卷积网络压缩图的扩散过程</p>
<p>一个隐藏的节点的表示通过将输入 ？ 得到状态转移矩阵</p>
<p>维度搞</p>
<p><span class="math display">\[Z_{i,j,:}^m = f(W_{j,:} \odot
P_{i,j,:}^m X_{i,:}^m)\]</span></p>
<p>P是概率，X是特征， W是权重 &gt; 这里H是什么？ 应该是表示值什么的吧？
尽管转移矩阵的高维中覆盖了大量的域，需要<span
class="math inline">\(O(N_m^2H)\)</span>的内存，会造成巨大的问题 #### 2)
PATCHY-SAN</p>
<p>用一个标准的卷积神经网络CNN来解决图分类问题 graph classification
tasks</p>
<p>将图结构数据转换拿为网格结构数据</p>
<ol type="1">
<li>给每个节点安排一个排序，基于的标准有多种多样，比如度，形成图的标记</li>
<li>为每个节点根据图的标记选择固定数量的邻居节点</li>
<li>使用标准的CNN来进行学习</li>
</ol>
<p>CNN的优点：能够基于排序保证移动不变性</p>
<h4 id="lgcn">3) LGCN</h4>
<p>建议基于节点特征的信息进行排序</p>
<p>vs PATCHY-SAN:</p>
<p>产生
node-level输出，对于每个节点聚集了关于邻居节点的特征矩阵，然后再特征矩阵中为每列进行排序，
将头k行的排序特征作为输入</p>
<p>在最后，采用1D CNN在相关的输入上得到隐藏节点的表示</p>
<blockquote>
<p>PATCHY-SAN需要没复杂的预处理，而LGCN不需要预处理。
LGCN建议了子图训练的策略，即使用一小部分样本的子图进行min-batch</p>
</blockquote>
<h4 id="mixture-model-network">4) Mixture Model Network</h4>
<p>试图利用标准的CNN来统一非欧式空间域 &gt;
大部分基于空间的方法在考虑的时候都忽略了节点与邻居将的相对位置关系</p>
<p>做的方法就是为每个邻居节点的关系进行定义，然后赋值不同的权重。</p>
<blockquote>
<p>绝大部分采用CNN,也有用GCN的
MoNet建议了使用高斯核来进行学习参数来动态调节权重</p>
</blockquote>
<h3 id="summary">5.2.4 Summary</h3>
<p>循环神经网络获得节点的稳定状态
基于组成的方法试图集合高级别有用的信息</p>
<p>两种结构中，每一层在训练中都需要更新所有节点隐藏的状态，但是内存往往很难将这些状态存下。</p>
<p>所以，进行子图训练的方法： 1. GraphSage 2. 随机异步训练的方法 SSE</p>
<p>但近几年的进步还是通过空间方法来建立更复杂的网络机构 1.
用门控机制来控制节点的深度和宽度 GeniePath 2.
设计两个图的卷积网络来切入本地的一致性和全局一致性 DuraGCN 3.
超参数来影响节点接收域的大小</p>
<h2 id="图池化模块">5.3 图池化模块</h2>
<p>很重要， CNNs, down-sampling</p>
<p>其中，mean/max/sum
pooling是最原始和最有效的加快计算，降低维度的方法</p>
<p><span class="math display">\[h_G = mean/max/sum(h_1^T, h_2^T, \cdots,
h_n^T)\]</span></p>
<p>已经证明，先池化可以减少傅里叶开销</p>
<p>ChebNet 对输入图形首先进行coarsen处理，如图5a;
其次，顶点的输入和coarsen后的版本在平衡二叉树中得到了改进。
当节点最粗糙的版本传递到了平衡二叉树的最低级别时产生了一个特别好的信号，池化带来巨大好的效果</p>
<p>DGCNN SortPooling,
先按SortPooling得到一个顺序，再依次取出这些点染成WL colors,
再排序。根据排序的结果取最有用的前k个，如果不够则置为默认值(0).</p>
<p>这个方法增加了池化网络来解决一个图结构的任务，该任务需要保证排列不变性</p>
<p>DIFFPOOL</p>
<p>产生图分层的表示，然后不止于CNNs相结合，并且考虑使用其他变化的神经网络结构。
&gt; 池化层嘛，所以难道这里说的是这里的池化层可以处理不同CNNs来的东西
与之前的方法相比，不再简单地聚聚一个图中的节点，而是提供一种大类的解决办法来分等级低池化不同的输入图
&gt; 这里的意思是该框架可以对不同的图进行操作吗？</p>
<p>主要的想法是学习一个cluster S在不同的层次l代表不同的内容，如<span
class="math inline">\(S^{(l)} \in R^{n_l \times n_l +
1}\)</span>.两个分割的GNNs同时处理两个输入cluster的节点特征<span
class="math inline">\(X^{(l)}\)</span> 以及coarsened的邻接矩阵<span
class="math inline">\(A^{(l)}\)</span>用来产生新的分配矩阵<span
class="math inline">\(S^{(l)}\)</span>以及embedding矩阵<span
class="math inline">\(Z^{(l)}\)</span> <span
class="math display">\[Z^{(l)} = GNN_{l,embed}(A^{(l)},
X^{(l)})\]</span></p>
<p><span class="math display">\[S^{(l)} = softmax(GNN_{l,pool}(A^{(l)},
X^{(l)}))\]</span></p>
<blockquote>
<p>？？？ cluster在这里是指啥意思？？，聚集的意思，
等于是分层，l是层次，所以说这里l是input的第l个元素？，然后A,X是每个元素的特征？</p>
</blockquote>
<p>可扩展到多种标准的GNN模块，他们拥有相同的数据输入，却有种不同的参数，因为各自的角色不同。
<span class="math inline">\(GNN_{l,embed}\)</span>可以产生新的embeddings
而<span
class="math inline">\(GNN_{l.pool}\)</span>产生输入节点可能安排到哪个clusters的一个指派。
结果，<span class="math inline">\(S^{(l)}\)</span>的每一行代表一个<span
class="math inline">\(n_l\)</span>节点或者clusters在layer l,
每一列表示下一层的<span class="math inline">\(n_l\)</span>.
一旦我们拥有了<span class="math inline">\(Z^{(l)}\)</span>和<span
class="math inline">\(S^{(l)}\)</span> <span
class="math display">\[X^{(l+1)} = S^{(l)^T} Z^{(l)} \in R^{n_{l+1}
\times d}\]</span> &gt; 通过S的支配去Z的新的embdding中计算新的X的表示,
初始化的Z应该为节点的表示 <span class="math display">\[A^{l+1} =
S^{(l)^T} A^{(l)} S^{(l)} \in R^{n_{l+1} \times n_{l+1}}\]</span> &gt;
使用邻接矩阵为输入，然后产生一个变粗的coarsened的邻接矩阵，根据clusters中每个pair的链接性的强弱
总之，DIFFPOOL重定义了图的pooling模块，通过使用两个GNNs来聚集节点。
任何一个标准的GCN模块都可以进行联合，不仅可以使性能增强，还可以加快卷积的速度</p>
<blockquote>
<p>两个GNNs,
一个来获得新的表示，一个来获得新的指派；如果是多个，是用来构成一个大矩阵的吗？</p>
</blockquote>
<h2 id="对比-spectral-and-spatial">5.4 对比 Spectral and Spatial</h2>
<p>在早期，主要的进步是靠基于频域的，但是有着明显的缺点。 - efficiency:
图一改变就需要重新特征分解， 基于空间的可以只训练a batch of nodes,
当节点增加时，可以使用sampling技术来提高效率 - generality:
基于频域的假定一个固定的图，使他们普遍变为一个新的不同的图。基于空间
的图，他们在每个节点上做卷积，他们的权重依然被不同的位置和结构共享 -
flexibility:
基于频域的只适用于无向图，Laplacian矩阵并未在有向图上有很好的定义，唯一的方法只有将有向图转为无向图。基于空间的更加灵活，可以处理多源的输入，比如边的特征和方向，因为这些输入可以聚集在聚集函数中
所以， 基于空间的模型更受欢迎</p>
<h1 id="beyond-graph-convolutional-networks">6. Beyond Graph
Convolutional Networks</h1>
<h2 id="gan">6.1 GAN</h2>
<p>注意力机制在序列基准的任务中已经成为了标准，优点在于能够集中在最重要的东西。
这一特性被证明是非常重要的。</p>
<p>用注意力带来很多很出，在聚集的时候 ### 6.1.1 方法</p>
<h4 id="gat">1) GAT</h4>
<p>就是考虑所有邻居节点的表示和考虑邻居节点的权重 &gt;
不同的子空间是指的，随着当前所处的不同位置，可能得到的数据不同，所以就把所有子空间的邻居节点的位置堆叠吗。感觉是这样的</p>
<p><span class="math display">\[h_i^t = \delta(\sum_{j \in N_i} \alpha
(h_i^{t-1},h_j^{t-1}) W^{t-1}h_j^{t-1})\]</span></p>
<p><span
class="math inline">\(\alpha(\cdot)\)</span>是注意力函数，控制节点和邻居节点之间的贡献
为了在不同的子空间中学习权重</p>
<p><span class="math display">\[h_i^t = ||_{k=1}^K \delta(\sum_{j \in
N_i} \alpha_k (h_i^{t-1},h_j^{t-1}) W_k^{t-1}h_j^{t-1})\]</span></p>
<p>这里||表示级联 &gt; ?</p>
<h4 id="gaan">2) GAAN</h4>
<p>考虑multi-head, 不过不是分配等选中，屙屎进行不同的权重分配</p>
<p><img data-src="equation22.png" /> #### 3) GAM
循环神经网络来解决图分类问题，通过访问不同序列的重要节点来展示图的各部分的信息
<img data-src="equation23.png" /> <span
class="math inline">\(f_h(\cdot)\)</span>是LSTM网络 <span
class="math inline">\(f_s\)</span>是网络在过程中选取当前节点的邻居，并且优先选取有高排名的节点，它有policy
network生成</p>
<p><span class="math display">\[r_t = f_r(h_t;\theta_r)\]</span>
其中<span
class="math inline">\(r_t\)</span>是随机排名向量预测哪个节点更加重要，从而应该给该节点配置更高的优先级
<span
class="math inline">\(h_t\)</span>包含了历史信息，agent已经从图中获得的。agent是用来给图的标记做预测的
#### 4) Attention Walks 不像DeepWalk使用固定的先验，Attention
Walks产生共现矩阵通过不同的注意力权重</p>
<p><span class="math display">\[E[D] = \tilde{P}^{(0)} \sum_{k=1}^C a_k
(P)^k\]</span> 这里D是共现矩阵 <span
class="math inline">\(P^{(0)}\)</span>是初始化矩阵
P指示转移矩阵的概率</p>
<h3 id="总结">6.1.2 总结</h3>
<p>注意力机制对图神经网络有3种方式 1.
在整个邻居节点时为每个邻居赋予不同的权重 2. 通过注意力权重整合多个模型
3. 通过注意力来指导random walks</p>
<p>它们同时也可以认为是基于空间的卷积神经网络
GAT和GAAN的优点在于可以动态学习邻居节点的权重
但是会带来时间和空间的消耗，当每对邻居被计算的时候</p>
<p><img data-src="GAN.png" /></p>
<h2 id="gae-1">6.2 GAE</h2>
<p>GCN, GCN+GAN, LSTM+GAN来设计图的自动编码</p>
<h3 id="gcn-based">6.2.1 GCN based</h3>
<h4 id="gae-2">1) GAE</h4>
<p><span class="math display">\[Z=GCN(X,A)\]</span> decoder: <span
class="math inline">\(\tilde{A} = \delta (Z Z^T)\)</span></p>
<p>优化目标为最小variational lower bound &gt; 简单理解为之间的距离 <img
src="equation28.png" /></p>
<h4 id="agra">2) AGRA</h4>
<p>GCN做编码器</p>
<p>GANs 采用min-max策略在产生和测试之间训练生成模型。
一个生成器同概率生成真假模型 然后测试器在真的样例中区分出假的样例</p>
<p>GANs使得节点的表示服从某个先验分布</p>
<p>生成器生成假的模型，测试其判断得出真的模型</p>
<h3 id="混合变体">6.2.2 混合变体</h3>
<ol type="1">
<li>NetRA</li>
</ol>
<p>与ARGA想法相同，不过它还正则化节点的隐藏表示，使其服从先验分布，在对抗性训练的同时。
不是重建邻接矩阵，它是恢复节点的序列，通过sequence-to-sequence结构的random
walks中采样得到</p>
<ol start="2" type="1">
<li>DNGR 用堆叠的降噪的自动编码器来重建pointwise的互信息矩阵PRMI
当图形采用random walks进行序列化得到的序列是 PRMI捕捉到节点的共现矩阵
<img data-src="equation29.png" /></li>
</ol>
<p>其中<span class="math inline">\(|D|=\sum_{v_1,v_2}
count(v_1,v_2)\)</span></p>
<p>堆叠的降噪的自动编码器能够学习到高度非线性的规律，不同于传统的神经自动编码器，它增加了输入的噪声，通过随机地将输入入口置为0
当缺失值存在时，学习的潜力也就越大</p>
<ol start="3" type="1">
<li>SDNE 保护一阶接近度和二阶联合</li>
</ol>
<p>一阶proximity定义为节点隐藏表示和邻居节点隐藏表示之间的距离，
目标是尽可能让表示互相接近，特别地，loss函数可以定义为 <span
class="math display">\[L_{1st}=\sum_{i,j=1}^n A_{i,j} ||h_i^{(k)} -
h_j^{(k)}||^2\]</span>
第二节proximity定义为节点的输入和重新构造之间的距离。输入是邻接矩阵中对应的行，目标是用来保护邻居节点的信息，损失函数定义为
<span class="math display">\[L_{2nd}=\sum_{i=1}^n ||(\hat{x}_i-x_i)\odot
b_i||^2\]</span> <span
class="math inline">\(b_i\)</span>是用来惩罚非0元素的输入的，当矩阵高度稀疏时
当<span class="math inline">\(A_{i,j}=0\)</span>, <span
class="math inline">\(b_{i,j}=1\)</span>;<span
class="math inline">\(A_{i,j}&gt;0\)</span>, <span
class="math inline">\(b_{i,j}&gt;1\)</span> 因此，总的目标函数就定义为
<span class="math display">\[L = L_{2nd} + \alpha L_{1st} + \lambda
L_{reg}\]</span></p>
<ol start="4" type="1">
<li>DRNE 重建的目标是节点表示，而不是整个图的数据</li>
</ol>
<p>loss function <span class="math display">\[L = \sum_{u \in V} ||h_v -
aggregate(h_u \in N(v)||^2\]</span></p>
<p>LSTM作为聚集函数来聚集根据阶排完的节点的序列</p>
<h3 id="总结-1">6.2.3 总结</h3>
<p>DNGR和SDNE仅仅使用了图的拓扑数据，
GAE,ARGA,NetRA,DRNE同时考虑了两方面</p>
<p>最大的挑战是关于邻接矩阵的稀疏性，导致译码器的正实体的数量远远小于负实体，为了解决这个办法，DNGR构造了密集矩阵，SDNE为0实体处理了惩罚，GAE重新赋值了权重，NetRA将图线性化为序列</p>
<h2 id="ggn-1">6.3 GGN</h2>
<p>目标是通过观察一系列图产生图。 大部分的方法都是domin specific.
化学分子图SMILES, 一些工作提供可替代性的点或边，然后进行对抗性训练 GCN
building blocks或用其他不同的结构</p>
<h3 id="gcn-based-1">6.3.1 GCN based</h3>
<ol type="1">
<li>MolGAN 整合了GCN,提高的GAN和RL来产生图。
GAN包括产生器和测试器，与其他一起竞争从而提高产生器的真实性。
产生器试图产生真实的数据，测试器试图辨别。然后还会再增加一个奖惩网络</li>
</ol>
<p><img data-src="MolGAN.png" /></p>
<ol start="2" type="1">
<li>DGMG spatial-based graph convolution networks来获得图的表示。
产生图的节点和边有产生的图的表示来决定</li>
</ol>
<p>加入一个顶点到增长的图，如此递归操作, 直到达到停止的标准
当decision变为false时，开始加边 当decision为true,
它会评估将性加入的节点连接到已存在的节点的可能性分布，并且由分布随机选择一个节点，
当一个新的节点和它的连接都被加入到图中后，DCMG再次更新图的表示</p>
<h3 id="杂项">6.3.2 杂项</h3>
<ol type="1">
<li><p>GraphRNN 扩展深度图产生模型通过两个级别的循环神经网络。
graph-level RNN增加一个节点到一个节点序列 edge--level
RNN产生一个二进制序列只是新节点和之前产生节点之间的链接 为了训练graph
level RNN 为了将图线性化为序列，GrapRNN采用BFS. 为了建模edge-level RNN,
GraphRNN假设多元伯努利分布或条件伯努利分布</p></li>
<li><p>NetGAN 联合LSTM和Wassertein GAN通过random-walk-based方法来产生图
该框架包括两个模块，产生器和测试器
产生器尽可能去通过LSTM来产生最合理的random walks,
测试器尽可能地辨别其中的真假 经过训练，就会获得节点的共现矩阵</p></li>
</ol>
<h3 id="总结-2">6.3.3 总结</h3>
<p>大问题，不像同步的图像和音频，可以直接由专家判断判断，质量无法评估。
MolGAN和DCNG用来很多额外的知识来评估产生的图的合理性。
GrapRHH和NetGAN通过图的统计数据，比如图的阶数来做
DCNG和GrapRNN产生节点和边序列化的方式 MolGAN和NetGAN共同产生节点和边</p>
<p>之前的方法的问题在于，随着图变大，产生一个长的序列必然带来问题。
后面的方法是一个图的全局属性很难维护
最近的方法采用了变化的自动编码器来产生图，建议了使用惩罚机制的邻接矩阵，然而会增加输出空间从n到n^2
还没有方法具有很好的大规模可扩展性</p>
<h2 id="gsn-1">6.4 GSN</h2>
<p>需要同时维护空间和瞬时性因素。
这类图往往有一个全局的图结构，但是会随着时间而改变
交通中，每个传感器作为一个节点记录交通的速度，边作为节点之间的距离，
图的任务就是预测节点将来的值或者标记，以及图的标记</p>
<p>GCNs, GCN+RNN/CNN, 循环结构</p>
<h3 id="gcn-based-2">6.4.1 GCN based</h3>
<ol type="1">
<li>DCRNN 扩散的卷积——空间因素 GRU序列到序列的结构——瞬时</li>
</ol>
<ul>
<li>空间 <img data-src="equation34.png" /> <span
class="math inline">\(D_O\)</span>是出度矩阵，<span
class="math inline">\(D_I\)</span>是入度矩阵 为了允许多输入输出channel
<img data-src="equation35.png" /></li>
</ul>
<p>P是输入的channel的数量 - 瞬时
循环单元会同时接收上一步临时节点的历史信息和邻居节点的卷积信息。
GRU-&gt;DCGRU <img data-src="equation36.png" />
为了适应多步的需求，采用sequence-to-sequence的结构</p>
<ol start="2" type="1">
<li><p>CNN-GCN 1D-CNN和GCN学习spatial-temporal 图数据 对于一个输入tensor
<span class="math inline">\(X \in R^{T \times N \times D}\)</span>,
1D-CNN随着时间轴来收集每个节点的瞬时性信息<span
class="math inline">\(X_{[:,i,:]}\)</span>
GCN操作来聚集空间信息，在每次的时间步骤中， <span
class="math inline">\(X_{[i,:,:]}\)</span>
收集空间信息，输出层是一个线性信息，产生关于每个节点的预测</p></li>
<li><p>ST-GCN
扩展不同的时间流来作为图的边用一个统一的GCN模型来统计两种信息
它还有一个标记函数来为每个边安排标记，根据两个相关节点之间的距离
所以，邻接矩阵可以用一个K邻接矩阵的求和来表示，K是标记的数量
它应用GCN到不同的权重到K个邻接矩阵上，并且求和他们 <img
src="equation37.png" /> ### 6.4.2 杂项</p></li>
</ol>
<ul>
<li>Structural-RNN 目标是预测节点在每个时间节点的标记
它包括两种类型的RNN，nodeRNN和edgeRNN
每个节点和边的瞬时信息由nodeRNN和edgeRNN传递
因为不同的RNN对不同的节点和边会急剧地增加模型的复杂性，所以他们代替为将nodes和edges活粉到不同的语义组。
比如，一个人主题关系图，包括多种两组节点，人节点和物品节点；三种边，人与人的边，人与物品的边，人与物品的边。
在同一语义组的节点或边使用相同的RNN模型
为了合并空间信息，nodeRNN将会将edgeRNN的输出作为输入</li>
</ul>
<h3 id="总结-3">6.4.3 总结</h3>
<p>DCRNN的优点在于能够处理长时间，因为它的循环神经网络结构
CNN-GCN会更优效率得益于1D CNN
ST-GCN考虑瞬时流作为节点的边，将会导致邻接矩阵平方式地增长。一方面，会增加计算图卷积层的计算开销。另一方面，为了捕捉长期依赖，卷积层需要堆叠很多次。
Structural-RN提高了模型的效率，通过共现相同的RNN在同语义组中。但是，它需要人们的先验知识来分割语义组</p>
<h1 id="applications">7. Applications</h1>
<p>很多的应用，文学 4类数据集</p>
<p>开源的图神经网络</p>
<p>实际的运用在各种领域</p>
<h2 id="datasets">7.1 Datasets</h2>
<ol type="1">
<li>Citation Networks 引用网络
数，作者和他们之间的引用关系，作者之间的创作关系。
无向图，相关的任务比如node classification, link prediction, node
clustering tasks</li>
</ol>
<p>三个有名的数据集 - Cora: 7个类 - Citeseer：6个类 - Pubmed：
通过TF-IDF向量来宝石 - DBLP: 计算机科学书目，参考文献</p>
<ol start="2" type="1">
<li>Social Networks 网上服务用户之间的相互关系</li>
</ol>
<ul>
<li>BlogCatalog: bloggers, label就是兴趣</li>
<li>Reddit:
无向图，论坛收集到的帖子，两个帖子之间可能包含相同用户者的评论</li>
<li>Epinions:
多关系图，关于一件在线商品的评论，其中评论可能有多种关系，trust,
distrust, coreview, co-rating</li>
</ul>
<ol start="3" type="1">
<li>Chemical/Biological Graphs 化学元素的组成可以用化学原子作为点，
化学键作为边组成 &gt; 由此来考虑产生图分类任务 graph classification
performance</li>
</ol>
<ul>
<li>NCI-1 NCI-9</li>
<li>MUTAG</li>
<li>D&amp;D 蛋白质结构，属于两种</li>
<li>QM9 分子式</li>
<li>Tox21</li>
</ul>
<ol start="4" type="1">
<li>Unstructured Graphs 无结构图
为了探索图神经网络在无结构化数据上的泛化性，k-NN使用最广泛</li>
</ol>
<ul>
<li><p>MNIST: 70000 28*28 &gt; ? convert to graph:
8-NN?graph基于像素的位置</p></li>
<li><p>Wikipedia dataset &gt; 单词共现网络</p></li>
<li><p>NewsGroup datasets 多个文档被划分为了20多种类别 &gt;
将文档作为节点，相似性作为节点的边的权重</p></li>
</ul>
<ol start="5" type="1">
<li>Others</li>
</ol>
<ul>
<li>METR-LA: 交通数据库</li>
<li>MOvieLens-1M: 6k用户为1million商品的排序,推荐系统的基准</li>
<li>NELL： 语言学习项目，事实以及实体之间的关系 <img
src="datasets.png" /></li>
</ul>
<h2 id="benchmarks-开源扩展">7.2 Benchmarks 开源扩展</h2>
<p>最常用的数据集 Cora, Pubmed, Citesser, PPI
大量的超参数，需要开源的程序才能获得同样的结果 <img
src="methods.png" /></p>
<p>开源代码 <img data-src="open-codes.png" /></p>
<h2 id="实际运用">7.3 实际运用</h2>
<p>GNNs 用于节点聚类，关系预测，图划分</p>
<ul>
<li>Computer Vision 计算机视觉
最大的应用，通过利用图神经网络探索视频中的图形结构，进行点云分类和分割，动作识别以及其他方向
在场景图的生成过程中，语义之间的关系有利于理解视觉场景背后的意义</li>
</ul>
<p>通过给定图片场景，图生成模型检测和识别物体以及预测物体之间的语义关系</p>
<p>另一个应用就是通过给定的场景图生产实际的图像</p>
<p>每个自然语言解释为一个对象，那么就可以根据给定的语义说明类构件出图像</p>
<p>在点云分类和分割中，一个点云通常被看做是一个3D点。那么更觉设备探索周围的㕂，有可以识别出有问题的汽车。
为了辨别物体通过点云，将点云转化为k邻居图或者抄点图，可以用图结构来探索其拓扑结构
&gt; 点云？？</p>
<p>在动作识别中，可以将人的关节分解，架构成图，从而用空间瞬时网络结构来学习人的动作行为</p>
<p>图像分类，人与人之间的行为，语义分割，视觉推理和问题解答</p>
<ul>
<li><p>推荐系统
得到高质量的推荐，推荐的关键就是为一个物品的重要性为用户打分。link
prediction</p></li>
<li><p>交通 graph based
空间瞬时图，路建模成点，路之间的距离建模成边，每个时间段的值建模为特征，目标来预测在某个时间段某段路的平均速度。
节省资源和节约能源</p></li>
</ul>
<p>taxi-demand prediction
给出taxi需求的历史数据，位置信息，天气信息和时间特征，可以德奥一个对于每个位置的joint表达，从而来一段时间内的汽车需求</p>
<ul>
<li>化学 学习化学式的结构</li>
</ul>
<p>node 分类，图分类，图形生成
在分子图上，学习分子指纹，预测分子特性，推理蛋白质种类，合成化学物</p>
<ul>
<li>其他</li>
</ul>
<p>节目评测，时间推理，社会原因分析，恐怖时间预测等等 # 8. Future
Directions 图的复杂性 ## Go Deep
深度的网络结构，经过无限次的卷积，所有节点的表示可以聚集为一个单节点；所以提高层数仍然是一个好的办法
## Receptive Field &gt; 感受野？？？ 什么东西？
这里的意思就是一个节点的感受野就是指中心节点以及他的所有邻居节点。
邻居的数量服从一个合法的分布，每个节点可能有一个邻居，可能多成千上百个邻居
采样引入后，任何选择一个节点的感受野值得研究 ## Scalability
可扩展性，大规模的图并不能扩展的很好。
主要的原因是当打包层次的图卷积时，该节点的最终装填会引起邻居的最终状态的改变，所以就会带来高复杂性的后向传播
现有的解决办法有快采样和子图训练，但是不够可扩展来解决大规模图的深度结构
## 动力学和异质性 现有的图神经网络做的都是静态的同质的图。
一方面，图的结构需要固定，另一方面，节点和边是同一来源。这两个假设不符合实际情况
比如在社会网络中，有人加入和退出 在推荐系统中，输入可能为图形或者文字
所以需要考虑新的方法</p>
]]></content>
      <categories>
        <category>gnn-parallel</category>
        <category>gnn</category>
      </categories>
      <tags>
        <tag>gnn-parallel</tag>
        <tag>gnn</tag>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>gnn-parallel gnn semi-gnn paper read</title>
    <url>/2019/gnn-parallel-gnn-semi-gnn-paper-read-1c84427ec79e/</url>
    <content><![CDATA[<h2 id="introduction">1. Introduction</h2>
<p>半监督学习步骤： 1. 选取标记数据，划分为训练集、验证集和测试集 2.
根据数据进行学习、训练模型</p>
<ul>
<li><p>模型目标函数 <span class="math display">\[\mathcal{L} =
\mathcal{L}_0 + \lambda \mathcal{L}_{reg}\]</span> 这里， <span
class="math inline">\(\mathcal{L}_0 = \sum_{(\vec{x}, y)} H(\vec{x},
y)\)</span> <span class="math inline">\(\mathcal{L}_{reg}=\sum_{i,j}
A_{ij} ||f(x_i)-f(x,j) ||^2 = f(X)^T (D - A) f(X)\)</span> &gt; 这里
<span class="math inline">\(D_{ii}=\sum_j A_{ij}\)</span>为对角矩阵,
该正则化项是二范数，所以<span
class="math inline">\(\lambda\)</span>为L2参数</p>
<p>其中 <span class="math inline">\(H(\vec{x}, y) = - \sum_i y&#39;_i
log y_i\)</span>， 表示交叉熵损失函数 &gt;
使用交叉熵损失函数式，上一步为softmax函数，即指数标准化函数; <span
class="math inline">\(y&#39;_i\)</span>是即真实类别，<span
class="math inline">\(y_i\)</span>是对应节点最终得出来的关于某个类别的概率</p>
<p>进一步， <span class="math display">\[y = softmax(\hat{A}\
ReLU(\hat{A}XW^{(0)})\ W^{(1)})\]</span> &gt;
y是深度神经网络预测出来的每个类别的概率的矩阵, 这里是三层的公式</p>
<p>多层的公式即为，<span class="math inline">\(y = softmax(\tilde{A}\
ReLU(\tilde{A}\ ReLU(...)\ W^{(n-1)})\ W^{(n)})\)</span></p>
<p>在这里层与层之间的更新公式有两种：</p>
<ul>
<li><span class="math inline">\(X^{(l+1)} = \delta
(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} X^{(l)}
W^{(l)})\)</span>
<ul>
<li><span class="math inline">\(\tilde{A}=A+I_N\)</span>:
这里增加考虑了自己的因素;</li>
<li><span class="math inline">\(\tilde{D}_{ii}=\sum_j
\tilde{A}_{ij}\)</span></li>
<li><span class="math inline">\(W_{(l)}\)</span>是每层的权重</li>
<li><span class="math inline">\(\delta\)</span>是激活函数，比如<span
class="math inline">\(ReLU(\cdot)=max(\cdot, 0)\)</span></li>
<li><span class="math inline">\(X^{(0)}= X\)</span>,
表示每一层表示得到的表示 <img data-src="asserts/paper2/fig1.png" /> &gt;
这里C是输入的channel, F是倒数第二层的输出channel</li>
</ul></li>
<li><span class="math inline">\(X^{(l+1)} = \delta
(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} X^{(l)}
W^{(l)}) + X^{(l)}\)</span> &gt; 又称为+残差 Residual</li>
</ul></li>
</ul>
<p><span class="math display">\[ \mathbf{\hat{A}} =
\mathbf{\tilde{D}^{-\frac{1}{2}}} \mathbf{\tilde{A}}
\mathbf{\tilde{D}^{-\frac{1}{2}}} \]</span> <span
class="math display">\[ \hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A}
\tilde{D}^{-\frac{1}{2}}\]</span> - 模型更新 &gt;
Adam优化器，自适应梯度下降优化器
https://www.jianshu.com/p/aebcaf8af76e</p>
<h2 id="公式的由来">3. 公式的由来</h2>
<p><a href="https://arxiv.org/pdf/1211.0053.pdf">spectual based</a></p>
<p><a href="https://hal.inria.fr/inria-00541855/document">Hammond.</a>
&gt; 近似方法推导的来源</p>
<p><a
href="https://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering.pdf">Cheby方法</a></p>
<h2 id="相关工作">4. 相关工作</h2>
<ol type="1">
<li>内存扩展</li>
<li>使用mini batch 随机梯度下降</li>
</ol>
<h3 id="基于图的半监督学习">4.1 基于图的半监督学习</h3>
<p>拉普拉斯矩阵： 标签传播、多种正则化、深度半监督表示</p>
<p>注意力机制： DeepWalk, &gt; skim-gram model,
简单来说就是，当要看当前单词时，向前或向后看几个单词 &gt;
通常这些做法有种更多的步骤或者宽度优先模式，所以需要考虑用哪一步进行优化才是最恰当的</p>
<h3 id="关于图的神经网络">4.1 关于图的神经网络</h3>
<p>2009的框架重复利用了收缩的想法进行传播误差直到最终节点的表示到达一个稳定的状态</p>
<p>2015年的做法介绍了一种类似卷积的传播规则作用在图上，并且针对于图级别的分类。但是可以发现，因为卷积要求有着固定的邻居。所以这种做法是不符合当节点的度有着很广的分布的情况。
&gt; 这篇文章会重新考虑计算邻接矩阵，所以不会担心有这种因素的出现</p>
<p>2016,1-DNN, 引入了排序的想法 本文的方法，2014,简单，可扩展</p>
<h2 id="实验">5. 实验</h2>
<h3 id="数据集">5.1 数据集</h3>
<p><strong>类别</strong> 1. 引用网络 Citeseer, Cora, Pubmed 2. 知识图
NELL, 本身属于二部图</p>
<p><strong>内容</strong> 数据： 数据类别， 节点， 边（这里会进行定义），
classes:节点的类别， features:输入的channels， Label rate:
用作训练的数据集</p>
<p><img data-src="asserts/paper2/dataset.png" /></p>
<p><strong>预处理</strong> - 引用网络
无向图，不用处理，二进制邻接举证；每个类只使用了20个标记，使用了全部的特征
&gt; 1. 是如何筛选出训练集和测试集的？ &gt; &gt; 2.
是否保证了训练集中各个标记的样本的比例相同？</p>
<ul>
<li><p>NELL 有向图，预处理同2016. 做法将(e1, r, e2)拆分为(e1,r1), (e2,
r2) <code>也就是将节点拆分成了很多片,
这样从某种程度就可以使得一条边可以被两个点同时共用</code>
所以也就使得得到的节点表示是稀疏向量，one-hot作为特征，所以产生了61278维，<code>这里可以注意到，one-hot每一个特征所拥有的取值即其位数</code>，如果两个节点中存在边的话，则说明边是存在的，则对应邻接矩阵中置为1</p></li>
<li><p>Random graphs
我们模拟各种尺寸的随机图数据集，并在每轮中测试训练时间。
一般的做法时，随机地为N个节点赋予2N条边。对于每个节点的特征初始化为<span
class="math inline">\(I_N\)</span>,
表示每个节点并没有什么特征。并为每个节点置一个假标记<span
class="math inline">\(Y_i = 1\)</span> &gt; 目的是为了什么？
有什么用？</p></li>
</ul>
<h3 id="实验部分">5.2 实验部分</h3>
<p>首先是3层的网络，附录B中有10层的网络。 data split技术 <a
href="https://arxiv.org/pdf/1603.08861.pdf">Yang, 2016</a> &gt; ？
这里是1000个样本做测试，500个样本做交叉验证的意思吗？</p>
<p>3层的网络，超参数： - dropout - L2 - number of units - optimizer &gt;
优化器，就是采用什么样的梯度下降方式</p>
<blockquote>
<p>这里不使用验证集作为训练，那还是用的交叉验证的方法吗？？</p>
</blockquote>
<p>在Cora上优化得到的超参数直接用到Citeseer, Pumbed。
训练中优化器使用的是Adam， 学习率为0.01 &gt;
Adam优化器，自适应梯度下降优化器
https://www.jianshu.com/p/aebcaf8af76e</p>
<p>停止条件：最大训练轮数200轮，如果交叉验证集误差连续10次不下降则停止训练。
权重初始化和特征向量标准化方法：<a
href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Glorot
&amp; Bengio 2010</a> 隐藏层单元：32个 忽略正则化项 &gt;
隐藏层单元的设置除了对业务的理解，还有什么其他的建议点？ &gt;
否则一般有经验公式</p>
<h3 id="baselines">5.3 baselines</h3>
<blockquote>
<p>注意到这里baselines比较了前面提到的基于图的半监督学习中所有目前有的论文的模型。并且可以忽略其中不适合的模型</p>
</blockquote>
<p>忽略了TSVM, 不适用于大规模分类</p>
<p>进一步与Lu提出的迭代分类算法ICA进行了比较，结合两个逻辑回归分类器，一个用于本地接地那特征，一个用于使用局部特征和聚合算子的关系进行分类。首先，使用所欲标记的训练集训练本地分类器并使用它用于引导为未标记节点的类标记。然后，运行迭代分类器，随机节点排序，对所有未标记的节点进行10次迭代。<code>这里是为了做什么</code>
L2交叉验证和聚集函数的选择都是基于每个数据集的验证集的性能分别进行选择
选择了Planetoid，选择了它们模型最好的变体</p>
<h2 id="结果">6. 结果</h2>
<p>ICA随机选择100论随机节点排序运行的平均准确率</p>
<h2 id="贡献">7. 贡献</h2>
<p>主要有两个贡献： 1. 提出了一种新的梯度计算公式 2.
这个模型可以快速用于大规模的半监督的节点分类中</p>
<h2 id="一些超参数">一些超参数</h2>
<pre><code>- dropout
&gt; 每层都可以设置，[0,1], 表示以多大的概率使当前节点停止工作，避免过拟合
- L2 正则化系数
&gt; ?为啥有第一层， 这里的理解不应该是$\lambda$吗
- number of units for each hidden layer 隐藏层节点个数
&gt; 隐藏层表示的特征数？ 对吗？
- 学习率
&gt; $\eta$: 梯度下降的步长</code></pre>
<h2 id="很神奇的地方">很神奇的地方</h2>
<pre><code>- filter公式的推出
- Tk的近似
- K=1, $\lambda_&#123;max&#125;$的取值</code></pre>
<h2 id="一些定义">一些定义</h2>
<p><span class="math inline">\(G = (\mathcal{V}, \mathcal{E})\)</span>
顶点数和边数</p>
<p>F-- output layer的channel个数 C-- input layer的channel个数 H-- input
layer的输出，channel, hidden layer的输入 ## 一些不懂的点</p>
<p>训练集 &gt;
由损失函数，特定的评价指标；一般看的训练误差也就是损失函数的误差。</p>
<p>交叉验证集：用于评价泛化性如何，是否产生了过拟合现象，然后交叉验证的准确率可以进行反应
&gt;
如果表现得很低，那么有可以在训练集上进行重新训练；再次交叉验证，唯一注意的是不能混用。
&gt;
然后，一般来说采用的是K交叉验证，即将数据集分为K份，最终的做法是取这些值的平均值来做</p>
<blockquote>
<p>???
K交叉取平均会不会混淆，因为在用的时候，实际是在多次训练时，虽然本次没有用到数据集，但是在下一次肯定用到了，那么是不是有问题</p>
</blockquote>
<blockquote>
<p>如果是独立的训练，那么又是取哪个值来做呢？ 注意关注一下交叉验证.
https://blog.csdn.net/lhx878619717/article/details/49079785
按这里的说法，就是分为k份，然后每次训练集是独立的，最终选取的目标其实就是测试误差最小的模型为最优模型。该模型的参数就是最终的参数
突然想起，之前的学习也说明了这里的问题</p>
</blockquote>
<p>测试集：最终的真实结果，未知 &gt;
从某种意义上讲，交叉验证的实际结果应该和测试集上表现尽量相同，也就是说性能度量指标基本上就是在这里用的。
&gt; 一般来说实验的精确率就是用交叉验证集和测试集的交过来反映来看 &gt;
但是这里不一定相等，因为存在训练集过小等因素</p>
<blockquote>
<p>比如，查准率，查全率，F1</p>
</blockquote>
<p>https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89</p>
<p>学习率：反向传播中的步长 L2正则化参数：L2的系数</p>
<p>矩阵 &gt;
一般来说，把向量定义为列向量；为什么？因为人们就作用来说，还是习惯左作用。
&gt; 比如A对应的线性映射为Ax https://www.zhihu.com/question/26304877</p>
<h2 id="不懂的地方">不懂的地方</h2>
<p>表达式不懂</p>
<p>hidden层的激活函数是怎么用的？</p>
<p>交叉熵和MSE最小平方法都是用来做损失函数的</p>
<p>几个概念： - 损失函数：单个样本 - 代价函数：针对总体 -
目标函数：通常会考虑正则化项</p>
<p>所以这里正则化项系数就是目标函数中使用的是哪种正则化项，然后就对应于哪个参数</p>
<p>其实，本身一般来说是把问题经过抽象变成最优化问题的，这里的最优化问题可以分为有约束最优化问题，无约束最优化问题以及其他；
然后，本身最优化问题有多种解的，比如模拟退火算法、遗传算法、蚁群算法、图割算法。
但是，在机器学习中，一直长学的求导占了主要的位置，所以考虑的就是使用求导法，也就是所谓的梯度下降，然后所以每次在考虑很多的问题都想要保证凸函数，因为这样才能保证取得全局最优解</p>
<p>https://blog.csdn.net/liujiboy/article/details/78078042</p>
<p>然后，又怎么转化到学习上去了呢？就是为什么是大量的样本上去了呢。其实，本身不管是什么事情，除非是固定的数学问题，都是一个学习的过程。那么，就永远不会到达最理想的状态，所以就是学习本身，那么引入正则化项也合理了，就是为了避免进行过拟合。</p>
<blockquote>
<p>更深入地从KL散度了解交叉熵
https://blog.csdn.net/tsyccnh/article/details/79163834</p>
</blockquote>
<p>sigmoid函数，1/(1+e^(-x)) 将R映射到了[0,1]</p>
<p>https://zhuanlan.zhihu.com/p/3824176</p>
]]></content>
      <categories>
        <category>gnn-parallel</category>
        <category>gnn</category>
      </categories>
      <tags>
        <tag>gnn-parallel</tag>
        <tag>gnn</tag>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>semi-paper code read</title>
    <url>/2019/gnn-semi-paper-code-read-44546d201ff5/</url>
    <content><![CDATA[<h2 id="论文1">论文1</h2>
<p>https://github.com/tkipf/gcn</p>
<p>Data - n<em>n n</em>d d=c:channels e=f:classes</p>
<ol type="1">
<li>gcn 文件组织结构
<ul>
<li>readme.md
<ul>
<li>data: d=c: chanels e=f:classes
<ul>
<li>citation network data: cora, citeseer, pubmed</li>
<li>nell: revisiting semi-supervised learning with graph embedding</li>
</ul></li>
<li>model: gcn, gcn_cheby, dense</li>
</ul></li>
<li>gcn
<ul>
<li>data
<ul>
<li>.tx the feature vectors of test instances</li>
<li>.ty the one-hot labels</li>
<li>.index the indices of test instances in graph, inductive
setting</li>
<li>.x : the feature vectors of the labeled training instances</li>
<li>.y : the labeled</li>
<li>.allx: all</li>
<li>.ally</li>
</ul></li>
<li>inits.py
<ul>
<li>uniform, glorot: [input_dim, output_dim], zeros, ones</li>
</ul></li>
<li>metrics.py
<ul>
<li>cross_entropy + accuary</li>
</ul></li>
<li>models.py
<ul>
<li>gcn: semi-superised</li>
<li>gcn_cheby: convolutional</li>
<li>dense: basic multi-layer perceptron</li>
<li>Model &gt; self.layers[0], 第一层的layer.
对第一层中的var的值，进行相加，这里的var只有weights, bias.
进行乘以固定系数相加 &gt; num_features_nonzero: dropout的方法也不同
<ul>
<li>init
<ul>
<li>name, logging</li>
<li>vars, placeholdres</li>
<li>layers, activations</li>
<li>inputs, outputs</li>
<li>loss, accuary</li>
<li>optimizer, opt_op</li>
</ul></li>
<li>build: tf.variable_scope(self.name)
<ul>
<li>build sequential layer model</li>
<li>store model variables for easy access</li>
<li>build metrics: weight_decay: 5e-4: weight for L2 loss on embedding
matrix. ???</li>
</ul></li>
<li>predict</li>
<li>_loss</li>
<li>_accuracy</li>
<li>save</li>
<li>load</li>
</ul></li>
<li>MLP
<ul>
<li><strong>init</strong>: inputs: features, input_dim, output_dim,
placeholders, optimizer, build</li>
<li>_loss: 变量的l2 loss???? += 交叉熵</li>
<li>_build; Dense</li>
</ul></li>
<li>GCN
<ul>
<li>_build: GraphConvolution</li>
</ul></li>
</ul></li>
<li>utils.py
<ul>
<li>load_data</li>
</ul></li>
<li>layers.py
<ul>
<li>get_layer_uid: 全场唯一uid</li>
<li>sparse_dropout: dropout for sparse tensors????</li>
<li>Layer
<ul>
<li>init: name, vars, logging, sparse_inputs</li>
<li>_call: return inputs</li>
<li>__call: add inputs, outputs ??? tf.summary.histogram()?//
为了方便展示直方图?</li>
<li>_log_vars: add vars in histogram</li>
</ul></li>
<li>Dense(Layer)
<ul>
<li>__init: input_dim, output_dim, placeholders, dropout=0.,
sparse_inputs, act, bias=false, featureless=false glorot()</li>
<li>_call
<ul>
<li>dropout:</li>
<li>transform: 是否使用稀疏矩阵相乘</li>
<li>bias: self.vars['bias']
没有输入的，只有输出，在隐藏层中，对结果产生影响</li>
</ul></li>
</ul></li>
<li>GraphConvolution: graph convolution layer(Layer)
<ul>
<li>act? support? bias? featureless? act: tensorflow activation</li>
<li>init
<ul>
<li>support 变量的个数 weights_i: glorot bias=zeros</li>
</ul></li>
<li>_call
<ul>
<li>convlve ??</li>
</ul></li>
</ul></li>
</ul></li>
<li>train.py
<ul>
<li>flags &gt; dataset, model, learning_rate, epochs,, hidden1-16,
dropout
<ul>
<li>weight_decay: weight for l2 loss on embedding matrix</li>
<li>early_stopping</li>
<li>max_degree: Chebyshev 不等式的阶</li>
</ul></li>
<li>placeholders
<ul>
<li>support: [preprocess_adj(adj)] &gt; 为什么要这么做?
因为gcn_cheby模型中每层的A实际上是不一样的</li>
<li>features:</li>
<li>labels:</li>
<li>labels_mask:</li>
<li>dropout: 注意稀疏矩阵和稠密矩阵 dropout方法还不一样</li>
<li>num_feature_nonzero:</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<p>corn - x: 140,1433 tx: 1000,1433 ty: 1000, 7 - allx: 1708 1433 ?
为何总数不相等</p>
<pre><code>- (allx,tx) 说明这两个不相等 </code></pre>
<h3 id="论文2">论文2</h3>
<p>https://github.com/kimiyoung/planetoid</p>
<ul>
<li>test_ind.py: induce model 的测试</li>
<li>test_trans.py: transive model的测试</li>
<li>ind_model.py: model add_data build gen_train_inst gen_graph
gen_lable_graph</li>
</ul>
]]></content>
      <categories>
        <category>gnn</category>
        <category>semi-gnn</category>
      </categories>
      <tags>
        <tag>gnn</tag>
        <tag>semi-gnn</tag>
      </tags>
  </entry>
  <entry>
    <title>ipython personnal reference</title>
    <url>/2019/ipython-personnal-reference-963c36810358/</url>
    <content><![CDATA[<blockquote>
<p>首先意图不过就是整理最常用和自己最关心的内容</p>
</blockquote>
<h3 id="常用">常用</h3>
<ol type="1">
<li>如何保存 <code>%save -r my-filename line_m-line_n line_r</code></li>
</ol>
<h3 id="总览">总览</h3>
<p>有两种形式 1. % 命令</p>
<ol start="2" type="1">
<li>: 命令</li>
</ol>
<p>? -&gt; Introduction and overview of IPython's features. %quickref
-&gt; Quick reference help -&gt; Python's own help system object? -&gt;
Details about 'object' object?? -&gt; Details about extra details</p>
]]></content>
      <categories>
        <category>tools</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>ipython</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo_study</title>
    <url>/2019/hexo-study-678ad92c1ed5/</url>
    <content><![CDATA[<p>sudo apt-get install nodejs sudo apt-get install node</p>
<p>Node.js: 在服务器端的javascript npm: 软件管理包 cnpm</p>
<h1 id="目录">目录</h1>
<ol type="1">
<li>npm install -g hexo-cli 安装客户端 <img data-src="/2019/hexo-study-678ad92c1ed5/1.jpg" class="" title="hello world"></li>
<li>建站 mkdir <code>&lt;folder&gt;</code> cd
<code>&lt;folder&gt;</code> hexo init npm install</li>
</ol>
<p><img data-src="1.jpg" /></p>
<ol start="3" type="1">
<li>目录结构
<ul>
<li>_config.sym
<ul>
<li>网站 title, subtitle, description, keywords, author</li>
<li>网址 url, root, permalink, permalink_defaults &gt; permalinks:
:category/:title</li>
<li>目录
<ul>
<li>source_dir(source): 资源文件夹，存放内容</li>
<li>public_dir(public): 公共文件夹，存放生成的站点文件</li>
<li>tag_dir: 标签文件夹</li>
<li>archive_dir: 归档文件夹</li>
<li>category_dir: 分类文件夹</li>
<li>code_dir: downloads/code: source_dir下的子目录</li>
<li>i18n_dir</li>
<li>skip_render: 跳过指定文件的渲染</li>
</ul></li>
<li>文件
<ul>
<li>new_post_name</li>
<li>post_asset_folder &gt; 总共有两种方式 &gt; 1. 放在source/images,
<img data-src="/images/image.jpg" /> &gt; 2. post_asset_folder: true</li>
<li>render_drafts?： 显示草稿</li>
<li>demo: &gt;</li>
</ul></li>
<li>分类&amp;标签
<ul>
<li>default_category: 默认分类</li>
</ul></li>
<li>日期、时间显示</li>
<li>分页
<ul>
<li>per_page: 4好像就合适</li>
<li>pagination_dir: page 分页目录???</li>
</ul></li>
<li>扩展
<ul>
<li>theme, theme_config</li>
<li>deploy: 部署部分的设置</li>
<li>meta_generator: meta generator标签。? 好像是html头部的一些东西</li>
</ul></li>
<li>包括或不包括目录和文件 glob表达式
<ul>
<li>include: 默认忽略git文件夹，是ok的</li>
<li>exclude:</li>
</ul></li>
<li>hexo server --config custom.yml自定义配置未见的目录</li>
<li>在主题下进行自我配置theme/my-theme/_config.yml</li>
</ul></li>
<li>package.json:
不用管，应用程序的信息；可以查看总共添加了哪些依赖</li>
<li>scaffolds模板文件: hexo new photo "filename" &gt;
注意这里photo.md存储在scaffolds下 &gt; 默认为post文件</li>
<li>source:
存放用户资源的地方，处理_post文件，其他_和.开头的文件会被忽略，markdown和html文件会被解析到public,
而其他文件会被拷贝过去</li>
<li>themes: 主题文件夹，根据主题来生成静态页面
<ul>
<li>_config.yml</li>
<li>languages</li>
<li>layout:
布局文件夹，用来存放主题的模板文件，决定网站内容的呈现方式。hexo采用的Swig模板
<ul>
<li>index: 首页</li>
<li>post</li>
<li>page</li>
<li>archive</li>
<li>category</li>
<li>tag</li>
</ul></li>
<li>scripts: 脚本问价加</li>
<li>source</li>
</ul></li>
</ul></li>
<li>命令
<ul>
<li>init:</li>
<li>new: 使用default_layout参数
<ul>
<li>-p, --path: 自定义新文章的路径, 决定文章文件的路径 !!! 测试 a &gt;
new about/me "About me" me.md title:"About me"</li>
<li>-r, --replace 同名文章替换</li>
<li>-s, --slug 新文章的文件名和发布后的url</li>
</ul></li>
<li>generate g
<ul>
<li>-d, --deploy</li>
<li>-w, --watch</li>
<li>-f, --force 重新生成文件</li>
</ul></li>
<li>publish [layout] <code>&lt;filename&gt;</code> 发布草稿</li>
<li>server
<ul>
<li>-p, --port: 重设端口</li>
<li>-s, --static: 只使用静态文件</li>
<li>-l, --log: 启动日记记录</li>
</ul></li>
<li>deploy -g,--generate</li>
<li>render 渲染文件 -o 输出路径</li>
<li>migrate 迁移</li>
<li>clean: 清除缓存文件db.json, 以及已经生成的静态文件public</li>
<li>list: 列出网站资料</li>
<li>version</li>
</ul></li>
</ol>
<blockquote>
<p>应用 1. 一键所有部署: hexo g -f -d 2. 模式： --safe
安全模式，不会载入插件和脚本? --debug 到debug.log --slient 隐藏终端信息
--draft 显示文件夹中的草稿文章 --cwd 自定义当前工作目录的路径</p>
</blockquote>
<ol start="5" type="1">
<li><p>文章</p>
<ul>
<li>布局 layout
<ul>
<li>false: 不要处理我的文章</li>
<li>page: source ? 好像只是路径不同，所以是路径问题?</li>
<li>post source/_posts</li>
<li>draft source/_drafts --draft 预览?</li>
</ul></li>
<li>title, date, updated, comments, tags, categories, keywords &gt;
分类具有顺序性和层次性，标签没有顺序性和层次 &gt; -[Diary, Linux] -[PS3,
]</li>
</ul></li>
<li><p>标签插件</p>
<ul>
<li>引用块 quote: &gt; <blockquote>
</blockquote></li>
<li>代码块 ocde &gt; <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure></li>
<li>反引号代码块 &gt; `<code>[langage][title][utl][link text] code
snippet</code></li>
<li>其他
<ul>
<li>youtube视频 <div class="video-container"><iframe src="https://www.youtube.com/embed/video_id" frameborder="0" loading="lazy" allowfullscreen></iframe></div> ? 如何用</li>
<li>插入Vimeo视频 <div class="video-container"><iframe src="https://player.vimeo.com/video/video_id" frameborder="0" loading="lazy" allowfullscreen></iframe></div></li>
<li>引用文章 {}</li>
<li>引用资源 &gt; 引用文件，图片，链接等， 注意这里是特殊的格式
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% asset_path slug %&#125;</span><br><span class="line">&#123;% asset_img slug [title] %&#125;</span><br><span class="line">&#123;% asset_link slug [title] %&#125;</span><br></pre></td></tr></table></figure></li>
<li>插入swig标签  </li>
<li>摘要 <code>&lt;!-- more --&gt;</code></li>
</ul></li>
</ul></li>
<li><p>数据文件夹 hexo3.0新增功能 source/_data:
可以在网站中复用这些东西，
比如在menu.yml中配置的信息可以通过代码解析</p></li>
<li><p>服务器</p>
<ul>
<li>npm install hexo-server --save</li>
<li>hexo server -p 5000 -i ip</li>
</ul></li>
<li><p>生成器</p>
<ul>
<li>hexo generate --watch查看变动</li>
</ul></li>
<li><p>部署</p>
<ul>
<li>可以部署多个deploy: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">- type:</span><br><span class="line">  repo:</span><br><span class="line">- type:</span><br><span class="line">  repo</span><br></pre></td></tr></table></figure></li>
<li>git
<ul>
<li>npm install hexo-deployer-git --save</li>
<li>参数
<ul>
<li>type: git</li>
<li>repo: 地址</li>
<li>branch:</li>
<li>meassage: 自动提交消息</li>
</ul></li>
<li>原理 &gt; 当hexo
deploy时，hexo会将public目录中的文件和目录推送到_config.yml对应的远端仓库，并且完全覆盖giants分支下的已有内容</li>
</ul></li>
</ul></li>
<li><p>变量</p>
<ul>
<li>全局变量
<ul>
<li>site 网站变量
<ul>
<li>posts</li>
<li>pages ??</li>
<li>categories</li>
<li>tags</li>
</ul></li>
<li>page: 针对该页面的内容
<ul>
<li>title</li>
<li>date</li>
<li>文章 posts
<ul>
<li>published</li>
<li>categories</li>
<li>tags</li>
</ul></li>
<li>首页 index
<ul>
<li>per_page</li>
<li>total</li>
<li>current</li>
</ul></li>
<li>归档 archive
<ul>
<li>archive</li>
<li>year</li>
<li>month</li>
</ul></li>
<li>category分类，与index布局相同
<ul>
<li>category</li>
</ul></li>
<li>标签 tag:
<ul>
<li>tag</li>
</ul></li>
</ul></li>
<li>config: 网站配置</li>
<li>theme: 主题配置</li>
<li>_ : loadsh函数库</li>
<li>path: 当前页面的路径（不含根路径）</li>
<li>url: 当前页面的完整网址</li>
<li>env: 环境变量</li>
</ul></li>
</ul></li>
<li><p>辅助函数</p>
<ul>
<li>&lt;%- image_tag(path, [options]) %&gt; 插入图片
<ul>
<li>alt, class, id, width, height &gt; CDN图片引用访问 Cloudinary</li>
</ul></li>
<li>gravatar 全球唯一关联邮箱图片</li>
<li>toc</li>
</ul></li>
<li><p>插件</p>
<ul>
<li>脚本 scripts</li>
<li>插件 node_modules hexo-XX
<ul>
<li>官方</li>
</ul></li>
</ul></li>
</ol>
<p>mathjax: true reward: false password:</p>
<p>Front-matter</p>
<p>npm install hexo-generator-searchdb --save</p>
<p>问题： 1. About页面没有 2. 对应的编辑器没有 3. 侧边栏不好看</p>
<p>https://blog.winsky.wang/Hexo%E5%8D%9A%E5%AE%A2/Hexo%E5%8D%9A%E5%AE%A2Next%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE/</p>
<p>todo</p>
<p>https://theme-next.org/docs/getting-started/</p>
<p>todo SEO工具 获取token</p>
<p>https://www.baidufree.com/1873.html</p>
<p>https://hui-wang.info/2016/10/23/Hexo%E6%8F%92%E4%BB%B6%E4%B9%8B%E7%99%BE%E5%BA%A6%E4%B8%BB%E5%8A%A8%E6%8F%90%E4%BA%A4%E9%93%BE%E6%8E%A5/</p>
<p>https://zhuanlan.zhihu.com/p/38143946 优化和维护暂时还不可，2-5天
https://www.jianshu.com/p/f8ec422ebd52</p>
<p>谷歌站点地图
https://search.google.com/search-console?resource_id=https%3A%2F%2Faugf.github.io%2F</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>linux keyboard using</title>
    <url>/2019/linux-keyboard-using-e7578316642f/</url>
    <content><![CDATA[<p>快捷键： hot key</p>
<p>https://www.cnblogs.com/EasonJim/p/7119214.html</p>
<p>如何查看？ 在桌面空白位置长按Win</p>
<p>如何屏幕最左化 ctrl+win+-&gt;<br />
&gt; 以下是针对Ubuntu的快捷键，测试没有效果。
进一步，通常可以在系统设置-&gt; 键盘-&gt;
快捷键中对相应的设置进行查看</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>keyboard</tag>
      </tags>
  </entry>
  <entry>
    <title>machinelearning cornerstone summary</title>
    <url>/2019/machinelearning-cornerstone-summary-8aa3eeac18fd/</url>
    <content><![CDATA[<p>what is ML?</p>
<ol type="1">
<li>定义 人的过程，观察，学习到技能</li>
</ol>
<p>机器的过程，数据学习到技能</p>
<p>技能即如何？</p>
<ol start="2" type="1">
<li>关键</li>
</ol>
<ul>
<li>存在潜在的模式</li>
<li>没有很简单的定义</li>
<li>有足够的数据</li>
</ul>
<ol start="3" type="1">
<li><p>应用场景 衣食住行</p></li>
<li><p>辨析 from f-&gt;ML-&gt;g: f为目标</p></li>
</ol>
<p>ML vs DM： DM is interesting pattern, ML is find underlying pattern
ML vs AI: AI is 智能 ML vs Statistics:
统计是试图从以往数据中学习点什么出来</p>
<ol start="5" type="1">
<li>例子 PLA， Perceptron算法，线性感知机法，主要想法是进行 eg：
图形结合的方法找最优解 &gt; 假设： 1. 问题具有最优解 2.
样本真实，没有噪声</li>
</ol>
<p>实际问题 - 算法怎么操作？ - 算法的正确性分析——算法能达到最优解。
是否存在线性可分的直线，如果存在，那么研究是否收敛到最优解。然后算法是否能停止。
&gt; 收敛的分析，探究与最优解的接近程度，内积是一种方法 &gt;
是否停止，即到达常数。 - 算法的时空复杂度分析： 对算法进行比较</p>
<p>对于最优的算法，其返回结果必然是最优的。</p>
<blockquote>
<p>每个算法的假设空间是否是一样的呢？
每一个问题都有假设空间，即其中参数来确定假设空间。但是由于假设空间不一定与问题空间对应，所以不一定能得到问题空间的解</p>
</blockquote>
<blockquote>
<p>这里是不是要看算法的类别？ 对！</p>
</blockquote>
<p>思考 如果假设1，2不成立怎么办？ 假设没有噪声，但不知道是否可学习？
寻找经验误差最小的。 此时，经验误差最小的难度是NP-hard. &gt;
一种做法就是选择局部最优解来做。</p>
<p>线性w^T形成的就只是线吗？ &gt;
对，只是线，这里其实是感知机模型，换句话说就只是所有样本点一起决定下的权值。
表示能力是否欠缺？ &gt; 只有可以线性可分的数据集才可以用。</p>
<p>PLA算法更新公式确实是改变了一定的角度，如何保证该改变的角度一定就引起来类别的转化？</p>
<p>随机化算法是怎么做的？</p>
<p>扩展： 假设不知道算法是否存在最优解，采用口袋算法，即 算法流程：
step1 随机选择一个w step2 如果有错误样本进行一次修正 step3
没有错误则停止，否则重复执行step2</p>
<ol start="4" type="1">
<li>分类</li>
</ol>
<ul>
<li>输出空间
<ul>
<li>2</li>
<li>多</li>
<li>回归</li>
<li>结构学习</li>
</ul></li>
<li>资料
<ul>
<li>监督</li>
<li>非监督</li>
<li>半监督</li>
<li>强化</li>
</ul></li>
<li>学习
<ul>
<li>Batch</li>
<li>online</li>
<li>active</li>
</ul></li>
<li>特征
<ul>
<li>concrete具体</li>
<li>raw原始</li>
<li>abstrut 过于抽象，编号信息</li>
</ul></li>
</ul>
<ol start="5" type="1">
<li>学习的前提 需要假设存在目标，且目标是一定的 Learning impossible,
adversarial</li>
</ol>
<p>于是在这里引入No Free Lunch, 目标不一定就无法进行学习，对！</p>
<p>学习的目标不可知, 如何学习？
还好有样本，可以使用概率论的概念即抽样来学习。</p>
<p>为什么可以学习？ 利用的就是抽样。 - 对应关系：
问题空间-&gt;假设空间</p>
<ul>
<li>关注样本，需要好的样本</li>
</ul>
<blockquote>
<p>不好的样例和不好的事</p>
</blockquote>
]]></content>
      <categories>
        <category>machinelearning</category>
        <category>cornerstone</category>
      </categories>
      <tags>
        <tag>machinelearning</tag>
        <tag>cornerstone</tag>
      </tags>
  </entry>
  <entry>
    <title>linux</title>
    <url>/2019/linux-fbd371a191e1/</url>
    <content><![CDATA[<h2 id="强大的常用命令-find-grep">强大的常用命令: find, grep</h2>
<p>https://www.cnblogs.com/skynet/archive/2010/12/25/1916873.html</p>
<p>find主要用于查找文件 grep(global search regular expression and print
out the line):
强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。</p>
<h3 id="find">1. find</h3>
<p>man: find [-H] [-L] [-P] [-D debugs] [-Olevel] [path]
[experssion]</p>
<p>find [path] [experssion] - path: find命令所查找的目录路径 -
experssion: expression可以分为"-options [-print -exec -ok...]" -
-options, 制定find命令下的常用选项 - -print,
find命令将匹配的文件输出到标准输出 - -exec,
find命令对匹配的文件执行该参数所给出的shell命令</p>
<p>常用选项以及实例 &gt;
可以不用加-print也可以正常输出，那么-print到底有啥用呢 &gt;
在本地测试时发现一个问题，bash test.sh, ok, 但是 ./test.sh permission
denied, 不知道是怎么回事 - -name: 按照文件名查找文件 - find /dir -name
filename 在/dir目录及其子目录下面查找名字为filename的文件 - find . -name
"<em>.c"
在当前目录及其子目录下查找任何扩展名为"c"的文件（即支持正则表达式） -
-perm 按照文件权限来查找文件<br />
- find . -perm 755 -print
在当前目录下查找文件权限为755的文件，即文件拥有者可以读、写、执行，其他用户可以读、执行的文件
- -prune
使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略
- find /apps -path "apps/bin" -prune -o -name "a.txt" -print
在/apps目录下查找a.txt，但不希望在/apps/bin目录下查找 &gt;
对的！不过必须要-print, -o才行，位置也不能错，todo, -o,
-print到底是什么作用啊？ - -user: 根据文件拥有者来查找文件 - find ~
-user sam -print 在$HOME目录中查找文件拥有者为sam的文件 - -mtime -n +n:
根据文件的更改时间来查找文件，-n表示文件更改时间在距现在n天以内，+n
表示文件更改时间距离n天以前 - find / -mtime -5 -print
在系统根目录下查找更改时间在5日以内的文件 - find /var/adm -mtime +3
-print 在/var/adm目录下查找更改时间在3日以前的文件 - type:
查找某一类型的文件 - 类型 &gt; b块设备文件， d目录， c字符设备文件，
p管道文件, l符号链接文件，f普通文件 - find /etc -type d -print
在/etc目录下查找所有的目录 - find . !-type d -print
在当前目录下查找除目录以外的所有类型的文件 - find /etc -type l -print -
-size n[c]: 查找文件长度为n块的文件，带有c时表示文件长度以字节计，不常用
- find . -size +10000c -print +表示大于 - find /home/apache -size 100c
print 正好 - find . -size -10 -print
在当前目录下查找长度不超过10块的文件（一块等于100字节） - -depth:
在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找 - find /
-name "CON.FILE" -depth -print
它将首先匹配所有的文件然后再进入子目录中查找 - -mount:
查找文件时不跨越文件系统mount点 - find . -name "</em>.XC" -mount -print
从当前目录查找位于本文件系统文件名以XC结尾的文件</p>
<h3 id="总结">总结</h3>
<ol type="1">
<li>最常用
<ul>
<li>查找文件, 可过滤一些文件，？？是否可以用正则表达式 -name
通配多种文件</li>
<li>时间、目录
<ul>
<li>-mtime 过滤时间</li>
<li>-prune 过滤目录</li>
</ul></li>
<li>大小、类型
<ul>
<li>-size</li>
<li>-type</li>
</ul></li>
</ul></li>
<li>高级
<ul>
<li>控制权限
<ul>
<li>-perm 过滤文件自身权限</li>
<li>-user 过滤拥有者的权限，</li>
</ul></li>
<li>访问顺序
<ul>
<li>-depth</li>
</ul></li>
<li>挂载点
<ul>
<li>-mount</li>
</ul></li>
</ul></li>
</ol>
<h3 id="grep">2. grep</h3>
<p>grep [options] pattern [file..] grep [options] [-e pattern] [-f file]
[file ...] ## 作业相关</p>
<p>jobs 查看正在进行的job ps 查看正在进行的进程</p>
<p>jobs 挂起 kill -stop PID kill %job_num kill pid &gt;
先经过ps查看一下</p>
<h2 id="查看端口">查看端口</h2>
<ol type="1">
<li><p>linux netstat -lnp | grep 8080 ps -aef | grep tomcat</p></li>
<li><p>windows</p></li>
</ol>
<p>netstat -ano | findstr 8080 taskkill /F /pid 1088</p>
<h2 id="ssh使用">ssh使用</h2>
<ol type="1">
<li>查看ip地址， ifconfig</li>
<li>sudo apt install openssh-server</li>
</ol>
<h2 id="apt-install">apt install</h2>
<p>https://www.cnblogs.com/hanxing/p/3996103.html</p>
<h3 id="安装位置">1. 安装位置</h3>
<p>/var/cache/apt/archieve 软件的安装缓存 sudo apt-get autoclean
只删除低版本的deb包 sudo apt-get clean 全部删除 &gt;
为了以后安装系统方便，可以将这些deb包保存在其他地方</p>
<p>一般的deb包都安装在/usr 或 /usr/share /usr/local中。
自己下载的压缩包或编译的包，有些可以选择安装目录， 一般放在/usr/local.
有时也放在/opt中。</p>
<p>如果想知道具体位置， dpkg -L XXX.deb &gt; eg: dpkg -L firefox</p>
<p>如果想知道apt-get install 安装的软件 dpkg -S softwarenmae | grep
cnf$</p>
<ol type="1">
<li>dpkg -L<br />
</li>
<li>dpkg -S apt-get install &gt; whereis 查看命令位置</li>
<li>/usr, /usr/share, /usr/local, /opt</li>
</ol>
<p>!!!! usr/share correct!!!</p>
<h3 id="apt-get">2. apt-get</h3>
<p>apt-get: advanced packaging tools &gt; apt-get需要root,
apt只需要当前用户</p>
<p><code>apt-get &lt;command&gt; [&lt;option&gt;] pkg1 [pkg2..]</code>
1. command: - update
重新获取软件包列表，很多时候软件安装不上就要先进行update一下 - upgrade
进行更新 - install, remove - autoremove: 自动移除全部不使用的软件包 -
purget 移除软件包和配置文件诶见 - source 下载源码档案 - autoclean 2.
args - -h 帮助文件 - -q 输出到日志 无进展指示 - -qq 不输出信息，错误除外
- -d 仅下载， 不安装或解压归档文件 3. 常用实例 - apt-cache search
pkg</p>
<h2 id="add-a-path-to-path">3. add a path to PATH</h2>
<p>~/bin: some distributions automatically put in your PATH if it
exists</p>
<ol type="1">
<li>add a path to PATH: <code>PATH=$PATH:~/opt/bin</code>
<ul>
<li>way1: 需要重启
<ul>
<li>~/.profile 当前用户 &gt; profile 侧面，轮廓</li>
<li>/etc/profile 所有用户</li>
</ul></li>
<li>way2: ~/.bashrc
<ul>
<li>vim ~/.bashrc</li>
<li>source ~/.bashrc</li>
</ul></li>
</ul></li>
<li>check the path
<ul>
<li>echo $PATH 检查环境变量 &gt; echo 重复，反射； 回应 ## 4. snap
？？？ 什么东西 add /snap/bin to $PATH</li>
</ul></li>
</ol>
<p>then can directly use</p>
<h2 id="lua环境安装">5. lua环境安装</h2>
<ol type="1">
<li>sudo apt-get install lua5.3</li>
<li>sudo apt-get install luarocks &gt; luarocks install gnuplot: install
torch first</li>
<li>git clone torch &gt; bash install-deps &gt; lua5.2 torch7 &gt; th
快捷命令</li>
</ol>
<h2 id="todo">todo</h2>
<ol type="1">
<li><p>proxy problem: 开机手动设置</p></li>
<li><p>查看后台进程</p>
<ul>
<li>ps</li>
<li>service &gt; chkconfig --list &gt; no find!!!</li>
</ul></li>
<li><p>uname -a: 查看当前版本信息</p></li>
<li><p>chrome 快速定位到搜索栏: ctrl+L, alt+D</p></li>
<li><p>最小化所有窗口 win + d ？ 最小化当前窗口， 终端重启一个</p></li>
<li><p>to add deepin some memory</p></li>
<li><p>mv 使用正则表达式</p></li>
<li><p>关于硬盘：rename没有必要</p></li>
<li><p>linux关于安装系统的命令</p>
<ul>
<li>ln命令： 功能是为某一个文件在另一个位置建议一个同步的链接
<ul>
<li>例子
<ul>
<li>ln -s link1 link2request to https://registry.npmjs.org/hexo-cli
failed, reason: Client network socket disconnected before secure TLS
connection was established &gt; 为link1文件创建软链接link2,
如果link1丢失，link2将会失效</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>百度网盘使用有问题，aria2使用频率不高，放弃</p></li>
<li><p>安装linux版的hexo &gt;
配置文件一般是有全局配置文件的，在～/.npmrc这些内容之下</p></li>
<li><p>vscode &gt; 配置总是让输入user和passwd, git config --global
credential.helper store</p></li>
<li><p>lantern &gt; what is proxy IP? 是否会影响其他的安装</p></li>
<li><p>在linux上安装pip <code>sudo apt-get install
python-pip(python2)</code></p></li>
<li><p><code>scp</code> 加-r, 上传，下载目录；
不加-r上传，下载文件</p></li>
<li><p><code>sudo apt-get install fim</code>: 展示图片，测试git
bash不行; 终端显示ok</p></li>
<li><p>linux远程登录windows todo &gt; 基于rdesktop: 但是好像不是命令行
https://blog.csdn.net/u011054333/article/details/79905102</p>
<ul>
<li>设置允许远程连接到计算机 &gt;
https://jingyan.baidu.com/article/b0b63dbf321c224a49307062.html
<ul>
<li>scp不行 5s内</li>
</ul></li>
</ul></li>
<li><p>查看某一端口是否被占用 &gt; lsof -i:2323; netstat -tunpl | grep
2323</p></li>
<li><p>查看是否有网 &gt; netstat -ntl 查看端口是否在监听</p></li>
</ol>
]]></content>
      <categories>
        <category>tools</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>todo</tag>
        <tag>linux</tag>
        <tag>snap</tag>
        <tag>lua</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title>lua learning</title>
    <url>/2019/lua-learning-b6b3f852624d/</url>
    <content><![CDATA[<p>https://www.runoob.com/lua/lua-miscellaneous-operator.html</p>
<ol type="1">
<li>data struture:
<ul>
<li>nil</li>
<li>boolean</li>
<li>number: 双精度的实浮点数</li>
<li>string</li>
<li>funcion: 由C或lua编写的函数</li>
<li>userdata: 任意存储在变量中的C数据解雇</li>
<li>thread: 表示执行的独立线路，用于执行协同程序</li>
<li>table: 关联数据 &gt; type() 查看类型</li>
</ul></li>
<li>variable
<ul>
<li>global</li>
<li>local</li>
<li>表中的索引 A.b, A[b], gettable_event(t, i)</li>
</ul></li>
<li>loop
<ol type="1">
<li>while (true)  do  执行体  end</li>
<li>do () while() end</li>
<li>for
<ul>
<li>数值 &gt; for var=exp1, exp2, exp3 do  执行体  end</li>
<li>泛型循环 相当于foreach &gt; for i, v in ipairs(a) do  print(i, v)
 end &gt; for k, v in pairs(table) do  print(k, v)  end</li>
</ul></li>
</ol></li>
<li>if: process control
<ul>
<li>if(cond) then  true-exp  end</li>
<li>if(cond) then  true-exp  else  false-exp  end</li>
<li>if(cond1) the  true1-exp  elseif(cond2)  true2-exp  else  else-exp
 end</li>
</ul></li>
<li>function
<ul>
<li>定义 &gt; <code>&lt;scope&gt; function &lt;function-name&gt; (arg1,
arg2, ..., argn) \ &lt;function-body&gt; \ return
result_params_comma_separated \ end</code></li>
<li>usage
<ul>
<li>add(...) 三点表示可变参数</li>
</ul></li>
</ul></li>
<li>运算符
<ul>
<li>+, -, *, /, %, ^, -</li>
<li>==, ~=, &gt;, &gt;=, &lt;=</li>
<li>and, or, not</li>
<li>a..b, #a</li>
</ul></li>
<li>string &gt; 以下均是静态方法
<ul>
<li>uppper</li>
<li>lower</li>
<li>gsub(mainstr, findstr, replacestr, num)</li>
<li>find(str, substr, [init, [end]]): index</li>
<li>reverse</li>
<li>format("the value is:%d", 4)
<ul>
<li>%c, %d, %f, %s</li>
<li>[符号][占位符][对齐标志-左对齐][宽度数值][小数位数] &gt; more:
https://www.runoob.com/lua/lua-strings.html</li>
</ul></li>
<li>char(arg): convert other type to char type to concat</li>
<li>byte(arg)</li>
<li>len(str)</li>
<li>rep(str, n): 返回n个拷贝</li>
<li>gmatch(str, re_pattern): return iterator</li>
<li>match(str, re_pattern): return the first match</li>
</ul></li>
</ol>
<p>? lua have not go to definition??</p>
<p>th TREPL都充满了方便的特性: 1. tab不全 2. 历史 history 3. 打印 print
4. eval() 自动打印 5. 自助:? 6. shell命令: $ ls</p>
<p>torch中文网学习 https://ptorch.com/docs/2/five-simple-examples</p>
]]></content>
      <tags>
        <tag>gnn</tag>
      </tags>
  </entry>
  <entry>
    <title>machinelearning cornerstone when can machines learn</title>
    <url>/2019/machinelearning-cornerstone-when-can-machines-learn-0a6b615fd984/</url>
    <content><![CDATA[<h1 id="the-learning-problem">1. The Learning Problem</h1>
<h2 id="introduction">1.1. Introduction</h2>
<p>theory+technique 多个角度概念 what + why + how + better:</p>
<h2 id="what-is-ml">1.2. what is ML?</h2>
<h3 id="definetion">1.2.1 definetion</h3>
<p>observation-&gt;learning-&gt;skill data-&gt;ml-&gt;skill</p>
<blockquote>
<p>so data is more like observation, will be better. learning skill how
to use in data</p>
</blockquote>
<p>learning: ml:</p>
<p>skill: improve some performance measure.</p>
<h3 id="application">1.2.2 Application:</h3>
<p>stock data-&gt;ML-&gt;more stock gain</p>
<ul>
<li>Tree Recognition 'define' trees and hand-program: difficult learn
from data(observations) and recognize</li>
</ul>
<h3 id="use-scenarios">1.2.3 Use Scenarios</h3>
<p>navigating on Mars cannot' define the solution &gt;
一般世界人，都使用的是规则来判定一件事。 high-frequency trading
consumer-targeted marketing</p>
<h3 id="key-essence-of-ml">1.2.4 key essence of ml</h3>
<ol type="1">
<li>some underlying pattern to be learned exisits target eg: predict
whether the next cry of baby</li>
<li>but no easy definition ! eg: determining whether a given graph
contains a cycle</li>
<li>this is data about the pattern eg:whether the earth will be
destoryed</li>
</ol>
<h2 id="learning-problem">1.3. Learning Problem</h2>
<ol type="1">
<li>Daily Needs Food Clothing Housing Transportation</li>
<li>Education</li>
<li>Entertainment</li>
</ol>
<h2 id="ml-vs-dmaistatistics">1.4 ML vs DM,AI,Statistics</h2>
<p>from f -&gt; ML -&gt; g. <img data-src="00001.png" /></p>
<p>ML vs DM <img data-src="00002.png" /> DM can help ML, and vice versa.
efficient computation</p>
<p>ML vs AI <img data-src="00003.png" /></p>
<p>ML vs Statistics(inference ) <img data-src="00004.png" /></p>
<h1 id="learning-to-answer-yes_no">2. Learning to Answer Yes_No</h1>
<h2 id="example">2.1 Example</h2>
<h3 id="pla算法设计">PLA算法设计</h3>
<p><strong>设计思想</strong> 知错能改，纠正错误的思想. 图形结合法来求解
<strong>类别</strong> 局部</p>
<p><strong>步骤</strong> 线性函数，感知机。
修正参数，w_{t+1}在错误案例上进行修正。 &gt; 知错能改法 &gt; Cyclic
PLA,简单的检查是否还有错误。 &gt;
对数据饶一圈，让这第100个人都没有犯错</p>
<h3 id="pla算法的正确性">PLA算法的正确性</h3>
<p><strong>假设</strong> 1. 问题具有最优解 2. 样本真实，没有噪声</p>
<p><strong>收敛到最优解</strong></p>
<p><strong>算法会停止（求迭代轮数）</strong></p>
<p>PLA用图形的夹角来做。P8</p>
<p>PLA是否可学习？ 判断两个数是否接近？ 做累积，两个向量内积越来越大</p>
<p><img data-src="00005.png" /></p>
<p><img data-src="00006.png" /></p>
<blockquote>
<p>资料是否是线性可分？资料这里是指D，还是实际分布</p>
</blockquote>
<blockquote>
<p>从某种分布上来说，未知资料是否线性可分。</p>
</blockquote>
<blockquote>
<p>理论这里对吗？就是是否线性可分 ## 2.2 Learning with noisy data</p>
</blockquote>
<blockquote>
<p>待测数据上有噪声 假设犯错率很低，那么假设没有犯错率</p>
</blockquote>
<p>假设没有噪声，但不知道是否可学习怎么办？ 试图去找犯错误最小的。
NP-hard</p>
<p>科学家的做法：找不到全局最好的解，所以考虑使用贪心。 Pocket
Algorithm，在自己的口袋保留最好的算法，根据步长随机更新的思想。 <img
src="00013.png" /></p>
<p><img data-src="00007.png" /> &gt;
因为是最优算法所以返回的结果必然都是最优的。对于算法的比较，记住一定从时间复杂度上看。
还有一旦是线性可分，那么就意味着算法都可以不犯错。</p>
<h1 id="types-of-learning">3. Types of Learning</h1>
<h2 id="v1-输出空间角度">v1 输出空间角度</h2>
<ul>
<li>binary classification</li>
<li>mulitclass classification</li>
<li>回归问题 &gt; 对于有限的复杂的输出可以看作是多分类问题</li>
<li>结构学习问题：比如学习蛋白质的长相，讲的话的语法树（输出空间中具有某种结果）
&gt; 其实从某种意义上也是划归到多分类上去。 ## v2 资料的角度</li>
</ul>
<ol type="1">
<li>监督学习: 完全是有标记样本</li>
<li>非监督学习: 未标记样本，分群 &gt; 监督可以看作是没有答案 &gt;
聚类，文章主题</li>
</ol>
<ul>
<li>density estimation: {x_n}</li>
<li>outlier detection: &gt; 难衡量好坏，因为没有目标</li>
</ul>
<ol start="3" type="1">
<li>半监督学习：有标记样本+未标记样本。</li>
<li>强化学习: 不断强化，给予惩罚和奖励；不断学得最终的目标。 &gt;
喂给机器资料，对机器进行评价，好还是不好 &gt; partial/implicit
information</li>
</ol>
<p><img data-src="00008.png" /></p>
<h2 id="v3-取得样本的方式学习的角度">v3 取得样本的方式，学习的角度</h2>
<ol type="1">
<li>Batch Learning</li>
<li>Online learing</li>
<li>active: "question asking" --query the yn of the chosen xn &gt;
有技巧地问问题，可以用很少的问题学习到很多的东西。标记很贵的情况。</li>
</ol>
<p><img data-src="00009.png" /></p>
<h2 id="v4-特征的角度">v4 特征的角度</h2>
<p>二维向量：对称性、密度性 - concrete - abstract
客户的编号，实际就是一种抽象了。 - raw <img data-src="00010.png" /></p>
<blockquote>
<p>如何找一个最合适的特征</p>
</blockquote>
<blockquote>
<p>至少可以从这些分类中寻找一个感兴趣的东西 <img data-src="00011.png" /> # 4.
Feasibility of Learning</p>
</blockquote>
<p><img data-src="00012.png" /> ## 4.1 Learning is impossible? adversarial
teacher &gt; 此时如何学习？ &gt; 有什么问题？目标不唯一 &gt;
这也是为什么 &gt; No free lunch,
我们坚持的是什么？如果我们坚持f不知道，我们要在D之外学到东西是不可能的。f一定是定下来的，否则是无法解决。再理解</p>
<blockquote>
<p>这个道理很常见，就像是猜数一样，一定要目标一定才可猜。</p>
</blockquote>
<blockquote>
<p>这也是为什么要用机器学习算法的原因，一般地话，为什么要有测试集，就是试图用测试集来衡量训练误差。</p>
</blockquote>
<blockquote>
<p>还有对于某些题的设定有问题，这其实就只是一种解释，需要更多的解释来完成这个问题
## 4.2 Inferring Something Unknown can we infer something unknown in
other scenarios? 随机采样，这就是为什么要用采样了？ 参数估计，大数定理。
数学上的定理Hoeffding，相差很远的可能性很小；特别是当样本够大，得到的估计趋于真实的估计。
注意这里两个方面，看多个变量 <img data-src="00014.png" /></p>
</blockquote>
<blockquote>
<p>从瓶子里去橙色球和其他颜色球，怎么知道原本中含有多少橙色球？一个想法就是通过对瓶子
的球进行采样一定数量，那么，根据采样的数量来就可以来估计真实的值。</p>
</blockquote>
<h2 id="connection-to-learning">4.3 Connection to Learning</h2>
<p><img data-src="00015.png" /></p>
<p>注意，这里考虑了假设空间和问题空间是一致的。
与学习之间的联系。首先我们有一大堆的假设，并从这些假设中抽取一个假设作为真实的假设。
然后，根据这个假设我们就需要得到未来的函数。那么，想法就是从满足这些假设的数据中独立同分布地抽取多个数据。
首先，数据如果足够多，利用这些数据学得的假设，并且，我们有理由相信从这些东西中学得的假设。
在数据集特别大的情况下，来学习得到的假设会更好，更满足实际的情况。</p>
<p>测试数据从某种意义上的设置就是想得到怎么样的数据？ &gt;
但是一般来说测试数据都是中肯的
还有一个方面就是用来纠正学习到的模型，因为学习到的模型有时候是过拟合的，即可解释为泛化能力。</p>
<p><strong>Verification of One h</strong></p>
<p><img data-src="00016.png" /> &gt;
这里比较了real学习和根据经验误差来学习的差别。</p>
<p>算法总是得到相同的假设，由此可以觉得该算法不好？ &gt;
假设空间小就意味着算法不好吗？ &gt;
经验误差小就意味着算法好吗？从某个方面可以这样看</p>
<p><img data-src="00017.png" /></p>
<p>ML学得的规则，不一定对过去有效，因为只是过去的抽样数据；不一定对将来有效，因为有一定误差的存在；在未来一百天中选规则也不成，因为构不成学习，不过是很多规则的累加</p>
<h2 id="connection-to-real-learning">4.4 Connection to Real
Learning</h2>
<p>bad sample: E_in and E_out far away--can get worse when involving
"choice".</p>
<blockquote>
<p>注意，数据的合理性，即样本是否合理。从某种意义上来说，需要看样本是否满足一些基本的分布，详细见西瓜书。
就是说所选取的样本是不好的样本，从另一个角度来看，就是一个指导的感觉就是还是说的是独立同分布的问题，即是否满足独立同分布。</p>
</blockquote>
<blockquote>
<p>训练的样本不是好的样本，这是一个检查的标准。</p>
</blockquote>
<p><strong>什么是Bad Sample</strong> 这个和过拟合有关吗？
好的数据任意进行选择就可以。
但是坏的数据会使算法踩到雷，算法得到不好的结果。</p>
<p>分析：假设对于每个假设都有bad example, 那么如何。</p>
<p>就是需要选取某个数据集，所有假设基本上都不会踩到雷。</p>
<p>评价，只要有一个不好就认为不好。 那么，不好的数据集的大小是多少？
<img data-src="00018.png" /></p>
<p>M是假设的个数。</p>
<blockquote>
<p>结论：只有样例过多才能满足要求；
现实的指导意义：只有尽可能地将数据认为是正反例合理的情况，否则其他不合理。</p>
</blockquote>
<p>所以，当数据合理时，我们认为满足PAC，此时Ein=Eout,
Eout就是在未知数据集上的表现情况；注意这里还未引入泛化误差的概念。那么，实际上就是选经验误差最小的，因为经验误差在这里认为是等于泛化的。</p>
<p>而泛化误差是用来进行评价的。</p>
<p>到此为止，说明了假设空间为有限的情况，并未扩展到假设空间为无限的情况。</p>
<p><img data-src="00019.png" /> &gt; 理解！</p>
]]></content>
      <categories>
        <category>machinelearning</category>
        <category>cornerstone</category>
      </categories>
      <tags>
        <tag>machinelearning</tag>
        <tag>cornerstone</tag>
      </tags>
  </entry>
  <entry>
    <title>machinelearning cornerstone why can machines learn</title>
    <url>/2019/machinelearning-cornerstone-why-can-machines-learn-41772de6ff2b/</url>
    <content><![CDATA[<h1 id="training-vs-testing">5. Training vs Testing</h1>
<h2 id="datasize">5.1 DataSize</h2>
<p><img data-src="00020.png" /> <img data-src="00021.png" /> <img
src="00022.png" /></p>
<blockquote>
<p>理解在精度下的容忍度，从而指导需要从实际情况中选择多少个样本？</p>
</blockquote>
<h2 id="effective-number-of-lines">5.2 Effective Number of Lines</h2>
<blockquote>
<p>union bound over-estimating ?</p>
</blockquote>
<p>如何衡量？ VC维来进行衡量，实际是哪个关注的是对数据的划分的数目。
&gt; 只需要可以将样本可分即可。</p>
<p>所以不同的算法就有假设空间</p>
<blockquote>
<p>再次理解线性函数
突然想到感知机的函数，感知机这里其实就是每个样本都有一个权值。 ？
在图像上，可以理解权就表示的是直线的斜率。
然后，x表示向量，即原点到这里的向量，那么进行更新就好了。 ？
如何预测的</p>
</blockquote>
<p>样本点是空间分布的 为什么觉得样本点是空间分布的是可行的？ &gt;
可以样本点在各个维度上的坐标作为特征来考虑。</p>
<p>2个 3个 +,-,+不可分 &gt; 可能有6种，可能有8种；最多8种。 4个， <img
src="00025.png" /> &gt; 任何情况下，都最多只有8种 &gt;
由此我们可以看出，得到了VC维的定义，在d维下存在，在d+1维下任意都不满足（考虑进行取反）。因为探究的是最多的情况</p>
<h2 id="effective-number-of-hyperthesis">5.3 Effective Number of
Hyperthesis</h2>
<p>大致过一下 Why can machine learn?
因为错误率可用VC维或R复杂度来衡量</p>
<p>How Can Machines Learn? 算法具体是怎么做的</p>
]]></content>
      <categories>
        <category>machinelearning</category>
        <category>cornerstone</category>
      </categories>
      <tags>
        <tag>machinelearning</tag>
        <tag>cornerstone</tag>
      </tags>
  </entry>
  <entry>
    <title>machinelearning gradient descent</title>
    <url>/2019/machinelearning-gradient-descent-cdac096ff45e/</url>
    <content><![CDATA[<p>SGD ? 是只是针对一个样本做的吗？ 难道不是学习了随机</p>
<p>无偏估计：不考虑系统误差，只有随机误差，在大数情况下有效。
也就是估计式的期望等于估计值</p>
<p>SGD Challenges: 1. 收敛速度跟学习速率关系很大，大容易震荡，小收敛很慢
2.
学习速率对所有特征都是一样的。事实上，应该某些特征下降慢，有些快，没有考虑稀疏性
3. 容易陷入不太好局部最小或鞍点。</p>
<p>误差曲面，权重为多维的 梯度与等高线的关系 梯度是等高线上的法向量
梯度是数字较低的等高线指向数值较高的等高线，梯度的模是函数在这个法线方向的方向导数
常见的有两种误差曲线：
一种一维的，一种等高线的，实际上就是反映在图像上多维的等高线
动量使得收敛过程更快地通过SGD来回震荡的峡谷</p>
<p>改进 1. 动量：
模拟物体运动的惯性，更新时一定程度上保留之前更新的方向，同时利用当前的batch的梯度微雕最终的更新方向。增加了一定程度上的稳定性，有一定的摆脱局部最优的能力
- 传统：首先计算当前位置的梯度，然后再更新累加的梯度方向移动 - NAG:
先在之前累加的梯度方向上移动，然后再计算当前位置的梯度？ &gt;
利用了物理中动量的思想，保持总的下降方向减小震荡，也比较容易跳出不太好的局部最小
2. 自动调节学习速率 - Adagrad:
Adagrad利用以前的梯度信息Gt判断对应的特征是否经常被更新，
平滑项用于防止分母为0 &gt;
考虑了之前的梯度的累加的信息，Gt是一个对角矩阵，每个对角线(i,i)的值为累加到t次迭代的对应参数wt梯度平方和，越到后面学习率会变得越来越小
- Rmsprop:
Adagrad的改进：解决Adagrad算法中学习率单调下降趋向于0的问题，把历史梯度累积窗口限定到固定的窗口
- Adadelta:
使用均方根来估计步长，使用临近时间窗口的步长来估计当前的步长；避免了手动调借参数
- Adam： 使用一阶和二阶矩估计 &gt; Adam = Rmsprop + Bias-crrection +
Momentum &gt;
初始化gradient较大，导致基于速度的算法NAG发生偏离又修正过来；具有自适应学习率的算法效果想加速版的SGD,能更加稳定地解决large
initial gradient问题</p>
<p>二阶优化方法</p>
<p>现实世界中所遇到的Hessian矩阵都是实对称的，实对称矩阵都能分解为实特征向量和实特征值
梯度下降无法利用含在Hessian矩阵的曲率信息。对于正曲率，梯度下降会下降得很慢；对于负曲率，梯度下降会下降得很快。当迭代点越靠近X，其搜索步长就越小，因而收敛速度越慢</p>
<p>牛顿法，寻找收敛速度快的无约束最优化方法，在每次迭代时，用适当的二次函数去近似目标函数f
&gt; 更新公式，二阶和一阶的内积和？ 二阶矩阵计算内容包含太多。</p>
<p>牛顿法考虑走了一步后，坡度是否会变得更大。要求二阶矩阵的逆，计算量巨大k^3</p>
<p>改进 - 共轭梯度 &gt; 避免求逆运算 &gt;
向量共轭是正交的推广，共轭方向法最多经过N步迭代，就可以到达极小值点，二次收敛性。沿共轭方向集的每个方向顺序做line
search的时候，在每个方向上都不需要做重复搜索。每个方向的移动都不会影响到在另一方向上已经找到的极小值？
CG:线性搜索并不严重依赖于线性搜索寻找该方向上和真正极小值很近的一点。 -
拟牛顿法 &gt; 不用二阶偏导数而构造正定对称阵 &gt; BFGS,
需要存储Hessian逆矩阵M, 空间复杂度O(n), 花费更少的时间改进每个线性搜索
line search: 搜索方向d_k
已经是确定的，目标是如何在一个确定的d_k上，找到一个合适的a_k</p>
]]></content>
      <categories>
        <category>machinelearning</category>
        <category>gradient-descent</category>
      </categories>
      <tags>
        <tag>machinelearning</tag>
        <tag>gradient-descent</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture1-summary</title>
    <url>/2019/nju-course-cplus-lecture1-summary-b9ef6f076085/</url>
    <content><![CDATA[<blockquote>
<p>静态数据区：全局变量、static存储类的局部变量以及常量的内存分配；
extern int x; 引用其他文件的全局变量，注意初始值。 使用说明：
尽量使用本地变量static; 全局变量赋初始值；外部全局变量使用extern.</p>
</blockquote>
<h1 id="上节课重点回顾">上节课重点回顾</h1>
<ol type="1">
<li>程序=算法+数据结构</li>
<li>代码区和栈区(普通局部变量)、堆区(malloc使用的变量)
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//file1.cpp</span><br><span class="line">int a=1;</span><br><span class="line"></span><br><span class="line">//file2.cpp</span><br><span class="line">extern int a; //</span><br><span class="line">int main()&#123;</span><br><span class="line">    a=100;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">new同malloc, 分配的变量在堆区中</span><br></pre></td></tr></table></figure></li>
<li>再理解循环，
以及递归调用。实际执行（中序遍历）。循环,退出条件。多种情况，基本及其他。返回值，参数忌大值
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">while()&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">for( ; ; )</span><br><span class="line">共享全局变量</span><br><span class="line"></span><br><span class="line">int recursion(int a) &#123;</span><br><span class="line">    if(a in basic) solve;</span><br><span class="line">    else &#123;</span><br><span class="line">        recursion(a/2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>引用，名字。指针，链表 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int f(int *b)&#123;</span><br><span class="line">    int c=3;</span><br><span class="line">    *b=c; // 在b未改变指向的地址之前做赋值。能够赋值成功</span><br><span class="line">    b=&amp;c; // 这样操作没什么用，如果返回b的值可能变了。</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main()&#123;</span><br><span class="line">    int a=1;</span><br><span class="line">    inf *b=a; // 这里初始化等价于int *b; b=&amp;a;</span><br><span class="line">    f(&amp;b); // 1-&gt;3</span><br><span class="line">&#125;</span><br><span class="line">// 指针没有那么恐怖，主要是看在哪定义的，即作用范围。如函数类以及参数，那么作用范围只不过是函数内而已。</span><br><span class="line"></span><br><span class="line">int g(int &amp;x)&#123;</span><br><span class="line">    int m=1;</span><br><span class="line">    x=&amp;m // 错误</span><br><span class="line">    x=m; //这里附带着就把原值给改变了</span><br><span class="line">&#125;</span><br><span class="line">main()&#123;</span><br><span class="line">    int a;</span><br><span class="line">    g(a);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">对于数组，同指针一样。指针就理解为链表，当选进去之后，出来还是首地址，但是该改变的都改变了</span><br><span class="line">void fun(int a[])&#123;</span><br><span class="line">    a[1]=1;</span><br><span class="line">&#125;</span><br><span class="line">int main() &#123;</span><br><span class="line">    int a[]=&#123;1,2&#125;;</span><br><span class="line">    fun(a);</span><br><span class="line">    cout&lt;&lt;a[1]; // 1</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>序列数据的表示，数组，链表，更多 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">数组 int a[N];</span><br><span class="line">单位长度 a+i*sizeof(int)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>链表
<ul>
<li>重新分配</li>
<li>访问元素，顺序，值</li>
<li>增加元素</li>
<li>删除元素 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">file1.h</span><br><span class="line">struct Node&#123;</span><br><span class="line">    int content;</span><br><span class="line">    Node *next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">不带头结点的单链表</span><br><span class="line">这里首先设计的就不合理。</span><br><span class="line"></span><br><span class="line">Node* find(Node *head,int i)&#123; </span><br><span class="line">    //？这里参数和返回值的类型</span><br><span class="line">    if(!i) return head;</span><br><span class="line">    else&#123;</span><br><span class="line">        //访问</span><br><span class="line">        Node *p=head;</span><br><span class="line">        int j=0;</span><br><span class="line">        while(p!=NULL &amp; j&lt;i)&#123;</span><br><span class="line">            p=p-&gt;next;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        if(p!=NULL) return p;</span><br><span class="line">        else return NULL; // 表示未找到</span><br><span class="line">        // return p;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Node* findByValue(Node* head,int value)&#123;</span><br><span class="line">    if(head.content==value) return head;</span><br><span class="line">    else&#123;</span><br><span class="line">        Node *p=head;</span><br><span class="line">        while(p!=NULL&amp;p-&gt;content!=value)</span><br><span class="line">            p=p-&gt;next;</span><br><span class="line">        return p;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool insert(Node *head, int value, int i) &#123; // 按所给的位置i插入value，不用返回值。</span><br><span class="line">    Node *q, *p; // 数组才需要new, 单个变量应该不需要。而且新定义的结构体也应该没有被定义在系统内吧</span><br><span class="line">    *p=head;</span><br><span class="line">    q-&gt;content=value;</span><br><span class="line">    if(i=0) &#123; // 注意这里是没有头结点的情况</span><br><span class="line">        q-&gt;next=p;</span><br><span class="line">        head=q;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        while(p!=NULL &amp; i-1)&#123; // 从0开始, 注意是找前一个</span><br><span class="line">            p=p-&gt;next;</span><br><span class="line">            i--;</span><br><span class="line">        &#125;</span><br><span class="line">        if(p==NULL) &#123;</span><br><span class="line">            delete q;</span><br><span class="line">            q=nullptr;</span><br><span class="line">            // q使用结束后，将其赋值为空。防止多次delete,还有后续使用</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        else&#123;</span><br><span class="line">            q-&gt;next=p-&gt;next;</span><br><span class="line">            p-&gt;next=q;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    delete p,q;</span><br><span class="line">    p=nullptr;</span><br><span class="line">    q=pullptr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void deleteP(Node *head, int value, int i) &#123;</span><br><span class="line">    Node *p;</span><br><span class="line">    if(i==0)&#123;</span><br><span class="line">        p=head-&gt;next;</span><br><span class="line">        head=p;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        while(p!=NULL &amp; i-1)&#123; // 从0开始, 注意是找前一个</span><br><span class="line">            p=p-&gt;next;</span><br><span class="line">            i--;</span><br><span class="line">        &#125;</span><br><span class="line">        Node *q=p-&gt;next; // 如果是最后一个也没关系，不过指向空而已</span><br><span class="line">        p-&gt;next=q-&gt;next;</span><br><span class="line">        delete p,q;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Node q; q.content</span><br><span class="line">// Node *q; q-&gt;content </span><br><span class="line">// 猜想是对的，箭头左边是指针；点号左边是实体</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li>命令
<ul>
<li>include <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">路径搜索策略:</span><br><span class="line">1. 当前目录</span><br><span class="line">2. 参数-L指定的目录</span><br><span class="line">3. gcc的环境变量CPLUS_INCLUDE_PATH</span><br><span class="line">4. gcc的内定目录</span><br><span class="line">gcc -E -v --prefix=..</span><br><span class="line">prefix/include</span><br><span class="line">prefix/local/include</span><br><span class="line">prefix/lib/gcc/--host/-version/include</span><br><span class="line"></span><br><span class="line">#include&lt;a.h&gt;</span><br><span class="line">从第2步开始</span><br><span class="line">#include &quot;a.h&quot;</span><br><span class="line">从第1步开始</span><br></pre></td></tr></table></figure></li>
<li>define <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define MAX(a,b) ((a)&gt;(b))?(a):(b)</span><br><span class="line">#define M 100</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>ifdef, if <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">file1.h</span><br><span class="line">#define ABC</span><br><span class="line">int a;</span><br><span class="line">void fun();</span><br><span class="line"></span><br><span class="line">file1.cpp</span><br><span class="line">#include &quot;file1.h&quot;</span><br><span class="line">void fun()&#123;</span><br><span class="line">    a=1;</span><br><span class="line">    cout&lt;&lt;a&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">file2.h</span><br><span class="line">#ifdef ABC</span><br><span class="line">    int b;</span><br><span class="line">#else</span><br><span class="line">    int a;</span><br><span class="line">    fun();</span><br><span class="line">#endif</span><br><span class="line">    int c;</span><br><span class="line"></span><br><span class="line">file2.cpp</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>neu ai course</title>
    <url>/2019/neu-ai-course-77110340f9f7/</url>
    <content><![CDATA[<h2 id="人工智能">人工智能</h2>
<h3 id="智能体与环境">1. 智能体与环境</h3>
<p>智能体：通过传感器感知所处环境并通过执行器对该环境产生作用的计算机程序及其控制的硬件。</p>
<p>任务环境</p>
<p>智能体种类，性能度量，环境，执行器，传感器</p>
<blockquote>
<p>智能体在环境中使用传感器，根据性能度量执行执行器。也就是智能体与环境的一个交互的过程。</p>
<p>任务环境：可观察与不可观察，确定性的与随机的，片段式的与延续式的</p>
<p>基于反射、模型、目标、效用的智能体</p>
</blockquote>
<h3 id="知识表示">2. 知识表示</h3>
<p>多种类别</p>
<ul>
<li><p>一阶谓词</p></li>
<li><p>产生式</p></li>
<li><p>语义网络</p></li>
<li><p>框架</p></li>
<li><p>剧本</p></li>
<li><p>过程</p></li>
<li><p>面向对象</p></li>
<li><p>Petri网</p>
<p>库所和变迁，有向狐，以及令牌等元素组成。</p></li>
<li><p>信念网</p></li>
<li><p>本体论</p></li>
</ul>
<h4 id="状态空间表示法">状态空间表示法</h4>
<p>两种：</p>
<ul>
<li>问题求解状态空间图</li>
<li>完整状态空间图</li>
</ul>
<blockquote>
<p>状态空间法表示法：</p>
<ul>
<li>初试状态集合S</li>
<li>操作F：走步、产生式、规则、数学算子、运算符号或逻辑符号等</li>
<li>目标状态集合G:</li>
</ul>
<p>作用：</p>
<p>提供
了一种新的解题思路，将问题重新表示。可以将实际问题的为无数的小块，将其隐含地转化为状态来做。然后，一种最简单的策略就是看与最终状态的相差值来看是否查看（一般还可以利用其它评价指标，这里突然想到了机器学习，是怎么想到各种评价指标的呢，从某种意义上还可以不停地多套）</p>
</blockquote>
<p>方法：搜索</p>
<blockquote>
<p>八数码问题</p>
</blockquote>
<ul>
<li>不可撤回式</li>
</ul>
<blockquote>
<p>沿一条路径单向延伸搜索</p>
<p>局部知识的利用，比如W(n)最大为原则来选择规则;
但可能停留在局部最优值</p>
</blockquote>
<ul>
<li>可撤回</li>
</ul>
<blockquote>
<ol type="1">
<li>回溯，可修正搜索路径</li>
<li>图搜索，展开式搜索，可保留完整的搜索树</li>
</ol>
</blockquote>
<h3 id="搜索问题">3. 搜索问题</h3>
<blockquote>
<p>状态空间： 由给定问题的所有可能状态组成的空间（全集G）</p>
<p>搜索空间：按某种策略在状态空间中选取的部分空间（G的子集）</p>
<p>解路径：求解问题的一条有效路径</p>
<p>搜索策略的基本思路：搜索空间中必有解路径；如果问题由解，尽量缩小搜索空间，且能否找到最佳解。</p>
<p>搜索策略的评价准则：总体费用最低，费用包括两部分：</p>
<ul>
<li>规则应用费用，执行规则的费用</li>
<li>控制费用：选择规则的费用</li>
</ul>
</blockquote>
<blockquote>
<p>3.1和3.2是无信息搜索策略，3.3是启发式搜索策略</p>
</blockquote>
<h4 id="回溯策略">3.1 回溯策略</h4>
<blockquote>
<p>原问题要选取的点化为多个点，选取每个点即为规则。所以在这里最重要的就是规则的排列，就是如果排列选取规则。</p>
</blockquote>
<h4 id="图搜索">3.2 图搜索</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">算法看上去没有那么复杂：</span><br><span class="line">要点1：</span><br><span class="line">- OPEN: 尚未扩充的节点； CLOSED:已经扩充过的节点</span><br><span class="line">- G中每个节点都唯一地指向一个父节点，意味着只能选取一个来做</span><br><span class="line">- &#123;mi&#125; = &#123;mj&#125; U &#123;mk&#125; U &#123;m1&#125;， 当前被扩充的全部节点=新扩充节点+OPEN+CLOSED</span><br><span class="line">- n是当前被选中的节点，它是OPEN表中排列在最前面的一个节点</span><br><span class="line">- 该算法对于连通图及树都适用</span><br><span class="line"></span><br><span class="line">&gt; 跟DFS不同的是，在扩展完节点后，修改原本已经是黑色节点的最优值，即这些节点的父亲节点可能会进行改变。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>DFS和BFS</p>
<p>BFS的变形：一致性搜索（每个点有评价指标，评价指标最重要），迭代加深搜索（限定深度，先DFS，再BFS）</p>
</blockquote>
<h4 id="启发式图搜索">3.3 启发式图搜索</h4>
<ul>
<li>A算法</li>
<li>爬山算法</li>
<li>分支限界法</li>
<li>动态规划法</li>
<li>A*算法</li>
<li>h函数与A*的关系</li>
<li>A*算法实例</li>
</ul>
<blockquote>
<p>设目标节点从s搜素到t, 中间经过n</p>
<p>定义几个评价指标：</p>
<p>k(s,n): 最佳路径耗散值</p>
<p>c(ni,nk): 路径耗散值等于该路径上所有相邻节点间耗散值的总和。</p>
<ol type="1">
<li>g*(n) = k(s,n):
从初始节点s到节点n的最小耗散值路径的实际耗散值。</li>
<li>h*(n)=min k(n.ti):
从节点n到目标节点集ti中所有节点最小耗散值路径的实际耗散值中的最小值。</li>
<li>f*(n) = g*(n) + h*(n):
从初始节点s约束通过节点n的最小耗散值路径的耗散值。</li>
<li>评价函数：f(n)=g(n)+h(n) 其中 f,g,h为f*,g*,h*的估计值</li>
</ol>
<p>h(n)为启发函数，g(n) &gt;= g*(n)</p>
</blockquote>
<blockquote>
<p>只考虑h(n), 爬山算法；只考虑g(n),分支限界法；</p>
<p>只考虑g(n),动态规划法</p>
<blockquote>
<p>解析，动态规划法仅保留queue中公共节点路径中耗散值最小的路径，余者删除；所以动态规划相比分支限界去掉了公共路径中的冗余部分，提高效率；如果问题空间是树结构，效率相同</p>
<p>？这样看，是BFS的用途；而算法课是DFS的拓扑路径</p>
</blockquote>
</blockquote>
<blockquote>
<ul>
<li>A*算法(最佳图搜索算法)</li>
</ul>
<blockquote>
<p>如果算法A有h(n)&lt;h*(n),则为A*算法.</p>
<blockquote>
<p>h*(n): 是n到t的最短的。实际预估的还要短，为什么？凸优化？</p>
<p>h*(n)未说明如何计算，实际上如何计算的？</p>
<p>h(n)=0, BFS.
h(n)越大越好，越接近h*(n)越好，意味着剩下的分支数的减小。</p>
</blockquote>
<p>几个结论：</p>
<blockquote>
<p>A*不结束， 必有f(n)&gt;f*(s)</p>
<p>A*结束前，必有f(n)&lt;f*(n)</p>
<p>对于有限图或无限图，如果存在路径，A*一定成功</p>
<p>A*选中的任何节点f(n)&lt;=f*(s)</p>
</blockquote>
<p>? A*失败的唯一原因是OPEN表为空， 不成立</p>
</blockquote>
<p>h(n)最好满足三角单调性限制，即c(ni,nj)&gt;=h(ni)-h(nj)</p>
<p>g(n)设计：与深度有关，或者路径长度</p>
<p>h(n)设计：当前位置到目标位置的各种距离。</p>
</blockquote>
<ul>
<li>与或图</li>
</ul>
<blockquote>
<p>这个也易于理解，与的话就说明这两步都需要走才行。但有个好奇的问题就是那为什么不直接合并呢</p>
</blockquote>
<p>与节点直接看作是连接节点，那么子节点分解的与节点的个数和为该节点的耗散值。</p>
<p>AO*算法</p>
<p>一般来说首先这里有一个h(n)函数，采用的就是启发式算法；对每个子节点找h(n)最小的，然后走h(n)最小的那条通路；如果走不通，则进行回溯。因为直接会回溯，所以没有g(n)就很正常</p>
<blockquote>
<p>扩展：博弈搜索</p>
<ul>
<li>极大极小搜索</li>
</ul>
<p>博弈搜索属于对抗的这种，即有对抗双方；双方可以进行对抗选择。然后A为先手，所以就想思考如何才能让A获胜。</p>
<p>全局有一个评价函数，评价值越高对A越有利。</p>
<p>因为是下棋所以考虑的就是对抗式搜索。</p>
<p>A想让自己胜利会选择max策略，B想阻止A获胜会选择min策略。</p>
<p>极大极小搜索的策略就是先根据宽度优先生成规定深度的全部博弈树，并计算叶子节点的棋局值。然后，从底向上倒推非端节点的棋局值。最终寻找出一条路径</p>
<p><span class="math inline">\(\alpha\)</span>-<span
class="math inline">\(\beta\)</span>搜索，在极大极小值算法的基础上增加了剪枝功能，并采用深度优先的策略进行搜索。？向上搜索还是向下搜索</p>
<p>很有效，代码不是那么难写，但需要花费一定功夫。</p>
<p>从某种程度上来说还是与子节点的排列顺序有关，即需要先搜索哪个节点</p>
</blockquote>
<h3 id="机器学习概述">机器学习概述</h3>
<p>设计一个学习系统，学习定义：对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随着经验E而自我完善，那么我们称这个计算机程序从经验中学习。</p>
<p>对于一个学习问题，必须明确：</p>
<ul>
<li>任务的种类T</li>
<li>衡量标准P</li>
<li>经验的来源E，数据库</li>
</ul>
<p>设计一个学习系统</p>
<p>（以西洋跳棋为例）</p>
<p>选择训练经验、选择目标函数、选择目标函数的表示、选择函数逼近算法（学习算法）、最终设计。</p>
<p>第一个关键属性，训练经验能否为系统的决策提供直接或间接的反馈。</p>
<ul>
<li>系统可从直接的训练样例，即各种棋盘状态和对应的正确走子中学习。</li>
<li>系统可能仅有间接的信息，即很多过去对弈序列和最终结局。（间接学习经验）</li>
</ul>
<p>第二个重要属性，训练样例的分布能多好第表示实例分布，最终系统的性能是通过后者来衡量</p>
<p>例子：西洋跳棋学习问题</p>
<blockquote>
<p>这里展示的只是粗略的模型，其中也是包含技巧的。比如中间通过几个模型组合，然后怎么来做得到最优结果</p>
</blockquote>
]]></content>
      <categories>
        <category>course</category>
        <category>neu</category>
        <category>ai</category>
      </categories>
      <tags>
        <tag>course</tag>
        <tag>ai</tag>
        <tag>neu</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture2-summary</title>
    <url>/2019/nju-course-cplus-lecture2-summary-357b5a9efb7d/</url>
    <content><![CDATA[<p>重点</p>
<ol type="1">
<li>抽象和封装 &gt;
抽象是外，封装是里；为什么好？栈举例，直接来，没有函数封装；结构体+函数封装，数据隐私问题，成员仍可被破坏。</li>
</ol>
<p>一个重要的问题：加访问控制 public, private(默认),protected</p>
<p>面向对象：类型和对象。程序若干个对象。对象之间关系，一是继承，传承特征；对象之间靠接口，公有函数的参数或友元来维持关系。</p>
<p>设计几大理念： 1. 抽象，控制住底层的复杂度 2.
封装，同上，侧重隐藏信息 3. 模块化，抽象封装是单个，模块化则是对整个而言
4. 软件复用：可复用的东西变得更多 5. 可维护性：代码框架灵活 6.
软件模型的自然度：能对应于问题空间</p>
<p>面向过程：过程即功能，特定功能集合，没有对象的概念。所有的东西会乱成一团。复用性差，太特殊</p>
<ol start="2" type="1">
<li>面向过程</li>
</ol>
<p>类型 对象（动态）</p>
<p>系统向一个对象通信(即只调用一个对象的接口).然后不定地解决问题。 &gt;
不过是类的问题。</p>
<ol start="3" type="1">
<li>特性：多态</li>
</ol>
<p>函数名，类型。</p>
<p>父类对象继承子类: 子类可以有两个选择 父类指针可以有两个指向
消息可以有多种发送选择</p>
<p>访问控制的建议 内部的东西private,
比如类的数据成员，类内部使用的成员函数。</p>
<p>调用未定义的类，指针+引用</p>
<p>对象，动态和静态、全局和局部。</p>
<ol start="4" type="1">
<li>使用对象</li>
</ol>
<ul>
<li><p>赋值</p></li>
<li><p>参数 const A &amp;</p></li>
<li><p>返回值</p></li>
<li><p>this</p></li>
<li><p>对象初始化，常量和引用一般不让初始化</p></li>
<li><p>构造函数和析构函数对应。</p></li>
<li><p>成员对象，拷贝构造函数</p></li>
<li><p>静态成员对象</p></li>
<li><p>f(const Data&amp; d){}, 然后 类的对象就分为两种：获取对象状态
const,外界元素均可访问，也要通过类的对象来操作，不够对应2那种参数可以进行使用；改变对象状态，需要类的对象来进行操作。
&gt; 换言之，是为常量对象而准备的</p></li>
<li><p>友元，不具有对称性和传递性，可以是类，全局函数或者类的成员函数（都行）。
&gt; 具体时间差没测试。效率上会消失多少？</p></li>
<li><p>类作为单独的模块，降低耦合。成员函数只向有限个元素发送。</p></li>
<li><p>作业：用类来实现矩阵和向量类型 矩阵：数据、行数、列数。
外界的获取接口：</p></li>
<li><p>获得行数和列数，int&amp; element(int x, int y),
这样是否可以通过地址来修改元素的值呢？ <code>m.element(1,2) =
m.element(1,2) + 1</code>, 不过说到底也是对的啊，进行的是值替代,
而这也是符合引用的定义的啊。</p></li>
<li><p>操作函数，对元素进行操作</p></li>
<li><p>构造函数: 对元素和空间进行检查。</p></li>
</ul>
<blockquote>
<p>注意：凡是函数，一定要记得对函数的输入数据进行检查和核对。</p>
</blockquote>
<p>向量：数据、维数。</p>
<ul>
<li>附录：补充 &gt; cout与cerr:
几次都遇到这种情况，不过我想今天应该明了。cout是控制台输出，当遇到endl，就不再缓冲，直接把数据输出。
cerr在命令行下， linux下命令行截取的是cerr,
1&gt;&gt;log输出的是控制台，2&gt;&gt;输出的是错误信息</li>
</ul>
<blockquote>
<p>缓冲，刷新的概念，集中输出，防止刷屏。可以看到缓冲好的数据，生活中有很多这样的例子。比如，电视机显式，等一段画面到来时再显示图像。
注意指针和实体数组，对于指针单位长度和数组元素一样。然后，new开辟的空间只能用指针来做。</p>
</blockquote>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>neu algorithm course</title>
    <url>/2019/neu-algorithm-course-c4c2d38c95c4/</url>
    <content><![CDATA[<h2 id="neu-algorithm">NEU-Algorithm</h2>
<p>主要是为了对比这学期学的算法书与本科学习的清华大学之间教材的区别。</p>
<p>清华大学教材</p>
<ol type="1">
<li>递归分治</li>
<li>动态规划</li>
<li>贪心策略</li>
<li>回溯法，一种复杂版的蛮力的感觉</li>
<li>分支限界法</li>
<li>随机化算法</li>
<li>线性规划与网络流</li>
</ol>
<p>还有一个思考点：</p>
<p>常规思路：</p>
<p>问题， BF1， BF2， 改进，......</p>
<p>大量的题之后</p>
<ol type="1">
<li>对于某道题，什么样的解法能将其搞定？什么样的解法能直觉达到最优</li>
<li>这些方法的适用范围以及时间复杂度</li>
</ol>
<h3 id="回溯法">4. 回溯法</h3>
<blockquote>
<p>从某种意义上感觉，回溯法是用来明确定义了问题的解空间。比如背包问题，有n个物品，则解空间就是{0,1}^N。
但这样下来感觉上有一个问题就是时间复杂度与n有关，不也不一定这样说，应该是说解空间为最多可以容纳多少个解。</p>
<p>！！！这里就涉及到问题的表示方法，即一个问题究竟怎样可以表示地最优</p>
</blockquote>
<p>利用了DFS框架，首先将代解的问题看作一棵搜索树。</p>
<h4 id="对应的问题定义是什么">1）对应的问题定义是什么？</h4>
<p>问题的解向量：回溯法希望一个问题的解可以表示为一个n元式(x1,x2,...,xn)的形式</p>
<p>显约束：对分量Xi的取值限定</p>
<p>隐约束：对于问题的一个实例，解向量满足现实约束条件的所有多元组，构成了该实例的一个解空间。</p>
<p>注意：同一个问题可以有多种表示n，有些表示方法更简单，所需表示的状态空间更小（存储量少，搜索方法简单）p(n)</p>
<h4 id="相关的一些定义">2） 相关的一些定义</h4>
<p>扩展节点：正在产生儿子的节点，即第一类灰色节点，当前最小灰色节点</p>
<p>活节点：一个自身已生成但其儿子还没有全部生成的节点，
即第二类灰色节点，非直系灰色节点</p>
<p>死节点：黑色节点</p>
<h4 id="实现方法">3）实现方法</h4>
<p>问题状态生成方法：</p>
<p>如果对一个扩展节点R，一旦产生了它的一个儿子C，就把C当做新的扩展节点。在完成对子树C的穷尽搜索之后，将R重新变成扩展节点，继续生成下一个儿子。</p>
<p>回溯法：为了避免发生那些不可能产生最佳解的问题状态，要不断地利用限界函数（bounding
function）来处死那些实际上不可能产生所需解的活节点，以减少问题的计算量。</p>
<p>具有限界函数的深度优先方法称为回溯法</p>
<h4 id="基本思想">4）基本思想</h4>
<ul>
<li><p>针对所给问题，定义问题的解空间</p></li>
<li><p>确定易于搜素的解空间结构</p></li>
<li><p>以深度优先方式搜素解空间，并在搜素过程中用剪枝函数避免无效搜素。</p>
<blockquote>
<p>常用剪枝函数：用约束函数在扩展节点处剪去不满足约束的子树；用限界函数剪去得不到最优解的子树。</p>
<p>即两个条件：</p>
<ul>
<li>每个值本身的约束</li>
<li>是否能得到最优解的约束</li>
</ul>
</blockquote></li>
</ul>
<h4 id="时空复杂度分析">5）时空复杂度分析</h4>
<p>空间：由于在搜素过程中是动态产生问题的解空间。所以，在任何时刻，算法只保存从根节点到当前扩展节点的路径即可。所以如果解空间树中从根节点到叶节点的最长路径的长度为h(n)，那么回溯法所需的计算空间通常为O(h(n))。而显式地存储整个解空间需要O(2^{h(n)})或O(h(n)!)内存空间。</p>
<p>时间：</p>
<blockquote>
<p>待处理？</p>
<p>两种分析方法，第一种，从树出发，即本身形成的结构，然后通过树的节点来分析复杂度；第二种，由代码出发，即代码往往能表示很多东西，从代码出发可以</p>
<p>感觉上是 O(2^n), O(n!), 这里n应该是最小表示来说</p>
<p>基于全局，从全局的所有结构中寻找结果，那么可以发现其性能复杂度是高于分支限界法的。</p>
<p>跟动态规划一样是万能解的感觉？</p>
</blockquote>
<h4 id="代码框架">6） 代码框架</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">backtrack-wrapper()&#123;</span><br><span class="line">  bestw = 0</span><br><span class="line">  backtrack(1);</span><br><span class="line">  cout&gt;&gt;bestw&gt;&gt;endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">void backtrack(int t)</span><br><span class="line">&#123;</span><br><span class="line">	if(t&gt;n || solution(x)) &#123;   // 注意这里t&gt;n, solution(x)应该在上一层更好，但是这里也没事。</span><br><span class="line">		temp = output(x); //已经搜索到叶节点; 这里只是输出的当前可行解。</span><br><span class="line">		if (temp &gt; bestw)</span><br><span class="line">			update bestw, bestx;</span><br><span class="line">	&#125;</span><br><span class="line">	else</span><br><span class="line">		// 排列树，例如任务的调度问题求最节约时间的任务调度，那么实际上求得的结果就是任务的排列。在这里做时考虑将边作为任务。</span><br><span class="line">		for(int i=t;i&lt;=n ;i++ )  //排列数由边构成</span><br><span class="line">			// 这里说明有n个孩子，注意问题已经发生改变</span><br><span class="line">			&lt;对x[i]相关统计量进行处理&gt; </span><br><span class="line">			// 前面的选择在x[i-1]中。</span><br><span class="line">			x[i] = i; // 注意这里需要进行定义</span><br><span class="line">			if (问题仍然未得到解决)</span><br><span class="line">			&#123;</span><br><span class="line">			swap(x[t],x[i]);</span><br><span class="line">			if (legal[t]) backtrack(t+1);</span><br><span class="line">			swap(x[t],x[i]) // 进行恢复</span><br><span class="line">			&#125;</span><br><span class="line">			&lt;对x[i]相关统计量进行恢复&gt;</span><br><span class="line">// 输出 backtrack(1) n=2</span><br><span class="line">// </span><br><span class="line">		</span><br><span class="line">		// 子集树</span><br><span class="line">		if(第一颗子树) &#123;</span><br><span class="line">				//动态变化的结果，等于说这里其实存储的是临时第t层的; 这里是遍历子树</span><br><span class="line">				// 这里会产生带到下一层的变量, 比如说当前使用量cw</span><br><span class="line">				if(constraint(x[t])&amp;&amp;bound(x[t]))  		                          backtrack(t+1);</span><br><span class="line">				//这里是进行子树回溯。为下一阶段同等的子节点做准备		</span><br><span class="line">		&#125;</span><br><span class="line">		if(第二颗子树) &#123;</span><br><span class="line">				...</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		for(int i=f(n,t);i&lt;=g(n,t);i++)  // 所以这里循环的次数就是子节点的个数。</span><br><span class="line">			x[t]=h(i);  h(i)为从f(n,t)到g(n,t)的选择，比如0,1</span><br><span class="line">			具体来说，这里应该再增加一个进行可以对各个子节点记性处理的操作。（</span><br><span class="line">			注意！该操作为什么要加在这里，肯定是在这里啊，想想递归思路）</span><br><span class="line">			if(constraint(x[t])&amp;&amp;bound(x[t]))  		                          backtrack(t+1);</span><br><span class="line">			// 这里可以加某一统计变量，比如说或选址少1啦</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">n表示最大递归深度</span><br><span class="line">t表示当前递归深度</span><br><span class="line">i为当前节点对应的子节点</span><br><span class="line">f(n,t): 当前扩展节点未搜索过的子树起始编号；难道还要重新搞起始节点？？？</span><br><span class="line">g(n,t): 当前扩展节点未搜索过的子树终止编号</span><br><span class="line">h(i)为第i个可选的问题表示</span><br><span class="line">x[t]这里是临时变量，可以替代很多情况的。</span><br><span class="line"></span><br><span class="line">constraint: 关于x[t]的约束，只有当前节点的值有关。</span><br><span class="line">bound: 关于能否产生解的约束，与x[t]有关，实际上还与前面的某个统计量有关。这里开始有点联想到那个什么矩阵,一般与剩余量有关。</span><br><span class="line"></span><br><span class="line">n为全局变量，需要提前得出来。</span><br><span class="line">bestw也为全局变量</span><br><span class="line"></span><br><span class="line">思考点： </span><br><span class="line">1. 进行进一步理解？有啥意义</span><br><span class="line">  进行问题结果建模，其中产生了问题结果状态树。所以此时时间复杂度分析是树节点的个数，同时需要考虑其他那些附加函数的复杂度。如果把他们看作1的话，易于分析。</span><br><span class="line">2. 与DFS框架来说有什么关系？</span><br><span class="line">  这里就是一种简单的树的结构，即仅仅只是对树进行DFS遍历而已。而DFS的精华在于对图的处理上。</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">进一步求解最优解和最优路径！</span><br></pre></td></tr></table></figure>
<p>7）其他</p>
<p>优点本质：</p>
<p>回溯法的约束条件是所有解都应满足的条件，所以从某种意义上来说回溯法可以得到所有解，其中包括最优解。</p>
<blockquote>
<p>这个跟图遍历不一样哟。</p>
</blockquote>
<p>但无限界bound函数时，该问题是判定问题，不是最优化问题</p>
<p>8）例子</p>
<p>按解空间为子集树和排列树进行划分</p>
<ul>
<li><p>子集树</p>
<blockquote>
<p>为什么叫子集树？答案的解是问题的解的子集。</p>
<p>问题：</p>
<p>一批n个集装箱要装上重量为c1和c2的轮船，每个集装箱i的重量为wi。且有</p>
<p><span class="math inline">\(\sum_{i=1}^n w_i \leq c_1 +
c_2\)</span>.</p>
<p>试图找出一种方案满足：</p>
<ol type="1">
<li>首先将第一艘轮船尽可能装满</li>
<li>将剩余的集装箱装上第二艘轮船</li>
</ol>
<p>目标：bestw，</p>
<p>其余设置量：cw, bestx, r</p>
<p>解题：</p>
<p>框架的层数对应n。 solution</p>
<p>根节点有两颗子树，选或不选（0/1）</p>
<p>可行性约束函数：<span class="math inline">\(\sum_{i=1}^n w_i x_i \leq
c_1\)</span></p>
<p>上界函数（不选择当前元素）：</p>
<p>当前载重量cw+剩余集装箱的重量r <span
class="math inline">\(\leq\)</span> 当前最优载重量bestw</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*W</span><br><span class="line">*x</span><br><span class="line">*bestx</span><br><span class="line">bestw</span><br><span class="line">cw = 0</span><br><span class="line"></span><br><span class="line">backtrack-wrapper()&#123;</span><br><span class="line">	backtrack(1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">backtrack(int t)&#123;</span><br><span class="line">	if(t&gt;n || solution(x)) &#123;</span><br><span class="line">		查看是否需要更新</span><br><span class="line">		*bestx = *x;</span><br><span class="line">		bestw = cw;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		if(cw + x[t] &lt;= c) // 搜索左子树</span><br><span class="line">			x[t] = 1;</span><br><span class="line">			cw += x[t];</span><br><span class="line">			backtrack(t+1);</span><br><span class="line">		if(cw + x[t] &gt; c) // 搜素右子树</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote></li>
<li><p>排列树</p>
<blockquote>
<p>为什么叫排列树？答案的解是问题的解的排列。</p>
<p>问题:</p>
<p>批处理作业调度：给定n个作业的集合{<span
class="math inline">\(J_1,J_2, ..., J_n\)</span>}.
每个作业必须先由机器1处理，然后由机器2处理。作业<span
class="math inline">\(J_i\)</span>需要机器j的处理时间为<span
class="math inline">\(t_{ji}\)</span>。要求对于给定的n个作业，制定最佳作业调度方案，使其完成时间和达到最小。</p>
<p>例子：</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(t_{j i}\)</span></th>
<th>j1</th>
<th>j2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>i1</td>
<td>2</td>
<td>1</td>
</tr>
<tr class="even">
<td>i2</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td>i3</td>
<td>2</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>数据结构：</p>
<p>存储: <span class="math inline">\(M[i][j]\)</span>,
注意i表示第i个作业，j表示机器j</p>
<p>注意这里有个问题就是j1上一个结束就可以执行下一个，而j2的话必须是上一个任务结束，下一个任务才能开始。所以数据结构</p>
<p>f1: 当前任务结束时间</p>
<p>f2*: f2[i] = max(f2[i-1], f1) + t2(i-1)</p>
<p>? 这题是否有问题？感觉并不需要最终相加啊</p>
<p>则由此可给出回溯法版的算法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">inital M;</span><br><span class="line">bestf</span><br><span class="line">*f2</span><br><span class="line">f1</span><br><span class="line">f</span><br><span class="line">*x</span><br><span class="line">*bestx</span><br><span class="line"></span><br><span class="line">backtrack-wrapper()</span><br><span class="line">&#123;</span><br><span class="line">backtrack(1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">backtrack(int t)&#123;</span><br><span class="line">	if(t&gt;n) &#123; // 已经将事情安排完</span><br><span class="line">		*bestx=*x</span><br><span class="line">		bestf=f</span><br><span class="line">		//</span><br><span class="line">	&#125;</span><br><span class="line">	else&#123;</span><br><span class="line">		for(int j=t;j&lt;=n;j++)&#123;</span><br><span class="line">			f1 += M[x[j]][1];</span><br><span class="line">			f2[i] = Max(f2[i-1], f1)+M[x[j]][2];</span><br><span class="line">			f += f2[i];</span><br><span class="line">			if(f &lt; bestf)&#123;</span><br><span class="line">				swap(x[t],x[i]);</span><br><span class="line">				backtrack(t+1);</span><br><span class="line">				swap(x[t],x[i]);</span><br><span class="line">			&#125;</span><br><span class="line">			f1 += M[x[j]][1];</span><br><span class="line">			f2[i] = Max(f2[i-1], f1)+M[x[j]][2];</span><br><span class="line">			f += f2[i];</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote></li>
</ul>
<p>其他例子</p>
<ul>
<li>最大团问题</li>
</ul>
<blockquote>
<p>感觉上进入右子树的时机给的很有问题。</p>
</blockquote>
<ul>
<li>图的m着色问题</li>
</ul>
<blockquote>
<p>教训就是要区分判定问题还是最优化问题</p>
</blockquote>
<h4 id="回溯法效率分析">7）回溯法效率分析</h4>
<p>回溯法取决于以下因素：</p>
<ul>
<li>产生x[k]的时间</li>
<li>满足显约束x[k]值的个数</li>
<li>计算约束函数的时间</li>
<li>计算上界函数的时间</li>
<li>满足约束函数和上界函数约束的所有x[k]的个数</li>
</ul>
<blockquote>
<p>由此可见，在选择约束函数式通常存在生成节点数与约束函数计算量之间的折中。</p>
</blockquote>
<h3 id="分支限界法">5. 分支限界法</h3>
<p>利用BFS框架</p>
<p>试图去寻找问题的一个解或者最优解。</p>
<blockquote>
<p>在分支限界法中，每个活结点只有一次机会成为扩展节点。活节点一旦成为扩展节点，就一次性生成器所有儿子节点。在这些儿子节点中，导致不可行解或导致非最优解的儿子节点被舍弃，其余儿子节点加入活节点链表。</p>
<p>感觉上有点像BestFS的框架的感觉，比较奇妙的以及感觉需要深入思考的就是这里怎么把一些兄弟节点给排除的。</p>
<p>剪枝策略：在算法扩展节点中，一旦发现一个节点的下界不小于当前找到的最短路长，则算法剪去以该节点为根的子树。所以从某种意义上来说是等于还是在基于之前的信息进行剪枝。
所以这里的剪枝函数必然是某种与路径相关的变量。</p>
</blockquote>
<p>2）算法框架</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">pq;</span><br><span class="line">cw;</span><br><span class="line">bestw;</span><br><span class="line"></span><br><span class="line">branchBound(s)  // 注意s可以是随机开始的一个点</span><br><span class="line">&#123;</span><br><span class="line">	pq Q;</span><br><span class="line">	Q.add(-1);</span><br><span class="line">	Ew=0;</span><br><span class="line">	bestw=0;</span><br><span class="line">	while(true) &#123;</span><br><span class="line">		for every w of v:</span><br><span class="line">			if(bound(w)) Q.add(w,..);//注意这里可以添加一些其他变量之类的东西。</span><br><span class="line">		// 注意这里可以做一些更新操作。</span><br><span class="line">		Q.delete(v);</span><br><span class="line">		if(v == -1) &#123;</span><br><span class="line">			if(Q.isEmpty) return bestw;</span><br><span class="line">			Q.add(-1);</span><br><span class="line">			Q.delete(Ew);</span><br><span class="line">			i++;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3）算法直观感觉</p>
<p>分支限界法常用来解离散最优解的问题。</p>
<p>算法过程：首先，队列中有第一个元素。然后，对队列中选取的节点的子节点加入到队列中。按照优先级选取某个元素，凡是操作某个元素，对应的临时变量进行更新；当到达叶子节点时，说明开始取得某个最优值。所以此时考虑对队列中小于最优值的进行剪枝。</p>
<p>一个问题就是对于离散树和排列树两种不同的情况应该如何考虑。</p>
<ul>
<li>单源最短路径</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Graph &#123;</span><br><span class="line">n; //顶点数</span><br><span class="line">*prev //前驱顶点数组</span><br><span class="line">**c  // 邻接矩阵</span><br><span class="line">*dist //最短距离数组</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MinHeapNode&#123;</span><br><span class="line">i; // 顶点编号</span><br><span class="line">length; //当前路长</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main()&#123;</span><br><span class="line">ShortestPath(s)</span><br><span class="line">// 找出s到其他所有顶点的最短路径。结果在*dist中。</span><br><span class="line">&#125;</span><br><span class="line">ShortestPath(int v)</span><br><span class="line">&#123;</span><br><span class="line">MinHeap&lt;&lt;MinHeapNode&gt;&gt; H(100);</span><br><span class="line">MinHeapNode E;</span><br><span class="line">E.i=v;</span><br><span class="line">E.length=0;</span><br><span class="line">dist[v]=0;</span><br><span class="line">while(true)&#123;</span><br><span class="line">for(int j=1; j&lt;=n;j++)&#123;</span><br><span class="line">	if(c[E.i][j]&lt;inf &amp;&amp; E.length+c[E.i][j]&lt;dist[j]) &#123;</span><br><span class="line">	// 第一个条件表示有边存在， 第二个情况表示比当前的dist[j]还要短</span><br><span class="line">		dist[j] = E.length+c[E.i][j];</span><br><span class="line">		prev[i]=E.i;</span><br><span class="line">		// 加入活节点列表</span><br><span class="line">		MinHeapNode N;</span><br><span class="line">		N.i =i;</span><br><span class="line">		N.length=dist[j]; // 注意这里的更新</span><br><span class="line">		H.Insert(N)</span><br><span class="line">	&#125;</span><br><span class="line">	try &#123;H.DeleteMin(E);&#125; // 这里蕴含了取下一个节点。</span><br><span class="line">	catch(OutOfBounds)&#123;break;&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>分支限界法有种感觉就是利用层次遍历，首先取一个节点，然后找它的儿子节点。对每个儿子节点扩充，因为是队列，所以处理起来感觉像是并行处理。如果两个节点扩展到同一个节点，那么选取最优的节点，而删除非最优的节点。</p>
<p>从某种意义上说，当源点的多条路遍历结果到达某个节点时，进行比对，选择最优的。</p>
<p>而跟bestfs不同的是，bestfs比较是同时发生一下选定的，而分支限界法是异步发生，异步选定的。</p>
</blockquote>
<h3 id="随机化算法">6. 随机化算法</h3>
<blockquote>
<p>随机化算法的特征是对所求解问题的同一个实例用同一随机化算法求解两次可能得到完全不同的效果。但是会在很大程度上降低时间复杂度。</p>
<p>常见的随机化算法：</p>
<ol type="1">
<li>数字随机化算法，常用于数值问题的求解</li>
<li>蒙特卡洛算法，常用于求问题的精确解</li>
<li>拉斯维加斯算法，不会得到不正确的解</li>
<li>舍伍德算法，求解的算法总是正确的。</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>course</category>
        <category>neu</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>course</tag>
        <tag>neu</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus</title>
    <url>/2019/nju-course-cplus-lecture1-67428cb9a1a1/</url>
    <content><![CDATA[<h2 id="程序设计基础知识回顾">0 程序设计基础知识回顾</h2>
<h3 id="基本">0.1 基本</h3>
<p>程序=算法+数据结构</p>
<p>在程序中，数据类型来描述数据，流程控制语句来实现算法</p>
<p>数据类型规定了两个集合： 1. 值集 2. 操作集</p>
<p>基本数据类型：对应机器指令能直接处理的数据
构造数据类型：由基本数据类型构造出来的数据，枚举、数组、结构、联合、指针、引用</p>
<p>程序实体在内存中的安排 -
静态数据区用于全局变量、static存储类的局部变量及常量的内存分配。如果没有显式初始化，系统将把它们初始化为0
- 代码区用于存放程序的指令 - 栈区用于auto存储类的局部变量 -
堆区用于动态变量的内存分配</p>
<p>对于返回值： - 如果是简单数据类型，通常在寄存器 -
否则，在一块临时内存空间，在调用者的栈空间，调用者把这块空间的地址传给被调用者，被调用者通过这个地址存储返回值</p>
<p>一般情况，不必关心栈的具体情况，进行混合语言编程，需要考虑不同语言在栈上的差别
过深的函数嵌套将造成栈空间不足。
对于参数来说，不应把大的结构按值传递给函数，不应定义很大的局部数组变量。
不要返回局部变量的地址，没有什么输出。 &gt;
这里仿佛懂了为什么不在函数里定义变量，而一般的算法竞赛的代码都在开头定义，因为最终所处的位置不一样。
&gt; 还有一点就是对于函数参数，最后的情况下还是进行地址传递的好。 ###
循环&amp;递归函数 &gt;
循环，重点关注的是退出的元素，即循环判断语句中的内容。</p>
<p>循环对计算机问题求解中的穷举法和迭代法提供支持</p>
<p>分而治之：
把一个问题分解为若干个子问题，而每个子问题的性质与原问题相同，只是在规模上比原问题要小。每个子问题的求解过程可以采用与原问题相同的方式来进行。</p>
<p>递归函数的关键：
递归条件：何时进行递归调用，它描述了问题求解的一般情况，包括：分解和综合过程
结束条件：何时不需递归调用，它描述了问题求解的特殊情况或基本情况</p>
<blockquote>
<p>递归函数中定义的局部变量在运行中分布在栈区中，而非静态数据区，因此此时临时变量将不再有效。所以务必注意在设计递归函数时的变量的要求是否符合实际的要求。
循环是在同一组变量上进行重复操作；递归则是在不同的变量组上进行重复操作
### 指针和引用</p>
</blockquote>
<blockquote>
<p>指针再理解，尽管数据结构是链表，其在底层的存储方式不过是一个一个位置块而已。而指针指向它，不过是指向这些块，并能通过这些块，不断继续能访问到下面的元素。
但是，一点有意思的是，指针就像路标，指示该点的位置。而且用指针可以改变链表后面的组织方式。但指针获得后面元素的指针，对元素之间进行一顿猛操作后。前面的指针依然生效，此时返回前面的指针，就是返回一种新的位置。</p>
</blockquote>
<p>指针只是一个位置的地址，可以在程序中间接来访问，通过p可以访问实参意外的数据，变量的地址；
初始化后，仍可指向其它变量
引用，变量的名字，只能直接访问实参的数据，初始化后，不能再指向其它变量。
&amp;=const *.</p>
<p>&amp;最好用，指向的变量不可改变，但可以在函数中改变其值。 &gt;
引用类型变量 int x=0; int &amp;y=x; //y是引用类型变量，x的别名 y=1;
cout&lt;&lt;x; // x==1
不要返回局部变量的引用，这样返回值可能会被修改。</p>
<p>const int &amp; 不可不改变其值</p>
<p>const int <em>: </em>p=1 X int * const p: p=&amp;x X</p>
<p>const三种用法 1. 放在开头，修饰内容，内容不可Ian const int a=5; const
int <em>p = 8; 2. 放在</em>后面，修饰指针，指针不可变 int a = 8; int*
const p = &amp;a; <em>p = 9; // 正确 int b = 7; p = &amp;b; // 错误 ###
序列数据的表示 #### 1. 静态表示 int a[N]; // N为一个常量或常量表达式
好处：能够快速访问序列元素a[i]: a的首地址+i</em>sizeof(int) #### 2.
动态表示 数据的内存空间随元素数量的变化动态分配 - 动态数组 int <em>p=new
int[n]; //动态分配数组空间，n可以是变量 p[i] //
使用数组元素，等价于</em>(p+i) int *q=new int[n+m] //扩大空间 ...//
元素从p到q的转移 delete []p; // 删除原来的空间 p=q; //p指向新的空间 p[j]
##### <strong>链表</strong>
为每个元素动态分配内存空间，各元素的内存空间不必联系。</p>
<p>为了能把离散的元素空间“串”起来
好处：空间补充容易，增加、删除元素不影响其它元素 strut Node{ int
content; Node <em>next; }; Node </em>head=NULL;</p>
<p>这里的链表头结点也有值. 所以访问时，头结点从第一个元素开始思考。
###### 访问链表元素 &gt; 输入是链表的头结点，目的是返回元素的值</p>
<ul>
<li>访问第i个元素(i=0,1,2,...) <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Node *p=head;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;i &amp;&amp; p!=<span class="literal">NULL</span>;j++)&#123;</span><br><span class="line">    p=p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(p!=<span class="literal">NULL</span>)  *p  <span class="comment">//访问第i个元素</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">设计数单位为i=<span class="number">4</span>，若从<span class="number">0</span>开始。值得注意的是这里</span><br><span class="line">Node *head;</span><br><span class="line">head=L;</span><br><span class="line"><span class="keyword">while</span>(p!=<span class="literal">NULL</span> &amp; i) &#123;</span><br><span class="line">    p=p-&gt;next;</span><br><span class="line">    i--;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>访问指定元素a <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Node *p=head;</span><br><span class="line">while(p!=NULL &amp;&amp; p-&gt;content!=a) p=p-&gt;next;</span><br><span class="line">if(p!=NULL) *p //访问元素a</span><br></pre></td></tr></table></figure></li>
</ul>
<h6 id="在单链表中增加元素">在单链表中增加元素</h6>
<blockquote>
<p>传入旧的链表，目的是返回新的链表。而新的链表由头结点返回标志即可。</p>
</blockquote>
<ul>
<li>分配新元素的空间 Node *p=new Node;</li>
<li>存储元素本身的内容 p-&gt;content=..</li>
<li>找到前一个元素的位置（设由q指向它）
<ul>
<li>按序号找:</li>
<li>按内容找</li>
</ul></li>
<li>把新元素q插入 p-&gt;next=q-&gt;next q-&gt;next=p;</li>
<li>特殊情况的处理！ 在表头增加元素q q-&gt;next=head-&gt;next
head-&gt;next=q; // 错误，这里把head当做空了 ######
在单链表中删除元素</li>
<li>找到前一个元素的位置（由q指向它），要删除p，则 p=q-&gt;next &gt;
删除元素： q-&gt;next=p-&gt;next; delete p;</li>
<li>特殊情况的处理！
<ul>
<li>要删除的元素不存在 &gt;
目的达到了，但关键就是是否需要进行报告所删除的元素不存在。 &gt;
此时遍历到最后一个节点的next节点，p==NULL</li>
<li>删除第一个元素 &gt; Node *p=head; &gt; if(n==0) { &gt; return
head-&gt;next; // &gt; }</li>
</ul></li>
</ul>
<blockquote>
<p>? 如何结合数组与链表的优点？ STL, vector,
可以动态开辟空间，还可以随机访问。 ？</p>
</blockquote>
<h3 id="编译预处理命令">编译预处理命令</h3>
<p>编译预处理命令不是C++程序所要完成的功能，而是用于对编译过程给出指导，其功能有编译预处理系统在编译时候来完成。
编译预处理命令主要有：</p>
<h4 id="include-文件包含命令">#include 文件包含命令</h4>
<p><文件名> 在系统指定目录下寻找文件 "文件名"
现在包含改文件所在目录下寻找指定文件，再找系统文件 &gt;
但是这里找的是工程目录？还是文件目录？</p>
<p>为多模块结构提供了支持 file1.h // 进行全局变量、函数的声明 file1.cpp
// 进行全局变量、函数的定义</p>
<p>file2.h file2.cpp</p>
<p>int main(){ double r; // 局部变量的定义 }</p>
<blockquote>
<p>如果file1.h和file2.h发生冲突怎么办</p>
</blockquote>
<h4 id="define-宏定义命令">#define 宏定义命令</h4>
<p>宏定义常用来定义变量和实现类似函数的功能： &gt; #define
<宏名>(<参数表>) <文字串> 如： #define max(a,b) ((a)&gt;(b) ?
(a):(b))</p>
<p>优点：效率更高
缺点：需要加上很多的括号，否则会出问题；有时会重复计算；替换时不进行参数类型检查和转换；不利于调试</p>
<h4 id="条件编译命令">条件编译命令</h4>
<blockquote>
<p>理解，一种感觉就是编写代码过程中，即实际的代码分布为多个文件，而怎么样把整个文件一起组织呢?
由小往大看，分为局部变量和全局变量。全局变量应该是在运行过程中堆栈中的静态数据区的。所以，这里一方面希望不能冲突
file1.h, file2.h冲突怎么办。
用条件编译设置指示变量来表示将编译哪些内容和不编译哪些内容。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;代码1&gt; 必须编译的代码</span><br><span class="line">#define ABC</span><br><span class="line">&lt;代码2&gt; 必须编译的代码</span><br><span class="line">#ifdef ABC</span><br><span class="line">&lt;代码2&gt; 如果宏名ABC有定义则编译之</span><br><span class="line">#else</span><br><span class="line">&lt;代码3&gt; //如果宏名ABC没有定义，编译之 </span><br><span class="line">#endif</span><br><span class="line">&lt;代码4&gt; //必须编译的代码</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意可以嵌入到代码中执行 宏可以在代码中定义，也可在编译环境中定义</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#if &lt;常量表达式1&gt; / #ifdef &lt;宏名&gt; / #ifndef &lt;宏名&gt;</span><br><span class="line">	&lt;程序段1&gt;</span><br><span class="line">#elif &lt;常量表达式2&gt;</span><br><span class="line">	&lt;程序段2&gt;</span><br><span class="line">......</span><br><span class="line">#elif &lt;常量表达式n&gt;</span><br><span class="line">	&lt;程序段n&gt;</span><br><span class="line">[#else</span><br><span class="line">	&lt;程序段n+1&gt;]</span><br><span class="line">#endif</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>作用： &gt; 避免包含头文件带来的重复定义或声明 &gt;
基于多环境的程序编制</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">重复包含下面的头文件不会引起多次编译</span><br><span class="line">//module1.h</span><br><span class="line">#ifndef MODULE1</span><br><span class="line">#define MODULE1</span><br><span class="line">......  //module1中的程序实体的声明或定义</span><br><span class="line">#endif</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">编译到不同的平台</span><br><span class="line">#ifdef UNIX</span><br><span class="line">	......  //适合于UNIX环境的代码</span><br><span class="line">#elif WINDOWS</span><br><span class="line">	......  //适合于WINDOWS环境的代码</span><br><span class="line">#else</span><br><span class="line">	......  //适合于其它环境的代码</span><br><span class="line">#endif</span><br><span class="line">......  //适合于各种环境的公共代码</span><br><span class="line"></span><br><span class="line">在开发阶段加入的调试信息：</span><br><span class="line">#ifdef DEBUG</span><br><span class="line">......  //调试信息，主要由输出操作构成 </span><br><span class="line">#endif</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture2</title>
    <url>/2019/nju-course-cplus-lecture2-aef72747c4c1/</url>
    <content><![CDATA[<h1 id="本节课重点">本节课重点</h1>
<h2 id="抽象和封装">1. 抽象和封装</h2>
<ul>
<li>抽象:
数据的使用者只需要知道数据能实施的操作以及这些操作之间的关系，不必知道数据的具体表示形式。</li>
<li>封装：将数据及其操作作为一个整体来进行实现。数据的具体表示对使用者是不可见的，对数据的访问只能通过封装体所提供的对外接口来完成。</li>
<li>案例
比如，栈的使用，首先不能直接在程序中定义，一不小心手误就会出错；其次，采用面向过程的想法：
struct Stack{}; void push(Stack &amp;s); 当我在其他地方定义一个void
f(Stack &amp;s),
会破坏Stack的数据；数据表示仍是公开的，可以对数据进行操作。</li>
</ul>
<p>所以引入面向对象。 public对外的接口， private隐藏的内容，外不可见
protect面向继承</p>
<p>把程序构造成由若干个对象组成，每个对象是由一些数据以及对这些数据所能实施的操作构成的封装体。
一个雷所描述的对象的特征可以继承。 &gt;
这里特征指private中的成员。对象所定义的操作即是其接口</p>
<h2 id="面向对象程序的执行过程">2. 面向对象程序的执行过程</h2>
<p>对象构成了面向对象程序的基本计算单位
对象间的消息传递是引起面向对象程序进行计算的唯一形式。 &gt;
从程序外部向程序中的某个对象发送第一条消息标志着程序的开始。该对象在处理这条消息的过程中又向其他对象发送消息，引起进一步的计算。当第一条消息处理结束后则程序的一次计算结束。消息处理可以分为同步和异步，这里显然只涉及到同步。</p>
<h2 id="对比">3. 对比</h2>
<p>提高软件开发效率和保证软件质量的几个基本程序设计手段 -
抽象（复杂度控制） - 封装（信息隐藏） - 模块化（组织大型程序） -
软件复用（延长开发周期） - 可维护性（延长软件寿命） -
软件模型的自然渡（缩小解题空间与问题空间的语义间隙） &gt;
最后一个方面可以思考到，实际上求解问题都可以划分各个状态。即通过状态空间来解题，所以可以看出来基于对象/类的解题方式与问题空间有很好的对应。</p>
<blockquote>
<p>面向过程是什么？强调的是过程即功能，数据和操作分离，数据没有保护，功能特定限定不可扩展。最后，与问题空间没啥关系。
最大的高手是能说出一堆东西还能找到准确的分类。</p>
</blockquote>
<h2 id="面向对象的基本内容">4. 面向对象的基本内容</h2>
<p>对象-值，类-类型。 多态：某一论域中的一个元素存在多种解释： -
一名多用：函数名、操作符重载 - 类属性： -
一函数可以对多种类型数据进行操作？ - 一个类型可以描述多种类型的数据</p>
<p>绑定：确定对多态元素的某个使用是多态元素的哪种形式？ - 静态绑定 -
动态绑定</p>
<p>面向对象程序特有的多态（继承） 1. 对象类型的多态:
子类对象可以属于子类，也可以属于父类 2.
对象标识的多态：父类的引用或指针可以引用或指向父亲对象，也可子类对象 3.
消息的多态：发给的消息可以发给子类，即，一个消息可以有多种解释（父类与子类有不同解释）</p>
<p>多态带来的好处： - 易于实现程序高层代码的复用 ？ -
使得程序扩充变得容易（只要增加底层的具体实现） -
增强语言的可扩充性（操作符重载）</p>
<h4 id="类">类</h4>
<p>对象构成了面向对象的基本计算单位，而对象的特征则是由相应的类来描述。因此，程序中首先要定义类。
注意：在C++中，也允许在结构和联合中定义函数，但成员的访问控制与类不同。
&gt; 结构和联合的成员默认为public,是否可以改我不知道？</p>
<p>访问控制就是public,private,protected.</p>
<p>public:公开 private:本类和友元的代码中访问，默认方式
protected:只能在本类、派生类和友元的代码中访问 &gt;
友元函数什么意思？</p>
<p><strong>访问控制设置的建议</strong> 1.
类的数据成员和在类的内部使用的成员函数应该指定为private,只有提供给外界使用的成员函数才指定为public.
具有public访问控制的成员构成了类与外界的一种接口，在一个类的外部只能访问该类接口中的成员</p>
<p><strong>数据类型定义时的注意</strong> 1.
在说明一个数据成员的类型时，如果未见到相应类型的定义，或相应的类型未定义完，则该数据成员的类型只能是这些类型的指针或引用类型。
&gt;
因为实际类型是无法解释代码的。而指针类型是现在符号表中定义，然后再寻找答案的。</p>
<ol start="2" type="1">
<li>成员函数的实现可在内外定义，在内外定义要用类名受限，区别于全局函数。</li>
<li>类成员函数名是可以重载的，它遵循一般函数名的重载规则。</li>
</ol>
<h4 id="对象">对象</h4>
<p>对象是动态运行中构造，类型是静态的形式。</p>
<p>对象可以分为全局对象、局部对象和成员对象？</p>
<hr />
<p>对象创建的两种方式 - 直接，实体变量，使用实体，在静态区或栈中 &gt;
静态区好像不可能？ 前面不说了吗？是这个意思吗？ - 间接，动态，使用指针
在堆中 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A *p;</span><br><span class="line">p=new A;  //创建</span><br><span class="line">*p,  p-&gt;  </span><br><span class="line">delete p;</span><br><span class="line"></span><br><span class="line">A *q;</span><br><span class="line">q=new A[100];</span><br><span class="line">q[i]   // *(q+i)</span><br><span class="line">delete []q;</span><br></pre></td></tr></table></figure> ****</p>
<ul>
<li><p>使用参数进行赋值
同类型一样，同类对象可以进行赋值，取对象地址之类的事情 <code>Data
b;</code></p></li>
<li><p>使用对象作为参数
使用对象做实参，不想函数在调用是创建一个大的元素又不想被修改 const Data
&amp;d &gt; 感觉上参数实际上就是一个地址</p></li>
<li><p>使用对象作为返回值 &gt;
务必注意一个事，如果想返回的是一个新对象返回值用Data；否则容易把参数中，原本函数中的值给改变。最重要的是自己到底是想还是不想被改变</p></li>
<li><p>每个对象，this指针 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 面向对象编程</span><br><span class="line">class A&#123;</span><br><span class="line">    public:</span><br><span class="line">        void g(int i)&#123;</span><br><span class="line">            x=i;</span><br><span class="line">            // 相当于this.x=i;</span><br><span class="line">        &#125;</span><br><span class="line">    private:</span><br><span class="line">        int x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 面向过程编程</span><br><span class="line">struct A&#123;</span><br><span class="line">    int x;</span><br><span class="line">&#125;</span><br><span class="line">void g(A *const this,int i)&#123;</span><br><span class="line">    this-&gt;x=i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">a.g(1); 等价于 g(&amp;a,1);</span><br></pre></td></tr></table></figure> &gt;
突然想到了，Python中编程，当初想要将 pub(x,y)变为x(y)的过程？
具体怎么做还得看一下相关书上的东西。</p></li>
</ul>
<hr />
<ul>
<li>对象初始化 特有的东西，init(), 自动被调用，很好！ 可重载 动态数组
默认 A(); 常量和引用不能被初始化,为什么？ &gt;
一旦被赋值了，那对象还要它干什么</li>
</ul>
<p>初试话顺序按类定义顺序，很显然</p>
<p>在构造函数中开辟的空间需要自己在析构函数中解决，特别是动态申请的空间。</p>
<ul>
<li>成员对象 数据成员可以是另一个类 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class A</span><br><span class="line">&#123;   int x;</span><br><span class="line">   public:</span><br><span class="line">	 A() &#123; x = 0; &#125;</span><br><span class="line">	 A(int i) &#123; x = i; &#125;</span><br><span class="line">&#125;;</span><br><span class="line">class B</span><br><span class="line">&#123;   A a;</span><br><span class="line">     int y;</span><br><span class="line">   public:</span><br><span class="line">	  B() &#123; y = 0;&#125; //调用A的默认构造函数对a初始化。</span><br><span class="line">     B(int i) &#123; y = i; &#125; //调用A的默认构造函数对a初始化。  </span><br><span class="line">     B(int i, int j): a(j) &#123; y = i; &#125; //调用A(int)对a 初始化。  </span><br><span class="line">&#125;;</span><br><span class="line">B b0; //b0.y初始化为0，b0.a.x初始化为0</span><br><span class="line">B b1(1); //b1.y初始化为1，b1.a.x初始化为0</span><br><span class="line">B b2(1,2); //b2.y初始化为1，b2.a.x初始化为2</span><br></pre></td></tr></table></figure></li>
</ul>
<p>析构的顺序跟执行顺序相反。 &gt; 容易想到，析构函数
先调用本身类，再调用成员对象 &gt; 应用场景：复杂的窗口调用关系时</p>
<ul>
<li>拷贝构造函数 <code>A(const A&amp;a)&#123;&#125;</code> ！ &gt;
正如其名，在需要拷贝，即值传递的时候用到 &gt;
比如说，构造函数就自定义的，那么拷贝构造函数？ &gt;
?默认构造函数是什么？-&gt; 隐式拷贝构造函数</li>
</ul>
<p>对于隐式拷贝构造函数： 1. 非对象成员逐个赋值 2.
对象成员优先选择构造函数，否则隐式 &gt;
这里注意，当成员构造函数中申请了一片空间，可能会同时指向一片空间</p>
<blockquote>
<p>p=new int[5];
这样会指向一个空间吗？首先，要看它的第一步动作，如果是</p>
</blockquote>
<p>对于自定义拷贝构造函数，注意成员对象默认构造函数，否则显式指定</p>
<blockquote>
<p>这里比较麻烦， 1. 定义对象 <code>A a，b; b=a;</code> 2.
对象作为值参数和返回值</p>
</blockquote>
<ul>
<li>const</li>
</ul>
<p>void f(const Date&amp; d){ d.get_day();
//不可以，无法知道实际上是否进行了数据成员改变，所以统一禁止 }</p>
<p>因此，将类的成员函数分为两类： - 获取对象状态 int get_day() const {};
//不能改变数据成员的值， 这下f中d.get_day()ok了 - 改变对象状态</p>
<hr />
<ul>
<li>同类对象共享数据（全局变量不行，不安全！） &gt; 问题如何引出？
static还有什么用？</li>
</ul>
<blockquote>
<p>采用静态对象，类直接可以获取。static int x; void f() {x++; } //
工厂模式，进行计数， 类可直接访问，只有一个备份
应用：实现对某类对象的计数</p>
</blockquote>
<ul>
<li>静态成员函数 静态成员函数只能访问类的静态成员。
静态成员函数没有隐藏的this &gt;
静态都可以通过对象和类两种方式来访问</li>
</ul>
<blockquote>
<p>在一些“纯”面向对象程序设计语言中，把类看作对象，用元类(meta
class)来描述. 静态成员属于“类对象”</p>
</blockquote>
<ul>
<li>友元 &gt; 暴露的一个超级大的接口，为了应对其他方面的不足。 &gt;
目的是为了提高在类的外部对类的数据成员的访问效率。</li>
</ul>
<p>友元可以是全局函数、其它的类或其它类的某些成员函数。 class A { ? //
感觉是public friend void func(); friend class B; friend void C::f();
private: int x; }</p>
<p>友元关系具有不对称性。 友元也不具有传递性
友元是数据保护和数据访问效率之间的一种折中方案</p>
<p>todo 用类来实现矩阵和向量类型 multipy的实现</p>
<p>类作为模块 - 类是一个自然的模块划分单位 - .h文件中存放的是类的定义 -
.cpp文件中是类成员函数的实现</p>
<p>一个模块一般有两个文件</p>
<blockquote>
<p>耦合性：模块与模块之间的依赖关系</p>
</blockquote>
<p>过程： 结构式</p>
<p>面向对象：降低耦合</p>
<blockquote>
<p>Demeter法则，一个类的成员函数除了访问自身类结构的直接子结构外，不能以任何方式依赖于任何其他类的结构。
每个成员函数只应向某个有限集合中的对象发送消息。
仅与你的直接朋友联系。</p>
</blockquote>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture3-summary</title>
    <url>/2019/nju-course-cplus-lecture3-summary-6932a488cfa1/</url>
    <content><![CDATA[<h2 id="操作符重载">操作符重载</h2>
<p>首先，不能考虑传统方法，即add，为什么？因为从某种意义上来讲极其不实用。</p>
<p>所以考虑重载操作符, 下列不能重载 . 标志作用域的 sizeof()
计算内存空间的 ?: 双判断的 :: 类的标志符</p>
<h3 id="一般地">一般地</h3>
<blockquote>
<p>全局友元函数和成员函数两种方式。
对比来说，也就是成员函数，默认前面有类.,
这其实是作为函数的默认参数this的，即const Complex&amp;</p>
</blockquote>
<p>那么就有一下几种操作符重载的例子，这里就只给出成员函数类型的
返回值、参数 - 双目 Complex opreator # (const Complex &amp;c) - 单目
Complex opreator *(); ++i; Complex &amp;opreator ++(); &gt;
前置++,返回运算后的结果。 i++; Complex opreator
++(int);//注意这里直接是int，没有变量名，只是为了区分。 &gt;
后置++，返回当前，实际+1；</p>
<hr />
<p>特别说明， 返回值的确定，当需要返回的是一个值得改变的值是用这个。
参数的确定 ****</p>
<h1 id="特殊地">### 特殊地</h1>
<blockquote>
<p>区分两种不同的含义，初始化时调用拷贝构造函数；赋值时重载函数、
都要注意默认的指针直接复制的问题</p>
</blockquote>
<p>[] &gt;很简单，类似于单目运算</p>
<p>new &gt; 分配空间+调用构造函数 &gt;
只能用静态成员来书写，static可以不用写 &gt; void <em>operator new(size_t
size) { void </em>p=malloc(size); // 调用系统堆空间分配操作
memset(p,0,size); //把系统申请到的堆空间初始化为全0 return p; }
返回类型必须为void *
参数size表示对象所需空间的大小，其类型为size_t（unsigned int） &gt;
可以选择带其他参数，此时就可以在非堆区分配空间 &gt; p = new
(buf局部变量) A(size);</p>
<p>delete &gt;</p>
<blockquote>
<p>从某种意义上说，new和delete可以提高效率。因为delete归还不是归还到堆区，而是归还原本new申请的空间.
进行空间管理</p>
</blockquote>
<p>() &gt; int opreator() (int x){return x+value;} A a(3);
cout&lt;&lt;a(10); &gt; 此时()将类对象作为了函数。有冒险用啊？ &gt;
比如新建一个随机数对象，初始化种子后random(1)，后面每需要一个随机数random()直接产生，很快！
&gt; ?,
这里跟函数对象有什么关系？这里是把类对象通过重载()作为函数使用</p>
<p>而函数对象，就是lambda表达式搞的是一大堆符号，然后后面跟一些参数。而也可以直接把它作为参数传递。</p>
<p>// 功能：求上下限为a,b的积分，步长假设为0.01 // 函数定义 double
integrate(double (*f)(double),double a,double b){ double sum=0;
for(double i=a; i&lt;=b; i+=0.01){ sum+=f(i); } return sum; }</p>
<p>// 使用：这里传入的函数对象是lambda表达式 integrate(<a
href="double%20x"></a>-&gt;double { return x*x; },0,1); &gt;
想想这真的可以做很多东西。</p>
<p>-&gt; 双目，第一个为指向类或结构的指针，第二个为第一个的成员 &gt;
例子：获取在程序执行的某个时刻获得某个对象被访问的次数 &gt;
注意，凡是成员对象，还有成员函数被访问都算，即暴露给外界可访问的东西。
对于成员函数很容易想到可以每个里面加上cout++;但是对于数据成员不好操作。
此时即智能指针 &gt;
想法即是在A类外部在套了个B类，B将A作为了成员，当接到访问时，
B-&gt;()-&gt;f(), 第二个才访问到A的内容， B-&gt;()。
为了完全模拟还要重载其他操作符，如*,[],... 太麻烦了！！
对于歧义问题即+这种操作符，一般地会进行隐式转化，但当有一方为类就很难，显式解决。</p>
<ul>
<li>lambda表达式</li>
</ul>
<blockquote>
<p>C++11给你规定了一堆东西，你可以拿去玩。其实也就是lambda函数那一章，其实后面还可以再加lambda表达式。最后再传递参数。</p>
</blockquote>
<p>所以就允许你用函数作为参数，其实这就很容易了。突然想起了scala.
而且lambda表达式还允许你加入局部变量之类的东西。</p>
<ul>
<li>继承</li>
</ul>
<p>提出就是为了最大程度的软件复用。
日常有多种行为，就是很小的改动的那种。
比如事务按层次来分类，对概念进行组合，软件进行增量开发等等</p>
<p>访问控制：自己，公开，继承。</p>
<p>继承破坏了封装性。 耦合性是事务之间的关联程度。</p>
<p>继承方式，过滤器</p>
<p>多态性：
子类又是父类；从某种意义上说，很强大。父类指针就可以随便用。</p>
<p>但又带来了问题了，可以随便用。但是肯定会指向自己，所以引进虚函数。允许指向未来更好的实现。
&gt; 高层代码完全不用修改。相比用union实现的。
于是有了纯虚函数，这就形成了真正意义上的抽象。</p>
<p>然后，还有聚集的方式。</p>
<p>总结：C++很好地用类进行数据的封装，保证了元素的私密性。
然后为了给外界提供一定的界限。 将数据的访问方式进行了分类。
对于获取信息的，外界全局函数就可以采用。const关键字很妙！
还有设置信息。</p>
<p>类作为类型。将不变的抽象给static元素。</p>
<p>然后，多态性。函数名，参数名。 再加上运算符号。</p>
<p>一对一并不完全符合世界的表述所以增加了多继承的方式。</p>
<p>然后再对类型的统一，最终就变为了泛型设计。</p>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture3</title>
    <url>/2019/nju-course-cplus-lecture3-7e25a3e3d0bf/</url>
    <content><![CDATA[<h1 id="本节课重点">本节课重点</h1>
<h2 id="操作符重载">操作符重载</h2>
<p>比如对于复数来说，怎么实现加法？ - 成员函数add - 全局函数</p>
<p>不符合数学上的习惯</p>
<p>不可以重载的符号：“. ”， “.* ”，“?: ”，“:: ”，“sizeof ”</p>
<p>原则：不改变操作数个数，不改变原操作符的优先级和结合性。</p>
<p>双目操作符重载： <返回值类型> operator # (<类型>);
//#代表可重载的操作符 friend Complex operator + (const Complex&amp; c1,
const Complex&amp; c2);</p>
<p>单目操作符重载： <返回值类型> operator # (); friend bool operator
!(const Complex &amp;c);</p>
<p>Counter&amp; operator ++() //前置的++重载函数 { value++; return
*this; }</p>
<pre><code>const Counter operator ++(int)  //后置的++重载函数
    &#123;   Counter temp=*this; //保存原来的对象
        value++; //写成：++(*this);更好！调用前置的++重载函数
        return temp; //返回原来的对象
    &#125;</code></pre>
<ul>
<li>=重载 隐私的赋值操作符重载函数：组个成员进行赋值操作</li>
<li>对于普通成员进行常规的赋值操作。</li>
<li>对于成员对象，则调用该成员对象类的赋值操作符重载函数进行赋值操作</li>
<li>对于基类成员，则调用基类的赋值操作符函数进行赋值操作。</li>
</ul>
<p>特别注意地是，等号的情况是特别容易出错的情况。因为这里对指针的操作就是
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class A&#123;</span><br><span class="line">	int a;</span><br><span class="line">	int b;</span><br><span class="line">	int *p;</span><br><span class="line">public:</span><br><span class="line">	A()&#123;&#125;; 构造函数</span><br><span class="line">	A(const A&amp;a); //拷贝构造函数</span><br><span class="line">	~A();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">A m,n;</span><br><span class="line">m=n;  // 实际上的操作就是 m.a=n.a, m.b=n.b, m.p=n.p. 最后一个就有问题了 </span><br></pre></td></tr></table></figure> &gt;
记住的就是拷贝构造函数和构造函数就是一样的，这里，不过参数不一样。拷贝构造函数参数是本身。
&gt; 赋值运算和</p>
<p>A&amp; operator = (const A&amp; a) { if (&amp;a == this) return
<em>this; //防止自身赋值。 delete []p; p = new char[strlen(a.p)+1];
//注意这里指针的赋值，首先删除原有的，然后，根据长度重新找，再赋值
strcpy(p,a.p); x = a.x; y = a.y; return </em>this; }</p>
<ul>
<li>[]重载 int &amp;operator<a href="int%20i"></a> //访问向量第i个元素。
{ return p_data[i]; }</li>
</ul>
<p>略去new, delete, ()， -&gt;的重载</p>
<ul>
<li>作业： 独立完成字符串的一系列动作。</li>
</ul>
<h2 id="lambda表达式">lambda表达式</h2>
<p>求定积分的函数：试图把函数作为参数。 C++11 double integrate(double
(*f)(double),double a,double b);</p>
<p>integrate(<a href="double%20x"></a>-&gt;double { return x*x;
},0,1);</p>
<ul>
<li>常用格式 [<环境变量使用说明>]<形式参数><返回值类型指定><函数体></li>
</ul>
<p><环境变量使用说明>：指出函数体中对外层作用域中的自动变量的使用限制：
空：不能使用外层作用域中的自动变量。
&amp;：按引用方式使用外层作用域中的自动变量（可以改变这些变量的值）。
=：按值方式使用使用外层作用域中的自动变量（不能改变这些变量的值）。
&amp;和=可以用来统一指定对外层作用域中自动变量的使用方式，也可以用来单独指定可使用的外层自动变量（变量名前可以加&amp;，默认为=）。</p>
<blockquote>
<p>理解：将lambda表达式看作是函数对象来实现 怎么用啊？需要找个例子 -
作用于实参 cout &lt;&lt; <a href="int%20x"></a>-&gt;int { return x<em>x;
}(3); - 传给其它函数 f(<a href="int%20x"></a>-&gt;int { return x</em>x;
}); // 这里依然不是很明朗，需要式子</p>
</blockquote>
<h2 id="继承-派生类">继承-派生类</h2>
<p>对事物按层次来分类，对概念进行组合，支持软件的增量开发。</p>
<p>继承的目的进行软件复用。 如何扩展？ 1、修改源代码。
2、继承。对一个面向对象的程序，在定义一个新的类时，把已有程序的一个或多个类的功能全部包含进来，然后再给出新功能的定义，或者重新定义。目标代码复用
派生类拥有除构造函数和赋值操作符重载函数外的所有成员
友元不能通过集成传递给派生类。 私有成员不能传递。
public-外界，即对象，实例， protected-面向继承 &gt; 继承和封装的矛盾</p>
<blockquote>
<p>protected的使用，用于今后不太可能发生变动的、有可能被派生类使用的、不适合对实例用户公开的成员声明</p>
</blockquote>
<blockquote>
<p>有个问题，既然private不能直接访问，那么复制过来又有什么用？按说明是需要复制过来
而且还占空间</p>
</blockquote>
<blockquote>
<p>如何是同名函数，则访问基类同名成员时要用基类名受限A::f()。但也可使用using
A::f;声明后直接使用</p>
</blockquote>
<blockquote>
<p>派生类的作用域大于基类的作用域</p>
</blockquote>
<blockquote>
<p>protected, 内部和子类，以及子类。而且是兼容的状态</p>
</blockquote>
<blockquote>
<p>父对象、子对象，对于包含的状态，可以允许</p>
</blockquote>
<blockquote>
<p>派生类对象，先初始化子对象 拷贝构造函数和赋值都是采用默认的形式</p>
</blockquote>
<p>实例：一个公司中的职员和部门经理类的设计</p>
<ul>
<li>分析 职员 工号、名字 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="多态性">多态性</h2>
<p>具有public继承关系的两个类，在C++中存在下面的多态： -
派生类对象的类型既可以是派生类，也可以是基类 -
基类的指针可以指向派生类或基类 &gt; 其实就是一个意思。 -
一个可以发送到基类对象的消息，也可以发送到派生类对象，怎么做到？缺例子？</p>
<p>由上面的知识可以带来消息的绑定问题。 &gt;
向基类的指针或引用所指向或引用的对象发送消息。</p>
<blockquote>
<p>问题：只要显式在参数中写定了基类还是父类，发现实际。</p>
</blockquote>
<ul>
<li>虚函数 virtual void f(){ }</li>
</ul>
<ol type="1">
<li>实现消息的动态绑定</li>
<li>指出基类中可以被派生类重定义的成员函数</li>
</ol>
<p>构造函数不能是虚函数，析构函数可以是虚函数。只要在基类中说明了虚函数，在派生类、派生类的派生类，同型购的成员函数都是虚函数
&gt;
意思是基类中将某个函数设置为虚函数，那么不管它继承到哪个位置，它将会一直是虚函数。</p>
<p>只有通过基类的指针或引用访问基类的虚函数时才进行动态绑定。</p>
<blockquote>
<p>当基类设置为纯虚函数后，之后的凡是基类指针，因为自身的函数设置为了虚函数。所以，它直接就指向了派生类的对象。</p>
</blockquote>
<p>何时需要定义虚函数？ &gt; 基类设计的不好，希望使用派生类。 &gt;
在基类中根本无法给出实现，子类往往会对应于不同的情况 （纯虚函数）</p>
<ul>
<li>纯虚函数 virtual int f()=0;
包含纯虚函数的类叫做抽象类，不能用于创建对象。
从某种意义上感觉像是接口的感觉。</li>
</ul>
<p>一般地，会把所有的函数都设置为纯虚函数，即 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Figure &#123;</span><br><span class="line">	public: </span><br><span class="line">		virtual void draw() const=0;  // 这里const是做何用的， 是注重返回值是定值吗？</span><br><span class="line">		&gt; 等下好像前面加了const, 是就限制了不能改变元素。所以，外部的全局函数就可以直接使用</span><br><span class="line">		virtual void input_data()=0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>一般的应用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- 图形的输入</span><br><span class="line">for (count=0; count&lt;MAX_NUM_OF_FIGURES;	count++)</span><br><span class="line">&#123;	int shape;</span><br><span class="line">	do</span><br><span class="line">	&#123;	cout &lt;&lt; &quot;请输入图形的种类(0：线段，1：矩形，2：圆，-1：结束)：&quot;;</span><br><span class="line">		cin &gt;&gt; shape;</span><br><span class="line">	&#125; while (shape &lt; -1 || shape &gt; 2);</span><br><span class="line">	if (shape == -1) break;</span><br><span class="line">	switch (shape)</span><br><span class="line">	&#123;	case 0: //线</span><br><span class="line">			figures[count] = new Line;	break;</span><br><span class="line">		case 1: //矩形</span><br><span class="line">			figures[count] = new Rectangle; break;</span><br><span class="line">		case 2: //圆</span><br><span class="line">			figures[count] = new Circle; break;</span><br><span class="line"> 	&#125;</span><br><span class="line">	figures[count]-&gt;input_data(); //动态绑定到相应类的input_data</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">- 图形的输出</span><br><span class="line">for (int i=0; i&lt;count; i++)	</span><br><span class="line">	figures[i]-&gt;draw();  </span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>此时可以看出，代码完全不需要改动。只需要将类的实现进行改变而已，很好地提高了效率。</p>
<p>考虑一种低效的实现方式，即使用union来做，可以发现，当增加新的图形种类是，需要修改下述代码，增加分支
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">图形数据的输入：</span><br><span class="line">	int count;</span><br><span class="line">	for (count=0; count&lt;MAX_NUM_OF_FIGURES; count++)</span><br><span class="line">	&#123;	int shape;</span><br><span class="line">		do</span><br><span class="line">		&#123;	cout &lt;&lt; &quot;请输入图形的种类(0:线段,1:矩形,2:圆,-1:结束):&quot;;</span><br><span class="line">			cin &gt;&gt; shape;</span><br><span class="line">		&#125; while (shape &lt; -1 || shape &gt; 2);</span><br><span class="line">		if (shape == -1) break;</span><br><span class="line">		figures[count] = new TaggedFigure; //空间利用效率不高！</span><br><span class="line">		switch (shape)</span><br><span class="line">		&#123; 	case 0: //线</span><br><span class="line">				figures[count]-&gt;shape = 0;</span><br><span class="line">				input_data(figures[count]-&gt;figure.line);</span><br><span class="line">  	 			break;</span><br><span class="line">			case 1: //矩形</span><br><span class="line">				figures[count]-&gt;shape = 1;</span><br><span class="line">				input_data(figures[count]-&gt;figure.rect);</span><br><span class="line"> 				break;</span><br><span class="line"> 		  case 2: //圆形</span><br><span class="line">				figures[count]-&gt;shape = 2;</span><br><span class="line">				input_data(figures[count]-&gt;figure.circle);</span><br><span class="line">  	 		break;</span><br><span class="line">	 	&#125; //end of switch</span><br><span class="line">	&#125; //end of for</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">图形的输出：</span><br><span class="line">	for (int i=0; i&lt;count; i++)</span><br><span class="line">	&#123;	switch (figures[i]-&gt;shape)</span><br><span class="line">			&#123; case 0:</span><br><span class="line">						draw(figures[i]-&gt;figure.line);</span><br><span class="line">						break;</span><br><span class="line">				case 1:</span><br><span class="line"> 						draw(figures[i]-&gt;figure.rect);</span><br><span class="line">						break;</span><br><span class="line">				case 2:</span><br><span class="line"> 						draw(figures[i]-&gt;figure.circle);</span><br><span class="line"> 						break;</span><br><span class="line"> 			&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>作业：用抽象类为栈的两个不同实现提供一个公共接口</p></li>
<li><p>使用抽象类给类提供一个抽象接口 &gt;
感觉上真的，抽象类实现真正意义上的抽象。</p></li>
</ul>
<p>class I_A{ public: virtual void f(int)=0; };</p>
<p>void func(I_A *p) { p-&gt;f(2); //
这里不知道p所指向的对象有哪些数据成员，因此无法访问它的数据成员。而且保证了类的封闭性。
}</p>
<blockquote>
<p>从某种意义上感觉对事件机制有了进一步的理解。
所有都由一个父类继承而来。而虚函数所定义的就是信号，就可以看作基类指针，完全不知道到底派生类的谁会接收它。</p>
</blockquote>
<p>代码复用的另一种方式——聚集
继承实际就是把一个类的代码复制到另一个类中来实现，具有继承关系的两个类之间通常属于一般与特殊的关系。
继承不是代码复用的唯一方式，有些代码复用不宜用继承来实现。如：“飞机”类复用“发动机”类。</p>
<p>具有聚集关系的两个类之间通常属于整体与部分的关系。</p>
<blockquote>
<p>访问控制仿佛如同一种过滤器一样；只能过滤到和当前一样的结果。
private只对自己使用。 protected针对继承元素。</p>
</blockquote>
<blockquote>
<p>之前就一直在想一个问题，可能让你一直继承下去吗？我这个世界可不想你做这些东西？
实际社会上还会存在哪些要求呢？</p>
</blockquote>
<blockquote>
<p>实际上来说的话，那么当一个类使用了private继承就是想不要再被其他继承下去。继承下去有毛线用，你又访问不到，所以说啊，你还不如好好使用的，有什么意思，对吧！
顶多是你可以.后再加上A::的作用域进行访问。如f()是A的private成员，对于B继承A，访问f()即为<code>b.A::f()</code></p>
</blockquote>
<p>继承与封装存在矛盾，聚集则否。
继承提供两种接口，而对于聚集，一个类对外只需提供一个接口</p>
<h3 id="多继承">多继承</h3>
<p>如何实现？ -
采用单继承，概念混乱，导致A和B之间增加了层次关系。易造成不一致。 -
聚集，不能实现子类型</p>
<p>顺序 class C: public A, public B{} 即按照继承的声明方式。</p>
<p>对于基类的指针会自动进行地址调整，也就是自动指向对应的存储空间。
函数名混淆，采用基类名限制。</p>
<p>重复继承问题，原本设置不对，应该把重复继承的部分设置为基类。</p>
<p>一种新的方式： class A{ int x; public: A(int i){x=i;} }</p>
<p>class B:virtual public A{ // 注意没？这里出现了虚拟继承的概念 int y;
}</p>
<p>间接包含虚基类的类：</p>
<p>虚基类的构造函数由该类的构造函数直接调用。（即虚基类的构造函数由最新派生出的类的构造函数调用）
虚基类的构造函数优先非基类的构造函数执行。</p>
<p>虚基类的实现其实比较复杂，并不是没有它了。而是将x移到最后，在原本x的位置存储了一个x的偏移量指针。</p>
<p>非纯虚基类，就是有自己的实现。但是允许你去用派生类的。因为自己做不好的原因。
### todo</p>
<ul>
<li>从上面的过程话说设计模式</li>
</ul>
<blockquote>
<p>那么这个世界的组织形式是什么？
分离，谁是谁的什么，还有或者谁组成了谁</p>
</blockquote>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture4-summary</title>
    <url>/2019/nju-course-cplus-lecture4-summary-3c575f3819fe/</url>
    <content><![CDATA[<p>泛型程序设计</p>
<blockquote>
<p>类型的多态</p>
</blockquote>
<p>首次尝试，c使用泛型指针。c++template关键字，剩余的事情交给编译器。
代码写得简单，就可以当做常见的int来做，而且不容易出错。 封装了一层。</p>
<p>what where who when how 1. 哪里使用？ 普通类型，直接，在类中。
特殊类型——类，需要把对应的操作，构造函数，复制构造函数处理安全。</p>
<ol start="2" type="1">
<li>怎么用？ template&lt;class T,int size&gt; 可加非这个量。
不具体化，不认的。</li>
</ol>
<p>类型冲突的请显式说出来</p>
<p>注意了：实现必须写在.h中，这是代码复用；不用担心重复解释，编译器会解决；然后，全局函数其他都要把<class T>标出来，特别是友元。</p>
<ol start="3" type="1">
<li>于是，C++, STL
远离类型，就是实际所分析和学的数据结构和算法，所以妙啊！
不过遇到具体类型套而已！</li>
</ol>
<ul>
<li><p>容器，常用数据结构。 &gt; 这里是序列化数据;
复杂的数据结构可以由这些给组合而成的，哈哈哈！</p></li>
<li><p>算法 &gt; 一些最常用的操作集合</p></li>
<li><p>迭代器 &gt;
也就是算法中对数据结构的抽象吧，主要是抽象为数组的处理一样，可以轻易找到头尾，下一个元素，以及向前，向后。</p></li>
</ul>
<p><a
href="https://blog.csdn.net/liyuan_669/article/details/22100165">迭代器是一种检查容器内元素并遍历元素的数据类型</a></p>
<p>字面不要过度推理，从权限上看</p>
<p>InputIterator: 单步迭代，不允许修改
相当于<code>vector&lt;int&gt;::const_iterator iter, 可以iter++,
不可以*iter=1;</code>注意区分 <code>const vector&lt;int&gt;::iterator
iter=v.beign, 可以*iter=1,不可以iter++</code></p>
<p>OutputIterator: 单步迭代，可以修改。</p>
<blockquote>
<p>突然这里对前面返回两种不同的东西有了实质的感觉，一个是正常，另一个是既不可以被修改，也不可以增加</p>
</blockquote>
<p>0: queue,stack,pq InputI: OutputI: ForwardI: BidrectionalI:
list,map,set Random-accessI: vector,deque,basic_string</p>
<p>类型 - 添加 push, insert - 大小 size, empty , resize,count - 访问
back,front, [],at,top,find - 删除 erase,clear,pop_back - 赋值与swap:
=,swap, assign()//重新设置</p>
<blockquote>
<p>然后按照需要思考会用哪些？</p>
</blockquote>
<blockquote>
<p>循环遍历 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  for (it=phone_book.begin(); it != phone_book.end(); it++) </span><br><span class="line">// 注意这里 end()返回的是最后的下一个元素，按照链表来看就是null. 具体是什么值我也不知道</span><br></pre></td></tr></table></figure> 首尾元素是head, tail</p>
</blockquote>
<ol start="4" type="1">
<li>todo 再想不同迭代器</li>
</ol>
<p>一种类型的定义：<a
href="https://blog.csdn.net/zhanh1218/article/details/33340959">如果需要定义真正的tuple，那就需要用const
vector<int> nums(10,9); 然后用const_iterator来访问</a></p>
<p>C++11新增加的内容 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">auto i1 = Container.begin();  // i1 is Container&lt;T&gt;::iterator </span><br><span class="line">auto i2 = Container.cbegin(); // i2 is Container&lt;T&gt;::const_iterator</span><br></pre></td></tr></table></figure></p>
<p>所以cbegin()的访问控制就是public</p>
<blockquote>
<p>不同迭代器代码上怎么看？怎么区分。对于容器来说是都返回其基类？由具体用的时候，再判断和出错.</p>
</blockquote>
<p><a
href="https://blog.csdn.net/sim_szm/article/details/8980879">褚略理解</a>
- 输入。 find, accumulate; 标准库istream_iterator - 输出。 copy,
ostream_iterator - 前向. replace - 双向。 reverse - 随机访问 sort, &lt;,
&gt;, !=, +,-,回退多个元素 &gt; 具体的算法有具体的应用</p>
<blockquote>
<p>发现很多接口的改进点：增加了越界的判断。比如[]和at，细想真的牛逼！</p>
</blockquote>
<ol start="5" type="1">
<li>算法</li>
</ol>
<p>分类 - 调序算法：实现按某个要求改变容器中元素次序的操作 &gt;
比如sort,</p>
<ul>
<li><p>编辑算法：实现对容器元素的复制、替换、删除、赋值等操作 &gt;
比如replace, transform</p></li>
<li><p>查找算法：实现在容器内查找元素或子元素序列等操作 &gt;
find,count_if</p></li>
<li><p>算术算法：实现在容器内进行求和、内积和、差等操作 &gt;
accumulate</p></li>
<li><p>集合算法：实现集合的基本运算，要求已经排好序？</p></li>
<li><p>堆算法：实现基于堆结构的容器元素，第一个元素最大</p></li>
<li><p>元素遍历算法 for_each</p></li>
</ul>
<p>算法指定在迭代器上，妙！迭代器自身相容，妙！
规定，作用范围一样，src_first,src_last, dst_first</p>
<p>函数参数：进行自定义，类型也为T</p>
<p>一个超级有趣的例子。</p>
<p>匹配一定条件的东西， count_if()-&gt;类-&gt;lambda表达</p>
]]></content>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture5-summary</title>
    <url>/2019/nju-course-cplus-lecture5-summary-e0699417912f/</url>
    <content><![CDATA[<p>总结</p>
<h1 id="输入输出">输入输出</h1>
<p>按输入输出的类型分为三种：控制台、文件、字符串（局部的内存区域） 1.
控制台 - C - 输出 &gt; putchar(), puts(), printf() %d,c,u,f - 输入 &gt;
getchar(), gets(), scanf() - C++ cin, cout, cerr直接, clog iomanip:
setw()? setiosflags(scientific, flags) setprecision cout.write();
cin.get(), cin.read(); cin.fail() // 是否输入成功，0表示成功 &gt;
一般地，对输出不需要判断文件结束，输入需要判断文件结束 - 操作符的重载：
继承的问题， display()</p>
<ol start="2" type="1">
<li>文件 永久保存数据的设备 文本(字符串)，二进制文件(机器表示)</li>
</ol>
<ul>
<li>C
<ul>
<li>输出 fopen(), fputc(), fputs(), fprintf(),size_t fwrite(sizeof())
//字节，二进制, fclose() &gt; 目录问题，路径写法。 打开方式: w创建,清除,
a尾 b; 不同操作系统，windows -&gt;</li>
<li>输入 fopen() NULL失败， &gt; r, b, fgetc(), fgets(), fscanf(),
fread(sizeof()). feof()判断是否到的文件的末尾</li>
<li>r+, w+, a+, b</li>
<li>fseek(), ftell, cur,end,set</li>
</ul></li>
<li>C++ 输出 out_file(), open, write, &lt;&lt; 输入 in_file(),read,
eof</li>
</ul>
<ol start="3" type="1">
<li><p>字符串 char buf[100]; ostrstream str_buf(buf,100);</p></li>
<li><p>其他 traits</p></li>
</ol>
<blockquote>
<p>思考，为什么独独设置了这三类？</p>
</blockquote>
<h1 id="异常处理">异常处理</h1>
<p>所谓异常，其实就是程序过程中出现的bug。其实主要可以分为以下几种。 1.
语法错误， 编译器会解决 2. 逻辑错误，很关键，要学会排错 -
不能运行，实现的逻辑有问题 - 能运行，有问题 - 输出错误 - 程序逻辑错误 -
有的函数的输入输出没有检查 - 编译出错 - 平台相关 3. 运行异常 -
程序对运行环境考虑不周 &gt; 这里很重要，务必注意程序的环境</p>
<p>鲁棒性，就是能应对足够多的异常。</p>
<p>处理异常的方法： 直接，当地抛出异常，即exit();
最大的问题可能就是当程序特别大的时候，程序员不知道什么地方出错了。</p>
<p>异地处理：参数值，新建参数值，全局变量，这些都不好。</p>
<p>推出抽象化，实际上也是通过全局变量来做的，不过交给了底层。上层可以用最简单的语句进行实现。</p>
<p>try{ 检测语句； }catch(类型 变量)</p>
<p>throw{} 一旦进行检测必然抛出，很优秀。
而且只抛出子层的，向上处理。没有就控制台。</p>
<p>上面是无法避免的可能出现的运行异常的处理。</p>
<p>只要不可控都要进行上面的处理。</p>
<p>下面聊到代码调试，如何测试bug</p>
<p>一般的怎么做就分析输出语句呗，看输出语句是否正确。 一种抽象assert();
易于定义位置。 以及可以一键清除。 ``<code>#define NDEBUG
#include&lt;cassert&gt;</code></p>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture5</title>
    <url>/2019/nju-course-cplus-lecture5-6d947ee08682/</url>
    <content><![CDATA[<h1 id="重点">重点</h1>
<h2 id="输入输出">9. 输入/输出</h2>
<p>输入、输出具体的实现会音操作系统和计算机硬件的不同而有所不同，与平台相关。
在C++中，一种基于字节流的操作。</p>
<p>分为： 1. 面向控制台的I/O iostream - istream, ostream 2.
面向文件的I/O fstream, ifstream, ofstream 3. 面向字符串变量的I/O
strstream, istrstream, ostrstream</p>
<p>在c++中，ios_base基类，ios派生。 I/O类都是用类模板来实现的</p>
<blockquote>
<p>因为输入输出通常会设计到外设，即经常考虑把程序所需要运行的数据输出到外设和从外设输入。
C++STL中的输入输出被C++编译程序所接受。但是，因为具体平台相关性，还可以采用其他方式进行输入输出。例如：Visual
C++提供的MFC基础类中包含了具有输入、输出功能的类。
但是，指定注意的一点就是以非C++标准库方式进行输入输出不利于C++程序的移植</p>
</blockquote>
<h3 id="面向控制台的io">9.1 面向控制台的I/O</h3>
<h4 id="基于函数库的控制台输入输出">9.1.1
基于函数库的控制台输入、输出</h4>
<p>C语言标准库的功能，C++保留了这些功能 - 输出 putchar(int ch);</p>
<p>int puts(const char *p);</p>
<blockquote>
<p>什么是标准输入平台？这里应该就是控制台输入输出的意思。</p>
</blockquote>
<p>printf() // 返回输出 字符个数或返回负数 注意printf("")这里如果是%s,
不接受空格和回车的，如果需要空格%[0-9a-zA-Z ]这样显式指定。 &gt;
记得字符又被分为了好几种，比如打印字符，什么字符之类。</p>
<ul>
<li>printf常用格式控制字符及其含义</li>
</ul>
<table>
<thead>
<tr class="header">
<th>控制字符</th>
<th>类型</th>
<th>输出格式</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>%c</td>
<td>int</td>
<td>字符</td>
</tr>
<tr class="even">
<td>%d</td>
<td>int</td>
<td>有符号十进制整数</td>
</tr>
<tr class="odd">
<td>%u</td>
<td>unsigned int</td>
<td>无符号十进制整数</td>
</tr>
<tr class="even">
<td>%x, %X</td>
<td>unsigned int</td>
<td>无符号16进制</td>
</tr>
<tr class="odd">
<td>%o</td>
<td>unsigned int</td>
<td>无符号8进制</td>
</tr>
<tr class="even">
<td>%s</td>
<td>char*</td>
<td>字符串</td>
</tr>
<tr class="odd">
<td>%e,%E</td>
<td>double</td>
<td>科学计数法的形式</td>
</tr>
<tr class="even">
<td>%f</td>
<td>double</td>
<td>一般形式</td>
</tr>
<tr class="odd">
<td>%%</td>
<td></td>
<td>字符%</td>
</tr>
</tbody>
</table>
<ul>
<li>输入 // 操作失败返回EOF int getchar();</li>
</ul>
<p>// 成功返回p，否则null char <em>gets(char </em>p);</p>
<blockquote>
<p>平台怎么处理空格和回车？是否会纳入考虑 scanf() //
返回实际输入并保存的数据个数或返回EOF %5f,
好像是指定位数来着？？测试</p>
</blockquote>
<h4 id="基于类库的控制台io">9.1.2 基于类库的控制台I/O</h4>
<p>C++的改变，用类来做。
问题：用库函数scanf和printf需要实现基本数据类型数据的输入和输出，实际操作的是格式串。
printf,scanf等于说是多参数，即输入的参数个数时可变的。这样冲某种意义上破坏了C++强类型的特点
&gt; C++强类型有什么特点？ &gt; 从某种意义上是不是有安全的概念？
另外，scanf和printf还有一个特点就是不能对用户自定义，只能操作基础的数据类型
。
而I/O类库提供了更为方便和安全的输入、输出操作，并且这些操作可以很容易地扩充到用户自定义类型的数据。</p>
<h5 id="预定义的控制台对象">1). 预定义的控制台对象</h5>
<p>在I/O类库中预定义了4个I/O对象，cin,cout,cerr以及clog，利用这些对象可以直接进行控制台的输入输出。
cin-&gt;istream. cout,cerr,clog-&gt;ostream
cout敌营这计算机系统的用于输出程序正常运行结果的标准输出设备，而cerr和clog则对应着计算即系统的用于输出程序错误信息的设备，通常都对应着显式器，但是cerr和clog不受输出重定向的影响。
&gt; linux的输出命令的感觉吗？ &gt;
重定向，也就是原本默认的标准输入，从新定义输出到文件。不受是不可操作的意思吗？？？？
并且cerr不对输出信息进行缓存，因此它有较快的响应效果。</p>
<h6 id="输出">输出</h6>
<p>对于指针的输出有一个特例，即输出指向字符串的指针时，不输出字符串的首地址，，而是输出字符串。</p>
<p>进一步，为了对输出格式进行进一步的控制，可以通过输出一些操纵符来实现。
例如： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;iomanip&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">int x =10;</span><br><span class="line">cout&lt;&lt;hex&lt;&lt;x&lt;&lt;endl; // 以十六进制输出x的值，然后换行。</span><br></pre></td></tr></table></figure> 其中，对于浮点数float,double和long
double,当输出格式为ios::scientific或ios::fixed时，精度设置操纵符setprecision用于设置小数点后的位数。
当什么没有时，用于设置浮点数有效数字的个数。</p>
<p>!!! 只对浮点数有效 &gt; setiosflags(ios::scientific) // 设置输出格式
&gt; resetiosflags(ios::scientific) // 取消输出格式</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>操作符</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>endl</td>
<td>输出换行符，并执行flush操作</td>
</tr>
<tr class="even">
<td>flush</td>
<td>使输出缓存的内容立即输出？？？</td>
</tr>
<tr class="odd">
<td>dec</td>
<td>十进制输出</td>
</tr>
<tr class="even">
<td>oct</td>
<td>八</td>
</tr>
<tr class="odd">
<td>hex</td>
<td>16</td>
</tr>
<tr class="even">
<td>setprecision(int n)</td>
<td>设置浮点数的精度</td>
</tr>
<tr class="odd">
<td>setiosflags(long flage)</td>
<td>设置/取消输出格式，flags的取值可以是:ios:scientific(指数形式),
ios:fixed(小数形式)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>注意: 设置一遍后均有效，然后应该是就近原则吧！
初始状态下，输出格式为自动方式，输出精度为6位有效数字。</p>
</blockquote>
<blockquote>
<p>很好奇cout是怎么解析&lt;&lt;符的？按照空格回车然后进行分隔吗？还是怎么的？</p>
</blockquote>
<blockquote>
<p>还存在其他类型吗？这样只对double类型进行了处理，一般来说输出应该不需要其他情况的输出了吧，对！
一般只有两种类型，double, str 还有其他需要控制输出的吗？？？</p>
</blockquote>
<blockquote>
<p>突然想起，输出扩展需要的有比如输出的数据对齐指定？待安排 ###### 输入
任何基本数据类型都可以通过cin对象和抽取操作符&gt;&gt;来进行输入。
在输入每个数据之间用空白符分开，最后输入一个回车符。另外也可以用一些操作控制符来控制输入的行为。
对于输入来说，感觉上也就字符串数据需要进行控制了吧，setw()用于指定输入字符的最大个数。</p>
</blockquote>
<blockquote>
<p>对，还需要清空输出吧？感觉上 cin &gt;&gt; setw(10) &gt;&gt; str; //
把输入的前9个字符和一个'\0'放入str中</p>
</blockquote>
<p>!!!!果然不出所料，果然对于输入流来说，当输入流没有用完时是接着用输入流的</p>
<p>get(), getline(*p, cout,delim) read() cin.get(ch); read();</p>
<blockquote>
<p>感觉这些输入地方太容易出错了，我之前就是这里老出错。不要有只取多少位数据的情况。</p>
</blockquote>
<p>特别地，cin的输入操作是无法读入空白符的，这时才可用上面的成员函数实现空白符的读入。
&gt; 所以此时一般扩展用getline</p>
<p>cin的输入操作是带输入缓存的，只有当用户输入“回车”时，输入的数据才会放入程序的变量中。
需要注意的是，基于类库的输入、输出操作中可能遇到问题（如没有正确输入数据等）。
因此，在操作后可通过下面的函数来判断操作是否成功。 bool ios::fail();
//true表示操作失败 怎么用？ &gt;
(cin&gt;&gt;ch2)返回的不是基本类型int,bool &gt; cin.fail()
那什么操作失败呢？ &gt; 比如int, 输入字符串</p>
<h4 id="抽取插入操作符和的重载">9.1.3
抽取、插入操作符&gt;&gt;和&lt;&lt;的重载。</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class A&#123;</span><br><span class="line">    int x,y;</span><br><span class="line">    friend ostream&amp; operator &lt;&lt;(ostream&amp; out, const A &amp;a);</span><br><span class="line">public:</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ostream&amp; operator &lt;&lt;(ostream&amp; out, const A &amp;a)</span><br></pre></td></tr></table></figure>
<p>//
从某种意义上理解，ostream是stream的子类，所以可行。这里是类为啥又可以？</p>
<p>一般来说，只做输出。</p>
<p>有几种方法，如何在继承下使有效？ 1.
如果在基类定义，而没有在派生类定义，派生类只能输出一部分值。 2.
如果在派生类定义，不能解决间接调用的情况
特别是用基类的指针，不知道会动态绑定到哪种情况的时候，考虑使用封装。
即在每个类里面重载display()函数，在&lt;&lt;中只需要调用display()函数即可。</p>
<h3 id="面向文件的输入输出">9.2 面向文件的输入，输出</h3>
<p>程序运行结果有时需要永久地保存起来，以供其他程序或本程序下一次运行时使用:程序运行所需要的数据也常常要从其他程序或本程序上衣词运行所保存的数据中获得。用于永久保存数据的设备称为外部存储器，如磁盘、磁带、光盘等。</p>
<h4 id="文件概述">9.2.1 文件概述</h4>
<p>在外部存储器中保存数据的方式通常由两种：文件和数据库。
本程序设计教程只介绍一文件方式永久性地保存数据，数据库由其他专门的课程介绍。在C++中，把文件看成由一系列字节构成的字节串，称为流式文件，对文件中数据的操作通常是逐个字节顺序进行。在对文件数据进行读写前，首先要打开文件，打开文件的目的是：把程序内部一个表示文件的变量与外部的一个具体文件关系起来，并创建内存缓冲区，每个打开的文件都有一个隐式的读写位置指针，它指向文件的当前读写位置。在进行读写操作时，每读入，写出一个字节，文件位置指针会自动往后移动一个字节的位置。
文件读写完毕后，通常需要关闭文件，其目的是把暂存在内存缓冲区中的内容写入文件，并归还打开文件是申请的内存资源。
在文件中，数据的存储方式有两种，文本方式和二进制方式。
文本方式一般用于存储具有行结构的文字数据，如源程序或纯文本格式的数据等。二进制方式一般用于存储无显式结构的数据，数据的格式由应用程序来解释，如目标代码程序以及二进制数据等。
这两种方式的主要区别是，文本文件中只包含可显示字符和有限的几个控制字符（如,;而二进制文件可以包含任意的没有显式含义的二进制文件。为了进一步区分两种存储方式，我们用一个例子来说明。
对于一个还只能输123457，可以用来种方式保存到文件中： 1.
文本方式：依次把1,2,3,4,5,6,7的ASCII玛写入文件（共7个字节） 2.
二进制方式：把整数123457的计算机内部表示（如补码）分解为字节写入文件（如果整数内部为32位，则为4个字节）。
&gt; 以二进制方式组织的文件不利于文件在不同计算机平台上使用。 &gt;
因为不同计算机平台的内部表示不一样 &gt;
关于文件的压缩的思路估计也有这样的一份。</p>
<h4 id="基于函数库的文件io">9.2.2 基于函数库的文件I/O</h4>
<p>C++从C语言标准库中保留下来的输入、输出函数库包含了对文件进行输入、输出操作的函数。
<code>#include&lt;cstdio&gt;</code> ##### 1) 文件的输出操作 - 打开文件
打开外部文件输出数据fopen <code>FILE *fopen(const char *filename, const
char *mode); // 打开文件</code> mode表示打开方式：
w:打开一个外部文件用于写操作。如果外部文件已经存在，则首先把它的内容清除；否则先创建该外部文件。
a:打开一个外部文件用于添加（从文件末尾）操作。如果不存在，则首先创建文件
另外，在打开方式的后面还可以加上b,指出以二进制方式打开文件。默认打开方式为文本方式。对一文本方式打开的文件，当输出字符为，在某些平台（如DOS和Windows平台）将自动转换为'''两个字符写入外部文件
一般来说，以文本方式组织的文件要用文本方式打开；以二进制方式组织的文件要用二进制方式打开。
以w方式打开文件时，文件位置指针指向文件的头；以a方式打开文件时，文件位置指针指向文件的尾。
文件打开成功后，fopen将返回一个费控的"FILE*"指针，该指针指向与打开文件有关的一些信息（如文件的内存缓冲区等），它将被之后的文件输出操作函数使用。
&gt;
就是实际上内存是按块组织的，这个指针会指向一些节点。当不断输出文件时，需要进行改变指针以扩大文件写的内容，还有更改好多相关的东西。
如果文件打开失败，则fopen返回空指针NULL. - 输出操作</p>
<p>文件打开成功后就可以往文件中写入数据了。往文件中写入数据的函数主要有以下几个。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 输出一个字符，输出成功时返回输出的字符</span><br><span class="line">int fputc(int c, FILE *stream);</span><br><span class="line"></span><br><span class="line">// 输出一个字符串，输出成功时返回一个非负整数。</span><br><span class="line">int fputs(const char *string, FILE*stream);</span><br><span class="line"></span><br><span class="line">// 输出基本类型数据，返回输出的字符数</span><br><span class="line">int fprintf(FILE *stream, const char *format[,argument]...)</span><br><span class="line">// 看来这里我搞错了，</span><br><span class="line"></span><br><span class="line">// 按字节输出数据。参数size为字节块的尺寸；cout为字节块的个数。返回实际输出的字节块的个数</span><br><span class="line">size_t fwrite(const void *buffer, size_t size, size_t count, FILE *stream);// size_t:unsigned int;</span><br></pre></td></tr></table></figure> &gt;
感觉操作系统，最难的一块就在于要计算好待数据内容的大小。 &gt;
数据存储也是按字节方式的，所以fwrite也是二进制方式，对!</p>
<p>在上面的函数中，都有一个FILE*类型的指针参数，该指针参数是fopen成功打开文件后返回的。
前三个函数主要以文本方式输出数据，而第4个函数则是以二进制方式。</p>
<ul>
<li><p>关闭文件 <code>fclose(FILE *stream);</code></p></li>
<li><p>作业
从键盘键入一批学生的成绩信息并把他们以文本格式存入外部文件:scores.txt。
//
注意这里为什么是字符串输入。因为这些字符都是可显式字符，所以可以显式指定，就在文件中看见这些内容</p></li>
</ul>
<blockquote>
<p>扩展版本：使用C++中的类 请务必注意循环输入的判断条件
还有一些系统目录是没有权限，怎么说吧，除非知道相对目录很清楚的情况外，都用绝对目录来做吧</p>
</blockquote>
<h5 id="文件的输入操作">2) 文件的输入操作</h5>
<ol type="1">
<li>打开文件 打开外部文件输入数据要用下面的函数来实现 <code>FILE *fp =
fopen(const char *filename, char *mode)</code>;
filename是要打开的外部文件名；mode是打开方式。 它可以是'r',
表示打开一个外部文件用于读操作，这时外部文件必须存在，否则打开文件失败。
另外，可以在后面加上b，表示以二进制方式打开文件，默认打开方式为文本方式，在进行输入操作时，外部文件中连续两个字符(Window)自动转换为一个字符.
读入字符0x1A(Ctrl+Z)时表示文件结束。
文件打开成功后，fopen将返回一个非空的"FILE
*"类型的指针，该指针用于今后的文件输入操作函数。文件打开失败后，fopen返回空指针
文件打开成功后，文件位置指针指向文件头。</li>
<li>输入操作 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 输入一个字符，然后返回字符的编码</span><br><span class="line">fgetc(FILE *stream);</span><br><span class="line">&gt; 哇，这个操作完全可以用来做循环条件啊，牛逼</span><br><span class="line"></span><br><span class="line">// 输入一个字符串，函数正常结束时返回string的值，否则返回NULL。</span><br><span class="line">char *fgets(char *string, int n, FILE *stream)</span><br><span class="line"></span><br><span class="line">// 输入基本类型的数据，返回值表示读入并存储的数据个数</span><br><span class="line">fscanf()</span><br><span class="line"></span><br><span class="line">// 按字节输入数据。</span><br><span class="line">size_t fread(const void *buffer, size_t size, size_t count, FILE *stream);</span><br><span class="line"></span><br><span class="line">// 判断文件结束。当文件位置指针在文件末尾时，继续进行读操作会使得feof返回非零(true)</span><br><span class="line">int feof(FILE *stream);</span><br></pre></td></tr></table></figure></li>
</ol>
<p>当从文件中读取数据时，必须知道文件的存储格式，包括数据的类型和存储方式等。
&gt; fscanf和fprintf(文本文件), fread和fwrite(二进制文件)对应 3.
关闭文件 fclose(FILE *stream)</p>
<ul>
<li>小练习
读取上一个中的数据，计算每个学生的平均成绩；统计男生人数。</li>
</ul>
<h5 id="文件的输入输出操作">3) 文件的输入、输出操作</h5>
<blockquote>
<p>在上面注意到一个点，输入和输出都涉及到文件打开方式，那么文件打开方式是否与实际情况相符合了呢？</p>
</blockquote>
<p>以w和a方式打开的文件只能对其进行输出操作；以r打开的文件只能进行输入操作。</p>
<p>mode扩展： - r+ 读写，文件必须存在 - w+ 读写。
文件不存在会创建一个空文件，否则情况一寸照的文件 &gt;
前面这两种不过是+号更多了一种功能，跟本身功能关系很大的 - a+
打开一个外部文件用于读、添加操作。如果文件不存在，则首先创建一个空文件。以这种方式打开的文件，输出操作总是在文件尾进行。</p>
<p>另外，在这些后面可以加上t,b, 文本，二进制。对！已经测试过！"w+b"</p>
<h5 id="随机输入输出">4) 随机输入/输出</h5>
<p>一般情况下，文件的读写操作都是顺序进行的，即在进行输入输出操作时，必须按顺序读入，这样降低了文件访问的小。
每个打开的文件都有一个位置指针，指向当前读写文字，每读入或写出一个字符，文件的位置指针都会自动往后移动一个位置。
<code>fseek(FILE *stream, long offset,int origin)</code>
其中，origin指出参考位置，它可以是SEEK_CUR, SEEK_END,
SEEK_SET;offset是移动的字节偏移量，正值往后移动，负值往前移动。
fseek返回值为0表示移动成功，否则表示移动失败。
当前位置可以通过<code>ftell(FILE *stream)</code> &gt; ?
是返回的基于开头的字节数吗？？？ &gt; 需要练习 <strong>练习</strong>
读入第二个学生的信息，把该学生的专业修改为COMPUTER。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;cstdio&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">...// 省略了Sex,Date,Major及Student的定义</span><br><span class="line">int main()&#123;</span><br><span class="line">    FILE *fp = fopen(&quot;d:\\students.dat&quot;, &quot;r+b&quot;)</span><br><span class="line">    if( fp==NULL) &#123;</span><br><span class="line">        printf(&quot;打开文件失败&quot;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">Student st;</span><br><span class="line">if (fseek(fp,sizeof(st),SEEK_SET)==0)&#123; // 文件指针指向第二个学生数据</span><br><span class="line">    fread(&amp;st,sizeof(st), 1,fp); //读入第二个学生信息</span><br><span class="line">    st.major=COMPUTER;</span><br><span class="line">    fseek(fp,-sizeof(st),SEEK_CUR);</span><br><span class="line">    fwrite(&amp;st,sizeof(st),1,fp); //修改后的第二个学生数据写入文件</span><br><span class="line">&#125;</span><br><span class="line">fclose(fp);  // 这里student 为结构体，所以不用重载，sizeof直接可以用，如果是类是否需要重载呢？</span><br><span class="line">return 0;</span><br></pre></td></tr></table></figure> ####
9.3.3 基于类库的文件I/O
前面展示了C的部分，下面展示使用I/O类库进行外部文件的输入、输出。
<code>#incldue&lt;iostream&gt;,  #include&lt;fstream&gt;</code> ##### 1)
输出
首先创建一个ofstream类(是ostream的派生对象)，使之与某个外部文静建立联系：
1. 直接方式 <code>ofstream outfile(文件名，打开方式)</code> 2. 间接方式
<code>ofstream outfile; outfile.open()</code> 打开方式ios::out 同w,
ios::app同a
打开方式还可以是上面的值与ios::binary按位或|的结果。默认为文本方式。
打开文件是否成功判断 <code>if(!out_file) 失败;   out_file.fail(),
!out_file.is_open()</code>
文件成功打开后，可以使用插入操作符“&lt;&lt;”,或ofstream的一些成员函数来进行输出操作.
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">out_file&lt;&lt;x;</span><br><span class="line">out_file.write((char *)&amp;x, sizeof(x));// 以二进制方式输出数据。</span><br><span class="line">out_file.close();</span><br></pre></td></tr></table></figure> <strong>练习</strong> 用I/O类库来实现9-1的程序功能。</p>
<blockquote>
<p>值得注意的是，对ostream和istream重载的插入操作符也能是ofstream和ifstream的对象。</p>
</blockquote>
<h5 id="输入">2) 输入</h5>
<p>同输出， 打开方式ios::in，同r。
<code>in_file.read((char*)&amp;x,sizeof(x));
//以二进制形式读入文件</code> 判断文件是否结束 <code>ios::eof(); //
返回非0表示上一次读操作中遇到了文件末尾</code></p>
<p><strong>练习</strong> ##### 3) 输入/输出与随机存取 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">istream&amp; istream::seekg(&lt;位置&gt;) // 指定绝对位置</span><br><span class="line">istream&amp; istream::seekg(&lt;位置&gt;, &lt;参照位置&gt;) // 指定相对位置</span><br><span class="line">streampos istream::tellg(); // 获取指针位置</span><br><span class="line"></span><br><span class="line">ostream&amp; ostream::seekg(&lt;位置&gt;) // 指定绝对位置</span><br><span class="line">ostream&amp; ostream::seekg(&lt;位置&gt;, &lt;参照位置&gt;) // 指定相对位置</span><br><span class="line">streampos ostream::tellg(); // 获取指针位置</span><br><span class="line"></span><br><span class="line">参照位置ios::beg, ios::cur, ios::end</span><br></pre></td></tr></table></figure></p>
<h3 id="面向字符串变量的输入输出">9.4 面向字符串变量的输入/输出</h3>
<p>有时，程序中有些数据并不直接输出到标准输出设备或文件，而是需要保存在程序中的某个字符变量中；程序中有些数据有时也不直接从标准输入设备或文件中获得，而是需要从程序中的某个字符变量中获得。这时，可以采用C++标准库的基于字符串变量的输入输出功能。
基于字符串变量的输入/输出功能的主要是sscanf和sprintf <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int sprintf(char *buffer, const char *format);</span><br><span class="line">int sscanf(char *buffer, const char *format);</span><br></pre></td></tr></table></figure>
与文件输入/输出不同，这里的输入源和输出目标不是文件，而是内存中一个区域:buffer.
比如说把int型变量转换为一个字符串存入字符数组a中.</p>
<p>对于基于I/O类库的字符串变量输入/输出操作，首先需要创建类istream,ostrstream或strstream的一个对象。
&gt; 在新的标准中被istringstream,
ostringstream和stringstream（头文件sstream）代替</p>
<p>// 输出 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;strstream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">ostrstream str_buf; // 默认构造采用可扩充的内部缓冲</span><br><span class="line">或</span><br><span class="line">char buf[1000];</span><br><span class="line">ostrstream str_buf(buf,100);</span><br><span class="line"></span><br><span class="line">int x,y;</span><br><span class="line">str_buf&lt;&lt;x&lt;&lt;y&lt;&lt;endl;  // 通过该途径使得x和y获得了值</span><br><span class="line">char *p = str_buf.str(); // 可获取str_buf中字符串缓存的首地址</span><br></pre></td></tr></table></figure></p>
<p>// 输入 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;strstream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">char buf[100];</span><br><span class="line">... // 通过某种途径在buf中存放了一些字符串</span><br><span class="line">istrstream str_buf(buf);</span><br><span class="line">或</span><br><span class="line">istrstream str_buf(buf,100);</span><br><span class="line">// 如果str_buf对象的构造没有给出长度，则认为它的缓存中的内容以&#x27;\0&#x27;结束</span><br></pre></td></tr></table></figure></p>
<p>另外，也可使用抽取操作符或者其他操作符。 &gt;
用处：就是用一个东西来进行收集的感觉。然后可以用，对是这样的感觉。</p>
<h3 id="其它点">9.5 其它点</h3>
<blockquote>
<p>怎么查看C++的版本？</p>
</blockquote>
<blockquote>
<p>Linux输出平台参数一般是怎么设置的？看起来有什么快捷的地方？有没有一本好书？</p>
</blockquote>
<blockquote>
<p>一般对于继承C中的输入，输出元素，返回结果如果为非负数表示正常，具体有什么含义？返回EOF表示出问题。其他有什么函数类似？</p>
</blockquote>
<blockquote>
<p>观察到一个点，如果正常结束的话是Process finished with exit code 0;
非正常结束返回的是一个有问题的数</p>
</blockquote>
<blockquote>
<p>wostream 是干什么用的？</p>
</blockquote>
<blockquote>
<p>ostream &lt;CharT, class_traits&gt;有什么用？ 为什么不能进行ostream
a; 使用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">template &lt;typename charT, type traints=char_traits&lt;charT&gt;</span><br><span class="line">class basic_string;</span><br><span class="line">class basci_istram</span><br><span class="line"></span><br><span class="line">// traits 特征，性状。</span><br><span class="line">basic_string&lt;char&gt; string;</span><br><span class="line">basic_string&lt;TCHAR&gt; string;</span><br><span class="line">// 这里TCHAR可以自己指定</span><br></pre></td></tr></table></figure> -
https://stackoverflow.com/questions/5319770/what-is-the-point-of-stl-character-traits</p>
</blockquote>
<ul>
<li>http://www.cplusplus.com/reference/string/char_traits/</li>
</ul>
<p>解释 官方给的定义是： Character traits: Character traits classes
specify character properties and provide specific semantics for certain
operations on characters and sequences of characters.
换而言之，这里的意思就是对字符串这个操作特别放宽了要求，允许你过滤或者定义特殊化的字符串。
其实，平时我们都是需要什么就进行什么过滤，而这里的感觉就是给你了机会，让你将其定义为类型，然后操作起来更简便。
这里是最初开始设计的内容，后面都是在这基础上的延伸。</p>
<blockquote>
<p>模式匹配问题，记得刷leetcode,感觉上就有这样类似的问题。即如何进行模式匹配，实际上就是涉及到DFA和NFA，有限自动机和无限自动机。然后可以发现有限自动机方式，是按照回溯的方法解析的，所以会超级耗费内存。这样一想也解释通了。</p>
</blockquote>
<blockquote>
<p>路径名问题，在Windows中为, /.有两种写法\,或者/(linux).
其实主要原因在于编译器如果进行解释吧！</p>
</blockquote>
<h2 id="异常处理">异常处理</h2>
<p>异常概述 C++的异常处理机制 程序调试</p>
<ul>
<li>程序的错误通常包括：
<ul>
<li>语法错误：程序的书写不符合语言的语法规则。这类错误可由编译程序发现。例如：
<ul>
<li>使用了未定义或未声明的标识符</li>
<li>左右括号不匹配</li>
</ul></li>
<li>逻辑错误：程序设计部当造成程序没有完成预期的功能。这类错误可通过对程序进行静态分析和动态测试发现。
<ul>
<li>把两个数相加写成了相乘</li>
<li>排序功能未能正确排序 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bool strlonger(char *str1,char *str2)&#123;</span><br><span class="line">    return strlen(str1)-strlen(str2)&gt;0;</span><br><span class="line">&#125;   </span><br><span class="line">strlonger(&quot;abc&quot;,&quot;1234&quot;) //?</span><br><span class="line">因为strlen()返回的是unsigned int, -1&gt;0这个被认为是真。 两个unsigned int运算结果不会进行自动转换。</span><br><span class="line">修改 (int)(strlen(str1)-strlen(str2))&gt;0</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li>运行异常：程序设计对程序运行环境考虑不周而造成的程序运行错误。
<ul>
<li>对于x/y操作，y输入了零</li>
<li>由内存空间不足导致的访问空指针：int <em>p=new int; </em>p=10;</li>
<li>输入数据的数量超过存放它们的数组的大小导致数组下标越界</li>
<li>多任务环境可能导致的文件操作错误</li>
<li>给一个采用二分法查找的函数提供了一个未排序的数组</li>
<li>数据超出了其类型所允许的范围（溢出）</li>
</ul></li>
</ul></li>
</ul>
<p>语法错误，编辑器会编译不通过. 逻辑错误：环境正常，结果不正确。
运行异常：环境正常，结果正确。环境不正常，结果不正确</p>
<p>在程序运行环境正常的情况下，导致运行异常的错误是不会出现的。
程序异常错误往往是由于程序设计者对程序运行环境的一些特殊情况考虑不足所造成的。</p>
<p>导致程序运行异常的情况是可以预料的，但它是无法避免的。</p>
<p>为了保证程序的鲁棒性，必须在程序中对可能的异常进行预见性处理。 &gt;
比如在输入的输入对输入的各种情况进行排查，原本的一个例子就是输入文件，然后文件路径不存在。</p>
<h3 id="处理异常的策略">处理异常的策略</h3>
<blockquote>
<p>思考：有时间异常不是错误，所以没有必要当场处理；而且，有可能当场有重要的事情，那么这样做的话其实是非常草率的一件事情。还有用exit或abort,
这种每次都一下子退出了，完全不知道出现了什么问题，对程序员来说是一种特别懵逼的状态。</p>
</blockquote>
<p>就地处理, 在发现错误的地方处理异常。
异地处理，在其他地方（非异常发现地）处理异常。</p>
<p>异常的就地处理</p>
<p>常见做法是调用C++标准库中的函数exit或abort -
abort立即终止程序的执行，不做任何的善后处理工作 -
exit在终止程序的运行前，会做关闭被程序打开的文件、调用全局对象和static存储类的局部对象的析构函数等工作。
注意：不要在对象类的析构函数中调用exit，否则该析构函数不能调用。</p>
<p>不管是abort还是exit，都"not user-friendly"</p>
<p>异常的异地处理。</p>
<p>发现异常时，在发现地（如在被调用的函数中）有时不知道如何处理这个异常，或者不能很好地处理这个异常，要由程序的其它地方（如函数的调用者）来处理。
例如，前面的函数f中打开文件失败，这时可以由调用者重新提供一个文件来解决。</p>
<h3 id="如何实现异常的异地处理">如何实现异常的异地处理？</h3>
<ol type="1">
<li>通过函数的返回值，或指针、引用类型的参数，或全局变量把异常情况通知函数的调用者，由调用者处理。在计算机网络中很多情况都是这样处理的。
&gt; 该途径的不足： &gt;
通过函数的返回值返回异常情况会导致正常返回值和异常返回值交叉在一起。
&gt;
通过指针，引用类型的参数返回异常情况，需要引入额外的参数，给设计带来负担
&gt;
通过全局变量返回异常情况会导致使用者忽视这个全局变量的问题，不知道它的存在。
&gt; 程序的可读性差！程序的正常处理与异常处理混杂在一起</li>
<li>通过语言提供的结构化异常处理机制进行处理 C++异常处理机制
把有可能遭遇异常的一系列操作（语句或函数调用）构成一个try语句块
如果try语句块中的某个操作在执行中发现了异常，则通过执行一个throw语句抛出一个异常对象，之后的操作不再进行。
抛置的异常对象将由能够处理这个异常的地方通过catch语句块来捕获并处理之。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void f(char *filename)&#123;</span><br><span class="line">    ifstream file(filename);</span><br><span class="line">    if (file.fail())  throw filename(); // 产生异常</span><br><span class="line">    int x;</span><br><span class="line">    cin&gt;&gt;x;</span><br><span class="line">    ...</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> int main()&#123;</span><br><span class="line">     char str[100];</span><br><span class="line">     ...</span><br><span class="line">     try&#123;</span><br><span class="line">         f(str); // 启动异常处理机制</span><br><span class="line">         // 如果在函数f中抛掷了char*类型的异常，则程序转到try后面的catch(char*str)处理</span><br><span class="line">     &#125; catch(char *fn)&#123; // 捕获异常</span><br><span class="line">         ...// 处理异常</span><br><span class="line">     &#125;</span><br><span class="line">     ...// 正常情况</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure> &gt;
一种直观的感觉，等于说try语句这里把所有的异常进行了传递，然后所有子的对象都会返回回来。如果从运行的角度来思考也很正常。然后，还有一个点，类也可以实现，即基类的指针一直指回基类？对吗？</li>
</ol>
<h3 id="try语句">try语句</h3>
<p>try语句块的作用是启动异常处理机制。其格式为： try{ 语句序列 }</p>
<p>上述的语句序列中可以有函数调用。</p>
<h3 id="throw语句">throw语句</h3>
<p>throw语句用于在发现异常情况时产生异常对象。 throw <表达式>
表达式为任意类型的C++表达式。 例如： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void f(char *filename)&#123;</span><br><span class="line">    ifstream file(filename);</span><br><span class="line">    if (file.fail())  throw filename(); // 产生异常</span><br><span class="line">    // 注意这里异常的对象为一个字符串指针，这里是与catch中的类型相互对应的。</span><br><span class="line">    int x;</span><br><span class="line">    cin&gt;&gt;x;</span><br><span class="line">    ...</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
执行throw后，接在其后的语句将不再继续执行，而是转向异常处理（由某个catch语句给出）
&gt; 这里也好理解，当出错的时候肯定是这样处理了啊 一个问题？
这样做属于异常的异地处理了。怎么说来看的话是封装了一层。即实际上也是用的全局变量，但是不是在返回一层时调用，可能是返回多层时进行调用的。细想一下，震惊了哈哈哈。
挺好，用本身自带的变量不好，重新开辟一个浪费，如果是全局变量则被忽视，所以倒不如由底层处理好了再说，真棒！</p>
<h3 id="catch语句">catch语句</h3>
<p>catch语句块用于捕获throw产生的异常对象并处理相应的异常。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">catch(&lt;类型&gt;[&lt;变量&gt;])</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
类型用于指出捕获何种异常对象，它与异常对象的类型匹配规则如若函数重载。
变量用于存储异常对象，它可以缺省，缺省时表明catch语句块只关心异常对象的类型，而不考虑具体的异常对象。
&gt;
这里想到了实际上做的时候确实只关心了异常对象的类型，而且是将类型分为了唯一的积累，这样处理起来就方便了很多。</p>
<p>catch语句块要紧接在某个try语句的后面。</p>
<p>一个try语句块可以跟多个catch语句块，用于捕获不同类型的异常对象并进行处理。
&gt;
这里做的是类型其实也还可以，但是很是不行，因为处理的准则应该是对应于哪种错误，关于类型直接反馈不到处理上。</p>
<p>关于try、throw和catch几点注意 -
在try语句块的语句序列执行中如果没有抛出异常对象，则其后的catch语句不执行，而是继续执行try语句块之后的非catch语句。
- 在try语句块的语句序列执行中如果抛掷了异常对象 -
该try语句块之后有能够捕获该异常对象的catch语句，则执行这个catch语句中的语句序列，然后继续执行这个catch语句之后的非catch语句
-
该try语句块之后没有能够捕获该异常对象的catch语句，则由函数调用链的上一层函数中的try语句的相应catch来捕获。
&gt; 这就是用到的向上层抛出异常。</p>
<ul>
<li><p>如果抛除异常对象的throw语句不是由程序的某个try语句块中的语句序列调用的，则抛掷的异常不会被程序中的catch捕获
&gt;
也就是不在try语句中，所以就要注意了，必须代码在检测范围中才能被检测啊，这是很浅显的道理了啊！</p></li>
<li><p>异常处理的嵌套 try语句是可以嵌套的</p></li>
<li><p>当在内层的try语句的执行中产生了异常，则首先在内层try语句块之后的catch语句中找，否则想上处理</p></li>
<li><p>如果抛掷的异常对象没有，则调用系统的terminate函数进行标准化异常处理。默认情况下，terminate函数将会去调用abort函数。</p></li>
</ul>
<p>还有一个很重大的问题，有时候终止程序需要很大的代价，那么是否可以做到程序不终止，一直到获得正确的数据为止呢？
&gt; ?????上层一直while循环</p>
<h2 id="程序调试">程序调试</h2>
<ul>
<li>一个处于开发阶段的程序可能会含有很多错误（逻辑或异常）。</li>
<li>发现和找出这些错误的一种手段是在程序中的某些地方家伙少年宫一些输出语句，在程序运行时把一些调试信息（如变量的值）输出到显示器。</li>
</ul>
<blockquote>
<p>啊啊，我现在都一直用的是这种笨办法</p>
</blockquote>
<p>这种方式存在以下问题： -
调试者必须对输出的值做一定的分析才能知道程序是否有错。 -
在开发结束后，去掉调试信息有时是一件很繁琐的工作 &gt; 难道是用 Debug,
或者调试工具？哇撒</p>
<p>？断言
实际上，在调试程序时输出程序中的某些变量或表达式的值，其目的是为了确认程序输出的这些值与预期的值是否相符。
上述的目的可以让程序设计者在程序的一些关键或容易出错的点上插入一些相关的断言来表达
- 断言是一个逻辑表达式，它描述了程序执行到断言处应该满足的条件 -
如果条件满足则程序继续执行下去，否则程序执行异常终止。
在程序测试阶段，断言可以帮助测试这发现程序的逻辑错误，也可以用来发现一些异常错误。</p>
<blockquote>
<p>语法错误首先X,然后的话异常只能按自己是否能够预知下得到。然后的断言最大的好处真的在可以发现程序的逻辑错误啊，真牛逼！其实这等同于输出的，就是每次debug这样真的好麻烦好吗？而且没有意思，哇咔咔，这样真有趣！</p>
</blockquote>
<blockquote>
<p>哇，想起了java的测试工具类，python的测试工具包，终于浮出水面了吗？</p>
</blockquote>
<p>宏assert</p>
<p>C++标准库提供的一个宏assert(cassert, assert.h),可以实现断言。
宏assert要求一个关系，逻辑表达式作为其参数，当assert执行时， -
如果表达式的值为false，则会显示出相应的表达式、它所在的源文件名以及所在的行号等诊断信息，然后调用库函数abort终止
- 当表达式的值为true时，程序继续执行</p>
<p>例如，下面的宏assert调用表示程序执行到该宏调用处变量x的值应等于1：
assert(x==1)
当程序执行到该调用处，如果x的值不等于1，则它会显示下面的信息并终止：
Assertion failed:x=1,fileXXX,line YYY 可以返现异常错误，如
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int divide(int x,int y)&#123;</span><br><span class="line">    assert(y==0);</span><br><span class="line">    return x/y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这是真的是超级好用的一个东西。
宏assert的实现是通过条件编译预处理命令来实现的： cassert, <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#ifdef NDEBUG</span><br><span class="line">#define assert(exp) ((void)0)</span><br><span class="line">#else</span><br><span class="line">#define assert(exp) ((exp)?(void)0:&lt;输出诊断信息并调用库函数abort&gt;)</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure>
&gt;
解释，也就是说宏assert只有在宏名NDEBUG没有定义时才有效，这时，程序一般处于开发、测试阶段。程序开发结束提交时，应该让宏名NDEBUG有定义。然后重新编译程序，这样，assert就不再有效了。</p>
<blockquote>
<p>在思考，#DEBUG有啥用？</p>
</blockquote>
<h3 id="一点有意思的记录">一点有意思的记录</h3>
<p>char <em>p="adad"; </em>p指向的是字符串。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strlen(p); // 传入指针就行，能想清楚。</span><br><span class="line">// 这本身就是其功能规定的，所以这里也不多说什么。觉得就这样吧，是对的。</span><br><span class="line">cout&lt;&lt;p;  //正常输出</span><br><span class="line">printf(&quot;%s&quot;,p); // 输出</span><br></pre></td></tr></table></figure>
<p>//
等下，我好想这里搞错了什么，或者说把一些事情。也就是说这里指针是没错的。因为这里是统一处理输入输出的函数。</p>
<p>// 另一个方面讲</p>
<p>太棒了，刚说自己想多了，结果才发现这里有说明的。</p>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture4</title>
    <url>/2019/nju-course-cplus-lecture4-89515bc1c2bf/</url>
    <content><![CDATA[<h1 id="重点">重点</h1>
<h2 id="泛型程序设计">泛型程序设计</h2>
<p>一个程序实体能对多种类型的数据进行操作或描述的特性称为类属性。具有类属性的程序实体通常有：
1. 类属函数 2. 类属类</p>
<p>类属也是一种多态，称为参数化多态。</p>
<p>比如说用通用指针。</p>
<p>如上所示，C++提供了两种实现类属函数的机制 -
采用通用指针类型的参数(C语言的做法) - 函数模板</p>
<h3 id="通用指针">通用指针</h3>
<p>整个世界就是由1构成的，可以升为万物的。 void
*，所有的父类。通用的都是byte.</p>
<p>这些东西然后不断地转换为其他的内容。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> 函数定义：</span><br><span class="line"> void sort(void *base, unsigned int count, unsigned  int element_size, int (*cmp)(const void*, const void*))&#123;</span><br><span class="line">     // 这里函数参数和也可以诶，发现我完全想复杂了。也就是说这里的话，只要弄个函数名做参数，其实也不所谓，没有我想的那么复杂，哈哈哈！两步就可以了</span><br><span class="line">     // 取第i个元素</span><br><span class="line">     (byte *)base + i*element_size</span><br><span class="line"></span><br><span class="line">    // 比较第i个和第j个元素的大小，利用调用者提供的回调函数cmp实现</span><br><span class="line">    (*cmp)((byte *)base + i*element_size, (byte*)base + j*element_size)</span><br><span class="line"></span><br><span class="line">    // 交换第i个和第j个元素</span><br><span class="line">    byte *p1 = (byte *)base + i*element_size;</span><br><span class="line">    byte *p2 = (byte *)base + j*element_size;</span><br><span class="line">    for(int k=0;k &lt; element_size;k++)&#123;</span><br><span class="line">        byte temp=p1[k]; p1[k]=p2[k]; p2[k]=temp;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> 这里的byte为typedef unsigned char byte;</span><br><span class="line"></span><br><span class="line">void sort(void *base, //需排序的数据（数组）首地址</span><br><span class="line">             unsigned int count, //数据元素的个数</span><br><span class="line">             unsigned int element_size, //一个数据元素所需的空间大小</span><br><span class="line">             int (*cmp)(const void *, const void *) ) //比较两个元素的函数</span><br><span class="line">&#123;   //不论采用何种排序算法，一般都需要对数组进行以下操作：	</span><br><span class="line">     //取第i个元素</span><br><span class="line">        (char *)base+i*element_size</span><br><span class="line">     //比较第i个和第j个元素的大小 （利用调用者提供的回调函数cmp实现）</span><br><span class="line">        (*cmp)((char *)base+i*element_size,</span><br><span class="line">                    (char *)base+j*element_size)</span><br><span class="line">     //交换第i个和第j个元素</span><br><span class="line">        char *p1=(char *)base+i*element_size,</span><br><span class="line">	     *p2=(char *)base+j*element_size;</span><br><span class="line">        for (int k=0; k&lt;element_size; k++)</span><br><span class="line">        &#123;	char temp=p1[k]; p1[k] = p2[k]; p2[k] = temp;</span><br><span class="line">        &#125; </span><br><span class="line">&#125; //上面的char用byte替代更好！typedef unsigned char byte;</span><br></pre></td></tr></table></figure>
<p>调用者需要调用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int A_compare(const void* p1, const void* v2)&#123;</span><br><span class="line">    if(*(*A)p1 &lt; *(A*)p2) return -1;</span><br><span class="line">    else if(*(*A)p1) &gt; *(A*)p2) return 1;</span><br><span class="line">    else return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 类属排序函数的使用</span><br><span class="line">int a[100];</span><br><span class="line">sort(a,100,sizeof(int),int_compare);</span><br><span class="line">double b[200];</span><br><span class="line">sort(b,200,sizeof(double), double_compare);</span><br><span class="line">A c[300]; // 如果这里A是类，就显示出了将比较符号重载的有效性</span><br><span class="line">sort(c,300,sizeof(A),A_compare)</span><br></pre></td></tr></table></figure> 品味！</p>
<h3 id="函数模板">函数模板</h3>
<p>函数模板是指带有类型参数的函数定义，其一般格式如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">template&lt;class T1, class T2,...&gt;</span><br><span class="line">&lt;返回值类型&gt; &lt;函数名&gt;(&lt;参数表&gt;)&#123;&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">template&lt;class T&gt;</span><br><span class="line">void sort(T elements[], unsigned int count)&#123;</span><br><span class="line">    // 取第i个元素</span><br><span class="line">    elements[i]</span><br><span class="line">    // 比较第i个和第j个元素的大小</span><br><span class="line">    elements[i]&lt; elemnets[j]</span><br><span class="line">    // 交换第i个和第j个元素</span><br><span class="line">    T temp = elements[i];</span><br><span class="line">    elements[i] = elements[j];</span><br><span class="line">    elements[j] = temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&gt; 来一起感叹，太他妈牛逼了。这template省去了好多麻烦！好高层的一种抽象，太棒了，果然！牛逼死了</span><br><span class="line"></span><br><span class="line">int a[100];</span><br><span class="line">sort(a, 100);</span><br><span class="line">double b[200];</span><br><span class="line">sort(b,200);</span><br><span class="line">A c[300];</span><br><span class="line">sort(c, 300);</span><br></pre></td></tr></table></figure></p>
<p>函数模板的使用——实例化 - 函数模板定义了一系列重载的函数 -
要使用函数模板所定义的函数，称为模板函数，首先必须对函数模板进行实例化：给模板参数提供一个类型作为值，从而生成具体的函数。
- 函数模板的实例化通常是隐式的 - 由编译程序来做，模板实参推演</p>
<p>当编译程序无法根据调用时的参数类型来确定所调用的模板参数，这时，需要在程序中显式第实例化函数模板。</p>
<p>除了类型参数外，函数模板也可以带有非类型参数，使用时需要显式实例化。
template&lt;class T, int size&gt; void f(T a){ T temp[size]; }</p>
<h3 id="类模板">类模板</h3>
<p>如果一个类的成员的类型可变，则该类称为类属类。在C++中，类属类用类模板实现。
template&lt;class T1, class T2&gt; class <类名>{}</p>
<p>使用 Stack<int> st1;</p>
<p>!!!
类模板中的静态成员仅属于实例化后的类，不同类模板实例之间不共享类模板中的静态成员。
template <class T> class A{ static int x; }</p>
<p>注意！在自己定义时，需要把模板的定义和实现都放在头文件中。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// file1.h</span><br><span class="line">template &lt;class T&gt; </span><br><span class="line">class S //类模板s的定义</span><br><span class="line">&#123;  T a;</span><br><span class="line">  public:</span><br><span class="line">    void f();</span><br><span class="line">&#125;;</span><br><span class="line">template &lt;class T&gt; </span><br><span class="line">void S&lt;T&gt;::f() //类模板s的实现  如果放在对应的file1.cpp中，会显示该实例不存在</span><br><span class="line">&#123; ......</span><br><span class="line">&#125;</span><br><span class="line">extern void func();</span><br><span class="line"></span><br></pre></td></tr></table></figure>
使用者通过包含这个头文件，把模板的源代码全包含进来，以备实例化所需。
因此，模板是基于源代码的复用、</p>
<ul>
<li>重复实例的处理
模板的复用会导致多模块的编译结果中存在相同的实例：</li>
</ul>
<ol type="1">
<li>相同的函数模板实例</li>
<li>相同的类模板成员函数实例 相同代码的存在会造成目标代码庞大！
如何处理？</li>
</ol>
<ul>
<li>由开发环境来解决：编译第二个模块的时候不生成这个函数</li>
<li>由连接程序来解决：舍弃多余的那一个</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">关于类模板的友元</span><br><span class="line">template &lt;class T&gt; class A;</span><br><span class="line">template &lt;class T&gt; void f3(A&lt;T&gt;&amp; a) &#123; ... &#125;</span><br><span class="line">template class&lt;T&gt;</span><br><span class="line">class A</span><br><span class="line">&#123; T x,y;</span><br><span class="line">  ......</span><br><span class="line">  friend void f1(A&lt;T&gt;&amp; a); //友元f1不是模板！</span><br><span class="line">  template &lt;class T1&gt; friend void f2(A&lt;T1&gt;&amp; a); //f2与A多对多实例化</span><br><span class="line">  friend void f3&lt;T&gt;(A&lt;T&gt;&amp; a); //f3与A一对一实例化(用相同参数类型)</span><br><span class="line">&#125;;</span><br><span class="line">void f1(A&lt;int&gt;&amp; a) &#123; ... &#125;</span><br><span class="line">template &lt;class T&gt; void f2(A&lt;T&gt;&amp; a) &#123;...&#125;</span><br><span class="line">......</span><br><span class="line">A&lt;int&gt; a1; //实例化A&lt;int&gt;</span><br><span class="line">A&lt;double&gt; a2; //实例化A&lt;double&gt;</span><br><span class="line">f1(a1); //OK，调用f1(A&lt;int&gt;&amp;)</span><br><span class="line">f1(a2); //链接错误! 调用f1(A&lt;double&gt;&amp;)，但它不存在！</span><br><span class="line">f2(a1); //实例f2&lt;int&gt;是A&lt;int&gt;和A&lt;double&gt;的友元</span><br><span class="line">f2(a2); //实例f2&lt;double&gt;是A&lt;int&gt;和A&lt;double&gt;的友元</span><br><span class="line">f3(a1); //实例f3&lt;int&gt;是A&lt;int&gt;的友元，但不是A&lt;double&gt;的友元！</span><br><span class="line">f3(a2); //实例f3&lt;double&gt;是A&lt;double&gt;的友元，但不是A&lt;int&gt;的友元！</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>总结：友元是外部，在说明友元时也需要在外部进行说明。</p>
</blockquote>
<h3 id="c标准库">C++标准库</h3>
<p>在C++标准库中，除了C标准库保留下来的一些功能外，其它功能大都以模板形式给出，这些模板构成了C++的标准模板库。
STL实现了数据结构和算法的复用，体现了泛型程序设计的精髓。
STL支持了一种编程思想模式。</p>
<p>STL主要包含： -
容器类模板：用于存储序列化数据元素，比如：向量、队列、栈、集合等 -
算法（函数）模板：用于对容器中数据元素进行一些常用的操作，如：排序、查找、求和等
- 迭代器类模板：实现了抽象的指针功能，它用于指向容器中的元素。 -
迭代器是容器和算法之间的桥梁：传给算法的不是容器，而是指向容器中元素的迭代器，算法通过迭代器实现对容器中数据元素的访问和遍历。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">#include&lt;numeric&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">int main()&#123;</span><br><span class="line">    vector&lt;int&gt; v;</span><br><span class="line">    int x;</span><br><span class="line">    cin&gt;&gt;x;</span><br><span class="line">    while(x&gt;0)&#123;</span><br><span class="line">        v.push_back(x);</span><br><span class="line">        cin&gt;&gt;x;</span><br><span class="line">    &#125;</span><br><span class="line">    vector&lt;int&gt;::iterator it1=v.begin();</span><br><span class="line">    vector&lt;int&gt;::iterator it2=v.end();</span><br><span class="line">    cout&lt;&lt;&quot;Max= &quot;&lt;&lt;*,ax_element(it1, it2)&lt;&lt;endl;</span><br><span class="line">    cout&lt;&quot;Sum=&quot;&lt;&lt;accumulate(it1, it2, 0)&lt;&lt;endl;</span><br><span class="line">    sort(it1, it2);</span><br><span class="line"></span><br><span class="line">    cout&lt;&lt;&quot;Sorted result is:\n&quot;;</span><br><span class="line">    for_each(it1, it2,[](int x)&#123;cout&lt;&lt;x&lt;&lt;&#x27;&#x27;; return;&#125;)</span><br><span class="line">    cout&lt;&lt;&quot;\n&quot;;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="容器">容器</h4>
<p>容器是由长度可变的同类型元素所构成的序列。
STL中包含了很多种容器，虽然这些容器提供了很多相同的操作，但采用了不同的内部实现方法，所以不同的容器适合不同的应用场合。
容器由类模板来实现</p>
<ul>
<li><p>vector&lt;&gt;
需要快速定位任意位置上的元素以及主要在元素序列的尾部增加、删除元素的场合
在头文件vector中定义，用动态数组实现</p></li>
<li><p>list&lt;&gt; 用于经常在元素序列中任意位置上插入或删除元素的场合。
list, 双向链表实现</p></li>
<li><p>dequeue&lt;&gt;
用于主要在元素序列的两端增加、删除元素以及需要快速定位任意位置上的元素的场合
dequeue, 用分段的连续空间结构实现</p></li>
<li><p>stack&lt;&gt; 用于仅在元素序列的尾部增加、删除元素的场合
基于deque实现</p></li>
<li><p>queue&lt;&gt; 用于仅在元素序列的头部增加、删除元素的场合
基于dequeue实现</p></li>
<li><p>priority_queue&lt;&gt;
与queue的操作类似，不同之处在于：每次增加，删除元素之后，它将元素位置进行调整，使得头部元素总是最大的。每次删除操作总是把最大的元素去掉。
在queue中定义，一般基于vector和heap实现</p></li>
<li><p>map&lt;关键字类型，值类型&gt; multimap</p></li>
<li><p>容器中每个元素是一个pair结构类型，该结构有两个成员：first和second，关键字对应first,
值对应second,元素是根据其关键字排序的。用于需要根据关键字来访问元素的场合</p></li>
<li><p>对于map，不同元素的关键字不能相同；对于multimap,不同元素的关键字可以相同</p></li>
<li><p>map中定义</p></li>
<li><p>set<元素类型> multiset</p></li>
<li><p>相对于map和multimap, 合一了</p></li>
<li><p>set中定义</p></li>
<li><p>basic_string&lt;&gt;</p></li>
<li><p>与vector类似，不同之处在于其元素作为字符类型，并提供了一系列与字符串相关的操作</p></li>
<li><p>string和wstring分别是它的两个实例：
basic_string<char>和basic_string<wchar_t></p></li>
<li><p>在string中定义</p></li>
</ul>
<h4 id="容器的操作">容器的操作</h4>
<ul>
<li>获取指定位置的元素</li>
<li>增加元素</li>
<li>删除元素</li>
<li>查找元素</li>
<li>获取容器首、尾元素的迭代器</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">T &amp;front();</span><br><span class="line">T &amp;back();  // vector, list,dequeue,queue</span><br><span class="line"></span><br><span class="line">void push_front(const T&amp;x) void pop_front;  //list,deque</span><br><span class="line">void push_back(const T&amp;x) void pop_back; //vector,list,dequeue</span><br><span class="line"></span><br><span class="line">void push(const T&amp;x) // 尾部stack, queue, priority_queue</span><br><span class="line">void pop() // 尾部stack, 头部queue, priority_queue</span><br><span class="line"></span><br><span class="line">T &amp;top();  const T&amp;top() const;  尾部stack , 头部priority_queue</span><br><span class="line"></span><br><span class="line">iterator begin();</span><br><span class="line">const_iterator begin() const;  除queue,priority queue, stack</span><br><span class="line">// 为什么有两种？有啥不一样的用的地方吗？</span><br><span class="line"></span><br><span class="line">iterator end();</span><br><span class="line">const_iterator end() const; 同上</span><br><span class="line"></span><br><span class="line">iterator insert(iterator pos, const T&amp; x);</span><br><span class="line">void insert(iterator pos, InputIt first, InputIt last);</span><br><span class="line">// pos 插入一个呼呼多个元素， vector, list, deque</span><br><span class="line"></span><br><span class="line">iterator erase(iterator pos)</span><br><span class="line">iterator erase(iterator first, iterator last);</span><br><span class="line">// vector, list, deque, map/multimap, set, basic_string</span><br><span class="line"></span><br><span class="line">T &amp;operator[](size_type pos)</span><br><span class="line">// pos上的引用， vector, deque, basic_string</span><br><span class="line"></span><br><span class="line">ValueType &amp; operator[](const KeyType&amp; key); // map</span><br><span class="line"></span><br><span class="line">T&amp; at(size_type pos);</span><br><span class="line">相比于[], 进行了越界检查； vector,deque,basic_string</span><br><span class="line"></span><br><span class="line">iterator find(const T&amp; key);</span><br><span class="line">// 根据关键字查找，找到返回；否则返回最后一个元素的下一个位置</span><br></pre></td></tr></table></figure>
<blockquote>
<p>值得注意的是，如果容器的元素类型是一个类，则针对该类需要： 1.
自定义拷贝构造函数和赋值操作符重载函数。 2. 重载比较操作符&lt;</p>
</blockquote>
<h4 id="迭代器">迭代器</h4>
<p>迭代器是实现了抽象的指针（智能指针）。它们指向容器中的元素。 &gt;
哇，抽象指针，牛逼</p>
<p>在STL中，迭代器是作为类模板来实现的，它们可以分为以下几种： -
输出迭代器output iterator - 用来修改它所指向的容器元素 - 间接访问操作
*输出迭代器 - ++操作</p>
<ul>
<li><p>输入迭代器input iterator</p>
<ul>
<li>用于读取它指向的容器元素</li>
<li>间接访问操作 *p</li>
<li>元素成员间接访问-&gt;</li>
<li>++, ==, !=操作</li>
</ul></li>
<li><p>前向迭代器 &gt;
哇，这个就应该是方向有关吧。只能一个方向，不过好奇的是这个方向有规定只能从头到尾吗？感觉上应该两种都被允许
用于读取、修改它所指向的容器元素 元素间间接访问操作和元素成员间接访问.
同义获取关联的对象 &gt;
如果是int，则访问的是其值，就对应于第一种情况；如果是类，就对应于第二种情况。
++,==,!=操作</p></li>
<li><p>双向迭代器 用于读取，修改它所指向的容器元素
元素间接访问操作和元素成员间接访问操作 ++,--,==,!=</p></li>
<li><p>随机访问迭代器 用于读取、修改它所要指向的容器元素
元素间接访问操作、元素成员间接访问和随机访问元素操作
++,--,&gt;=,&lt;,&gt; &gt;
随机访问吗？应该是对于固定存储的吧？不然实现算法复杂度不一样唉，真好奇实现方法。
&gt; 对！下面得到了回答</p></li>
</ul>
<p>从上到下，从派生类到基类</p>
<p>哦，来啦</p>
<p><strong>各容器的迭代器类型</strong> - vector,deque, basic_string,
begin/end返回的是随机访问迭代器 - list,map,set返回的是双向迭代器 &gt;
这两个因为内部的物理实现结构不一样 -
对于queue,stack,priority_queue,不支持迭代器 &gt;
为啥，不支持前向后向吗？queue本身支持，但是因为queue,stack有其特定的持有顺序所以不支持吗？特殊功能，而priority_queue更是由于实现复杂。每一次动荡代价不一样。</p>
<blockquote>
<p>迭代器的作用就是每个变量的指示，最多的应用自己所见到的就是遍历。所以怎么说感觉上应该能得到下一个元素的地址的那种</p>
</blockquote>
<h4 id="算法">算法</h4>
<p>分类 调序算法 编辑算法 查找算法 算术算法 集合算法 堆算法
元素遍历算法</p>
<p>STL算法体现了一种高度抽象： - 每一个算法都完成一个特定的功能 -
大部分算法都是遍历指定的容器元素，对满足条件的元素执行默认的或自定义的操作。
-
使用者只需要提供：容器（迭代器）、操作条件以及自定义操作，而控制逻辑则有算法内部实现。循环不用操心</p>
<p>算法处理的是容器的迭代器，这样的好处很明显，能够提高算法对容器的适应性。虽然容器各不相同，一个算法往往可以接受相容的多种迭代器</p>
<p>一个算法能接收的迭代器的类型时通过算法模板参数的名字来体现的。一个算法能接收与参数类型相容的所有种类的迭代器。
&gt;
这里应该不是都是最大的权限即随机访问迭代器吧？这样虽然特别妙？不对指针不应该是指向基类吗？那么怎么的？感觉上应该是限定的</p>
<p>然后就规定一下显式的操作说明吧：
参数容器的作用范围应该一样。一般地，参数(src_first, src_last,
dst_first)</p>
<p>自定义操作
有些算法要求使用者提供一个函数或函数对象作为自定义的操作条件，因为往往返回结果为false或true.
所以可以看作谓词。 Pred: 一元谓词，需要一个元素作为参数
BinPred:二元谓词，需要两个元素作为参数 eg: count_if(InIt first,InIt
last, Pred cond); &gt; 注意这里的默认参数，感觉上应该与vector<int>x,
这里的int, 即class相关。 即一元谓词，二元谓词的参数。对的！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;numeric&gt;</span><br><span class="line">accumulate() // 累积算法,返回值</span><br><span class="line">transform() // 变换，映射算法</span><br></pre></td></tr></table></figure>
<p>发现越到后面越有点像数据库的内容了。</p>
<ul>
<li>作业 STL算法应用——在学生容器中做统计 学生：name, sex, birth_place,
major 功能：init, sort, display, match_major. &gt;
match_major内容特别多，可以考虑用函数对象来做</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">利用函数对象来解决上面的问题</span><br><span class="line">class MatchMajor</span><br><span class="line">&#123;	   Major major;</span><br><span class="line">	public:</span><br><span class="line">	   MatchMajor (Major m)</span><br><span class="line">	   &#123;	major = m;</span><br><span class="line">	   &#125;</span><br><span class="line">	   bool operator ()(Student&amp; st)</span><br><span class="line">	   &#123; return st.get_major() == major;</span><br><span class="line">	   &#125;</span><br><span class="line">&#125;;</span><br><span class="line">count_if(students.begin(),students.end(),</span><br><span class="line">			              MatchMajor(COMPUTER))；</span><br><span class="line">count_if(students.begin(),students.end(),</span><br><span class="line">			              MatchMajor(PHYSICS))；</span><br><span class="line">count_if(students.begin(),students.end(),</span><br><span class="line">			              MatchMajor(XXX))；</span><br><span class="line"></span><br><span class="line">// 扩展</span><br><span class="line"></span><br><span class="line">    bool operator ()(Student&amp; st)</span><br><span class="line">    &#123; return st.get_major() == major &amp;&amp; st.get_sex() == sex;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">count_if(students.begin(),students.end(),</span><br><span class="line">             MatchMajorAndSex(COMPUTER,FEMALE)) //计算机女生</span><br><span class="line"></span><br><span class="line">// lambda表达式</span><br><span class="line">count_if(students.begin(),students.end(),</span><br><span class="line">        [](Student &amp;st) &#123; return (st.get_major() == COMPUTER)</span><br><span class="line">			     &amp;&amp; (st.get_sex() == FEMALE); &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//统计出生地为&quot;南京籍计算机专业&quot;的学生人数</span><br><span class="line">cout &lt;&lt; &quot;出生地为\&quot;南京\&quot;的学生人数是：&quot; </span><br><span class="line">      &lt;&lt; count_if(students.begin(),students.end(),</span><br><span class="line">  [](Student &amp;st) &#123; return (st.get_major() == COMPUTER) </span><br><span class="line">          &amp;&amp; (st.get_birth_place().find(&quot;南京&quot;)!= string::npos);&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这里的思想很妙，但对象作为函数传递时，默认调用的就是A()，无参数的，所以此时就显示出了重载()运算符的好处</p>
<blockquote>
<p>当实体完全是为了存储数据使用的时候，此时就演化为了数据库这门课程</p>
</blockquote>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture6-summary</title>
    <url>/2019/nju-course-cplus-lecture6-summary-0bbddf9f302b/</url>
    <content><![CDATA[<h1 id="重点">重点</h1>
<ol type="1">
<li>Window是一种基于图形界面的多任务操作系统。同时多个，交互，用户操作</li>
</ol>
<ul>
<li>两种方式：直接的应用程序，API</li>
<li>应用方式: 单文档、多文档、对话框。 &gt;
单文档是什么？多文档是什么？</li>
</ul>
<p>基于消息驱动的，不断地处理消息</p>
<ol start="2" type="1">
<li>面向过程，基于Windows API
每个应用程序都提供了一个主函数，首先进行注册每一类的窗口，其次创建主窗口，然后进入消息循环。再对消息进行分类处理。
消息还可以生成新的消息。</li>
</ol>
<blockquote>
<p>实际上是Windows将每个窗口都进行了分类，也就是每个窗口和消息都具有总的类别。HWND,
UINT
然后，主窗口接收消息，接收到消息后传递到对应的窗口。对应的窗口可以考虑再进行窗口的改变，再生成新的消息加入消息队列，如此反复，直到消息队列中的消息被完全处理完。</p>
</blockquote>
<p>可重入函数，哪些函数是可以重新调用其他函数的？</p>
<p>资源：程序代码，菜单id，显示文字，对话框类型，尺寸与位置,
存储在相应的资源文件.rc中</p>
<ol start="3" type="1">
<li>面向对象，基于MFC类库的支持 对象： 窗口，文档
应用程序包含成员对象窗口和文档</li>
</ol>
<blockquote>
<p>多文档和单文档，多文档允许同时操作多个文档；单文档只允许操作单个文档。</p>
</blockquote>
<p>然后，所有的分类标准也是从CObject派生的，派生了AA,Ex,FS,A</p>
<p>MFC主要类 - 窗口类 1. 基本窗口类Cwd &gt;
从后面来看这里应该是基类没错了。 2.
框架窗口类应该是基本窗口类的子类或者基本窗口类是它的参数的感觉，因为它要对子窗口进行管理以及提供更多的比如对标题栏、菜单栏、工具栏等的支持。
3. 视类：显示数据。位于多文档框架的可显示区。 4.
对话框类，特殊的弹出来的类 - 文档类 CDocument - 应用框架类 1. 文档模板类
2. 应用类 - 绘图类 - 文件输入/输出类 - 常用数据类型</p>
<p>文档-视结构</p>
<p>CView, CDocument, CFrameWnd, CDocTemplate, CWinApp</p>
<p>应用向导 类向导 &gt; 如何将GUI与面向对象设计联系起来？</p>
<p>GUI设计 - 菜单 - 对话框 消息，成员函数 - 绘图
绘图函数，绘图工具；作用范围 - 坐标变化</p>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture7</title>
    <url>/2019/nju-course-cplus-lecture7-8f8dec171c14/</url>
    <content><![CDATA[<h1 id="重点">重点</h1>
<h2
id="转移构造函数转移赋值操作符重载函数">转移构造函数&amp;转移赋值操作符重载函数</h2>
<p>拷贝构造问题
当用一个临时或即将消亡的对象去初始化另一个同类的对象时，目前的拷贝构造函数实现效率不高</p>
<p>主要对应的是一种情况：即当类作为返回值时，调用拷贝构造函数后会立即消亡。</p>
<p>在C++中就提出了一种转移构造函数的概念。</p>
<p>转移构造函数即进行资源转移 A(A&amp;&amp; x) { p=x.p; x.p=NULL; }</p>
<p>赋值操作符重载， 转移赋值操作符重载</p>
<h2 id="函数式逻辑式程序设计">函数式&amp;逻辑式程序设计</h2>
<p>从本质上说，用计算机来解决实际问题就是通过对反映问题本质的数据进行处理来实现的:
程序=算法+数据结构</p>
<p>如何看待和组织算法和数据结构却存在着不同的做法，从而形成不同的程序设计范式：
-
程序设计范式是设计、组织和编写程序的一种方式，它往往要基于一组理论、原则和概念
- 不同的范式将采用不同的程序结构和程序元素来描述程序。 -
范式具有针对性，不同的范式往往适合于解决不同类型的问题。</p>
<ol type="1">
<li>过程式程序设计</li>
</ol>
<ul>
<li>一种以功能为中心、基于功能分解和复合的程序设计范式。</li>
<li>程序由一些子程序构成，每个子程序对应一个子功能。子程序描述了一系列操作，它是操作的封装体，实现了过程抽象。</li>
<li>程序的执行过程体现为一系列的子程序调用</li>
<li>在过程式程序中，数据处于附属地位，它独立于子程序，在子程序调用时通过参数或全局变量传给子程序使用。</li>
</ul>
<ol start="2" type="1">
<li>面向对象程序设计</li>
</ol>
<ul>
<li>一种以数据为中心，基于数据抽象的程序设计范式。</li>
<li>程序由一些对象构成，对象是由一些数据及可施加于这些数据上的操作所组成的封装体。</li>
<li>对象的特征由相应的类来描述，一个类描述的对象特征可以从其它的类获得。</li>
<li>程序的执行过程体现为各个对象之间相互发送和处理消息</li>
<li>在面向对象程序中，数据表现为对象的属性，对数据的操作是通过向包含数据的对象发送消息（调用对象提供的操作）来实现。</li>
</ul>
<ol start="3" type="1">
<li>函数式程序设计</li>
</ol>
<ul>
<li>程序由一组数学函数构成，计算过程体现为一系列的函数应用（把函数作用于数据）</li>
<li>基于的理论是递归函数理论和lambda演算</li>
</ul>
<ol start="4" type="1">
<li>逻辑式程序设计</li>
</ol>
<ul>
<li>程序由一组事实和一组推理规则构成，在事实基础上运用推理规则来实施计算。</li>
<li>基于的理论是谓词演算。</li>
</ul>
<h2 id="命令式声明式程序设计">命令式&amp;声明式程序设计</h2>
<ol type="1">
<li>命令式程序设计</li>
</ol>
<ul>
<li>强调对“如何做”的描述，要对操作步骤和状态变化给出明确的描述。例如，过程式和面向对象程序设计</li>
<li>与冯洛伊曼结构一致，是使用较广泛的程序设计范式，适合于解决大部分的实际应用问题。</li>
</ul>
<ol start="2" type="1">
<li>声明式程序设计</li>
</ol>
<ul>
<li>强调对“做什么”的描述，而如何做则由实现系统自动完成。例如，函数式和逻辑式程序设计</li>
<li>有良好的数学理论支持，并且，设计出的程序具有潜在的并行性。适合于需要大量进行复杂的符号处理（非数值计算）的人工智能领域的应用。</li>
</ul>
<p>函数式程序设计的几个基本特征</p>
<ul>
<li>“纯”函数：引用透明（无副作用，以相同的参数调用函数总得到相同的值）</li>
<li>没有状态（数据不可变）：计算不改变已有数据，而是产生新的数据。（无赋值操作）</li>
<li>函数也是值（first-class citizen)
：函数的参数和返回值都可以是函数。（高阶函数）</li>
<li>表达式的惰性（延迟）求值（Lazy evaluation）：需要的时候才计算。</li>
<li>潜在的并行性。</li>
</ul>
<p>函数式程序设计的几个基本技术</p>
<ul>
<li>递归：实现重复操作，不采用迭代方式（循环）。</li>
<li>尾递归：递归调用是递归函数的最后一步操作，编译可优化之。
就是返回参数的return f(a,b); 这里f(a,b)不应该含有任何运算
尾递归有以下几个好处： 便于编译程序优化：
<ul>
<li>重用本次调用的栈空间</li>
<li>自动转成迭代 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">T f(T1 x1, T2 x2, ...)</span><br><span class="line">&#123;  ......</span><br><span class="line">    ... return f(e1,e2,...);</span><br><span class="line">    ......</span><br><span class="line">    ... return f(e3,e4,...);</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line">改成：</span><br><span class="line">T f(T1 x1, T2 x2, ...)</span><br><span class="line">&#123;  while (true)</span><br><span class="line">    &#123; ......</span><br><span class="line">       ... &#123; x1 = e1; x2 = e2; ... continue;&#125; </span><br><span class="line">       ......</span><br><span class="line">       ... &#123; x1 = e3; x2 = e4; ... continue;&#125;</span><br><span class="line">       ......</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li>map/reduce（映射/规约）：对一个集合中的元素做映射和规约操作。</li>
<li>currying（柯里化）：把接受多个参数的函数变换成接受单一参数（原函数的第一个参数）的函数，该函数返回一个接收剩余参数的函数。（函数约简）</li>
</ul>
<p>map, reduce操作</p>
<ul>
<li>惰性和并行求值</li>
</ul>
<p>对于一个函数式程序：（示意） a = f1();  //f1是一个纯函数b = f2(); 
//f2是一个纯函数 ...... if (...)  ... a + b ...
由于f1、f2是纯函数，哪个先执行都可以，甚至可以并发执行！
f1、f2也可以到需要它们的时候（a+b）再执行（惰性求值）；如果程序中没用到它们，f1、f2也可以不执行！</p>
<p>逻辑式程序设计简介</p>
<p>程序由一组事实和一组推理规则构成，在事实基础上运用推理规则来实施计算。
基于的理论就是谓词演算</p>
<p>特征 - 数据（事实和规则）就是程序 -
计算（匹配、搜索、回溯）由实现系统自动完成。</p>
<p>语言 Prolog</p>
<blockquote>
<p>逻辑式程序设计是事实和规则作为数据。
给定目标，系统会自动进行搜索来探讨是否有效
函数式程序设计给人的感觉就是运用这些来做。</p>
</blockquote>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course-cplus-lecture6</title>
    <url>/2019/nju-course-cplus-lecture6-0d4b502fed85/</url>
    <content><![CDATA[<h1 id="重点">重点</h1>
<p>Windows简介 消息驱动的程序结构 基于Windows
API的过程式Window应用陈旭设计
基于MFC和"文档-视"结构的面向对象Windows应用程序设计</p>
<h2 id="windows简介">Windows简介</h2>
<p>Window是一种基于图形界面的多任务操作系统 -
系统中可以同时运行多个应用程序 - 每个应用程序通过窗口与用户进行交互 -
用户通过鼠标的单击，双击，拖放，菜单选择以及键盘输入来进行操作</p>
<p>Windows功能以两种方式提供： -
工具（应用程序）：资源管理器、记事本、画图，。。。直接使用 - 函数库:
作为Windows的API。</p>
<p>单文档应用 - 只能对一个文档的数据进行操作 -
只有结束当前文档的操作后，才能进行下一个文档的操作 多文档应用 -
可以同时对多个文档的数据进行操作 -
不必等到一个文档的所有操作结束，就可以对其它文档进行操作，对不同文档的操作是在不同的子窗口进行的
对话框应用 - 以对话框的形式操作一个文档数据 -
对文档数据的操作以各种control空间来实现 -
程序以按确定或取消等按钮来结束</p>
<p>Windows应用程序的结构属于消息（事件）驱动的结构：
程序的任何一个动作都是在接受到一条消息后发生的</p>
<p>Windows的消息有： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WM_KEYDOWN/WM_KEYUP（键盘按键）</span><br><span class="line">WM_CHAR（字符）</span><br><span class="line">WM_LBUTTONDOWN/WM_LBUTTONUP/WM_LBUTTONDBLCLK/WM_MOUSEMOVE （鼠标按键）</span><br><span class="line">WM_COMMAND（菜单）</span><br><span class="line">WM_PAINT（窗口内容刷新）</span><br><span class="line">WM_TIMER（定时器消息）</span><br><span class="line"></span><br></pre></td></tr></table></figure>
每个Windows应用程序都有一个消息队列，Windows系统会把各个应用程序的消息放入各自的消息队列。
大部分的消息都关联到某个窗口 - 每个窗口都有一个消息处理函数</p>
<p>Windows应用程序不断从自己的消息队列中获取消息并调用相应窗口中的消息处理函数来处理获得的消息。
这个“取消息-处理消息”的过程构成了消息循环。
当取到某个特定消息后，消息循环结束。</p>
<p>主程序 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//初始化</span><br><span class="line">...</span><br><span class="line">// 进入消息循环</span><br><span class="line">while(取消息)   消息队列</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    //处理消息 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 消息处理函数：
注意：每个消息的处理时间不宜太长，否则会造成程序"假死"现象(程序不响应其它消息)
&gt;
这个消息队列应该是最外面的队列吧，那么对于最里面的队列。每个队列都是这样做的吗？好奇！</p>
<h2 id="基于window-api的过程式windows应用程序设计">基于Window
API的过程式Windows应用程序设计</h2>
<p>每个Windows应用程序都必须提供一个主函数WinMain，其主要功能是: -
注册窗口类：窗口的基本信息：名字、基本风格、消息处理函数、图标、光标、背景颜色;
每类窗口都需要注册 - 创建应用程序的主窗口，其他窗口等需要时再创建 -
进入消息循环，直到接收到WM_QUIT消息后，消息循环结束。</p>
<p>程序还要为每类窗口提供一个消息处理函数，用于处理发送到它的消息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;windows.h&gt;</span><br><span class="line">int APIENTRY WinMain(HINSTANCE hInstance, HINSTANCE hPrevInstance, LPSTR IpCmdLine, int nCmdShow // 主窗口显式方式)</span><br><span class="line">WinMain()&#123;</span><br><span class="line">    // 注册窗口类</span><br><span class="line">    RegisterClass(.., WindowProc, &quot;my window class&quot;);</span><br><span class="line">    ...</span><br><span class="line">    // 创建主窗口</span><br><span class="line">    HWND hWnd;</span><br><span class="line">    hWnd = CreateWindow(&quot;my window class&quot;, ..., x,y, width,height,...)</span><br><span class="line">    ShowWindow(hWnd, nCmdShow)</span><br><span class="line">    ...</span><br><span class="line">    // 进入消息循环</span><br><span class="line">    while(GetMessage(&amp;msg, NULL, 0, 0))&#123; // 消息队列</span><br><span class="line">        ...</span><br><span class="line">        DispatchMessage(&amp;msg) // 消息处理函数</span><br><span class="line">    &#125;</span><br><span class="line">    return msg.wParam;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 窗口处理函数</span><br><span class="line">LRESULT CALLBACK WindowProc(HWND hWnd, // 窗口标志 </span><br><span class="line">                            UINT message, // 消息标识, WPARAM wParam, LPARAM lParam...) &#123;</span><br><span class="line">    switch(message) &#123;</span><br><span class="line">        case WM_KEYDOWN:</span><br><span class="line">            wParam   //wParam为按键在键盘上的位置，扫描码</span><br><span class="line">        case WM_CHAR: // 字符健消息</span><br><span class="line">            wParam</span><br><span class="line">        case WM_COMMAND: // 菜单消息</span><br><span class="line">            switch(wParam) //wParam是菜单项的标识</span><br><span class="line">            &#123;</span><br><span class="line">                case ID_FILE_OPEN:</span><br><span class="line">                case ID_START_TIMER:</span><br><span class="line">            &#125;</span><br><span class="line">        case WM_LBUTTONDOWN: // 鼠标左键按下消息</span><br><span class="line">            IParam</span><br><span class="line">        case WM_PAINT: // 窗口刷新消息</span><br><span class="line">        case WM_TIMER: // 定时器消息</span><br><span class="line">        case WM_CLOSE: // 请求关闭窗口消息</span><br><span class="line">            DestoryWindow(hWnd); // 撤销窗口</span><br><span class="line">            break;</span><br><span class="line">        case WM_DESTROY: // 窗口被关闭消息</span><br><span class="line">            PostQuitMessage(0);</span><br><span class="line">            break;</span><br><span class="line">        defalut:</span><br><span class="line">            return DefWindowProc();</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消息处理函数中还可以生成新的消息，方式有两种: - PostMessage
消息放入消息队列 - SendMessage 直接调用消息处理函数 他们的参数为: HWND
hWnd, UINT Msg, WPARAM wParam, LPARAM lParam. 消息参数1和2 &gt;
hWnd接收消息的窗口标识，应该是把窗口进行了分类的感觉吧。Msg实际也是将消息标识进行了分类</p>
<p>消息处理函数应是可再入的
由于消息处理在处理一条消息时可能会主动产生一些新消息，这些消息并不放入消息队列，而是直接调用消息处理函数来处理这些消息，遮掩，就有可能导致小夏处理函数的一次执行还未结束，另一次执行就开始的现象，这可能会引起数据的不一致错误。
&gt;
这里消息的概念是平行的，假设每个消息可能对实际的函数产生不一样的结果。</p>
<p>因此，消息处理函数应该是一个可重入函数，即函数调用者要自带工作区（数据空间）：
- 函数需要的数据需要通过参数来传递 - 函数不能有static存储类的局部变量 -
在函数中访问全局变量也可能导致函数不可再入 &gt;
实话说，不懂什么意思，函数需要自己调用吗？还是怎么的？</p>
<p>资源 每个Windows应用程序，除了程序代码外，还包含一些资源描述：
菜单：菜单ID, 菜单项ID/显示文字 对话框:对话框类型，尺寸与位置</p>
<p>资源描述有规定的格式，存储在相应的资源文件(.rc)中，经编译后将作为Windows应用程序的一部分被链接到应用程序的目标文件中。
资源可以用VC++的资源管理器来进行可视化编辑。 &gt;
这里的资源也就对应着C++的内容</p>
<h3
id="面向对象的windows应用程序设计">面向对象的Windows应用程序设计</h3>
<p>基于Windows API的程序设计是一种基于过程抽象的程序设计范式。
通过调用API函数编写程序的粒度太细、太繁琐，开发效率不高。
如何以更大粒度的程序元素（如对象）来开发Windows应用程序？ -
Microsoft的MFC类库提供了以面向对象范式进行应用程序开发的支持。</p>
<p>窗口对象 - 显示程序的处理数据 - 处理Windows的消息、实现与用户的交互 -
窗口对象之间可以存在聚集关系</p>
<p>文档对象 - 管理在各个窗口中显示和处理的数据 -
文档对象与窗口对象之间可以存在着一对多的关系</p>
<p>应用程序对象 - 管理属于它的窗口对象和文档对象 - 实现消息循环 -
与他的窗口对象及文档对象之间构成 聚集关系。</p>
<blockquote>
<p>聚集关系实际上就是指窗口之间的互相联系。
理解：窗口对象主要是显示程序，窗口对象之间可以互相存在关系；文档对象即主要指的是每个窗口中的数据，可以考虑窗口中的数据。
窗口就是数据的显示层，而文档就是指的具体数据。应用程序对象就是main函数的感觉。</p>
</blockquote>
<p>对Windows应用，应用程序对象和主窗口对象只有一个，子窗口对象和文档对象则可以有多个，它们在程序运行的不同时刻创建。</p>
<p>例如，对于一个多文档的Windows应用程序 -
在程序开始运行时，首先创建应用程序对象; -
由应用程序对象来创建主窗口对象； -
在程序运行过程中，用户选择主窗口菜单项"文档|打开"，创建一个稳定那个对象以及相应的子窗口对象。
&gt; 也就是说文档对象其实是叶节点的感觉，是最底层的东西。</p>
<p>MFC Microsoft Foundation Class library 微软基础类库</p>
<p>MFC是微软公司提供的支持以面向对象范式进行Windows应用程序开发的一个基础类库
-
MFC提供了一些类来描述应用中对象的基本功能，应用程序可以通过集成这些类来实现各自的特殊功能。
&gt; 在这里，想起qt中，本身有Dialog, Frame等对象，实际上感觉也是如此的。
- MFC还提供了一种基于"文档-视"结构的应用框架。 &gt;
所谓框架需要进行好好理解，所谓框架一般来说是指的在实际问题过程中不断向前发展。一般来说最好了解框架的历史。但是实际上如果一开始接触不到这个信息的话，只有先进行框架的原理和功能，以及如何使用等方面进行先理解。当理解明白后，直接使用。注意！不要迷信框架，最后把如何从很复杂的东西抽象到框架的过程理解明白。当然，第一步肯定是要会用框架。</p>
<p><img data-src="00001.png" /> &gt;
由图可以看出，首先CObject分为了应用的框架Application Architecture,
异常Exceptions, 文件服务File Services, 基本类型Arrays, Lists, Maps,
Internet Services, 以及Graphical Drawing, Control Support, Menus, ODBC
Database Support, DAO Database Support, Synchronization, Windows
Sockets等高级专题。 &gt; 对于Application
Architecture用可以分为CCmdTarget即能处理Windows消息的类，往下派生CWind,分为以下几类，
Frame Windows, Control Bars, Property Sheets以及 Dialog Boxes
以及Views以及Controls等等。 &gt;
还有一部分Class不是从CObject派生的，也就是说不是采用的面向对象范式。
&gt; Internet Server API, Run-time Object Model Support, Structures,
Support Classes, Typed Template Collections, OLE Type Wrappers, OLE
Automation Typesm Synchronization.</p>
<p><img data-src="00002.png" /> &gt;
可以看出CCmdTarget被分为了好几类，CWinThread, CWinApp 线程的，
CDocument文档的， CDocTemplate文档类型的。 <img data-src="00003.png" /></p>
<h4 id="mfc提供的主要类">MFC提供的主要类</h4>
<ul>
<li>窗口类
<ul>
<li>基本窗口类CWnd
<ul>
<li>实现窗口的基本功能: &gt;
一般的消息处理、窗口大小和位置管理、菜单管理、坐标系管理、滚动条管理、剪切板管理、窗口状态管理、窗口间位置关系管理，等等
&gt; 是其他窗口类的基类</li>
</ul></li>
<li>框架窗口类
<ul>
<li>提供对标题栏、菜单栏、工具栏、状态栏以及属于它的子窗口的管理功能。</li>
<li>CFrameWnd: 提供了单文档应用主窗口的基本功能</li>
<li>CMDIFrameWnd: 提供了多文档应用主窗口的基本功能</li>
<li>CMDIChildWnd: 提供了多文档应用子窗口的基本功能 &gt;
一个窗口中有多个CView,CMDIChildWnd和CMDIFrameWnd一定对应吗？</li>
</ul></li>
<li>视类CView
<ul>
<li>实现程序数据的显示功能以及操作数据时与用户的交互功能</li>
<li>视窗口位于单文档应用主窗口CFrameWnd和多文档应用子窗口CMDIChildWnd的客户区（可显示区）</li>
</ul></li>
<li>对话框类CDialog
<ul>
<li>对话框是一种特殊的窗口，用于获取用户的输入信息。</li>
<li>每个对话框都包含了一些对话框控件（如：按钮、列表框、单选/多选框等），这些控件属于对话框对象的成员对象。</li>
<li>CDialog类封装了对话框的基本功能，它构成了所有对话框的基类。</li>
</ul></li>
</ul></li>
<li>文档类CDocument
<ul>
<li>对程序要处理的数据进行管理，包括磁盘文件I/O.</li>
<li>一个CDocument类的对象至少要对应一个CView类的对象 &gt;
这里也就是所谓的数据-展示的感觉 &gt;
刚刚最开始自己的感觉就是应该是数据与文档对应</li>
</ul></li>
<li>应用框架类 &gt; 这里是怎么组织的，真让人好奇
<ul>
<li>文档模板类
<ul>
<li>实现对文档、视窗口和框架窗口所构成的对象组的管理功能。（用于支持基于“文档=视”结构的应用框架）</li>
<li>CDocTemplate: 文档模板的基类 &gt; CView+CDocument</li>
<li>CSingleDocTemplate: 单文档模板基类</li>
<li>CMultiDocTemplate: 多文档模板类 &gt;
这里跟自己的理解是一样的吗？它的意思是这里进行管理的功能？</li>
</ul></li>
<li>应用类CWinApp
<ul>
<li>提供了对Windows应用程序的各部分进行组合和管理的功能，其中包括对主窗口和文档模板的管理以及实现消息循环等、
&gt;
换言之，应用类调用文档模板类，实现消息循环。文档模板类实现对文档、视窗口、框架窗口所构成的对象组的管理。文档即数据，视窗口即文档的数据，框架窗口即整个菜单栏，状态栏以及其他的等等</li>
</ul></li>
</ul></li>
</ul>
<p><img data-src="00004.png" /> - 绘图类 - 绘图环境类CDC -
实现Windows应用程序中的绘图功能：文本以及几何图形（线、矩形、椭圆等）的输出
- 要关联一个窗口以及一些绘图工具 - 绘图工具类CPen, CFont, CBrush -
实现笔、字体、刷子等绘图所需的绘图元素。 - 文件输入 -
CFile类：实现了基于字节流的文件I/O -
CArchive类：通过重载操作符&lt;<和>&gt;实现了对基本数据类型和MFC类对象的文件I/O.
- 常用数据类型 -
CPoint点坐标，CRect矩形信息，CSize矩形的宽度/高度，点之间的偏移量等 -
字符串类CString</p>
<h4 id="文档-视结构">文档-视结构</h4>
<ul>
<li>文档
<ul>
<li>用于存储和管理程序中的数据。</li>
</ul></li>
<li>视
<ul>
<li>显示文档数据以及实现对文档数据进行操作时与用户的交互功能</li>
</ul></li>
<li>文档与视一起可以实现：
<ul>
<li>数据的内部存储形式和数据的外部表现形式相互独立</li>
<li>一个文档对象对应一个或多个视对象，即，对于同一个文档数据可以用不同的方式进行显示和操作</li>
</ul></li>
</ul>
<p>MFC提供了一个基于“文档-视”结构的应用框架，主要由以下类构成： - CView
- CDocument - CFrameWnd - CDocTemplate - CWinApp
应用框架规定了各个组成部分之间的关系，它带来的好处是简化了程序的控制流程设计。</p>
<p>基于“文档-视”结构的多文档应用框架的控制逻辑 -
首先创建一个CWinApp类的应用对象，然后 -
调用CWinApp类的成员函数InitInstance类对应用对象进行初始化： -
创建一个CMultiDocTemplate类的文档模板对象，并调用CWinApp类的成员函数AddDocTemplate把它加入到应用对象中。
-
创建一个CMDIFramWnd类的主框架窗口对象，并记录在应用对象的数据成员m_pMainWnd中。
- 调用CWinApp类的成员函数Run,进入消息循环。 &gt; 也就是说CWinApp-&gt;
InitInstance;
类文档模板对象，主框架窗口对象。然后容纳其他的。最后就是进行消息循环，其实也是Run的一个封装。
- 用户选择菜单项"文件|打开"后，调用CWinApp类的成员函数OnFileOpen: -
显示打开文件对话框，让用户选择要打开的文件 -
根据文档模板创建三个对象：文档CDoument,子框架窗口CMDIChildWnd和视CView,
并建立起他们之间的关联。 -
调用CDocument对象的成员函数OnOpenDocument从磁盘文件读取数据: -
创建一个CArchive类的对象。 -
以CArchive类的对象作为参数调用CDocument的成员函数Serialize从磁盘读入数据并存放在文档对象中。
-
调用对应CView对象的成员函数OnInitialUpdate通知相应的视进行数据显示，这时，CView类的成员函数OnUpdate将会被调用，它会向CView对象发送WM_PAINT消息
- CView对象收到WM_PAINT消息后将调用CView的成员函数OnDraw显示文档的数据
&gt;
这里他们三者之间的联系未说明白。首先，前面已经说到了管理的是消息队列。现在就是当面对具体的消息(事件)时的动作，此时是如果选择文件/打开后，首先会建立CDoucent,
CView, CMDIChildren.
然后，在想这里的子框架的作用是否是打开不断的目录。其次，这里的CView类的成员函数发送WM_PAINT，应该会等待CDocument的一个消息后才会启动OnDraw吧，感觉上是这样的
- CView对象(视)与CDocument对象(文档)之间的交互 -
通过CView对象的成员函数GetDocument可获得相应的文档对象 -
通过CDocument对象的成员函数GetFirstViewPosition和GetNextView可获得相应
的视(可以有多个) -
修改文档数据后，可以通过CDocument对象的成员函数SetModifiedFlag设置修改标记为true,并调用CDocument对象的成员函数UpdateAllViews通知相应的视刷新显示
- 这时，CView对象的成员函数OnUpdate和OnDraw将会被调用。 &gt; 理解：
等于那个动作会调度CView，CView然后是CDocument的父亲，通过这些就可以显示函数。
- 用户选择菜单项“文件|保存” -
调用CDocument对象的成员函数OnSaveDoucument把文档数据保存到磁盘中： -
创建一个CArchive类的对象 -
以CArchive类的对象作为参数调用CDocument对象的成员函数Serialize把文档中的数据写入磁盘
- 调用CDocument对象的成员函数SetModifiedFlag设置修改标记为false. -
用户选择菜单项“文件|关闭” - 调用CDocument对象的成员函数OnFileClose; -
调用CDocument对象的成员函数IsModified判断文档是否被修改，如果被修改，提示用户保存数据，然后按菜单项"文件|保存"处理
- 调用CDocument对象的成员函数OnCloseDocument撤销相应的视和子框架窗口 -
撤销文档对象 - 用户选择菜单项“文件|退出”或关闭主窗口： -
向应用的主窗口（CMDIFrameWnd类的框架窗口）发送一条WM_CLOSE消息。 -
主窗口收到WM_CLOSE: - 关闭所打开的文档（包括相应的视和子框架窗口） -
撤销主窗口 - 向应用发送一条WM_QUIT消息 -
在CWinApp类的成员函数Run的消息循环中收到WM_QUIT消息后， - 退出消息循环 -
调用CWinApp对象的成员函数ExitInstance做程序退出前的一些处理。</p>
<p>CView <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- CDocument *m_pDocument;</span><br><span class="line">// 存储对应文档对象的指针</span><br><span class="line">- CDocument *GetDocument() const;</span><br><span class="line">// 获得对应的文档对象</span><br><span class="line">- virtual void onDraw(CDC *pDC)=0;</span><br><span class="line">// 处理窗口刷新消息:WM_PAINT;</span><br><span class="line">- virtual void onInitialUpdate();</span><br><span class="line">// 视对象创建时被调用</span><br><span class="line">- virtual void OnUpdate(CView *pSender, LPARAM IHint, CObject* pHint);</span><br><span class="line">// 文档对象的数据发生改变时调用该函数刷新相应的视对象。默认处理: 发送WM_PAINT消息。</span><br></pre></td></tr></table></figure> &gt; 不亏为抽象类的感觉</p>
<ul>
<li>CDocument <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- void AddView(CView *pView);</span><br><span class="line">// 给文档对象增加一个关联的CView类的对象，双向注册的感觉？.  通过参数的形式组合，倒也很正常。 不过是有GetDocument来调用它</span><br><span class="line">- void RemoveView(CView *pView);</span><br><span class="line">// 使一个CView类的对象脱离于文档对象的关联</span><br><span class="line">- virtual POSITION GetFirstViewPosition() const;</span><br><span class="line">// 获取关联的第一个CView对象的位置</span><br><span class="line">- virtual CView* GetNextView(POSITION&amp; rPosition) const;</span><br><span class="line">// 获取指定位置的CView对象，rPosition自动往后移动一个位置</span><br><span class="line">- void UpdateAllViews(CView* pSender, LPARAM IHint=0L, CObject* pHint=NULL);</span><br><span class="line">// 向关联的CView对象发送刷新消息。当pSender为NULL时，向关联的所有CView对象发送刷新消息。</span><br><span class="line">&gt; 怎么实现刷新？首先思考，这个刷新肯定是由某个动作触发的，那么把它加在其余的后面就可以了呗。对！</span><br><span class="line"></span><br><span class="line">void SetModifiedFlag(BOOL bModified=TRUE);</span><br><span class="line">设置文档修改标记。</span><br><span class="line">BOOL IsModified( );</span><br><span class="line">判断文档是否被修改。</span><br><span class="line">virtual BOOL OnSaveDocument(LPCTSTR 							lpszPathName ); </span><br><span class="line">把文档中数据保存到文件名为lpszPathName 的文件中去。</span><br><span class="line">virtual BOOL OnOpenDocument(LPCTSTR 							lpszPathName );</span><br><span class="line">从文件名为lpszPathName 的文件中读取文档数据。</span><br><span class="line">virtual BOOL OnNewDocument( );</span><br><span class="line">对文档数据进行初始化。</span><br><span class="line">virtual void OnCloseDocument( ); </span><br><span class="line">关闭文档。</span><br><span class="line">virtual void Serialize( CArchive&amp; ar ); </span><br><span class="line">用于文档数据的序列化（写入磁盘文件或从磁盘文件读出）。</span><br><span class="line">一般由OnSaveDocument和OnOpenDocument来调用</span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CArchive档案类</span><br><span class="line">// 实现对基本数据类型和从CObject继承的对象的文件输入/输出操作</span><br><span class="line">CArchive重载了操作符&lt;&lt;和&gt;&gt;</span><br><span class="line">IsLoading();  // 输入</span><br><span class="line">IsStoring();  // 输出</span><br></pre></td></tr></table></figure>
<p>CDocTemplate文档模板类 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CDocTemplate类的构造函数（其参数为文档、视以及框架窗口的类信息）：</span><br><span class="line">CDocTemplate(UINT nIDResource,</span><br><span class="line">	  	CRuntimeClass* pDocClass, </span><br><span class="line"> 		CRuntimeClass* pFrameClass, </span><br><span class="line">	       CRuntimeClass* pViewClass );</span><br></pre></td></tr></table></figure></p>
<p>CWinApp <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">virtual BOOL InitInstance(); </span><br><span class="line">应用程序初始化，包括注册窗口类、创建/显示主窗口等。它由WinMain调用。</span><br><span class="line">virtual int Run();</span><br><span class="line">实现消息循环。它由WinMain调用</span><br><span class="line">virtual int ExitInstance();</span><br><span class="line">应用程序结束处理，由Run调用。</span><br><span class="line">virtual CWnd *GetMainWnd( ); </span><br><span class="line">获得主窗口对象指针。</span><br><span class="line">void AddDocTemplate(CDocTemplate* Template );</span><br><span class="line">把一个文档模板加入到CWinApp类的对象中</span><br><span class="line">afx_msg void OnFileNew( );</span><br><span class="line">提供对“File|New”菜单消息的处理功能。</span><br><span class="line">afx_msg void OnFileOpen( );</span><br><span class="line">提供对“File|Open”菜单消息的处理功能。</span><br></pre></td></tr></table></figure></p>
<p>Application Wizard应用向导 -
要在程序中建立应用框架中各对象的创建和操作代码将是一件很麻烦的工作。
VC++提供了一个应用向导，基于MFC的多文档应用程序，会自动建立5个雷，并分别为这些类写了一些必要的代码:
CMyApp CMainFrame CChildFrame CMyView CMyDoc
在应用向导建立的应用程序中有一个CMyApp类的全局对象theApp,它将在WinMain执行之前创建。
为了体现"纯"面向对象特性，在应用向导建立的应用程序中隐藏了主函数WinMain.
在隐藏的WinMain中， -
首先调用theApp的成员函数InitInstance对应用程序进行初始化 -
然后去调用theApp的成员函数Run进入消息循环
消息循环结束之后，将会调用theApp的成员函数ExitInstance进行程序结束前的一些处理。
在应用向导建立的应用程序中对消息处理函数进行了结构化处理: -
通过消息映射机制把Windows消息与相应类的成员函数关联起来 -
各个消息的处理分别由相应类的一个成员函数来实现。</p>
<p>类向导 为应用程序中从MFC派生的类增加/删除成员 -
消息处理成员函数（菜单、窗口、键盘、鼠标） - 基类中可重定义的成员函数 -
新定义数据成员（成员变量） - 对话框类与各个“控件”所对应的数据成员
为应用程序增加/删除基于MFC的类</p>
<h4 id="图形用户接口设计gui">图形用户接口设计GUI</h4>
<ul>
<li>菜单</li>
<li>对话框</li>
<li>绘图</li>
<li>坐标变换</li>
</ul>
<h5 id="菜单">菜单</h5>
<p>菜单是执行程序功能的一种手段。 -
一个程序可以有多个菜单，每个菜单都有一个标识。 -
菜单有菜单项构成，每个菜单项包含： - 标识 - 显示文字和提示文字 -
处理函数 - 菜单的外观设计可以用资源编辑器来完成 -
菜单处理函数可以用类向导来添加。 ##### 对话框
对话框是一种窗口，它是Windows应用程序与用户进行交互的一种重要手段。
每个对话框都包含了一些对话框控件（如：按钮、编辑、列表、组合等），这些控件属于对话框对象的成员对象（子窗口）
&gt; 子窗口这个概念原来等效于成员对象啊？
一个对话框往往需要对应一个对话框模板 - 每个对话框模板都有一个标识 -
对话框模板描述了对话框的组成，包括：对话框的标识和尺寸；对话框中各个控件的标识、类型、尺寸与位置等
- 对话框模板可用资源编辑器来设计 &gt;
哪些东西是可以机器化的呢？比如说，这里利用机器，UI来设计，其实就是应用了这里的东西的感觉。其实莫过于最奇妙的东西就是，消息的发送和传递。谁是参数？在注册的时候需要些什么东西？</p>
<p>每个对话框都对应着一个对话框类，它可以用类向导来管理： -
为对话框控件指定消息处理函数 - 为对话框指定成员变量</p>
<p>CDialog对话框类
程序中需要打开对话框时，首先要创建一个对话框类的对象，然后调用该类的成员函数DoMadal.如:
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CMyDlg dlg; // 创建一个对话框类的对象dlg.</span><br><span class="line">dlg.m_...=...; //通过dlg的成员变量设置对话框中各控制的初试内容。</span><br><span class="line">...</span><br><span class="line">if((dlg.DoModal()==IDOK)) // 显示对话框，返回值可以为IDOK何IDCANCEL &#123;</span><br><span class="line">    ... = dlg.m_...; // 取对话框控制中的内容。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 公共的对话框类 - CFileDialog: 文件打开/保存对话框 -
CFontDialog: 字体选择对话框 - CColorDialog: 颜色选择对话框 -
CPrintDialog: 打印设置对话框 - CFindReplaceDialog: 查找/替换对话框</p>
<h5 id="绘图--cdc类">绘图--CDC类</h5>
<p>设备环境类CDC用于实现Windows应用程序中的绘图功能。
进行绘图时，首先要创建一个CDC类或其派生类的对象，该对象将包含绘图时所需要的各种元素，包括:
- 绘图函数，如：输出文字、画线、画矩形、画椭圆等 -
绘图工具，如：字体、颜色、笔、刷子等
在创建CDC类或其派生类的对象时需要指出它所对应的窗口对象，绘图操作将在相应窗口中进行。
应用框架在调用CView的OnDraw成员函数时，会自动创建一个CDC类的对象，作为参数传给OnDraw.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">文本输出函数 </span><br><span class="line">virtual BOOL TextOut(int x,int y,LPCTSTR lpszString,int nCount);</span><br><span class="line">BOOL TextOut(int x,int y,const CString&amp; str);</span><br><span class="line">virtual int DrawText(LPCTSTR lpszString,int nCount,LPRECT lpRect,UINT nFormat );</span><br><span class="line">int DrawText(const CString&amp; str,LPRECT lpRect,UINT nFormat);</span><br><span class="line">设置字符和背景颜色</span><br><span class="line">virtual COLORREF SetTextColor( COLORREF crColor ); </span><br><span class="line">virtual COLORREF SetBkColor( COLORREF crColor ); </span><br><span class="line">COLORREF类型的值可以用宏“RGB(red,green,blue)”来表示，例如，RGB(255,0,0)表示红色；RGB(0,255,0)表示绿色； RGB(255,255,255)表示白色。</span><br><span class="line"></span><br><span class="line">几何图形输出函数</span><br><span class="line">画线段</span><br><span class="line">//定线段的起点坐标</span><br><span class="line">CPoint MoveTo( int x, int y );</span><br><span class="line">CPoint MoveTo( POINT point );</span><br><span class="line">//从起点坐标开始画线直到指定的终点坐标</span><br><span class="line">BOOL LineTo( POINT point );</span><br><span class="line">BOOL LineTo( int x, int y );</span><br><span class="line"></span><br><span class="line">画矩形。</span><br><span class="line">BOOL Rectangle( int x1, int y1, int x2, int y2 );</span><br><span class="line">BOOL Rectangle( LPCRECT lpRect );</span><br><span class="line"></span><br><span class="line">画椭圆，参数为外接矩形。</span><br><span class="line">BOOL Ellipse( int x1, int y1, int x2, int y2 );</span><br><span class="line">BOOL Ellipse( LPCRECT lpRect ); </span><br><span class="line"></span><br><span class="line">选择绘图工具函数</span><br><span class="line">选择系统提供的绘图工具</span><br><span class="line">virtual CGdiObject* SelectStockObject(int nIndex); </span><br><span class="line">选择自定义的笔。返回CDC中原来的笔的指针。</span><br><span class="line">CPen* SelectObject( CPen* pPen ); </span><br><span class="line">选择自定义的刷子。返回CDC中原来的刷子的指针。</span><br><span class="line">CBrush* SelectObject( CBrush* pBrush ); </span><br><span class="line">选择自定义的字体，返回CDC中原来的字体的指针。</span><br><span class="line">virtual CFont* SelectObject( CFont* pFont );</span><br><span class="line">注意：用完绘图工具之后，要把绘图工具从CDC类的对象中选出来，以免CDC类对象消亡时重复撤销它包含的绘图工具！ </span><br></pre></td></tr></table></figure>
<p>绘图工具 - 画笔（用于画线） - 构造函数的参数为笔型、笔宽以及颜色
<code>CPen(int nPenStyle, int nWidth, COLORREF crColor);</code> -
刷子（用于填充封闭图形） - 构造函数的参数为刷子的颜色
<code>CBrush(COLORREF crColor);</code> - 字体 -
先创建一个默认构造的CFont类的对象，然后调用该类的CreatePointFont成员函数完成字体的构造
<code>CFont();</code> <code>bool CFont::CreatePointFont(int nPointSize,
LPCTSTR lpszFaceName, CDC* pDC=NULL);</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void CMyView::OnDraw(CDC* pDC)</span><br><span class="line">&#123;	COLORREF old_text_color=pDC-&gt;SetTextColor(RGB(255,0,0)); 					//把字符颜色设置成“红”色。</span><br><span class="line">	COLORREF old_bk_color=pDC-&gt;SetBkColor(RGB(0,255,0)); 					//把字符背景颜色设置成“绿”色。</span><br><span class="line">	pDC-&gt;TextOut(0,0,&quot;hello&quot;); //在位置(0,0)处显示字符串&quot;hello&quot;</span><br><span class="line">	CPen pen(PS_SOLID,2,RGB(0,255,0)),*old_pen; //创建一个绿色的实线笔</span><br><span class="line">    old_pen = pDC-&gt;SelectObject(&amp;pen); //把新笔选进CDC类的对象中</span><br><span class="line">	CBrush brush(RGB(0,0,255)),*old_brush; //创建一个蓝色的刷子</span><br><span class="line">	old_brush = pDC-&gt;SelectObject(&amp;brush); //把新刷子选进CDC类的对象中</span><br><span class="line">    pDC-&gt;MoveTo(0,0); pDC-&gt;LineTo(200,200); //画一个绿色的线段</span><br><span class="line">	pDC-&gt;Rectangle(0,50,100,150); //画一个内部为蓝色、边为绿色的矩形</span><br><span class="line">	pDC-&gt;SelectObject(old_pen); //把原来的笔选回到CDC类的对象中</span><br><span class="line">	pDC-&gt;SelectObject(old_brush); //把原来的刷子选回到CDC类的对象中</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void CStudentsView::OnDraw(CDC* pDC)</span><br><span class="line">&#123; CStudentsDoc* pDoc = GetDocument();</span><br><span class="line">   CFont *old_font=(CFont *)pDC-&gt;SelectStockObject(ANSI_FIXED_FONT);</span><br><span class="line">   for (int i=0,num=pDoc-&gt;get_num_of_students(); i &lt; num; i++)</span><br><span class="line">  &#123; STUDENT_TYPE st;</span><br><span class="line">    pDoc-&gt;get_student(i,st);</span><br><span class="line">    CString temp;</span><br><span class="line">    temp.Format(&quot;%-10.10s%-10.10s%-4.4s%-10.10s%-20.20s%-40.40s&quot;,</span><br><span class="line">                st.number,st.name,st.sex,st.birthdate,st.birthplace,st.address);</span><br><span class="line">    if (i != current_student)</span><br><span class="line">    &#123; pDC-&gt;SetTextColor(RGB(0,0,0));</span><br><span class="line">       pDC-&gt;SetBkColor(RGB(255,255,255));</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    &#123; pDC-&gt;SetBkColor(RGB(0,0,0));</span><br><span class="line">       pDC-&gt;SetTextColor(RGB(255,255,255));</span><br><span class="line">    &#125;</span><br><span class="line">    pDC-&gt;TextOut(0,i*20,temp);</span><br><span class="line">  &#125;</span><br><span class="line">  pDC-&gt;SelectObject(old_font);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>CView的一些派生类 - CScrollView(带滚动功能的视) -
CEditView(具有编辑功能的视) - CFormView(具有表格功能的视) -
CHtmlView(具有Web浏览功能的视)</p>
<h5 id="坐标转换">坐标转换</h5>
<p>CScrollView <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void CScrollView::SetScrollSizes( </span><br><span class="line">  		int nMapMode, </span><br><span class="line">  		SIZE sizeTotal, </span><br><span class="line">  		const SIZE&amp; sizePage = sizeDefault, </span><br><span class="line">  		const SIZE&amp; sizeLine = sizeDefault );</span><br><span class="line">nMapMode：映射方式（坐标的逻辑单位，坐标轴方向）</span><br><span class="line">例如：MM_TEXT（逻辑单位为像素点，坐标原点位于左上角，x轴从左向右，y轴从上往下。</span><br><span class="line">sizeTotal：文档内容的大小</span><br><span class="line">sizePage：文档滚动页的大小</span><br><span class="line">sizeLine：文档滚动行的大小</span><br><span class="line">需要在CScrollView的OnUpdate和OnSize中调用。</span><br><span class="line"></span><br><span class="line">void CStudentsView::OnUpdate(CView* pSender, LPARAM lHint, CObject* pHint) </span><br><span class="line">&#123; // TODO: Add your specialized code here and/or call the base class</span><br><span class="line">  CStudentsDoc* pDoc = GetDocument();</span><br><span class="line">  </span><br><span class="line">  // TODO: calculate the total size of this view</span><br><span class="line">  CSize sizeTotal,sizePage,sizeLine;   </span><br><span class="line">  sizeTotal.cx = 100; //文本宽度固定</span><br><span class="line">  sizeTotal.cy = pDoc-&gt;get_num_of_students()*20; //文本长度</span><br><span class="line">  RECT rect;</span><br><span class="line">  GetClientRect(&amp;rect); //获取视窗口的大小</span><br><span class="line">  sizePage.cx = rect.right-rect.left-8; //页宽度</span><br><span class="line">  sizePage.cy = rect.bottom-rect.top-20; //页长度</span><br><span class="line">  sizeLine.cx = 8; //行宽度</span><br><span class="line">  sizeLine.cy = 20; //行高度</span><br><span class="line"></span><br><span class="line">  SetScrollSizes(MM_TEXT,sizeTotal,sizePage,sizeLine);</span><br><span class="line"></span><br><span class="line">  Invalidate();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void CStudentsView::OnSize(UINT nType, int cx, int cy) </span><br><span class="line">&#123; CScrollView::OnSize(nType, cx, cy);</span><br><span class="line">	</span><br><span class="line">  // TODO: Add your message handler code here</span><br><span class="line">  CStudentsDoc* pDoc = GetDocument();</span><br><span class="line">  </span><br><span class="line"> // TODO: calculate the total size of this view</span><br><span class="line">  CSize sizeTotal, sizePage, sizeLine; </span><br><span class="line">  sizeTotal.cx = 100;</span><br><span class="line">  sizeTotal.cy = pDoc-&gt;get_num_of_students()*20;</span><br><span class="line">  sizePage.cx = cx-8;</span><br><span class="line">  sizePage.cy = cy-20;</span><br><span class="line">  sizeLine.cx = 8;</span><br><span class="line">  sizeLine.cy = 20;</span><br><span class="line">  </span><br><span class="line">  SetScrollSizes(MM_TEXT,sizeTotal,sizePage,sizeLine);</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> <img data-src="00005.png" /> 坐标转换函数
OnPrepareDC(&amp;dc,NULL); 为ScrollView初始化dc dc.DPtoLP(&amp;point);
从物理坐标转换到逻辑坐标 dc.LPtoDP(&amp;point);
从逻辑坐标转换到物理坐标</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void CStudentsView::OnLButtonDown(UINT nFlags,</span><br><span class="line">                                                       CPoint point) </span><br><span class="line">&#123;</span><br><span class="line">  // TODO: Add your message handler code here </span><br><span class="line">  // and/or call default</span><br><span class="line">  </span><br><span class="line">  CClientDC dc(this);</span><br><span class="line">  OnPrepareDC(&amp;dc,NULL); //transform dc to   </span><br><span class="line">                                        //scrollview</span><br><span class="line">  dc.DPtoLP(&amp;point); // 物理坐标转逻辑坐标</span><br><span class="line"></span><br><span class="line">  current_student = point.y/20;   </span><br><span class="line"> </span><br><span class="line">  Invalidate(); //重新显示视窗口内容，OnDraw将被调用</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="一点反思">一点反思</h3>
<p>学习的几个过程 1.
首先，如果课件足够好，也可以不用记笔记，这样的效率高，但是能够记住吗？但是感觉上最有用的可能就是反思吧？也就是说并不意味着一定要记很多笔记。
记住，衡量的标准一直是上课预估后面不会做的易错点，还有精华的地方自己是否掌握了，这才是最重要的。</p>
<p>按照以前的学习态度，如果是自己在乎的知识。
首先，第一次一定要要么有好的课本，或者材料特别好。
看书，并且记自己不懂的地方。
第一次看书下来，主要讲什么的大体的脉络要清晰。</p>
<p>然后还要衡量所花的时间等诸多因素。</p>
<p>然后，再将笔记进一步总结。练过所有需要练习的局部知识点，然后开始自己。
学习知识点还有几遍，然后就是大量地做题，直到做到彻底掌握这个知识点为止。
最后，如果时间充裕再看其他知识点进行迁移，弄明白整个过程。</p>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>cplus</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>cplus</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course distributed system</title>
    <url>/2019/nju-course-distributed-system-23a6ca7a515b/</url>
    <content><![CDATA[<h2 id="分布式系统模型">分布式系统模型</h2>
<ol type="1">
<li>什么是分布式系统？</li>
</ol>
<ul>
<li>分布式系统是若干个独立的计算机的集合，这些计算机对于用户来说就像是单个相关的系统</li>
</ul>
<ol start="2" type="1">
<li>为什么要分布式？</li>
</ol>
<ul>
<li>让用户连接到资源;</li>
<li>保证资源在网络上分布的透明性;</li>
<li>分布式系统是开放的</li>
<li>分布式系统是可扩展的</li>
</ul>
<ol start="3" type="1">
<li>分布式系统透明性和开放性的含义</li>
</ol>
<p>透明性可以运用到分布式系统中的各个方面 -
访问，隐藏数据表示形式的不同以及资源访问方式的不同 -
位置，隐藏资源所在位置 - 迁移，隐藏资源是否移动到另一个位置 -
重定位，隐藏资源是否在使用过程中移动到另一个位置 -
复制，隐藏是否对资源进行复制 -
并发，隐藏资源是否由若干个相互竞争的用户共享 -
故障，隐藏资源的故障和恢复 - 持久性，隐藏资源在内存中还是在硬盘中</p>
<p>（未答透明性的级别）</p>
<p>开发性的含义</p>
<p>一个开发是系统应该是一个这样的系统，它根据一系列准则来提供服务，这些准则描述了所提供服务的语法和语义
- 能够与其他开放系统的富户及你想嗯交互，与潜在的环境无关 -
系统应该遵守明确的接口定义 - 系统应该支持应用的可移植性 -
系统应该能够易于交互 -
它必须是灵活的，要能够方便地把有不同的开发人员开发的不同组件组合成整个系统。</p>
<ol start="4" type="1">
<li>分布式系统、网络操作系统和基于中间件的系统</li>
</ol>
<ul>
<li>分布式操作系统，紧耦合的操作系统，用于多处理器系统和同构式多计算机系统，主要目标是隐藏及管理硬件资源</li>
<li>网络操作系统，松耦合的操作系统，用于异构式多计算机系统（LAN和WAN），主要目标是向远程客户提供本地服务</li>
<li>中间件，位于网络操作系统通用服务上的附加层，主要目标是提供分布式透明性</li>
</ul>
<ol start="5" type="1">
<li>分布式系统的类型</li>
</ol>
<ul>
<li>Distributed computing systems（云计算LAN，网格计算）</li>
<li>Distributed information systems（TP monitor）</li>
<li>Distributed pervasive systems (分布式普适系统,移动计算系统等等)</li>
</ul>
<ol start="6" type="1">
<li>机制和策略的理解</li>
</ol>
<ul>
<li>需要对不同策略的支持
<ul>
<li>对客户端cache数据一直性要求有多高</li>
<li>可以允许下载代码执行哪些操作</li>
<li>面对不同带宽，如何调整QoS的要求</li>
<li>通信过程需要什么程度的加密</li>
</ul></li>
<li>理想上，分布式系统仅仅提供机制
<ul>
<li>允许动态设置缓存测绿</li>
<li>支持不同程度的移动代码信任</li>
<li>每个数据流提供可调的QoS参数</li>
<li>提供不同的加密算法</li>
</ul></li>
<li>机制与策略分离原则
<ul>
<li>机制由系统实现，策略由用户完成</li>
<li>机制放在底层，策略放在高层</li>
<li>机制集中在少数模块，策略散布在多处</li>
</ul></li>
</ul>
<h2 id="分布式系统架构">分布式系统架构</h2>
<ol type="1">
<li>分布式系统架构风格</li>
</ol>
<ul>
<li>组织为逻辑上不同的部分，每个部分分布在不同的机器上
<ul>
<li>层次结构</li>
<li>面向对象式的结构</li>
</ul></li>
<li>在空间上或者时间上对进程进行的分离
<ul>
<li>事件总线，发布订阅模式</li>
<li>共享数据空间</li>
</ul></li>
</ul>
<ol start="2" type="1">
<li>分布式系统组织形式</li>
</ol>
<ul>
<li>中心式
<ul>
<li>C/S模式</li>
</ul></li>
<li>非中心式
<ul>
<li>结构化P2P</li>
<li>非结构化P2P</li>
</ul></li>
<li>混合式(BitTorrent）</li>
</ul>
<ol start="3" type="1">
<li><p>客户-服务器模式和对等模式</p></li>
<li><p>分布式系统组织为中间件</p></li>
</ol>
<h2 id="进程和线程">进程和线程</h2>
<ol type="1">
<li>进程 vs 线程 程序是静态的代码和数据
进程是动态的代码和数据的实例</li>
</ol>
<p>进程时具有独立功能的程序关于某个数据集合的一次进行活动，是资源分配和调度的基本单位
线程是进程的实体，是CPU调度的基本单位</p>
<ol start="2" type="1">
<li>代码迁移</li>
</ol>
<ul>
<li>强迁移 vs 弱迁移 定义： 将整个进程从一台机器搬到另一台机器上
强迁移：迁移后的程序可以从当前开始执行
弱迁移：迁移后的程序必须从初始状态开始执行</li>
</ul>
<ol start="3" type="1">
<li>代码迁移vs虚拟机迁移</li>
</ol>
<ul>
<li>优势：
代码迁移最多包含代码，数据，执行状态的迁移，总传输量远小于一个虚拟机，所以轻量，网络负载小，无需引入其他中间语言</li>
<li>不足：在异构系统中可能不适合执行迁移的代码，进程/线程/处理器上下文可能高度依赖于本地硬件，OS和运行时系统</li>
</ul>
<h2 id="通信">通信</h2>
<ol type="1">
<li>通信的类型</li>
</ol>
<ul>
<li>远程调用RPC</li>
<li>基于消息的通信</li>
</ul>
<ol start="2" type="1">
<li>远程调用RPC 注意：对于基本的RPC调用，client要有进入localOS中。</li>
</ol>
<ul>
<li>RPC工作过程：
<ul>
<li>客户过程以正常方式调用客户存根</li>
<li>客户存根生成一个消息，然后调用本地操作系统</li>
<li>客户端操作系统发送消息给远程操作系统</li>
<li>服务器存根将参数提取出来，然后调用服务器</li>
<li>服务器执行要求的操作，操作完成后将结果返回给服务器存根</li>
<li>服务器存根把结果打包为一个消息，然后调用本地操作系统</li>
<li>服务器操作系统将含有结果的消息发送给客户端操作系统</li>
<li>客户端操作系统将消息交给客户存根</li>
<li>客户存根将结果从消息中提取出来，返回给调用它的客户过程</li>
</ul></li>
<li>故障处理
<ul>
<li>客户无法定位到服务器
<ul>
<li>解决：使用特定的返回值/异常处理</li>
</ul></li>
<li>客户发给服务器的请求消息丢失
<ul>
<li>解决：设置一个timer, 超时重发</li>
</ul></li>
<li>服务器发给客户的应答消息丢失
<ul>
<li>解决：设置一个
timer,对于不幂等的请求，为客户请求分配序号，服务器区别不同的请求</li>
</ul></li>
<li>服务器在收到消息后崩溃 1 接受后，执行前崩溃 2 执行后，发送前崩溃
<ul>
<li>解决：等待服务器启动,然后重发请求/立即放弃并报告失败/不做任何保证</li>
</ul></li>
<li>客户机在发送消息后崩溃
<ul>
<li>解决：根绝 extermination: 在日志文件中纪录 RPC
请求，重启后清除孤儿再生 reincarnation:
将时间划分成不同时期，重启后广播新的时期开始。一旦收到广播消息，
kill所有 remote computations.温和再生 gentle reincarnation:
将时间划分成不同时期，重启后广播新的时期开始。收到广播消息时，定位
remote computations 的 owner，kill 没有 owner 的。过期 expiration:
赋予每个 RPC 一个一个执行时间 T，未完成任务需显式申请附加配额。</li>
</ul></li>
</ul></li>
<li>动态绑定
<ul>
<li>client寻找server过程使用，client提供paras(versionm),
handler处理</li>
<li>为什么？
<ul>
<li>（1）灵活性</li>
<li>（2）可以支持多个服务器提供相同接口</li>
<li>（3）binder（具有粘结剂的意思）可以确认客户端和服务器使用相同的接口版本</li>
</ul></li>
<li>缺点
<ul>
<li>（1）输出、引入接口需要额外管理，花费时间</li>
<li>（2）在大型分布式系统中，binder的存在可能会是通信瓶颈</li>
</ul></li>
</ul></li>
</ul>
<ol start="3" type="1">
<li>基于消息的通信</li>
</ol>
<ul>
<li>暂时（一旦发出接收后便不再存在无论是否被接收） vs
永久（信息在中间件永久存在，如邮件系统）</li>
<li>异步（local buffer暂时保留，qq离线消息） vs 同步（对话，
blocked）</li>
</ul>
<ol start="4" type="1">
<li>流数据</li>
</ol>
<ul>
<li>视频、音频，雷达;对时间敏感</li>
<li>流数据+QoS（服务质量，评价指标）
<ul>
<li>需要传输的数据的位数</li>
<li>通信之间的延迟</li>
<li>end-to-end的延迟</li>
<li>最大延迟时间</li>
</ul></li>
<li>可能考点：组播通信两种方式
<ul>
<li>Application-level：
<ul>
<li>chord-based tree building</li>
<li>覆盖网</li>
<li>epidemic algortihms</li>
</ul></li>
<li>Gossip-based data dissemination</li>
</ul></li>
</ul>
<h2 id="同步与资源管理">同步与资源管理</h2>
<ol type="1">
<li>同步问题</li>
</ol>
<ul>
<li>系统需要决定谁先谁后</li>
</ul>
<ol start="2" type="1">
<li>时钟同步机制</li>
</ol>
<ul>
<li>系统标准时间UTC</li>
<li>网络同步（T1-T0-I）/2</li>
<li>The Berkeley Algorithm:公认时间，平均时间</li>
<li>Averaging Algorithm:去掉最高和最低</li>
</ul>
<ol type="1">
<li>逻辑时钟</li>
</ol>
<ul>
<li>Lamport算法</li>
<li>向量时撮</li>
</ul>
<ol start="2" type="1">
<li>分布式系统中的互斥访问</li>
</ol>
<ul>
<li>集中式算法</li>
<li>分布式算法</li>
<li></li>
</ul>
<ol start="3" type="1">
<li>分布式系统中的选举机制</li>
</ol>
<h2 id="复制与一致性">复制与一致性</h2>
<ol type="1">
<li>复制的优势与不足</li>
<li>数据一致性模型</li>
<li>数据一致性协议实例
<ol type="1">
<li>基于法定数量的协议</li>
</ol></li>
</ol>
<h2 id="容错">容错</h2>
<ol type="1">
<li>可信系统</li>
<li>提高系统可信性的途径</li>
<li>K容错系统</li>
<li>拜占庭问题</li>
<li>系统回复
<ol type="1">
<li>回退恢复</li>
<li>前向恢复</li>
</ol></li>
<li>检查点</li>
</ol>
<h2 id="大数据处理系统">大数据处理系统</h2>
<p>Big data analytics: making sense of complex data</p>
<p>Input: unstructured, multimodal, Hig-dimensional, interconneccted,
growing fast in volume</p>
<p>Goal: discover interpretable patterns; understand causal
relationships; make informed predictions and decisions</p>
<p>Challenge： - the growth of data volume - the complexity of analytics
- limitied cluster resources</p>
<p>Solution overview - Normalize quality metrics - Pedict quality
improvent - Quality-driven scheduling</p>
<h2 id="物联网">物联网</h2>
<ol type="1">
<li><p>物联网的概念
物联网是一个基于互联网、传统电信网等信息载体，让所有能够被独立寻址的普通物理对象实现互联互通的网络</p></li>
<li><p>物联网分类 普通对象设备化 自治终端互联化 普适服务智能化</p></li>
<li><p>物联网四层模型</p></li>
</ol>
<ul>
<li>综合应用层：从以数据服务为主要特征的文件传输到以用户为中心的应用</li>
<li>管理服务层：将大规模数据组织起来，为上层应用提供支撑</li>
<li>网络构建层：吧下层设备接入互联网，供上层服务使用，包括3G、4G、Wifi、蓝牙、NFC等通信技术</li>
<li>感知识别层：联系物理世界和信息世界，包括RIFD、无限传感器、移动终端等感知设备。射频识别技术</li>
</ul>
<p>基于目标定位的微动作感知识别机制</p>
<h2 id="云计算">云计算</h2>
<ol type="1">
<li>简要说明虚拟化技术所解决的问题，并说明虚拟化技术与云计算的关系</li>
</ol>
<ul>
<li>虚拟化技术所解决的问题：虚拟化是由位于下层的软件模块，将其封装或抽象，提供一个物理或软件的接口，使得上层的软件可以直接运行在这个虚拟的环境和运行在原来的环境一样</li>
<li>虚拟化技术与云计算的关系：
<ul>
<li>虚拟化具有以下优点，有利于云计算
<ul>
<li>封装与隔离的特点，保证每个用户有安全可信的工作环境</li>
<li>多实例的特点，保证较高的资源利用率，为服务器合并提供基础</li>
<li>硬件无关性的特点，整合异构硬件资源，可实现虚拟机迁移，使资源调度、负载平衡容易实现</li>
</ul></li>
<li>特权功能的特点，用于云计算的入侵检测和病毒检测</li>
<li>动态调整资源特点，便于云计算的细粒度的可扩展性</li>
</ul></li>
</ul>
<ol start="2" type="1">
<li><p>Openstack为代表的基本功能是什么
IaaS，基础设施即服务组件，让任何人都可以自行建立和提供云端运算服务。此外，openstack也用作建立防火墙内的“私有云”，提供机构或企业内各部门共享资源。以openstack为代表的IaaS的功能：为IT行业创造虚拟的计算和数据中心，使得其能够把计算单元、存储器、I/O设备、带宽等计算机基础设施，集中起来成为一个虚拟的资源池来为整个网络提供服务。</p></li>
<li><p>应用场景一适合，应用场景二不适合。OpenStack是基于虚拟化的IaaS云平台，提供的是有性能损耗的虚拟化资源，适用于资源类型较为单一、资源需求实时变化的系统，不适用于高性能计算。</p></li>
</ol>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>distributedSystem</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>distributedSystem</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course mapreduce experiment</title>
    <url>/2019/nju-course-mapreduce-experiment-7b4ad2932b94/</url>
    <content><![CDATA[<p>实验说明</p>
<h2 id="mapreduce-java编程">MapReduce Java编程</h2>
<p>主要工作： ### 1 实现Map类
https://hadoop.apache.org/docs/r2.7.4/api/org/apache/hadoop/mapreduce/Mapper.html
Mapper是hadoop提供的抽象类<br />
Mapper&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; - setup(Context context) -
map(KEYIN key,VALUEIN value, CONTEXT context) - cleanup(Context context)
- run(CONTEXT context) // 一般不使用</p>
<p>KEYIN，VALUEIN...类型 &gt;LongWritable -- long <br/> &gt;IntWritable
-- int <br/> &gt;Text -- string <br/> &gt;Object -- void</p>
<blockquote>
<p>这里往往还包含
Partitioner（Hash的方法）和Sort两个部分，一般编程不会涉及到 ### 2
实现Reduce类 ### 3 实现main函数 （Job） conf -&gt; Job 见例子</p>
</blockquote>
<p><a
href="https://github.com/apache/hadoop/tree/trunk/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples">github
hadoop example例子</a> ## ch2 wordcount</p>
<h3 id="hdfs-相关命令">hdfs 相关命令</h3>
<p>hadoop fs: - -ls -R - -rmr - -put localfile dfsfilepath &gt; eg: -put
data/wordcount/*.html input/wordcount <br/> &gt; hdfs://绝对路径 - -cat
file.data - -mkdir -p - -get</p>
<p>hadoop jar localjar_path class_path para1 para2</p>
<h3 id="paras">paras</h3>
<blockquote>
<p>注意这里的路径只能hdfs上的文件 - inputPath: must exisit, file or dir
- outputPath: dir, the dir can't exisit</p>
</blockquote>
<h2 id="ch3-带词频的倒排索引">ch3 带词频的倒排索引</h2>
<p><a
href="https://www.jianshu.com/p/5e059dbad553">InvertedIndex.java</a></p>
<p>具体设计跟之前的一样</p>
<h3 id="paras-1">paras</h3>
<ul>
<li>inputPath: dir</li>
<li>outputPath</li>
</ul>
<p>scp命令使用 &gt; scp -r target/Lab-1.0-SNAPSHOT.jar
eugenewang@114.212.81.14:~/Documents</p>
<p>hadoop jar /home/eugenewang/Documents/Lab-1.0-SNAPSHOT.jar
InvertedIndex /input/invertedindex/exp3_sample_data
/output/invertedindex/exp3</p>
<h2 id="其他知识">其他知识</h2>
<p>关于FileSplit,InputSplit更多介绍 <a
href="https://blog.csdn.net/xingliang_li/article/details/53285447?utm_source=blogxgwz4">FileInputFormat类中split切分算法和host选择算法介绍</a></p>
<p><a
href="https://hadoop.apache.org/docs/r2.9.0/api/org/apache/hadoop/mapred/FileSplit.html">Class
FileSplit</a></p>
<h2 id="扩展">扩展</h2>
<ol type="1">
<li>使用另外一个 MapReduce Job 对每个词语的平均出现次数进行全局排序,
输出排序后的结果。</li>
</ol>
<p>思考：新建一个排序job,将临时文件作为输出，在其map中，我们将输入每一行进行分割，将词频作为key，其他的作为value,重载Comparator类，进行从小到大排序，之后进行输出即可</p>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course mapreduce summary</title>
    <url>/2019/nju-course-mapreduce-summary-aaa91ad6c31a/</url>
    <content><![CDATA[<h2 id="ch1-大数据技术简介">ch1 大数据技术简介</h2>
<p>数据规模到底多大才叫大数据？
大数据一词的重点不是在于数据规模的定义，而是指信息技术发展已经进入了一个新时代</p>
<p>大数据的特点：5V - Volume: 大容量：PB级规模 - Varirty:
多样性：结构化/非结构化 - Velocity: 时效性： 实时处理 - Veracity：
准确性：结果准确 - Value： 大价值：深度价值</p>
<p>大数据处理技术产生的背景 - 多核/多处理器并行计算 -
MapReduce大数据并行计算 - 行业大数据应用需求</p>
<p>大数据分析应用的ABCD关键要素 算法模型 业务场景 计算力 数据资源</p>
<p>结构特征 - 结构化数据 - 半结构化数据</p>
<p>获取和处理方式 - 静态（线下数据）/非实时数据 -
动态（流式/增量式/线上）/实时数据</p>
<p>关联特征 - 无关联/简单关联数据（键值记录型数据） -
复杂关联数据（图数据）</p>
<p>大数据处理的主要技术问题</p>
<p>存储：巨量数据如何存得下</p>
<p>计算：巨量数据如何快速完成计算</p>
<p>分析：如何返现大数据的深度价值</p>
<p>大数据研究的基本途径</p>
<ul>
<li>降低尺度，寻找数据尺度无关近似算法</li>
<li>新算法，寻找新算法降低计算复杂度</li>
<li>并行化，分而治之，并行化处理</li>
</ul>
<h2 id="ch2-mapreduce简介">ch2 MapReduce简介</h2>
<p>提高计算机硬件性能的而主要手段 - 提高字长、流水式微体系结构技术 -
提高集成度 - 提高主频</p>
<p>按照系统类型来分，并行计算系统通常包括 -
多核/众核、对称多处理、大规模并行处理、集群、网格等不同类型</p>
<p>按照程序设计模型/方法分类，并行计算主要可以分为 -
共享内存变量程序设计方式 - 消息传递程序设计方式 -
MapReduce程序设计方式</p>
<p>为什么需要大规模数据并行处理 - 处理数据的能力大幅落后于数据增长 -
海量数据隐含着更准确的事实</p>
<p>什么是MapReduce - 基于集群的高性能并行计算平台 -
并行程序开发与运行框架 - 并行程序设计模型与方法</p>
<p>为什么MapReduce如此重要？ - 高效的大规模数据处理方法 -
改变了大规模尺度上组织计算的方式 -
第一个不同于冯洛依曼结构的、基于集群而非单机的计算方式的重大突破 -
目前为止最为成功的基于大规模计算资源的并行计算抽象方法</p>
<p>对付大数据处理——分而治之 - 大数据分而治之的并行化计算 -
大数据任务划分和并行计算模型</p>
<p>构建抽象模型——Map和Reduce -
主要设计思想：为大数据处理过程中的两个主要处理操作提供一种抽象机制 -
典型的流式大数据问题的特征 -
Map和Reduce操作的抽象描述，提供一种抽象机制，把做什么和怎么做分开，程序员仅需要描述做什么，不需要关心怎么做
- 基于Map和Reduce的并行计算模型和计算过程</p>
<p>上升到框架——自动并行化并隐藏底层细节 - 主要需求、目标和设计思想 -
实现自动并行化计算 - 为程序员隐藏系统层细节 -
MapReduce提供统一的构建并完成以下的主要功能 - 任务调度 - 数据/代码互定位
- 出错处理 - 分布式数据存储与文件管理 -
Comibiner和Partitioner(设计目的和作用)</p>
<p>MapReduce的主要设计思想和特征 - 向外横向扩展，而非向上纵向扩展 -
失效被认为是常态 - 吧计算处理向数据迁移 - 顺序处理数据、避免随机访问数据
- 为应用开发者隐藏系统层细节 - 平滑无缝的可扩展性</p>
<p>MapReduce提供的主要功能 -
任务调度：负责为划分后的就hi算任务分配和调度计算节点；同时负责监控这些节点的执行状态
-
数据/代码互定位：为了减少数据通信，一个基本原则是本地化数据处理，即一个计算节点尽可能处理其本地磁盘上所分布存储的数据
- 出错处理 - 分布式数据存储与文件管理 - Combiner和Partitioner：
将中间结果数据进入reduce节点前需要进行合并处理，把具有同样主键的数据合并到一起避免重复传送，优化网络传输，在Map之后执行；而Partitioner的主要设计目的和作用是数据分区，将数据分配到合适的Reduce节点，避免不同Reduce节点上数据的相关性，在Reduce之前执行</p>
<h2 id="ch3.-googlehadoop-maqreduce基本构架">ch3. Google/Hadoop
MaqReduce基本构架</h2>
<p>Google MapReduce的基本工作原理 -
并行化处理的基本过程，系统中有一个负责调度的主节点，以及数据Map和Reduce工作节点（Worker）
- 带宽优化（Combiner的设计目的和作用），优化到Reduce的结果 -
用数据分区解决数据相关性问题（Partitioner的设计目的和作用），即根据一定的策略对Map输出的中间结果进行分区
- 失效处理：
主节点失效checkpoinr,检查整个计算作业的执行情况；工作节点失效，直接终止
-
计算优化，把一个计算任务让多个Map节点同时做，取最快完成者的计算结果。冗余节点</p>
<p>分布式文件系统GFS的基本工作原理 - Google GFS的基本设计部原则 -
廉价本地磁盘分布存储 - 多数据自动备份解决可靠性 -
为上层的MapReduce计算框架提供支撑</p>
<p>Google GFS的基本构架和工作原理 - GFS Master的主要作用 - GFS
ChuckServer的主要作用 - 数据访问工作过程 - GFS的系统管理技术</p>
<p>分布式结构化数据表BigTable - BigTable设计动机和目标 -
需要存储管理海量的结构化半结构化数据 - 海量的服务请求 -
商用数据库无法使用 - BigTable数据模型——多维表 -
行关键字、列关键字、时间戳</p>
<ul>
<li>BigTable基本构架
<ul>
<li>子表服务器</li>
<li>子表存储结构SSTable（对应于GFS数据块）</li>
<li>子表数据格式</li>
<li>子表寻址</li>
</ul></li>
</ul>
<p>Hadoop MapReduce主要组件 NameNode相当于Google的MasterServer
DataNode--ChunckServer - 文件输入格式InputFormat <br>
定义文件如何分割和读取，选择文件或者其它让对象，用来作为输入；定义InputSplits，将一个文件分为不同任务，mapred.min.split.size；为RecordReader提供一个工厂，用来读取这个文件。
- TextInputFormat, LineRecordReader - KeyValueTextInputFormat -
SequenceFileInputFormat
一个MapReduce程序统称为一个Job，一个Job有许多个任务构成
JobConf.setInputFormat</p>
<ul>
<li><p>Mapper <br>
每一个Mapper类的实例生成了一个Java进程，负责处理某一个InputSplit上的数据，用Maper.Context</p></li>
<li><p>Combiner <br> conf.setCombinerClass(Reduce.class)</p></li>
<li><p>Partitioner &amp;&amp; Shuffle</p></li>
<li><p>Sort，
传输到每一个Reduce节点上的，将被所有的Reduce函数接收的Key,value会被hadoop自动排序</p></li>
<li><p>Reducer</p></li>
<li><p>OutputFormat <br> 与InputFormat对应</p></li>
</ul>
<p>Hadoop系统中，JobTracker的主要作用是
作业控制（作业分解、状态监控），资源管理，而TaskTracker的主要作用是
汇报心跳、执行JobTracker的命令，NameNode的作用是存储了所有文件元数据、文件与数据块的映射关系，以及文件属性等核心数据；DataNode的作用是存储具体的数据快
## ch4 程序安装 ## ch5 MapReduce算法设计 MapReduce处理流程 1. map 2.
shuffle and sort 3. reduce</p>
<p>可编程控制部分 Mapper： setup(), map(), cleanup() Shuffle:
Partitioner(划分均匀，查找快速) Sort Reduce: setup(), reduce(),
cleanup()</p>
<p>应用</p>
<ol type="1">
<li>构建单词同现矩阵</li>
<li>文档倒排索引，在map阶段单词在前，文档名在后，有效负载（如词频，只是需要在前一步进行统计即可）</li>
<li>专利文献数据分析,统计被引文献，citing, cited</li>
</ol>
<h2 id="ch6-hbase-hive">ch6 HBase Hive</h2>
<p>Hadoop
HBase基本数据类型是一张多维表，该表的存储和检索有行关键字和列关键字、时间戳三个关键字组成，其数据操作访问是
通过JavaAPI和MapReduce接口编程实现，而Hive是一个分布式数据仓库，其数据操作访问编程是通过SQL实现</p>
<h2 id="ch7-高级mapreduce编程技术">ch7 高级MapReduce编程技术</h2>
<p>用户自定义Partitioner和Combiner 组合式</p>
<h2 id="ch8-基于mapreduce的搜索引擎算法">ch8
基于MapReduce的搜索引擎算法</h2>
<p>PageRank算法</p>
<h2 id="ch9-数据挖掘基础算法">ch9 数据挖掘基础算法</h2>
<h3 id="k-means算法">k-means算法</h3>
<p>将给定的多个对象分成若干组，组内的各个对象是相似的，组间的对象是不相似的。
数据点的类型可以划分为欧氏和非欧 对于欧式空间，取各个数据点的平均值
对于非欧空间，取某个处于最中间的店，取若干个最具代表性的点</p>
<p>k-means: 第一步，选区k个初始点,作为出事的cluster center 第二步，Loop
{ 对输入中的每一个点p： { 计算p到各个cluster的距离 将p归入最近的cluster
} 重新计算各个cluster的中心 }
第三步，根据最终胜出的簇中心对所有数据元素进行划分聚类的工作</p>
<p>问题：
样本数据有n个，预期生产k个cluster，则k-means算法t次迭代过程中的时间复杂度为O(nkt)</p>
<p>并行化算法设计 思路： 在处理每一个数据点是，只需要知道cluster
center的信息</p>
<p>将所有数据分布到不同的MapReduce节点上，每个节点只对自己的数据进行计算
每个Map节点能够读取上一次迭代生成的cluster center
Reduce节点综合每个属于每个cluster的数据点，计算出新的cluster centers
(Reducer的个数实际上就和聚类中心的个数相同)</p>
<p>全局文件 - 当前的迭代次数 - K个不同聚类中心的数据结构（id, center,
数据点的个数）</p>
<pre><code>class Mapper
setup()&#123;
    读取全局的聚类中心数据 centers
&#125;
map(key, p) //p 为一个数据点
&#123;
    minDis = Double.MAX_VALUE
    index = -1
    for i=0 to Centers.length
    &#123;
        dis = ComputeDist(p, Centers[i])
        if (dis &lt; minDis&gt;)  // 替换k个点
        &#123;
            minDis = dis;
            index = i;
        &#125;
    &#125;
    emit(Centers[i].ClusterID, (p,1)) 
    // 1表示数据点的个数
&#125;

class Reducer
reduce(ClusterID, value=[p(pm1, n1), (pm2, n2), ..])
&#123;
    pm = 0.0, n=0;
    k = 数据点列表中数据项的总个数
    for i=0 to k
    &#123;
        pm += pm[i]*n[i]; n+=n[i];
    &#125;
    pm = pm/n;
    emit(ClusterID, (pm,n));// 输出新的聚类中心的数据值
&#125;</code></pre>
<h3
id="基于mapreduce的分类并行化算法">基于MapReduce的分类并行化算法</h3>
<p>从一组已经带有分类标记的训练样本数据集来预测一个测试样本的分类结果</p>
<h4 id="knn">kNN</h4>
<p>k-NN:
计算测试样本到各训练样本的距离，取其中距离最小的K个，并根据这K个训练样本的标记进行投票得到测试样本的标记。</p>
<p>并行化思路 全局变量： 样本数据和k个最近的样本</p>
<p>对于每一个的样本数据，检查如果就hi算出来的值比目前大则替换，否则保留
根据所保留的k个最大的值得到最终的分类标记</p>
<h4 id="朴素贝叶斯分类">朴素贝叶斯分类</h4>
<p>关键：对于一个未知类别的样本X，可以先分别计算出X属于每一个类别Yi的概率P(X|Yi)P(Yi),
然后选择其中概率最大的Yi作为其类别
理解：因为分母都是一样的，所以实际上考虑的就是分子的情况</p>
<p>并行化算法设计思路：
用MapReduce扫描数据集，计算每个类别Yi出现的频度FYi，以及每个属性值出现在Yi的频度FxYij</p>
<p>训练集的并行化代码 class Mapper map(key, tr) { tr: trid,A,y emit(y,1)
// 类别 for i=0 to A.length { emit(&lt;y, xni, xvi&gt;, 1) } } class
Reducer reduce(key, value_lsit) // Key为分类标记y, 或者&lt;y, xni,
xvi&gt; { sum = 0 while(value_lsit.hasNext()) { sum +=
value_lsit.next().get() } emit(key, sum) }</p>
<p>测试样本分类预测Mapper</p>
<pre><code>class Mapper
setup()
&#123;
    读取从训练数据集中得到的频度数据
    分类频度表 FY = &#123;(Yi, 每个Yi的频度FYi)&#125;
    属性频度表 FxY = &#123;(&lt;Yi, xnj, xvj&gt;, 出现频度FxYij)&#125;&#125;
&#125;
map(key, ts) // ts为一个测试样本
&#123;
    ts tsid, A
    MaxF = MIN_VALUE; idx = -1
    扫描每个表，找到类别最大的表所在的位置
    emit(tsid, FY[idx].Yi)
&#125;</code></pre>
<h4 id="svm短文本分类">SVM短文本分类</h4>
<p>训练阶段，对于多类（480类）问题，为了提高多类精度，首先针对每个类做一个2class两类分类器
预测阶段，分别用480个分类其对每个待预测的样本进行分类并打分，选择分类为”是“且打分最高的类别作为该样本可能的预测类别，则将该测试样本判定为不属于480类的异类</p>
<p>第一步，用训练数据产生480个2-class分类器模型 Map:
将每个训练样本的分类标签ClassID作为主键，输出（ClassID, &lt;true/ false,
特征向量&gt; Reduce： 具有相同ClassID的键值对进入同一个Reduce</p>
<p>第二步，用480个2-Class分类器模型处理测试数据 Map：
将每个测试样本，以SampleID作为主键，输出（SampleID, &lt;LableID,
评分Score&gt;） Reduce: SampleID</p>
<h2 id="ch10-spark系统及其编程技术">ch10 Spark系统及其编程技术</h2>
<h3 id="scala">Scala</h3>
<ol type="1">
<li>val, var 不变引用和可变引用</li>
<li>基于JVM、面向对象、函数式编程</li>
<li>类是对象的抽象，对象是类的具体实现，占内存</li>
</ol>
<h3 id="spark-vs-hadoop">Spark vs Hadoop</h3>
<p>Spark不足： 不擅长做以下计算： 1. 实时计算：Map
Reduce无法在毫秒内或者秒级内返回结果 2.
流式计算：流式计算的输入数据是动态的，设计特点决定了数据源必须是静态的
3.
DAG计算：多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。每个MapReduce的阿左也输出结果都会写道磁盘，会造成大量的磁盘IO，性能非常的地下。
4. 没有利用好内存资源，频繁第磁盘草坪做 Spark优点： 1. Spark
把中间数据放到内存，迭代运算效率高。Spark支持DAG图的分布式并行计算的编程框架，减少了迭代过程中的数据的读写磁盘，提高了处理效率。（延迟加载）
2.
容错性高。Spark引进了弹性分布式数据集RDD的抽象，他是分布在一组节点的制度对象集合，这些集合式弹性的，如果数据集一部分丢失，则可以通过“血统：对它们进行重建。另外在RDD计算时可以通过CheckPoint来实现容错。
3.
更加通用。mapreduce只提供了map和reduce两种操作，而spark提供了很多种，大致分为Transformation和Action两大类</p>
<h3 id="rdds">RDDs</h3>
<ol type="1">
<li>基于RDD之间的依赖关系组成lineage,重计算以及checkpoint等机制保证容错性</li>
<li>只读、可分区，这个数据集的全部或部分可以缓存在内存中，在多次计算间重用，弹性指内存不够时可以与磁盘进行交换</li>
</ol>
<h3 id="spark的基本构架和组件">Spark的基本构架和组件</h3>
<p>Spark： mapreduce，rdd，function programing
本地运行模式，独立运行模式，mesos，yarn两套资源管理框架</p>
<p>Spark集群的基本结构 - Master node：
集群部署式的概念，式整个集群的控制器，负责整个集群的正常运行，管理Worker
node - Worker node： 式计算节点，接收主节点命令与进行状态汇报 -
Executors: 每个Worker上有一个Executor，负责完成Task程序的执行 -
Spark集群部署后，需要在主从节点启动Master进程和Worker进程，对整个集群进行控制</p>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>mapreduce</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>mapreduce</tag>
      </tags>
  </entry>
  <entry>
    <title>nju-course mlt</title>
    <url>/2019/nju-course-mlt-773e74fb10e7/</url>
    <content><![CDATA[<h2 id="basicinequality">1. BasicInequality</h2>
<p>有哪些不等式？ 这些不等式是为了解决什么样的问题的？</p>
<p>凸函数：杰森不等式说明函数的期望大于期望的函数，这说明了什么？</p>
<ol type="a">
<li>基本不等式</li>
</ol>
<ul>
<li>杰森不等式 &gt; 杰森不等式即变量的期望的函数小于函数的期望</li>
<li>Markov不等式 &gt; 将<span class="math inline">\(P{X \geq
a}\)</span>的概率与期望联系在一起</li>
<li>chernoff不等式 &gt; 将指数以及指数的性质引入。</li>
<li>大数定理 &gt; 说明了大概率事件的问题</li>
<li>信息熵不等式 &gt; 有什么用处，暂时未知</li>
</ul>
<ol start="2" type="a">
<li><p>Concentration &gt; 研究期望与样本均值之间的关系</p></li>
<li><p>Martingale不等式 &gt;
结论很有意思，得到了函数与函数期望之间关系的不等式 McDiarmid不等式 A
martingale is a sequence of random variables for which, at a particular
time in the realized sequence, the expectation of the next value in the
sequence is equal to the present observed value even given knowledge of
all prior observed values.</p></li>
</ol>
<h2 id="pac理论">3. PAC理论</h2>
<p>PAC理论是什么？ 主要应对的是什么问题？</p>
<p>PAC是概率近似正确的表达式。首先对于衡量的指标，泛化误差也就是在未知样本上预测结果与真实结果的差异性，如果预测函数是真实的概念类，那么泛化误差应该为0.
经验误差是在已知有限样本数据上的真实与否的一个估计值。
PAC学习假设数据原本是存在某一个分布的，而且手上的数据集是通过iid采样得到的。那么，
经验误差的期望就应该与泛化误差相等，由于iid条件和期望的线性性。</p>
<p>注意到，这里的经验误差的计算方式非常简单。</p>
<p>对于PAC可学习，即我们希望尽可能学习到真实的概念，此时就提出了以<span
class="math inline">\(1-\delta\)</span> 满足泛化误差小于某个常数</p>
<p>但是，我们知道学习任务实际上是有两类的：
第一类，简单的，可以在假设空间中学习到概念，此时使用的就是PAC理论
第二类，困难的，不可以在假设空间中学习到概念。这种情况往往就是假设空间不合理，不可知PAC可学习。</p>
<p>对于不可知PAC可学习，此时采用的方法就是使用集中不等式，有给出期望与数据样本的均值之间的关系，所以可以采用就将泛化误差与训练误差之间联系在一起。
这也是为什么实际上做的时候，训练样本不断使样本的误差达到最小，从而在未知样本上保持好的性能。</p>
<p>有什么用？
某任务在什么样的条件下可学得较好的模型？需要多少训练样例才能获得较好的模型？</p>
<p>因为机器学习是在假设空间中寻找概念，所以最重要的一个因素就是衡量假设空间的复杂度。
&gt;
注意在实际问题中，假设空间其实就是问题的定义域。假设空间可分就是目标概念在假设空间中可以找到，然后实际上就是&gt;证明算法，若算法给定就选该算法，若算法未给定，一般考虑选择经验风险最小化的算法。
&gt; 然后根据定义即证明了可分 如果假设空间复杂度有限，用个数来衡量
由前面的PAC可学习公式我们就可以得到样本复杂度。
一般来说都解题步骤就是首先得到算法，然后图形结合得到泛化整个集合的泛化误差，然后通过独立同分布得到与单个泛化误差之间的关系，最终即可得到样本复杂度。
## 4. 复杂度 - 为什么可以用PAC理论来得到学习算法？
当认为处理每个样本的时间是常数，则算法的复杂度就与样本复杂度相关。又由PAC定义，如果概念在假设空间中可以由假设空间复杂度得到样本复杂度。
- 如果假设空间无限，引入假设空间，增长函数和VC维。 &gt;
无限假设空间的另一种理解方法就是定义域往往是无穷的
无限假设空间被有限大小的数据集限制。
增长函数即指该概念可以出现多少不同类的情况，则增长函数一定小于H_D
VC维就是log_2 {增长函数}</p>
<ul>
<li>增长函数可以通过不等式放缩。</li>
<li>研究数据分布相关的假设空间复杂度 &gt;
考虑到现实中的某些标记不一定是真实标记，此时选择事先考虑随机噪声的假设更好。为什么这样更好？因为这里也是往往认为这种时间是具有一定分布的，即是随机噪声。
&gt;
常见的噪声的取值为0.5的概率取某值，当然在其他情况下，噪声可能有其他的分布。
&gt;
为什么要用上界来衡量？如同增长函数的感觉，上界来衡量的感觉就是去找最大的情况，而所有做的过程都是这样来做的。</li>
</ul>
<p>注意有两种复杂度： 第一种，经验复杂度，即在随机噪声上的期望
第二种，分布复杂度，即在具体分布上的期望</p>
<p>几个复杂度求解的例子。</p>
<p>作业1-习题3：
求R复杂度时注意关于期望的运算最好使用期望原本的公式。</p>
<h2 id="泛化性">5. 泛化性</h2>
<p>机器学习模型在未见数据上的预测能力。泛化性的好坏可由泛化误差界来表示。
所以泛化性的评价标准就是泛化误差。
由前面的分析可知，泛化误差区分可分和不可分两种情况。
对于可分的情况，样本复杂度是关于名同事我们还可以知道泛化误差的收敛速率
对于不可分的情况，此时用的是误差经验最小化来查看结果。 &gt;
注意不可分与假设空间无限两个概念不要弄混。</p>
<p>无限空间泛化误差界： - 基于VC维的泛化误差界 -
基于Rademacher复杂度的泛化误差界</p>
<p>在研究SVM的VC维时，引入间隔理论，即</p>
<p>假设x的直径的最大长度为r，权向量的最大模为某个定值。最终根据不等式的放缩、期望以及期望的性质最终可得大小关系式。</p>
<p>评价：所求的泛化性是对所欲算法都适用的，与具体的学习算法无关。 ## 6.
稳定性 <span class="math inline">\(\zeta_D\)</span>:
算法基于样本集返回的假设。 z: 代指实际的标签(x,y) 关于移除样本的<span
class="math inline">\(\beta\)</span>-稳定性和替换样本<span
class="math inline">\(\gamma\)</span>。</p>
<p>因为稳定性的定义是两个误差的绝对值，所以趋于稳定即这个值越小越好。那么想要基于稳定性的算法具有收敛性，从某个角度理解就是需要该算法能够随着样本的增大而缩小，因为只有样本容量这一个大小。</p>
<p>定理6.1利用McDiamnd不等式给出了基于稳定性所学的假设的泛化误差界。
给出了泛化误差界与训练误差界之间的关系。</p>
<ul>
<li>稳定性与可学习性之间有什么关系？
稳定性关注点是算法输出的假设的误差，并不考虑空间中所有假设。
一个结论：若果学习算法是ERM且稳定的，那么假设空间是PAC可学习的。
为什么？ 因为从稳定性的定义来看就是损失函数上套了一层。</li>
</ul>
<p>次梯度，即实际函数与函数的点的切线的距离。
这里的关键是有次梯度的关系表达式，即泰勒级数的一阶展开式。将<span
class="math inline">\(B_F\)</span>和稳定性定义，以及梯度联系在一起。
特别说明地是，这里在证明稳定性的上界的时候可以发现，首先是证明了<span
class="math inline">\(\Delta h\)</span>的最大值的上界。 然后再用<span
class="math inline">\(\delta\)</span>可容许将稳定性的误差放缩为<span
class="math inline">\(\Delta h\)</span>，最终得到稳定性的范围。
注意这里是讨论了基于核正则化算法的稳定性。</p>
<p>注意到定理6.1,可以发现最关键的就是分析损失函数的上界以及替换误差.</p>
<p>课文中只给出了基于再生核的泛化误差界，没有给出其他。
还有一点就是本文的讨论都是基于均匀稳定性导出的泛化误差界，但均匀稳定性并不是算法奏效的必要条件，
## 7. AdaBoost分析
集成学习即利用某种规则将各个学习结果进行整合从而获得比单个学习器显著优越的泛化性能。</p>
<p>弱学习器的定义：弱学习器是指在多项式时间内存在一个学习器，其错误率低于50%，即存在比随机猜略好的学习方法。</p>
<p>简单版的AdaBoost算法
在每一轮迭代中，产生一个弱学习器ht,该学习器比随机猜的性能略好，然后根据产生的弱学习器ht，每一个样本被赋予一个权重，如果样本点被正确地分类，那么它的权重越小，表明在下一轮训练中被选中的概率越低。相反，如果某样本点没有被准确地分类，那么它的权重就会提高，然后更显样本集并用于下一轮的学习训练，整个训练过程如此迭代，最后将所有得到的弱分类器通过权重结合起来。</p>
<p>这里是使用了最优化，使泛化误差去极小值，最终得到权值的更新公式。</p>
<p><strong>泛化误差反应的是在未知结果上的好坏，而函数空间复杂度则反应的是学习的程度如何，比如是否过拟合之类的信息</strong></p>
<p><strong>奥卡姆剃刀原理</strong>：在于经验数据一致的模型中，模型越简单，泛化性越好；模型越复杂，泛化性越差。</p>
<ul>
<li>AdaBoost间隔 AdaBoost间隔理论的定义：
间隔定义为正确/错误分类样本(x,y)的基分类器权重之差，在一定程度上了反映了分类器的可信度。
有种执行区间的感觉。</li>
</ul>
<p>AdaBoost间隔结论
学习器在真实分布上的泛化错误率与在训练集上的间隔有关，与训练集的大小，基学习器的个数有关。
所以说明了AdaBoost算法但训练错误率时不停止训练，可以进一步增大间隔，从而提高学习方法的泛化性而没有过拟合。
也就是AdaBoost算法不易引起过拟合现象。想想真的是超级神奇了。</p>
<ul>
<li><p>AdaBoost VC维泛化误差性
由VC维得到结论：随着迭代轮数的增加，学习器函数空间复杂度增加，从而导致发生过拟合风险。不过这是有问题的。</p></li>
<li><p>AdaBoost Rademaer泛化误差性
可以发现，这里所用的都是利普西子条件来分析的。 ## 8. 一致性
结构风险，1范数-稀疏性，2范数-平均性</p></li>
</ul>
<p>一致性这里研究的就是模型和测试的结果之间是否一致，至少在理论上提供保证。</p>
<p>KNN 经验风险最小化。 Tree 拆分法</p>
<p>所以这里的问题的起点变为了首先给定样本空间和标记空间。D是这两个空间的笛卡尔积的一个联合分布。分布D可分解为边缘分布和条件概率，为什么？
&gt; 因为联合分布的定义就是边缘分布乘以条件概率</p>
<p>若函数给出一个分类器或决策函数，其错误率定义为 &gt;
R(g)=Pr[g(X)!=Y]=E[I_{g(X)!=Y}]</p>
<p>那么，考虑最优分类器及其性质 &gt;
这里应该有理论上最优和基于后验最优。</p>
<p>只考虑所有可测函数，选出最符合后验概率的，作为最优。</p>
<blockquote>
<p>注意这里给定任意的损失函数来做经验风险最小化。
首先按照条件期望展开，然后把g(X)即分类器当做变量。对损失求极值，由此可以得到最优分类器和最优风险。
此时就被称为贝叶斯风险和贝叶斯分类器。</p>
</blockquote>
<blockquote>
<p>注意指示函数非凸不连续做不到效果，所以建议使用对数，指数和sigmoid函数。
如果是凸函数可以得到全局最优解。 各点最小，全局最小。</p>
</blockquote>
<ul>
<li>这里的<span class="math inline">\(\eta(x)=Pr(Y=1|X=x)\)</span>
一种经典的条件概率估计方法：Plug-in学习方法。 &gt;
该学习方法是通过训练数据集来估计<span
class="math inline">\(\eta(x)\)</span>, 即学习器<span
class="math inline">\(g(x)=I[\widehat\eta(x) &gt; \frac {1}{2}]\)</span>
&gt; 这里是训练集预测的结果差异 实际上理解就是少数服从多数</li>
</ul>
<p>然后，将Plug-in学习器与最优分类器的错误率之差建立了与两个n(x)的差的期望</p>
<ul>
<li>拆分算法 &gt;
将示例空间划分为多个互不相交的单元格A1,A2,...。对每个单元格投票的方法赋予标记，还是少数服从多数。</li>
</ul>
<p>A(X)这里表示包含X的单元格。N(X)表示训练集中与示例X落入同一单元格的实例数。</p>
<ul>
<li><p>Box算法</p></li>
<li><p>随机森林一致性</p></li>
<li><p>替换损失函数一致性 &gt; 替换函数一般都需要是凸函数。 &gt;
替换函数一致性是指替换损失的最优解接近于0,1损失的最优解 &gt;
替代函数的种类： &gt; 1. 最小二乘损失函数 <span
class="math inline">\((1-t)^2\)</span> &gt; 2. Hinge损失函数 <span
class="math inline">\(max(0,1-t)\)</span> &gt; 3. 指数损失函数 <span
class="math inline">\(e^{-t}\)</span> &gt; 4. 对数损失函数 <span
class="math inline">\(log(1+e^{-t})\)</span> &gt; 5. 平方Hinge损失函数
<span class="math inline">\((max(0,1-t))^2\)</span></p></li>
</ul>
<h2 id="优化">9. 优化</h2>
<blockquote>
<p>监督学习目的想在未知样本中能预测到好的结果，实际上就是测试数据上的期望的性能。往往思考的时候添加个损失函数，所以就变成了是带损失的期望风险最小化。</p>
</blockquote>
<h3 id="凸优化">9.1 凸优化</h3>
<blockquote>
<p>凸优化求解经验风险最小化 几个概念 1. 凸集合 2. 凸函数的几种判定方式 ?
Jensen不等式有什么性质 凸函数能保证局部最优解就是全局最优解。
一阶条件的理解：可以想象成梯度的等温线然后来做。
一般地，Affine,Exponential,Powers,Powers of absolute value, Negative
entropy都是凸函数 几种合起来的套路：
非负加权、线性加权、max、sup(只需要自由变元满足即可) 3. 共轭函数
注意：无论原函数f是否为凸函数，共轭函数f*都为凸 4. 对偶问题 KKT条件： -
原始问题约束 - 对偶问题约束 - 互补松弛条件 - 原函数梯度为0 5. 优化方法
对于梯度下降，目的就是为了分析其在凸函数情况下的收敛速率。 ?</p>
</blockquote>
<blockquote>
<p>? 所以说可以认为凸优化在这里就对应于定步长的梯度下降。</p>
</blockquote>
<blockquote>
<p>凸优化再思考，凸优化为什么表达式是最优化目标min,小于等于，还有必须是纺织函数；
因为Jensen不等式，所以就有加权函数值小于等于函数值加权，所以就能找到最优化目标。</p>
</blockquote>
<h3 id="随机优化">9.2 随机优化</h3>
<blockquote>
<p>随机优化是类大的引题，随机优化是一种方法，一种思想。然后在机器学习中就对应于经验风险最小化部分。</p>
</blockquote>
<p>随机优化求解有两种方法：样本平均近似和随机近似。</p>
<h4 id="样本平均近似">样本平均近似</h4>
<p>机器学习领域的经验风险最小化。
其核心思想是对随机变量进行独立采样，然后利用定义在m个样本上的平均函数来近似未知的目标函数
&gt; ?，这里的随机变量是R复杂度，还是样本值？什么鬼？</p>
<p>然后衡量的目标就是经验风险最小化学的w，在目标函数上w与目标函数上最优解之间的误差
&gt; 这里的w与F对应的是什么？</p>
<p>然后通过不等式放缩即找
平常情况下的w在目标函数中的值和在样本平均中的值的差</p>
<h4 id="随机近似">随机近似</h4>
<blockquote>
<p>利用目标函数F的有噪声观测直接优化问题，如果可以观测到目标函数值，则称为零阶随机优化；如果可以观测到目标函数的梯度，则称为一阶优化</p>
</blockquote>
<p>两个例子 1. 随机梯度下降</p>
<ol start="2" type="1">
<li>阶段随机梯度下降 阶段</li>
</ol>
<h3 id="完全信息在线学习">9.3 完全信息在线学习</h3>
<blockquote>
<p>这一章以及后面就涉及到在线学习的内容了。在线学习在某种意义上可以看作是学习器与对手之间的博弈过程。完全信息在线学习能观测到全部的信息，赌博机在线学习只能观测到局部的信息。</p>
</blockquote>
<ol type="1">
<li><p>基于专家建议的预测 &gt; 对手给出yt,
每个专家给出自己的意见，然后统帅根据某种方法综合专家的意见（线性或者加权），这种方法带有参数，共N个专家，训练T轮。
&gt;
如何学习最优决策？目标是统帅做出决策所获得的损失和专家的损失和相近。（就是专家最牛，希望自己的决策最终能趋近于专家的决策）</p></li>
<li><p>在线凸优化 &gt;
对于损失函数的选择，从某种意义上感觉来说还是与函数的性质有关。</p></li>
<li><p>在线梯度下降 &gt; 这里分凸函数和强凸函数</p></li>
<li><p>在线牛顿法 &gt; 指数凹函数</p></li>
<li><p>在线批处理转换</p></li>
</ol>
<blockquote>
<p>从某种意义上，可以再看看源码中怎么写的 ### 9.4 赌博机在线学习
对于赌博机来说，学习器预测错误后并不知道正确答案。</p>
</blockquote>
<ol type="1">
<li>多臂赌博机 &gt;
学习器的遗憾就是探索和利用之间的折中；一方面，为了准确均值估计需要探索;另一方面，学习器又倾向于选择最大收益的手臂。</li>
</ol>
<blockquote>
<p>注意选择不能只是选均值大的。</p>
</blockquote>
<blockquote>
<p>评价准则：首先最优选择是什么？事先知道答案，即选择了最优的。那么就是T*Ui;
其次，实际做的是什么？就是每轮真正的选择之和。</p>
</blockquote>
<p>一种做法就是置信上界，为每个手臂维持一个均值加一个变量，注意这个变量定的方式暂时未知。</p>
<ol start="2" type="1">
<li>线性赌博机 &gt;
一个问题，噪声具有分布，怎么观测到噪声，噪声有什么用。</li>
</ol>
<p>首先，这里有个目标；目标可以是最小方差。然后，可以取得一个权重，并根据这个权重找到对应的置信趋于，有置信区域找到上界。然后再根据各个标签的置信区域的上界来找到<span
class="math inline">\(X_{t+1}\)</span>。
然后提交观测的样本，再进行学习。
注意，一些扩展的tips，最小方差，在线最小方差。</p>
<ol start="3" type="1">
<li>凸赌博机</li>
</ol>
<p>在赌博机的设定下，学习器智能观测到损失函数<span
class="math inline">\(f_t\)</span>在决策<span
class="math inline">\(w_t\)</span>上的值<span
class="math inline">\(f(w_t)\)</span>,因此是无法直接应用梯度下降的。
所以这里引入了从函数值估计梯度的技术。
首先在x组成的空间中随机选择一个单位向量，然后学习器根据这个单位向量选择决策<span
class="math inline">\(w_t=z_t+\delta
u_t\)</span>;同时，对手选择一个损失函数。学习器遭受损失，并更新<span
class="math inline">\(z_t\)</span>。值得注意的是这是就能从<span
class="math inline">\(z_t\)</span>近似来做，最终来做凸优化。 ## 补充
#### 1.频率 vs 贝叶斯</p>
<h4 id="频率">频率</h4>
<blockquote>
<p>有上帝之手的感觉，假设事物在冥冥之中服从一个分部，这个分布的参数是未知的，但是是固定的</p>
</blockquote>
<p>最大似然估计MLE:
首先假定一个分布，然后基于最大期望估计得到模型的参数。参数固定。</p>
<h4 id="贝叶斯">贝叶斯</h4>
<blockquote>
<p>世界是不确定的，人们对世界先有一个预判，而后通过观测数据对这个预判进行调整。我们的目标是要找到最优的描述这个世界的概率分布。参数是一个随机变量，符合一定的概率分布。</p>
</blockquote>
<p>最大后验估计MAP: 对世界预判后，不断改变参数找到最适合的分布</p>
<p>过拟合？频率派的专有词 频率学派——最大似然估计 MLE. &gt;
EM算法使用的就是MLE</p>
<p>缓解办法： 1. 添加正则化项 2. 模型集成</p>
<p>贝叶斯学派——最大后验估计MAP</p>
<p>缓解办法： 1. 引入先验，做最大后验估计？ &gt;
认为正则化项实际是一种先验分布，比如u均值的拉普拉斯分布，0均值的高斯分布
2. 计算后验分布的积分（相当于给不同模型进行加权组合）</p>
<h3 id="三种函数的性质">三种函数的性质</h3>
<p>凸函数：局部最优就是全局最优
强凸：只有唯一的最优值，因为表达式中涉及到二阶值，所以此时可以看出强凸有距离的概念。强凸使得前一轮的信息可以直接用到当前论</p>
<h3 id="nothing-is-more-practical-than-a-good-theory">Nothing is more
practical than a good theory!</h3>
<p>Notations - Input space - Fuction: g - Risk of g: 泛化风险 -
Regression function: 回归问题 - Target function: 非回归问题 &gt; ?
后两个是最优的function</p>
<p>普通的策略都是经验风险最小化来得到最优分类器，然后防止过拟合引入正则化项。</p>
<blockquote>
<p>所以必然考虑到基于训练集得到的分类器的误差与最小分类器得到的误差之间的关系。
最优分类器可能没在假设空间中。</p>
</blockquote>
<p>然后根据二次bound可以bound到 <span
class="math inline">\(R(g_n)-R_n(g_n)\)</span>,即generalization下最优误差与经验风险最小化误差的差值。</p>
<p>如果带有损失函数用来分析一致性、稳定性之类，利用Lipschitz条件进行放缩</p>
<p>分析<span class="math inline">\(R(g_n)-R_n(g_n)\)</span>
利用Hoeffding's Inequilty 推出假设空间为有限的界</p>
<p>若假设空间为无限，由秧差得到R复杂度。</p>
<blockquote>
<p>当面对具体算法，因为是凸优化问题；就可以根据分类器即函数的性质得到收敛速率之类的事情。
### 应用 未标签数据的应用： 四种，其中前三种已经有理论证明。 1.
生成式方法。
从有标记数据中学得参数，作用在未标记数据上。然后更新有标记数据集，进而更新参数。
2. 半监督SVM 一次性读入数据，不能中间添加数据。
不能在采样点秘籍的地方穿过 3. 图 标签传播，进行随机游走 4. 一组分类器
基于不一致性进行学习；多视图学习</p>
</blockquote>
<h3 id="generalization">Generalization</h3>
<ul>
<li>证明PAC &gt; 写出最优分类器，然后拆分，然后做</li>
<li>VC &gt; 打散，假设空间可自己构造</li>
<li>算R &gt; 假设带进入做期望</li>
<li>R的性质</li>
</ul>
<ol type="1">
<li>R(aH)=|a|R(H)</li>
<li>R(H1+H2)=R(H1)+R(H2)</li>
<li>R(max(h1,h2)) &lt;= R(h1) + R(h2) &gt; max=<span
class="math inline">\(\frac{1}{2} (x+y+|x-y|)\)</span></li>
</ol>
<ul>
<li>为什么对假设空间进行限制的合理？
因为误差会随假设空间的维度增大而减小</li>
<li>证明最优分类器 &gt; 把一般的表达式写出来，证明最小值即最优</li>
<li>稳定性 &gt; 说明有界，并且证明<span
class="math inline">\(\delta\)</span>可容许</li>
</ul>
]]></content>
      <categories>
        <category>course</category>
        <category>nju</category>
        <category>mlt</category>
      </categories>
      <tags>
        <tag>nju</tag>
        <tag>course</tag>
        <tag>mlt</tag>
      </tags>
  </entry>
  <entry>
    <title>numpy study</title>
    <url>/2019/numpy-study-99af00a28daf/</url>
    <content><![CDATA[<h2 id="numpy">2. numpy</h2>
<p>https://www.numpy.org.cn/</p>
<blockquote>
<p>python
太慢！！有个点就是关于python的切片都是复制，不是引用！不同numpy
numpy基于C直接操作连续内存空间，比纯Python快10到100倍，并且使用内存更少</p>
</blockquote>
<p>numpy提出的ndarry很好用,主要理解通用的数值数据处理上的强大功能，特别是在数组操作上
pandas主要用于统计和分析</p>
<p>！！！ 如何用整个数组的思想 &gt; %time 可以直接统计时间</p>
<h3 id="ndarry">2.1 ndarry</h3>
<ul>
<li>属性与方法 &gt; 可以认为如果改变了属性，必然会返回一个新的结构
<ul>
<li>ar.shape: () 元组
<ul>
<li>di.reshape(): 改变形状, 返回一个新的数组 &gt; di.reshape() ==
np.reshape(di, 4)</li>
</ul></li>
<li>ar.dtype:
<ul>
<li>基本类型
<ul>
<li>int64: 指的是位数, 64位，即8字节; 代码i8</li>
<li>float64 default</li>
<li>uint8</li>
<li>complex64: 用两个32位的浮点数表示 &gt; ? 复数如何定义</li>
<li>bool: 代码?</li>
<li>object: python对象 代码O</li>
<li>string_: 固定长度 S10, 10字节，每个字符一字节</li>
<li>unicode_: U10</li>
</ul></li>
<li>ar.astype(np.float64): 转换类型, 总会创建一个新的数组</li>
</ul></li>
<li>ar.ndim： 有几维</li>
<li>ar.T: 返回转置，仍然未原数组的引用</li>
<li>ar.tranpose((1,0,2)):
轴对换，按照给定的元组进行重新轴的安排，比如获得新的数组</li>
<li>转置=轴变换, ar.swapaxes(1,2): x,y,z;
这里就是对y轴和z轴进行变换</li>
</ul></li>
<li>创建
<ul>
<li>已有
<ul>
<li>np.array(sequence， dtype="")</li>
<li>np.asarray(arr) // 不确定是否是该类型</li>
</ul></li>
<li>特定矩阵
<ul>
<li>np.ones(shape) , ones_like(x): 根据shape和类型创建</li>
<li>np.zeros(shape) zeros_like np.zeros((2,3))</li>
<li>np.eye(3) 单位矩阵</li>
<li>np.arange(10): 返回一维矩阵</li>
<li>np.linspace(a, b, nums): 返回[a,b]闭区间的nums个数的数据</li>
</ul></li>
<li>随机初始化
<ul>
<li>随机数： np.random.randint(a, size)</li>
<li>不同: np.random.choice(a, size=(4,))</li>
<li>np.random.shuffle(arr) 打乱现有的</li>
</ul></li>
</ul></li>
<li>运算: vectorization, 作用到元素级别
<ul>
<li>基本操作 &gt; *, -, /, **, &gt;(bool)， == &gt;
保证shape相同，不同用到广播
<ul>
<li>基本操作上可以大做文章，比如跟已知的数组进行比较，</li>
<li>条件之间可以进行 ==, !=, ~, &amp;, | 等多种操作 &gt; 对于<em>,
如果两个操作树维度不等，按低维开始进行运算 </em>相等于 np.multiply
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data[name == &#x27;Bob&#x27;, 2:], 如果name是一维矩阵，矩阵的长度需要与比较的轴的长度相等</span><br><span class="line">mask = (names = &#x27;Bob&#x27;) | (names == &#x27;Will&#x27;), 注意这里and,or无效，要使用&amp;，|</span><br></pre></td></tr></table></figure> &gt;
因此，可以通过布尔将数组中所有的值给置为某种操作。</li>
</ul></li>
<li>切片操作 &gt;
注意是原始数组的试图，即不会被赋值，任何其他操作都会反映到原变化.
即是等号也会如此 &gt; ? 如何复制, reshape是否会改变原本的值 &gt;
看了下，是不能step的</li>
<li>花式索引
<ul>
<li>arr[i]:
即如果是二维的，那么默认操作就会直接将该轴对应的值全都进行改变</li>
<li>arr[[1,2,3],[1,2,3]]: 可以直接返回对应的列和行， 直接进行切片</li>
</ul></li>
<li>扩展，赋值运算 拷贝arr.copy()
<ul>
<li>np.tile(arr, shape) &gt;
如果shape的维数大于arr的维数，那么直接按shape的坐标来分配 &gt; 否则,
就考虑操作在对应维度上，比如先操作在行上，接着在列上，等等</li>
<li>np.repeat(3, 4) [3,3,3,3] &gt; np.repeat(arr, [1,2], axis=0) //
axis轴上, 第0行复制1次，第1行复制2次</li>
</ul></li>
<li>stack 将arr进行合并，打包在一起
<ul>
<li>vstack((arr1, arr2)): 默认 axis=1, 组合在一起 =
np.stack((arr1,arr2), axis=0)</li>
<li>hstack((arr1, arr2)): [1,2,3] , [2,3,4] =&gt; [1,2,3,2,3,4]:
一维扁平化的感觉</li>
<li>stack((arr1, arr2)): 高级，重新组合为性的数组</li>
</ul></li>
</ul></li>
<li>高级操作
<ul>
<li>通用函数ufunc: 快速的元素级数组函数
<ul>
<li>一元 &gt; 如果设置一个参数，返回array; 设置两个参数，在原数组操作;
当然二元除外
<ul>
<li>幂函数 np.sqrt(arr) <code>arr**0.5</code>; np.square(arr)
<code>arr**2</code></li>
<li>指数函数, 底数函数 np.exp(arr) np.log(arr) np.log10() np.log2(),
np.log1p(arr) <code>log(1+x)</code> &gt;
这里参数可以是一个，即对一个数组进行统计；如果是两个矩阵，则对应元素级别做</li>
<li>拆分小数 remainer, whole_part = np.modf(arr):
返回小数的小数，整数部分</li>
<li>绝对值 np.abs, fabs: 对于非复数值，fabs更快</li>
<li>获取符号 np.sign(arr): 获取符号</li>
<li>对数进行近似整数化 np.ceil() 上; np.floor() 下; np.rint()
四舍五入;</li>
<li>判断值的类型，np.isnan() 不是一个数字的; np.isfinite() np.isinf</li>
<li>三角函数 cos, cosh, sin</li>
<li>逻辑非 np.logical_not -arr</li>
</ul></li>
<li>二元
<ul>
<li>最值np.maximum(x,y) np.NaN为最终结果 np.fmax() np.NaN不考虑;
np.minimum(), np.fmin()</li>
<li>加减 np.add(), np.subtract()</li>
<li>乘 np.multipy, 除np.divide, 丢弃余数 np.floor_divide, 向下整除;
np.mod求余</li>
<li>乘方 np.power</li>
<li>传递正负号 np.copysign</li>
<li>greater, greater_equal, less, less_equal, not_equal</li>
<li>&amp;, | , ^ , ~可对数组使用，list不行, 使用np.logical_and,
np.logical_or, np.logical_xor</li>
</ul></li>
</ul></li>
<li>利用数组进行数据处理
<ul>
<li>范围值 np.arange(start, end, step)</li>
<li>网格数据 x,y = np.meshgrid(arr_1d, arr_1d) &gt; 得到
arr_1d作为x轴的网格数据, 即x的每列元素相同</li>
</ul></li>
<li>将条件逻辑表述为数组运算 np.where(cond, true_ope, false_ope) &gt;
将条件表达式的思想进行转变 <code>result = [(x if c else y) for x,y,c in
zip(xarr, yarr, cond)]</code>
<ul>
<li>数组比较res = np.where(cond, xarr, yarr) //后面两个不必为数组 &gt;
cond为真, 按xarr操作；否则，按yarr操作</li>
<li>值比较 res = np.where(cond, 2, -2)</li>
<li>值、数组比较 res = np.where(arr&gt;0, 2, arr)</li>
</ul></li>
<li>数学和统计方法 &gt; aggregation, reduction, 属于arr的操作;
axis是站在留下来的数据角度思考的
<ul>
<li>和，平均值 arr.mean(), arr.sum() &gt; axis=0,
表示留下第一维,其余维度都会进行计算;
如果，如果没有参数，则对所有元素操作</li>
<li>最值 max, min</li>
<li>最值索引 agrmin, argmax, 同上</li>
<li>标准差和方差 std, var</li>
<li>累加和 累加积 arr.cursum() arr.cumprod , 同上, axis=0,
0维不进行操作</li>
</ul></li>
<li>用于布尔数组的方法
<ul>
<li>(arr==1).sum() bool当做0和1</li>
<li>存在 (arr==1).any()</li>
<li>任意 (arr==1).all()</li>
</ul></li>
<li>排序
<ul>
<li>就地排序 arr.sort() ; 返回副本 np.sort() &gt; 参数为1,
对第1维进行排序</li>
</ul></li>
<li>唯一化及集合逻辑
<ul>
<li>返回唯一元素 np.unique(x)</li>
<li>返回公共元素 np.intersect(x,y)</li>
<li>返回并集 np.union1d(x,y)</li>
<li>返回是否包含的布尔数组 np.in1d()</li>
<li>集合的差 np.setdiff1d()</li>
<li>集合的对称差 np.setxor1d()</li>
</ul></li>
<li>用于数组的文件输入输出
<ul>
<li>np.save, np.load</li>
</ul></li>
<li>线性代数 <code>numpy.linalg</code>
<ul>
<li>矩阵相乘 x.dot(y) np.dot(x,y) x @ np.ones(3)</li>
<li>对角矩阵的操作 arrdd=np.diag(arr1d) arr1d=np.diag(arrdd)</li>
<li>计算对角线元素的和 a.trace() np.trace()</li>
<li>行列式 det()</li>
<li>本特征值、本征向量？ <span class="math inline">\(D = U^T A
U\)</span> U^T, np.diag(A) = LA.eig(D) &gt; 为什么有本?</li>
<li>QR分解？ qr</li>
<li>SVD分解？ svd</li>
<li>矩阵的逆 inv</li>
<li>解线性方程组 Ax=b, x=LA.solve(A,b)</li>
<li>最小二乘解？ x=LA.lstsq(A,b)</li>
</ul></li>
<li>伪随机数生成 import np.random as nrd &gt; np.random.seed(1234):
指定了全局状态;
那么每次设置这个值时，第一次都会产生相同的数,这个特点可以进行利用; &gt;
想真正的实现随机数，1. 随机种子随机指定： 2. 使用np.random.RandomState,
创建一个与其他隔离的随机数生成器
<ul>
<li>指定随机种子
<ul>
<li>nrd.seed(int) 随机种子</li>
</ul></li>
<li>返回某种数
<ul>
<li>nrd.permutation(arr/list1)
返回一个序列的随机排列或返回一个随机排列的范围</li>
<li>shuffle(arr/list1) 对一个序列就地随机排列</li>
<li>randint(a, size=shape) [0,a) randint(a,b, size=shape) [a,b) &gt;
注意和python自带的randint不同[a,b]</li>
</ul></li>
<li>根据分布产生样本值，paras = (d1,d2,d3)
<ul>
<li>rand(d1,d2) 产生均匀分布的样本值 [0,1)
随机数的分布范围属于【0,1)</li>
<li>binomial 产生二项分布的样本值</li>
<li>normal(loc=0.0, scale=1.0) randn 产生正态高斯分布的样本值</li>
<li>beta 产生beta分布的样本值</li>
<li>chisquare 卡方分布</li>
<li>gamma Gamma分布</li>
<li>uniform [0,1) 均匀分布</li>
</ul></li>
<li>均匀分布 ranf = random = sample = random_sample [0,1)</li>
</ul></li>
<li>随机漫步 &gt;
一个简单随机漫步的例子：从0开始，步长1和-1出现的概率相等;
即取0,1之间的随机数,然后记录每一步的位置，就可以认为走路的过程为随机漫步
&gt; 多维，一次模拟多次随机漫步; 也可用分布来模拟随机漫步</li>
</ul></li>
</ul>
<blockquote>
<p>一些tips: 转换为对角阵，使用乘法来做 1. 对列求和, 然后做每行；直接 T
/ np.sum(T, axis=1, keepdims=True) // 保证最后得出的结果是矩阵 2.
np.mat(A): 返回矩阵的抽象类型，什么时候用到也不知道</p>
</blockquote>
]]></content>
      <categories>
        <category>machinelearning</category>
        <category>numpy</category>
      </categories>
      <tags>
        <tag>numpy</tag>
        <tag>machinelearning</tag>
      </tags>
  </entry>
  <entry>
    <title>python-study</title>
    <url>/2019/python-study-764325c9e34f/</url>
    <content><![CDATA[<h2 id="vscode的好处">1. vscode的好处</h2>
<ol type="1">
<li>显示思路过程</li>
<li>实时性显示</li>
<li>块编程</li>
<li>批处理</li>
</ol>
<h2 id="机器学习常用的库">2. 机器学习常用的库</h2>
<ul>
<li><p>核心库与统计：Numpy、Scipy、Pandas、StatsModels。</p></li>
<li><p>可视化：Matplotlib、Seaborn、Plotly、Bokeh、Pydot、Scikit-learn、XGBoost/LightGBM/CatBoost、Eli5。</p></li>
<li><p>深度学习：Tensorflow、PyTorch、Keras。</p></li>
<li><p>分布式深度学习：Dist-keras/elephas/spark-deep-learning。</p></li>
</ul>
<p>自然语言处理：NLTK、SpaCy、Gensim。</p>
<p>数据抓取：Scrapy。</p>
<h2 id="python使用总结">3. python使用总结</h2>
<p>jupyter - b? 查看文档 - b?? 查看源码 - %shell命令 - qucikref
快捷查看</p>
<h3 id="基本类型">3.1 基本类型</h3>
<h4 id="null类型">3.1.1 null类型</h4>
<p>注意一个想法，python中万物均可对象化，这么说的意思就是所有东西都有它的类型和值。
&gt;
特别需要注意的是，哪些时候使用引用即可，哪些使用必须使用一个新的对象</p>
<blockquote>
<p>dir() 查看参数的方法, type() 查看类型, id()=hashCode, - ==: value
equality - is: reference equality is是==加上两个对象的位置是一样 ==
isinstance(some_object, (int, float)) &amp;&amp; value</p>
</blockquote>
<p>None表示不是对象？什么时候会碰到？？ &gt;
比如函数参数时，什么都没有传递过来，都是有默认值的情况！！！ &gt;
表示空对象, 类型是NoneType, 值是为空 &gt; if(None) =False //
一般是None的话，最好事先说出。 &gt;
True和Flase类型也跟None不一样，他们是bool类型</p>
<p>NULL: 表示空字符，str</p>
<p>"": 0: False: True:</p>
<h4 id="值和引用">3.1.2 值和引用</h4>
<ul>
<li><p>值类型: 数值、字符串、元组(注意这里是元组) &gt;
即只能自己改自己，不能因为赋值就改变自己，因为赋值它始终是产生了一个新的内存地址</p></li>
<li><p>引用类型： 列表、集合、字典 &gt; 本身允许被改变</p></li>
</ul>
<h4
id="and-or替代了-依然是按位操作-它的优先级始终是小于比较大于赋值的">3.1.3
and, or替代了&amp;&amp;, ||; &amp;,|依然是按位操作，
它的优先级始终是小于比较，大于赋值的</h4>
<blockquote>
<p>python中int之间的and, or;
始终是按照先将其转化为bool类型，然后按照实际的and,or判断逻辑，不行则返回即返回值</p>
</blockquote>
<h4 id="section">3.1.4</h4>
<ul>
<li>可执行的伪代码</li>
<li>使用缩进而不是括号</li>
<li>万物皆可对象</li>
<li>动态引用，强类型</li>
<li>鸭子类型，不关注具体类型，而是关注能做什么</li>
<li>属性和方法
<ul>
<li>getattr(a, attr)(x): 反射，属于强类型</li>
</ul></li>
<li>可变 vs 不可变</li>
<li>单值，即标量类型
<ul>
<li>None</li>
<li>str</li>
<li>bytes</li>
<li>float</li>
<li>bool</li>
<li>int</li>
</ul></li>
<li>数值类型
<ul>
<li>**, 平方</li>
<li>7.2324</li>
<li>6.78e-5</li>
<li>3 / 2: 实际的除法</li>
<li>3 // 2: 整除</li>
</ul></li>
<li>字符串
<ul>
<li>', ", """</li>
<li>r' ', "\" 字面值和转义</li>
<li>不可变的，即s[1]=2是错误的。
<ul>
<li>hash(): 可行；</li>
<li>=：产生一个新的对象</li>
</ul></li>
<li>基本操作
<ul>
<li>长度 len()</li>
<li>清空 str=""</li>
<li>判断某种属性
<ul>
<li>isalnum() // 数字和单词</li>
<li>isalpha() // 单词</li>
<li>isdecimal() // 数字 byte</li>
<li>islower() // 小写</li>
</ul></li>
<li>字母相关操作
<ul>
<li>lower()</li>
<li>captialize()</li>
<li>upper()</li>
</ul></li>
<li>常见操作
<ul>
<li>查找
<ul>
<li>次数， count(substr,start, end)</li>
<li>位置
<ul>
<li>index(str, ) rindex // 异常</li>
<li>find(str, ) rfind // lower, -1</li>
<li>endswith, startswith</li>
</ul></li>
</ul></li>
<li>去空格
<ul>
<li>strip(), rstrip()</li>
</ul></li>
<li>划分为列表： split, rsplit</li>
<li>替换， replace(A, B)</li>
<li>合并两个字符串
<ul>
<li>join</li>
</ul></li>
<li>格式化
<ul>
<li>{0:.2f}, {0:s}, {2:d}</li>
</ul></li>
<li>encode, decode</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="元组-集合-列表-字典">3.2. 元组(), 集合{}, 列表[], 字典</h3>
<h4 id="list">3.2.1 list []</h4>
<ul>
<li>长度 &gt;
特别地，长度一般是有多种方法，具体哪种一般来说看源代码怎么定义的，对于Tree结构，习惯性地包括定义size,那么使用size方法绝对是最优秀的
<ul>
<li>__len__方法</li>
</ul></li>
<li>插入
<ul>
<li>尾部， apppend</li>
<li>任意， insert(index, value)</li>
</ul></li>
<li>删除
<ul>
<li>尾部， pop()</li>
<li>任意， del li[index]</li>
<li>值， remove(value)</li>
</ul></li>
<li>查找
<ul>
<li>单点查找
<ul>
<li>是否存在 in</li>
<li>index: li.index(value)</li>
<li>value: li[index]</li>
</ul></li>
<li>范围查找
<ul>
<li>d[start:end:step] // 可为负</li>
</ul></li>
</ul></li>
<li>合并list
<ul>
<li>+性能低</li>
<li>extend(list2)</li>
</ul></li>
<li>其他
<ul>
<li>li.sort(key=) // 原地排序</li>
<li>sorted(li) // 返回副本</li>
<li>reversed</li>
</ul></li>
</ul>
<blockquote>
<p>允许范围查找，赋值，删除，即切片</p>
</blockquote>
<h4 id="dict">3.2.2 dict</h4>
<blockquote>
<p>key必须是可以hashtable的数据，即唯一性, 可以通过hash来检验;
一般来说只有值类型可哈希 <strong>doc</strong> ,
查看文档中的使用说明，输入与输出 isinstance(1, set)
查看是否是需要的类型</p>
</blockquote>
<ul>
<li>插入
<ul>
<li>set(key, defalut) // 存在不改变值 &gt; 可加后续操作 set(key,
default).appende(key)</li>
<li>di[key]=value // 存在改变值</li>
</ul></li>
<li>删除
<ul>
<li>del d[key]</li>
<li>di.pop(key) // 返回当前元素</li>
</ul></li>
<li>查看
<ul>
<li>存在： in di // 默认在keys()中查看</li>
<li>di[key] // KeyError 异常</li>
<li>do.get(key, default_value) // 不存在返回特定的值</li>
</ul></li>
<li>合并dict
<ul>
<li>update(di2) // 完全舍弃旧值</li>
</ul></li>
<li>输出
<ul>
<li>di.keys() // Iterable类型</li>
<li>di.values()</li>
</ul></li>
<li>由两个列表创建
<ul>
<li>di = {k:v for k,v in zip(list1, list2)} // 会吞并重复元素</li>
<li>di = dict(zip(list1, list2)) &gt; li = list(zip(list1, list2)) // [(
), ( )] 此时内部为元组</li>
</ul></li>
<li>分解为两个列表
<ul>
<li>list1, list2 = dict.keys(), dict.values() // python3是对应的顺序
&gt; list1, list2 = zip(*li) // li为列表时</li>
</ul></li>
<li>一些进一步简化的操作
<ul>
<li>defaultdict // 可设置value默认值 &gt; from collections import
defaultdict &gt; by_letter=defaultdict(list) // 中间传入的为类型</li>
</ul></li>
</ul>
<blockquote>
<p>一个很神奇的现象, di = {1:2, 2:5} ci=di 1. di = {} , ci =&gt; {1:2,
2:5} 2. di[1]=5 ci[1]=&gt;5</p>
</blockquote>
<p><font color="red">defaultdict</font> &gt; 可以用来指定value的类型</p>
<h4 id="集合-set">3.2.3 集合 set</h4>
<blockquote>
<p>特殊的字典，只有健没有值; 同样不可重复. 没有特定的位置性.
像元组则是序列数据，即可重复出现</p>
</blockquote>
<ul>
<li>插入： add(x)</li>
<li>删除： remove(x)</li>
<li>清空： clear()</li>
<li>合并集合： a.update({1,2})</li>
<li>清楚首元素： a.pop() // 默认最小元素， 可以做堆</li>
<li>两个集合的运算
<ul>
<li>A是B的子集： A.issubset(B)</li>
<li>A是B的父集： A.issuperset(B)</li>
<li>并集
<ul>
<li><div class="line-block"></div></li>
<li>union</li>
</ul></li>
<li>交集
<ul>
<li>&amp;</li>
<li>intersection</li>
</ul></li>
<li>差集， -, 不够减为空</li>
<li>异或 ^</li>
<li>支持 &amp;=</li>
</ul></li>
</ul>
<h4 id="推导式">3.2.4 推导式</h4>
<ul>
<li><p>list</p></li>
<li><p>tuple: !!! 有个特别好的特性就是generator, 即满足惰性求值;
而且是值类型 &gt;
所以这里得到的结果不是tuple类型，而是generator</p></li>
<li><p>{} 结果两种</p>
<ul>
<li>dict</li>
<li>set</li>
</ul></li>
</ul>
<h4 id="复制">3.2.5 复制</h4>
<ul>
<li>copy只复制一层</li>
<li>深度复制 &gt; import copy &gt; di = copy.deepcopy(my_dict)</li>
</ul>
<h4 id="一些好的方法">3.2.6 一些好的方法</h4>
<ul>
<li><strong>mro</strong>_ ：动态类型， 判断属于哪些类型</li>
<li>isinstance(A, type): 判断是否属于某个类型</li>
<li>if, <strong>len</strong>, 查看是否为0,
and都是转变为bool类型来做</li>
<li><strong>doc</strong>: 查看基本的函数输入，输出文档</li>
<li>dir(): 查看所拥有的方法</li>
</ul>
<h3 id="语句">3.3 语句</h3>
<ul>
<li>if A: pass elif: pass else: pass</li>
<li>while A: pass</li>
<li>for i in range(2):</li>
<li>try: except Exception: finally ### 3.4 函数</li>
</ul>
<h4 id="基本">3.4.1 基本</h4>
<ul>
<li>参数
<ul>
<li>顺序性， 有默认值的放在最后</li>
<li>*args, **kwargs 默认为None</li>
<li>可为函数</li>
<li>字典式指定值 &gt; 无参数时，为None</li>
</ul></li>
<li>变量： 严格作用域</li>
<li>返回值：
<ul>
<li>多值</li>
<li>字典</li>
</ul></li>
</ul>
<h4 id="匿名函数">3.4.2 匿名函数</h4>
<p><code>lambda paras: return_value</code> <code>lambda x,y : x+y</code>
&gt; 可以引用在任何需要使用函数作为参数的情况中 如 map, reduce, sort
&gt; reduce 还是不大好理解</p>
<h4 id="柯里化">3.4.3 柯里化</h4>
<p>部分参数应用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">add_number = lambda x,y: x+y</span><br><span class="line">from functools import partial</span><br><span class="line">add_five = partial(add_numbers, 5)  // 相比于默认参数，是动态默认参数</span><br></pre></td></tr></table></figure></p>
<p>#### 3.4.4 生成器 generaotr 惰性求值 - return =&gt; yeild - gen = (
)</p>
<p>#### 3.4.5 itertools模块 &gt; 用于许多常见数据算法的生成器</p>
<p>https://www.liaoxuefeng.com/wiki/1016959663602400/1017783145987360</p>
<ul>
<li>combinations(, k): 产生组合数</li>
<li>permutations(): 产生排列数</li>
<li>groupby, 将相同的字符串给弄出来 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; for key, group in itertools.groupby(&#x27;AAABBBCCAAA&#x27;):</span><br><span class="line">...     print(key, list(group))</span><br><span class="line">...</span><br><span class="line">A [&#x27;A&#x27;, &#x27;A&#x27;, &#x27;A&#x27;]</span><br><span class="line">B [&#x27;B&#x27;, &#x27;B&#x27;, &#x27;B&#x27;]</span><br><span class="line">C [&#x27;C&#x27;, &#x27;C&#x27;]</span><br><span class="line">A [&#x27;A&#x27;, &#x27;A&#x27;, &#x27;A&#x27;]</span><br></pre></td></tr></table></figure></li>
<li>chain(iter1, iter2[,..]): 串联多个iter</li>
<li>repeat('A',n): 重复n次</li>
<li>cycle("ABC"): 循环，直到ctrl+c退出 #### 3.4.6 字节、位运算 (n &amp;
0x3f3f3) &gt;&gt;1: 人可用</li>
</ul>
<h3 id="类">3.5 类</h3>
<ul>
<li>命名特点
<ul>
<li>属性: 名词</li>
<li>方法：动词, 注意要加括号</li>
<li></li>
</ul></li>
</ul>
<h3 id="其他模块">3.6 其他模块</h3>
<h4 id="正则表达式">3.6.1 正则表达式</h4>
<ul>
<li>模式: r" "
<ul>
<li>替换：str = re.sub(origin_str, res_str, str)</li>
<li>匹配首个结果 re.match(, test) None(False)</li>
<li>划分 li = re.split(r' ',str)</li>
<li>分组 li = re.group(r' ', str) //group(0)为原始, 1-k为分组结果</li>
</ul></li>
<li>方法
<ul>
<li>单个字母匹配
<ul>
<li>字</li>
<li>空格</li>
<li>字母或数字</li>
<li>. 任意</li>
<li>0<sub>9,a</sub>z 特别</li>
<li>. 转义， 匹配原字符</li>
</ul></li>
<li>次数
<ul>
<li>a 1次</li>
<li>a+ &gt;=1</li>
<li>a* &gt;=0</li>
<li>a{n} n次</li>
<li>a{n,m} n~m次</li>
</ul></li>
<li>特别
<ul>
<li>^ 指定必须从数字开头</li>
<li>$: 指定必须数字结尾</li>
</ul></li>
<li>范围
<ul>
<li></li>
<li>(A|B)： 两个可选 &gt; ()
子表达式的开始和结束，在分组时起到特别的作用，一个括号表示一个group</li>
</ul></li>
</ul></li>
<li>特别说明：正则表达式匹配为贪婪模式</li>
</ul>
<h4 id="文件模块">3.6.2 文件模块</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for i in open(path): // i默认有行结束符，记住用rstrip()</span><br></pre></td></tr></table></figure>
<ul>
<li><p>f.read(121)</p></li>
<li><p>f.tell()</p></li>
<li><p>f.seek(3): 移动指针到指定字节</p></li>
<li><p>模式： r, w, a, r+, b, U</p></li>
</ul>
<h4 id="collections">3.6.3 collections</h4>
<ul>
<li><p>namedtuple &gt; 为tuple的每一项起名字 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from collections import namedtuple</span><br><span class="line">Point = namedtuple(&#x27;Point&#x27;,[&#x27;x&#x27;,&#x27;y&#x27;])</span><br><span class="line">p = Point(1,2)</span><br><span class="line">p.x  # 1</span><br><span class="line">p.y # 2</span><br></pre></td></tr></table></figure></p></li>
<li><p>deque &gt; list支持的太过分,
deque缩小限制，只允许两端插入和删除</p>
<ul>
<li>append, appendleft</li>
<li>pop , popleft</li>
</ul></li>
<li><p>defaultdict &gt; 设置默认的值 dd = defaultdict(lambda:
"N/A")</p></li>
<li><p>OrderedDict &gt; 保证先进先出的顺序，可以当做队列用</p></li>
<li><p>ChainMap &gt; 将多个dict, 合为一个逻辑dict ## 4. 优化</p></li>
</ul>
<p>https://python-web-guide.readthedocs.io/zh/latest/idiom/idiom.html#true-false-none</p>
<h3 id="a.-链式1a7">a. 链式：1&lt;a&lt;7</h3>
<h3 id="b.-ba-if-ab-else-b">b. b=a if a&gt;b else b</h3>
<h3 id="c.-xyyx">c. x,y=y,x</h3>
<h3 id="d.-strmyname-my-age-.formatname-age">d. str="myname:{} my age
{}".format(name, age)</h3>
<h3 id="e.-list-dict使用">e. list, dict使用[],</h3>
<p>odd_list=[e for e in mulist if e%2==1]</p>
<p>user_list = [{'name': 'lucy', 'email': 'lucy@g.com'}, {'name':
'lily', 'email': 'lily@g.com'}] user_email = {user['name']:user['email']
for user in user_list if 'email' in user}</p>
<h3 id="f.-if-none-特别说明">f. if None 特别说明</h3>
<p>if() : pass 实际调用的是l.__len__()==0</p>
<p>if something is None: // None是单例对象 // 注意</p>
<h3 id="g.-index变量访问-enumerate">g. index变量访问, enumerate;</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for index,  element int enumerate(my_container)</span><br></pre></td></tr></table></figure>
<h3 id="h.-避免使用可变变量作为函数参数的默认初始化值-none">h.
避免使用可变变量作为函数参数的默认初始化值, None</h3>
<p>// 可以使用None作为可变对象的占位符</p>
<h3 id="i.-函数参数即函数">i. 函数参数即函数</h3>
<p>// 一切都可对象，可以把参数作为函数使用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator as op</span><br><span class="line">def print_table(operator):</span><br><span class="line">    for x in range(1, 3):</span><br><span class="line">        for y in range(1, 3):</span><br><span class="line">            print(str(operator(x, y)) + &#x27;\n&#x27;)</span><br><span class="line"></span><br><span class="line">for operator in (op.add, op.sub, op.mul, op.div):</span><br><span class="line">    print_table(operator)</span><br><span class="line"></span><br></pre></td></tr></table></figure> ### j.
防御式编程, 不断检查参数</p>
<h3 id="k.-dict实现switch..case..">k. dict实现switch..case..</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># bad</span><br><span class="line">def apply_operation(left_operand, right_operand, operator):</span><br><span class="line">    if operator == &#x27;+&#x27;:</span><br><span class="line">        return left_operand + right_operand</span><br><span class="line">    elif operator == &#x27;-&#x27;:</span><br><span class="line">        return left_operand - right_operand</span><br><span class="line">    elif operator == &#x27;*&#x27;:</span><br><span class="line">        return left_operand * right_operand</span><br><span class="line">    elif operator == &#x27;/&#x27;:</span><br><span class="line">        return left_operand / right_operand</span><br><span class="line"># good</span><br><span class="line">def apply_operation(left_operand, right_operand, operator):</span><br><span class="line">    import operator as op</span><br><span class="line">    operator_mapper = &#123;&#x27;+&#x27;: op.add, &#x27;-&#x27;: op.sub, &#x27;*&#x27;: op.mul, &#x27;/&#x27;: op.truediv&#125;</span><br><span class="line">    return operator_mapper[operator](left_operand, right_operand)</span><br></pre></td></tr></table></figure>
<h3 id="l.-namedtuple">l. namedtuple ?</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># bad</span><br><span class="line">rows = [(&#x27;lily&#x27;, 20, 2000), (&#x27;lucy&#x27;, 19, 2500)]</span><br><span class="line">for row in rows:</span><br><span class="line">    print &#x27;&#123;&#125;`age is &#123;&#125;, salary is &#123;&#125; &#x27;.format(row[0], row[1], row[2])</span><br><span class="line"></span><br><span class="line"># good</span><br><span class="line">from collections import  namedtuple</span><br><span class="line">Employee = namedtuple(&#x27;Employee&#x27;, &#x27;name, age, salary&#x27;)</span><br><span class="line">for row in rows:</span><br><span class="line">    employee = Employee._make(row)</span><br><span class="line">    print &#x27;&#123;&#125;`age is &#123;&#125;, salary is &#123;&#125; &#x27;.format(employee.name, employee.age, employee.salary)</span><br></pre></td></tr></table></figure>
<h3 id="m.-isinstance">m. isinstance</h3>
<h3 id="n.-with">n. with</h3>
<h3 id="o.-yeild关键字-惰性求值">o. yeild关键字, 惰性求值</h3>
<p>([ expression ]) // 本身就是惰性求值 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># bad</span><br><span class="line">def f():</span><br><span class="line">    # ...</span><br><span class="line">    return biglist</span><br><span class="line"></span><br><span class="line"># good</span><br><span class="line">def f():</span><br><span class="line">    # ...</span><br><span class="line">    for i in biglist:</span><br><span class="line">        yield i</span><br></pre></td></tr></table></figure></p>
<h3 id="p.-wraper">p. Wraper</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from functools import wraps</span><br><span class="line"></span><br><span class="line">ef beg(target_function):</span><br><span class="line">    @wraps(target_function)</span><br><span class="line">    def wrapper(*args, **kwargs):</span><br><span class="line">        msg, say_please = target_function(*args, **kwargs)</span><br><span class="line">        if say_please:</span><br><span class="line">            return &quot;&#123;&#125; &#123;&#125;&quot;.format(msg, &quot;Please! I am poor :(&quot;)</span><br><span class="line">        return msg</span><br><span class="line"></span><br><span class="line">    return wrapper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@beg</span><br><span class="line">def say(say_please=False):</span><br><span class="line">    msg = &quot;Can you buy me a beer?&quot;</span><br><span class="line">    return msg, say_please</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="好用的工具">5. 好用的工具</h2>
<p>https://blog.csdn.net/moqsien/article/details/79544876</p>
<h2 id="一些其他">6. 一些其他</h2>
<h3 id="二分搜索和维护已排序的列表">6.1 二分搜索和维护已排序的列表</h3>
<p>bitsect: 二分搜索</p>
<p>bitsect.bitsect(c, 2) // 搜索插入的位置 bitsect.insort(c,5) //
插入元素</p>
<h3 id="排序">6.2 排序</h3>
<p>a.sort(key=len) sorted(a)</p>
<h3
id="zip-将多个列表元组或其它序列成对组合为一个元组列表-ziplist-解压">6.3
zip: 将多个列表、元组或其它序列成对组合为一个元组列表; zip(*list),
解压</h3>
<p>seq1 = ['foo', 'bar', 'baz'] seq2 = ['a', 'b', 'c'] zip(seq1, seq2)
&gt; type zip</p>
<p>a = list(zip(seq1,seq2))</p>
<p>解压 seq1, seq2 = zip(*a)</p>
<h3 id="reversed翻转">6.4 reversed翻转</h3>
<p>另外，注意range也是一种类型</p>
<p>关于relu的倒数可以直接用</p>
<h2 id="关于python解释器">7. 关于Python解释器</h2>
<ol type="1">
<li>脚本语言 vs 编译语言</li>
</ol>
<p>首先，脚本语言需要能够实时运行，与编译语言来说有何不同？
脚本语言需要进行保存上下文变量</p>
<blockquote>
<p>特别地， C vs Python 1. 没有类型：
在实现阶段，那么需要进行多层的类型匹配。这会花费大量的时间 2. 函数参数？
python中对参数是如何进行解释的？ 如果按照python来参数是进行怎么解释的 3.
？</p>
</blockquote>
<ol start="2" type="1">
<li>解释器 ？ 解释器是如何实现的</li>
</ol>
<ul>
<li>CPython: 使用C语言对python进行解释</li>
<li>IPython: 在CPython的基础上向上封装了一些高级接口 &gt;
另外，还有一些其他的接口，比如JPython, 用jav来做</li>
</ul>
<p>## 8. 关于其他 当显示Microsoft Visual C++ 14.0 is
required.时，可到以下网站进行安装
https://www.lfd.uci.edu/~gohlke/pythonlibs/#pygraphviz</p>
<p>查看某个属性或者方法是否可以调用？ hasattr(obj, attr)</p>
<p>callable(getattr(obj, funcName))</p>
<p>numpy注意使用浮点数</p>
<p>列表解析 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">list_c = [item if item &gt; 5 else 1 for item in list_a]</span><br><span class="line"></span><br><span class="line">list_c = []</span><br><span class="line">for item in list_a:</span><br><span class="line">    if item &gt; 5:</span><br><span class="line">        list_c.append(item)</span><br><span class="line">    else:</span><br><span class="line">        list_c.append(1)</span><br></pre></td></tr></table></figure></p>
<h4 id="python-远程分享目录">python 远程分享目录</h4>
<p>ifconfig -&gt; eno1 -&gt; 114.212.86.85</p>
<p>python2 -m SimpleHTTPServer &gt; 本地下localhost:
8000可以查看目录</p>
<p>专注于当前的事，不要老是去做一些有的没的东西</p>
]]></content>
      <categories>
        <category>python</category>
        <category>study</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>python thinking</title>
    <url>/2019/python-thinking-7ea8bfd5048c/</url>
    <content><![CDATA[<p>python学习指南</p>
<h2 id="tuple-list-dict的基本操作">tuple, list, dict的基本操作</h2>
<ol type="1">
<li><p>增加元素，默认</p></li>
<li><p>重新赋值元素</p></li>
<li><p>删除元素</p></li>
<li><p>查找某元素是否存在</p></li>
<li><p>list的切片</p></li>
<li><p>元素统计</p></li>
<li><p>互相转化</p></li>
</ol>
<h2 id="输入输出">输入输出</h2>
<ol type="1">
<li><p>标准输入和文件输入</p></li>
<li><p>标准输出和文件输出</p></li>
<li><p>格式化输出 "%s "%('da','ada')</p></li>
</ol>
<h2 id="目录管理">目录管理</h2>
<ol type="1">
<li>打开路径、目录生成、删除等</li>
<li>保存</li>
</ol>
<h2 id="面向对象">面向对象</h2>
<ol type="1">
<li>继承，多继承</li>
<li>多态</li>
<li>参数化</li>
</ol>
<h2 id="数据处理">数据处理</h2>
<p>Numpy, ndarray - 数据整理和清理、子集构造和过滤、转换等 -
数组算法，如排序、唯一化、集合运算 - 描述统计和数据聚聚合/摘要运算 -
异构数据集的合并/连接运算 - 条件逻辑表述为数组运算 - 数据的分组运算</p>
<p>pandas</p>
<p>Matpliot</p>
<p>数学函数图形</p>
<p>平面图</p>
<p>散点图</p>
<h2 id="注释与测试">注释与测试</h2>
<ol type="1">
<li><p>文件注释</p></li>
<li><p>函数注释</p></li>
<li><p>单元测试</p></li>
</ol>
<p>file的打开，文件的打开</p>
<p>环境的特殊的变量的设置</p>
<p>函数</p>
<p>类，抽象化设计</p>
<p>随机数</p>
]]></content>
      <categories>
        <category>tools</category>
        <category>python</category>
        <category>thinking</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python pylint</title>
    <url>/2019/python-pylint-29782d020373/</url>
    <content><![CDATA[<p>https://blog.csdn.net/Jason_Lewis/article/details/75386598</p>
]]></content>
      <categories>
        <category>coding_reference</category>
        <category>pylint</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pylint</tag>
      </tags>
  </entry>
  <entry>
    <title>paper-read-graphsage</title>
    <url>/2019/paper-read-graphsage-6ea74422864d/</url>
    <content><![CDATA[<p>Overview:</p>
<p>stochastic generalization of graph convolutions, and it is useful for
massive, dynamic graphs that contain rich feature information.</p>
<p>看自身的PPT, 实际上关于k的提法，从1,2,...,k其他是对于每个节点。
比如说图上的每个节点，先分别做一跳的表示。
不断地一起共同的做，最终可以发现实际上所求的目标就最终表示是k跳来决定的。</p>
<p>关键表达式其实就只有那一个。</p>
<p>为什么inductive?
实际上感觉是在图上把问题给固定下来了，也就是说实际上，来一个性的点之后，直接按照之前的所有的函数和模式，学习新的表示即可。
&gt; 此时的表示是基于之前训练得到的新的表示? 还是旧的表示? &gt;
之前的学习是学习对应的函数和参数，所以说?</p>
<blockquote>
<p>那么对于未知节点的表示，实际上又是如何查找和运行的呢?</p>
</blockquote>
<p>hierarchical 层次</p>
<p>hierarchical pool: 层次遍历。 &gt; 如果将gnn适用于对整个图分类。</p>
<p>Characterize GNN's discriminative power</p>
<h2 id="paper">paper</h2>
<h3 id="dataset">dataset</h3>
<h4 id="ciatation-data">Ciatation data</h4>
<p>predicting paper subject categories. six biology-related fields for
2000-2005. node lable: six</p>
<p>n = 302421, fix_size = 9.15 undirected citation graph dataste.</p>
<p>train: 2000-2004 2005 test. 30% for validation</p>
<p>features: node degrees and processed the paper abstracts
300-dimensional word vectors.</p>
<h4 id="reddit-data">Reddit data</h4>
<p>which community different Reddit posts belong to.</p>
<p>users post and comment on content in different topical
communities.</p>
<p>node label: the community.</p>
<p>sampled 50 large communities. post-post graph.</p>
<blockquote>
<p>in the month of September, 2014.</p>
</blockquote>
<p>n=232965, fix_size=492 first 20 days for training and remaining for
testing (0.3 for validation)</p>
<p>features: 300-dimensional GloVe CommonCrawl word vectors.</p>
<p>each post concatenated 1. the average embedding of the post title. 2.
the average embedding of all the post' comments 3. the post's score. 4.
the number of comments made on th post</p>
<h4 id="protein-protein-interactions">Protein-protein interactions</h4>
<p>the task of generalizing across graphs. requires learning about node
roles rather than community structure.</p>
<p>protein roles, in terms of their cellular functions from gene
ontology. 我们未来了解节点的角色，即蛋白质的作用是什么, protein.
使用基因本体论为它们做标记。</p>
<p>节点与节点之间交互会构成人体的不同组织</p>
<p>various protein-protein interaction graphs.</p>
<p>node: protein graph: human tissue.</p>
<p>features: positional gene sets, motif gene sets and immuological
signatures labels: gene ontology sets</p>
<p>n=2373, fix_size = 28.8</p>
<h3 id="theoretical-analysis">5. Theoretical analysis</h3>
<p>为了探究GraphSage如何学习图结构，尽管它本质上可能是基于功能。
作为案例研究，我们考虑了graphsage是否可以学习预测节点的聚类稀疏，即节点1跳领域内闭合的三角形比例。
&gt; 反映在图上是连在一起的意思吗？
聚类系数是衡量节点本地淋雨聚类程度的一种流行度量，它是许多更复杂结构图案的基础。</p>
<p>我们可以证明算法1能够将聚类稀疏近似为任意精度</p>
<p>Theorem 1?: 公式表达</p>
<p>对于每个图，都有一个算法1的参数设置，这样，如果每个节点的特征都不同，则它可以将改图的聚类系数近似为人影精度。</p>
<p>即使从绝对连续的随机分布中采样节点特征输入，GraphSage也可以了解局部图的结构。</p>
<p>证明背后的基本思想是，
如果每个节点都有唯一的特征表示，则我们可以学习将节点映射到指标向量并识别节点领域。
定理1的证明依赖于池聚合器的某些属性，所以更优 ### Appendices</p>
<h4 id="algorithm-2">Algorithm 2</h4>
<p>首先第一步预处理， K轮： Bk=B B(k-1) = Bk 加上 u的点的邻居 B(k-2) =
B(k-1) 加上所有点的邻居 &gt; ? 反着来违反直觉，然后k=2是，即采样了S2,
又采样了S1*S2 2-hop neighbors. &gt; 解释说这里其实是采样过程而已</p>
<p>12-13 解释说运算肯定是只包括当前所需要的运算</p>
<h4 id="dataset-1">Dataset</h4>
<h4 id="deatails">Deatails</h4>
<ol type="1">
<li>Hyperparameter selection Random Walk: 50 random walks of length 5
from each node in order to obtain the pairs needed for the unsupervised
loss. Python, Perozzi[28]</li>
</ol>
<p>Logistic regression model SGDCClassifier from the scikit-learn Python
package[26], with default settings.</p>
<p>Hyperparameter selection DeepWalk: 0.01, 0.001, 0.0001 initial
learning rates. 2<em>1e-6, 2</em>1e-7, 2*1e-8 unsupervised model</p>
<p>big 1024, small 512</p>
<p>All models user rectified linear units All the unsupervised GraphSAGE
models and DeepWalk used 20 negative sample with context distributaion
smoothing over node degress using a smoothing parameter of 0.75.</p>
<p>rates: 0.2, 0.4, 0.8</p>
<p>batch sizes 512, batch size 64</p>
<ol start="2" type="1">
<li>Hardware 4 NVIDIA Titan X Pascal GPUS (12Gb of RAM at 10Gbps speed),
16 Intel Xeon CPUS(E5-2623 v4 @ 2.60GHz)</li>
</ol>
<p>3 days in a shred resource setting. &gt; 查一下这些硬件</p>
<p>Titan X GPU: 4-7 days full resources were dedicated</p>
<ol start="3" type="1">
<li><p>Notes on the DeepWalk implementation DeepWalk is also equivalent
to the node2vec model with p=q=1</p></li>
<li><p>Notes on neighborhood sampling: subsample edges so that no nodel
has degree large than 128. we only sample at most 25 neighbors per node.
downsampling allows us to store neighborhood information as dense
adjacency list, improves computational efficiency.</p></li>
</ol>
<p>Reddit data, downsampled the edges of the original graph as a
pre-processing step, since the original graph is extremely dense. ##
code</p>
<h3 id="tensorflow">tensorflow</h3>
<p>stochastic generalization of graph convolutions.</p>
<p>GraphSage now has better support on smaller, static gaphs, don't have
node features. 'identity features"</p>
<p>task of inductive generalization(generating embeddings for nodes that
were not present during training)</p>
<p>identity features: increase the runtime. potentially increase
performance(at the usual risk of overfitting)</p>
<p>GraphSage is intended for use on large graphs &gt;100000 nodes.</p>
<p>example_data: ppl</p>
<ol type="1">
<li>running the code if your benchmark does not require generalizing to
unseen data, --identity_dim ?flag to a value int ht range [64, 256] &gt;
目标是不需要inductive? 没错吧，那么不应该是也可以用到自身特征吗？ make
the model embed unique node ids as attributes. increase the runtime and
number of parameters , performance. &gt; node ids,
节点标号作为属性，什么鬼？<br />
set this flag and not try to pass dense one-hot vectors as featres(dut
to sparsity) &gt; 单独抽出来可以理解 the "dimension" of identity
features specifies how many parameter there are per node in the sparse
identity-feature lookup table. &gt;
这个维度是怎么展现的？不精确的？</li>
</ol>
<p>example_unsupervised.sh</p>
<p>set a samll max iteration， very near convergence ?</p>
<p>example_supervised.sh</p>
<p>for PPI data &gt; mulit-output?
除了节点编号，还要输出什么？懂了！，这里的意思是individual nodes to
belong to multiple classes. --sigmoid, defalut: one-hot</p>
<ol start="2" type="1">
<li>Input format --train_prefix: specifies the following data files.
X-G.json: a networkx-specified file decribing the input graph. Nodes
have 'val' and 'test' 表示是交叉验证集和测试集的一部分 X-id_map.json:
graph_node-ids映射到连续的整数 X-class_map.json: graph node ids map to
classes X-feat.npy: a numpy-stored array of node features. ordering
given by id 应该是对应的整数 X-walks.txt: a text file random walk
co-occurrences (one pair per line) &gt; 共同出现的节点标号</li>
</ol>
<p>run random walks. graphsage.utils run_walks</p>
<ol start="3" type="1">
<li>Model variants
<ul>
<li>graphsage_mean</li>
<li>graphsage_seq</li>
<li>graphsage_maxpol</li>
<li>graphsage_meanpool</li>
<li>gcn</li>
<li>n2v_an implementation of DeepWalk</li>
</ul></li>
<li>logging directory
<ul>
<li>--base_log_dir: default to the current directory;
<sunp/sunsup>--<data_prefix>/graphsage-<model_description>/</li>
<li>supervised model output F1 scores</li>
<li>unsupervied train emmeddings and store them。 val.npy, val.txt.
5-10Gb &gt; unsupervised 干什么？ 再看论文， use to the downstream
machine learning applications. <code>eval_scripts</code></li>
</ul></li>
</ol>
<h3 id="代码">代码</h3>
<ol type="1">
<li>tesorflow: 代码未看，速度快 python -m graphsage.supervised_train
--train_prefix ./example_data/ppi --model graphsage_mean --sigmoid</li>
</ol>
<p>python -m graphsage.unsupervised_train --train_prefix
./example_data/ppi --model graphsage_mean --max_total_steps 1000
--validate_iter 10</p>
<blockquote>
<p>in order to learn useful, predictive representations in a fully
unsupervised setting, use graph-based loss function.
因为是无监督，所以loss是自己定义出来的，不需要真实标记参与进来 修改PPT,
这里应该是无监督学习</p>
</blockquote>
<p>与GCN最大的区别，在于多了concat操作。</p>
<p>samp_neighs = [sample_neigh + set([node[i]])]</p>
<p>代码还有一个mock的bug未解决</p>
<p>注意到这里其实有好几个loss functions</p>
<ol start="2" type="1">
<li>pytorch: 代码已看，速度快 总结：总依据是原本的算法。 word
embedding特征, cora, pubmed引用数据集是这么做的！ 其他建议</li>
</ol>
<p>每轮是batch, 训练数据的读入。 256, 1024, 然后random.shuffle.
下次再参与训练。</p>
<p>在这里的特征使用了word embedding gcn: 81.5 4s, 训练方式是所有
graphsage: 0.874 两个进行对比，不同在哪里！</p>
<p>问题？ graphsage说将gcn改变为inductive, 就是这里进行改变吗？</p>
<p>有证明sample取不同的阈值，可以达到不同的精确度</p>
<h2 id="论文查找">论文查找</h2>
<p>论文： Hamilton W, Ying Z, Leskovec J (2017) Inductive Representation
Learning on Large Graphs</p>
<h3 id="parallel-215">parallel 215</h3>
<ol type="1">
<li><p>Neugraph</p></li>
<li><p>parallel computation of graph embedding: ! large graphs. framwork
for parallel computation of a graph embedding using a cluster of compute
nodes with resource constraints. propose a new way to evaluate the
quality of graph embeddings that is independent of a specific inference.
computation scales well, while largely maintaining the embedding
quality.</p></li>
<li><p>Accurate, Efficient and Scalable Graph Embedding &gt; a major
challenge is to reduce the complexity of layered GCNs and make them
parallelizable and scalable on very large graphs</p></li>
<li><p>Towards Efficient Large-Scale Graph Neural Network
Computing</p></li>
</ol>
<p>3篇文章是互不影响的关系</p>
<p>interesting</p>
<ol type="1">
<li><p>Deep Inductive Graph Representation Learning</p></li>
<li><p>large-Scale learnable graph convolutional networks &gt; subgraph
train</p></li>
<li><p>Generalizable Resource Allocation in Stream Processing via Deep
Reinforcement Learning &gt; RL</p></li>
<li><p>Deep Neural Representation Learning on Dynamic Graphs via
Self-Attention Networks &gt; 动态图</p></li>
</ol>
<h3 id="distributed">distributed</h3>
<h3 id="cluster-system">cluster system~~</h3>
]]></content>
      <categories>
        <category>gnn</category>
      </categories>
      <tags>
        <tag>gnn</tag>
      </tags>
  </entry>
  <entry>
    <title>spark study thinking</title>
    <url>/2019/spark-study-thinking-1-649b108ce6d3/</url>
    <content><![CDATA[<p>spark中map就是把数据集分配到各个节点上，然后各个节点执行 &gt;
思考Partioner的过程是什么</p>
<p>Partitioner感觉上是全局变量 &gt;
HashPartitioner就是把Hash桶做成了</p>
<p>inputSplit, 一定要比它大，这样就可以使得每一部分执行的数据少</p>
<p>flatMap并没有那么简单，也就是说 flatMap = map + flatten &gt;
flatMap(t=&gt;f(t)) f返回的是什么类型，最终结果就是什么类型</p>
<p>reduce(x+y=&gt;x) reduceByKey(x+y=&gt;x)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mapPartitions(iter =&gt; &#123;    // mapPartitions即 Mapper端的数据进行了Combine计数</span><br><span class="line">      val pair = mutable.Map.empty[WrapArray, Long]</span><br><span class="line">      while (iter.hasNext) &#123;</span><br><span class="line">        val arr = new WrapArray(iter.next())</span><br><span class="line">        val value = pair.get(arr)</span><br><span class="line">        if (value == None) &#123;</span><br><span class="line">          pair(arr) = 1L</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          pair(arr) = value.get + 1L</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      pair.iterator   // 这种写法很精妙，进行学习</span><br><span class="line">    &#125;)</span><br><span class="line">    // 每次返回一个迭代器，下次还可以考虑继续使用这个迭代器</span><br></pre></td></tr></table></figure>
<p>基本类型的迭代器可以定义</p>
<p>自定义迭代器
https://blog.csdn.net/XiaoHeiBlack/article/details/77014626</p>
<p>groupByKey(): RDD, Iterable[V] reduceByKey(): U+U=&gt;U</p>
<blockquote>
<p>思考迭代器</p>
</blockquote>
<p>FPGrowth思路整理</p>
<p>MLlib做法： 1. 产生每个分区的数据集 &gt; val part =
partitioner.getPartition(item), 这一步依然感觉很懵逼? &gt;
mapreduce中map的过程实际上就不过是map的数据集的个体变大的。所以按照自己想的就是
&gt; 代码这里的感觉就是用的默认集群的？？？ 2.
将每个分区的数据集合并为一棵子树 3. 将所有分区合并为一个大的子树 4.
从这个大的子树中提取对应的频繁项集</p>
<p>defaultParallelism(): cluster default trait: 相当于接口</p>
<p>sc.text(): 这里默认的也是这个参数</p>
<p>FPNewDef做法 1. 产生对应分区的数据集 2. 对每个分区进行相同合并 3.
数据重新写为(key, value) 4. 映射到对应的分区 &gt;
所以就要用分区内的排序来做 repartitionAndSortWithinPartitions
https://www.jianshu.com/p/5906ddb5bfcd 5.
分区内根据顺序收集，从而形成条件树 &gt;
这里可以直接根据收集结果来产生频繁项集啊</p>
<p>NewIdea 1. 产生分区的数据集 2. 可选，Combine(需要开销) 3.
数据重新分为(key, value) 4. reduceByKey &gt;
收集对应的key，然后直接产生条件树</p>
<blockquote>
<p>因为类没有实现迭代器的特性，所以不能这样用？
居然可以用排序就可以了，牛逼，牛逼
如果是对所有的元素做某种运算，但不需要产生最后的结果，只需要foreach</p>
</blockquote>
<blockquote>
<p>第一个想法，一个是将每个(key,value)的value映射为一个FPNewNode,
然后添加，需要重新改写数据结构
第二个想法，reduceByKey，先收集到一个集合，然后再对该集合进行下一步做法</p>
</blockquote>
<p>? spark任务调用顺序</p>
<p>spark-shell --master spark://slave033:7077</p>
<p>例子： 1 2 3 4 1 2 4 2 3 2 4</p>
<p>partion: 2</p>
<p>1: 1 2 3 4 -&gt;<br />
1 2 4</p>
<p>2: 2 3 2 4</p>
<p>总结：
FPTree中的extract是对所有的项都要来直接求解，试着不需要。只需要对某一个地方进行求解即可。
然后这里的 extract又是个递归</p>
<p>summries中包含所有元素</p>
<blockquote>
<p>怎么生成数据？关于大数据集的
slave033上的文件和hdfs上的文件有什么区别？ &gt;
这个问题实际上是想问这里用到的是啥？</p>
</blockquote>
<p>本地进行模拟运行 ## 学到的知识</p>
<h3 id="spark.default.parallelism">1. spark.default.parallelism</h3>
<blockquote>
<p>如果不进行设置，默认值是底层HDFS的block数量（HDFS中有设置）;
一般这是个特别需要设置；
在默认情况下，非常小，如果不调节它就起不到分布式的效果了。通常来说也不会只调节到num_executors*executor-cores，因为相当于只给每个节点分配了对应很少的值，所以实际上的话，是在2~3倍。为什么呢，因为有的task运行速度快，有的慢，为了避免快的执行完等慢的，所以可以考虑多加进行设置，这样的话就能充分利用到集群了。
? hdfs block的数量？？ https://www.iteblog.com/archives/1659.html</p>
</blockquote>
<h3 id="scala语法">2. scala语法</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class FPTree</span><br><span class="line">  def merge(other: FPTree[T]): this.type = &#123;</span><br><span class="line">    other.transactions.foreach &#123; case (t, c) =&gt;</span><br><span class="line">      add(t, c)  // 这里就默认的是this.add()</span><br><span class="line">    &#125;</span><br><span class="line">    this</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="spark参数配置优先级">3. Spark参数配置优先级</h3>
<ol type="1">
<li>SparkConf</li>
<li>spark-submit spark-shell</li>
<li>spark-defaults.conf &gt; 在文件中进行配置 ### 4. 零散知识点</li>
</ol>
<h4 id="提交">4.1 提交</h4>
<ol type="1">
<li>spark-shell</li>
</ol>
<ul>
<li>--master spark://host:port本身的运行模式</li>
<li>--deploy-mode: driver端位于哪里</li>
<li>dirver-memory, dirver-cores &gt; driver-memory,
driver-cores指的是driver端执行的情况</li>
</ul>
<ol start="2" type="1">
<li>运行模式</li>
</ol>
<ul>
<li>standalone模式</li>
<li>spark on yarn, dirver在本地</li>
<li>spark on yarn, dirver在集群 &gt;
其实standalone和其他没有什么区别吧，主要就在于standalone是主模式，而yarn各个节点都相同</li>
</ul>
<ol start="3" type="1">
<li>yarn</li>
</ol>
<p>yarn: 整个资源管理在一个资源池中，想要获取资源通过在资源池中进行获取
&gt;
这里yarn把整个集群集合在了一起，具体yarn是怎么执行的需要看居然的yarn的东西。</p>
<p>然后，关于yarn的就有几个特别的参数：</p>
<p>worker是资源分配单位 executor是任务执行单位</p>
<p>executor的内存主要分为几块 1. 执行自己的代码所需要的内存,默认值20% 2.
shuffle所需要的内存，默认20% 3. 持久化的内存,默认60%</p>
<p>资源参数调优: 1. num-executors: 总的executor数 &gt;
总共的任务执行单元</p>
<ol start="2" type="1">
<li>executor-cores</li>
</ol>
<h3 id="inputpath">inputPath</h3>
<blockquote>
<p>在哪里？ hdfs://master:port/根路径</p>
</blockquote>
<blockquote>
<p>默认情况下为master节点上的9000端口</p>
</blockquote>
<p>注意到一个问题： aggreateByKey一直都是根据key来处理
reduceByKey(partioner, <em>+</em>) 可以使结果放在对应的位置上</p>
<p>学长的代码，想法依然是那样的。感觉上还是最终落在了收集fpTree上，而且并没有什么优化啊。</p>
<p>前面汇聚相同的什么用?</p>
<p>在倒数第二个的时候依然是形成fpTree,然后提取</p>
<h2 id="scala编程">scala编程</h2>
<p>注意区分Iterator和</p>
<h2 id="师兄代码的想法">师兄代码的想法</h2>
<p>建树开销，即考虑的是</p>
<p>spark-submit 默认参数在 spark-defaults.conf中 ？
master是否进行资源的分配</p>
<p>--dirver-memory https://www.cnblogs.com/weiweifeng/p/8073553.html</p>
]]></content>
      <categories>
        <category>spark</category>
        <category>thinking</category>
      </categories>
      <tags>
        <tag>thinking</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>spark study thinking</title>
    <url>/2019/spark-study-thinking-a261c8159f04/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">val file_split = args(2).toInt  // 文件的切分，将文件划分为多少个mapper</span><br><span class="line">val numPartition = args(3).toInt // mapper后，形成多少个reducer</span><br><span class="line"></span><br><span class="line">// 还有其他建议参数</span><br><span class="line">// driver-memory, driver-cores 内存主要是启动内存，存储启动的数据，</span><br><span class="line">// ? driver所使用的数据，首先数据本身是可以放在多个位置吧，然后，其次，数据来源是本地文件的话，应该也可以在worker节点上，因为这样本身就可以做，在task执行时，直接就近选取接地那执行即可</span><br><span class="line">// 其而，是当执行collect()时， 数据将被拉回driver端？？？</span><br><span class="line"></span><br><span class="line">// executor-memory, executor-cores:</span><br><span class="line"></span><br><span class="line">// spark-default-parrallism: 如果一直从头默认，尽管是reduceByKey, 它有个参数partitioner也使用的是默认，那么这样看来也就是说基本上都是这个参数，除非中间设置repartitiones; 这里官方的建议是总cores的2-4倍</span><br><span class="line"></span><br><span class="line">// 然后 executor和worker,driver的对应, 首先系统会计算driver,worker剩下的内存，然后按照某种策略（一个worker装满再装下一个，还是一个一个worker地装）, 于是就形成了执行单元。</span><br><span class="line"></span><br><span class="line">// 对于每个executor, 在执行时必然需要用到数据，会采用就近原则，比如使用的是hdfs架构时，会优先从某个就近的地方读取</span><br><span class="line"></span><br><span class="line">// 分给每个executor的内存，有几个用途：1. 运行，包括代码执行, 所以有堆外内存，用于调节GC; </span><br><span class="line"></span><br><span class="line">// executor:  executor-cores， 按系统能给的最大程度在每个worker上给予的方式来分配executor. 然后executor, 然后，关于executor启动以及后面的执行又是怎么折腾的呢？怎么看出负载均衡这些东西的？ spark-ui</span><br><span class="line">https://blog.csdn.net/dandykang/article/details/48525467</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>所以整个并行化，spark需要关注的点</p>
<ol type="1">
<li><p>mapper前的预处理操作</p></li>
<li><p>数据传送到mapper的开销</p></li>
<li><p>mapper的个数 &gt; task执行完后的负载均衡,
有小任务和大任务，有的先执行完，有的后执行完</p></li>
<li><p>mapper数据汇集的通信开销 &gt; 这个过程又名shuffle, shuffle read:
抓取数据, 这里涉及到将mapper的结果抓取过来，然后进一步考虑怎么搞;
shuffle write: 将数据按key值分发到各个reducer上 &gt;
感觉上处理shuffle的是保存一个类似hash的东西来做的</p></li>
<li><p>reducer的个数 &gt; reducer再将结果汇聚到driver端</p></li>
</ol>
<p>关于一些默认的东西一般在spark安装的文件里，进行spark安装环境的解析</p>
<p>然后具体怎么做的，就主要的想法是参照源码</p>
<p>然后，涉及到整个系统的：</p>
<ol type="1">
<li><p>环境准备，怎么将所有东西给放在一起</p></li>
<li><p>代码执行</p>
<ul>
<li>集群初始化：面向对象的思想，首选一个外部消息导致整个事件触发，然后如此直到达到某个结束标志
<ul>
<li>调度单位，将事情作为不同方面进行调度；比如，掌管通信的，掌管DAG的，然后，再起对应的名字；最终再进行来做</li>
</ul></li>
<li>Dirver端执行代码，分配到mapper端，惰性求值，当在mapper端遇到需要收集数据，即需要将这个数据分离时，即认为该stage结束，则开始进行运算。
这里会进行DAG世袭图的计算。 &gt; DAG世袭图的提出 &gt; 查看sparkUI</li>
<li>如何保证容错 &gt;
这里的想法就是在整个Driver端维持？，还是？。不对！应该是会维持计算图，首先进行思考，优先从就近的前一步抓取未计算完的数据。所以，这就意味着把某一步的RDD计算结果放在某一个位置上于是就显得很重要了！</li>
<li>这里的checkpoint，已然忘记是不是说的也就是这个感觉</li>
</ul></li>
<li><p>数据库操作，SQL层抽象，存储，hdfs存储到每个节点</p></li>
</ol>
<p>SparkUI的几个东西： 18080; 系统： 8080 - jobs
job的概念，其实也就是一次map/reduce过程，当然也可以看作是action操作结束后。唯一需要特别注意的是，job最终即action的结果又会回到Driver端，由系统再次分配job.
一个SparkContext中一个任务，一个任务多个job. &gt; 物理时，Master, Slaves
&gt; 工作时，Driver, Worker
Dirver不等于Master，因为Dirver根据不同的执行方式，可以分布在不同的位置，比如
各种部署模式 &gt; &gt; 本地模型 local[4], 用来模拟线程;
Client提交任务，所以我们很多时候一般都是上环境进行提交任务Driver;
在Standalone, 这里指的是master单独的意思，即spark defalut，
此时Master=Driver;
其余有两种，一种是本地为Dirver端，与集群进行交互，但是本地机器不是集群机器，当运行大量任务时，会带来很严重的开销';一种是本地把代码提交到集群，集群再选择一个节点做Driver，注意此时每个节点的地位相同
- event timeline: executor的执行状态
<font color="red">可以分析出来是否负载均衡</font> - DAG visualization:
整个的stage图，就是按宽stage和窄stage来进行划分 - Skipped Stages, Failed
Stages - stages 对于每个stages由着以下的指标： - 任务延迟 - 持续时间 -
GC Time - Shuffle Red Blocked Time - Shuffle Read Size</p>
<pre><code>- 每个executor的状态数据
- 每个tasks的执行状况</code></pre>
<ul>
<li>storage 存储，关于在每个点或者其他点上存储的东西</li>
<li>environment
<ul>
<li>runtime information</li>
<li>spark properties</li>
<li>classpath entries</li>
</ul></li>
<li>Executors: 每个executors的执行状态</li>
</ul>
<p>整个Spark技术内幕主要包括以下几个方面： - RDD的实现</p>
<ul>
<li><p>Scheduler模块 &gt; 关于调度如何实现的</p></li>
<li><p>Deplo模块 &gt; 消息传递，容错，运行模式</p></li>
<li><p>Executor模块 &gt; 分配， task的执行</p></li>
<li><p>Shuffle模块 &gt; Hash Based Read/ Shuffle Write</p></li>
<li><p>Storge &gt; 存储模块</p></li>
</ul>
<p>Spark编程需要的内容 - scala常用数据类型的了解 - spark编程环境的问题 -
RDD编程 &gt; 创建RDD， RDD的各种操作，常见转化和行动操作， 持久化 -
键值对操作<em> &gt; 主要说的是PairRDD, 目前来说，并没遇到 -
数据读取和保存 &gt; 本地和hdfs://master:9000<br />
- 进阶</em> &gt;
累加器，广播变量，基于分区操作，与外部程序间的管道，数值RDD的操作 -
运行spark-submit, 打包和依赖 - 关键性能度量 - 并行度 - 序列化格式：
这里好像只涉及到使用 kryo工具 - 内存管理 - 硬件供给 - Spark Sql* &gt;
未涉及到，好像后面可以通过sql语句直接得到，所以超级简单</p>
<p>一些实战 &gt; 进行数据分析，从而来提高熟练度</p>
<h2 id="语言编程">2. 语言编程</h2>
<p>数据结构 1. 变量，常量 2. 物理上不同的类型 - 基本类型，Int,String -
静态数据结构，长度不可变，比如List, Array, - 变长 vector, ArrayBuffer; -
hash结构， - tree结构， 堆 - 抽象结构，栈、队列 - (key, value)对 &gt;
注意思考，一般这种的内部实现是什么样的; 比如说平衡二叉树 3. 访问特性来看
- 迭代器，只支持iterator - travesac: 支持随机访问 -
支持从前或者从后访问</p>
<ol start="3" type="1">
<li><p>基本操作符： +, -, ==, equals, &gt;=, ., -&gt;</p></li>
<li><p>扩展操作符： ++= --</p></li>
<li><p>常见操作</p>
<ul>
<li>合并两个集合</li>
<li>插入某个元素，某个元素不存在</li>
<li>删除某个元素，元素不存在</li>
<li>查看某个元素是否存在</li>
<li>判断是否为空</li>
<li>初始化</li>
<li>是否为满</li>
<li>清空</li>
<li>转换为其他集合 &gt; 默认hashCode, ==, euqals的实现,
&gt;小于比较的实现</li>
</ul></li>
<li><p>泛型</p>
<ul>
<li>支持所有类型 &gt; 迭代器</li>
<li>抽象的算法</li>
</ul></li>
<li><p>类</p>
<ul>
<li>抽象类， 接口</li>
<li>抽象抽象类， traits</li>
<li>类的继承，派生； 可以互用的方法</li>
</ul></li>
<li><p>其他编程范式</p>
<ul>
<li>map(), reduce()等以及扩展的操作，还有变量在里面或者变量在外面</li>
</ul></li>
<li><p>基本常见语句的操作：循环，条件；特殊的语句</p></li>
<li><p>其他类别：</p>
<ul>
<li>文件操作，交互</li>
<li>异常处理，捕捉 &gt; try, catch; assert(); 宏语句来一件更改是否执行,
继承测试</li>
</ul></li>
<li><p>多文件</p>
<ul>
<li><p>整个项目，组；</p>
<ul>
<li>资源文件</li>
<li>配置文件</li>
<li>测试文件</li>
<li>源代码
<ul>
<li>包的概念， 包这里的概念与C中不同可以理解为物理上的文件组织转换为了包
&gt; 更进一步从文件上分割了各个包，使得文件的组织更加合理
<ul>
<li>功能划分： 实体，数据库访问层，网页层，逻辑层 &gt;
按照功能，或者考虑用其他的方式进行划分</li>
</ul></li>
<li>类的概念</li>
</ul></li>
</ul></li>
<li><p>引用已有代码： 这里是人类的精华，使用依赖的概念。</p>
<ul>
<li>如何进行管理这些依赖的东西？ jar(java), .net(C++类库)</li>
<li>在自己的工程中引用: mvn管理， pom文件配置，自动化处理包 &gt;
将资源放在云端，maven， 需要地则通过网络拉取在编译时进行整合到程序中
&gt; 这里是在一般机器所有层上进行扩展的。 &gt; 比如如果是java,
首先机器上是具备有jvm虚拟机的。C++, MinGW,
所以之后的包的所有东西都是基于这些基本的接口进行调用的。所以是更上一层的抽象.</li>
</ul></li>
<li><p>因为涉及到各种功能，所以需要考虑计算机的基本功能进行支持，比如</p>
<ul>
<li>计算机网络：联网与其他计算机进行交互</li>
<li>计算机文件系统： linux相关命令</li>
<li>安全：
设置网络访问权限，网络防火墙，从小到大网络的权限的设置。从网络向下到各层文件，所以又涉及到各层文件的私密网络。
外加网络通信</li>
<li>接口，与外部显示器，音箱，键盘等各种输入输出设备的兼容</li>
</ul></li>
<li><p>再向下，计算机上层功能的实现，全都可以抽象为一台具有CPU计算，存储和输入输出的机器。输入则认为是代码，输出则认为是结果。
&gt;
不管是图像显示还是声音，可以看作是输出在特定物理设备上的反映。它遵从一定的物理表现形式就可以表现为某个点。声音是频率，图像是光的变化，即像素点
&gt;
对于文件系统的功能，可以看作是有超大的一块内存，然后按某种特别地形式对文件进行组织管理，于是乎就可以抽象出各类文件。这块地方其实先划分为块，然后再划分为其他。也可以分为系统区，文件节点区，具体文件区，其他所有的不过是层抽象。
&gt;
对于安全，不过是对输入输出进行处理。计算机网络，对输入进行处理</p></li>
<li><p>再向下，CPU可以抽象为一个累加器？，或者其他什么，这一层可以放在上层。根据图灵机知道这是可行的；然后，实际上可以由累加器来看出由0,1的基本的与，或，非，对应于各类的逻辑电路，最终然后得到各种功能的叠加</p></li>
<li><p>最向下，于是就到了逻辑管层</p></li>
<li><p>往上，编译原理，当一段抽象代码出来时机器是怎么做的呢，首先，将所有依赖的东西加进来然后构成源代码。接着，将源代码进行词法、语法分析，接着进行会形成一些底层一点的东西，进行符号表解析，最简单的理解就是把所有文件，都不歧义地翻译为一个文件的内容。当然，中间因为是对多文件进行翻译，所以需要一些基本的辅助数据结构，如符号表。因为从某种意义上来说，最终结果为汇编语言，而汇编语言并没有什么特别的语言结构，所以需要把变量和函数都给简单地组织为需要进行访问几次内存，等来做。
最终代码执行阶段，所谓代码执行，也就是将静态转换为动态，根据代码中初始化的东西进行分配资源，根据算法进行代码运行，然后最终出结果
&gt;
编译器一定都是有shell终端的，所以很多时候远远可以考虑使用shell终端来进行机器</p></li>
</ul></li>
<li><p>如果共享网络</p></li>
</ol>
<p>new 1. 算法 - 并行化算法 - 串行化算</p>
]]></content>
      <categories>
        <category>spark</category>
        <category>thinking</category>
      </categories>
      <tags>
        <tag>thinking</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>study todo</title>
    <url>/2019/study-todo-475e42e6f3b0/</url>
    <content><![CDATA[<ol type="1">
<li><p>日志，了解加使用</p></li>
<li><p>命令行</p></li>
<li><p>环境</p></li>
<li><p>计算机基础4本经典书籍</p>
<ul>
<li>编译原理龙书</li>
<li>深入理解计算机系统</li>
<li>计算网络：自顶向下</li>
<li>现代操作系统</li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>todo</category>
        <category>study</category>
      </categories>
      <tags>
        <tag>todo</tag>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>spark study</title>
    <url>/2019/spark-study-ee540432fb17/</url>
    <content><![CDATA[<p>sc.textFile(,numpartition)</p>
<p>如果numpartition参数比实际划分的SplitSize小的化，则按照SplitSize的数目在每个executor上执行；否则就按照numpartition参数进行执行；</p>
<p>一定要区分资源调度和任务执行</p>
<p>在任务执行阶段，每个executor只会按照其对应的InputSize单位来执行数据。如果有多个executor,
则按照多个的executor来进行执行</p>
<h1 id="写代码要考虑的事">写代码要考虑的事</h1>
<p>代码之前——环境，环境如何配置？ 代码载体——IDE, 有哪些特点？
代码语言——常用操作和模板进行总结，语法特性要能表达出来，用语言能够实现出任意自己想实现的犯方法
- 角度1 - 数据结构 &gt; 1. 对基本数据结构操作的了解 &gt; 2.
这些操作的输入、输出参数是什么？如何实现的？快慢如何 &gt; 3.
如何自己定义？ - 算法 &gt;
设计算法，算法正确性，算法的时间空间复杂度，算法的实现，代码复杂度 -
角度2 基本数据结构，字符串，数组，元祖，列表，字典这些抽象的数据结构；
对象，多态，操作符重载， 异常， debug</p>
<p>代码调试——如何测试自己的代码是否正确 &gt; 测试语句，继承测试
代码维护——Git, 版本控制 代码执行——编译器执行的角度（一般不用去考虑）
代码上线——命令行设置</p>
<blockquote>
<p>非设计算法，主要调用接口，那么关注代码的含义，代码对应着实际上有哪些操作
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import spark</span><br><span class="line">// 前面一系列的环境配置先耍开</span><br><span class="line"></span><br><span class="line">def main()&#123;</span><br><span class="line">    </span><br><span class="line">    val conf = new SparkConf().setAppName().setMaster</span><br><span class="line">    conf.set()  // 这里可以配置哪些项？这些项又表示着什么？</span><br><span class="line"></span><br><span class="line">    val sc = new SparkContext()   // 2.3之后spark是怎么执行的</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>计算模式中节点故障和慢节点容错处理 特别是在流和交互式SQL查询中</p>
<p>RDD能够保存世系图，而且提供保存到各个部分的功能。
所以RDD能够很好地处理并行计算中的数据共享</p>
<p>spark编程中开发者需要编写一个驱动程序来链接到工作进程，驱动程序定义一个或者多个RDD以及相关行动操作，驱动程序同时记录RDD的继承关系。
工作进程是一直运行的进程</p>
<p>操作 -
定义操作，创建RDD，来自于内存集合和外部存储系统，转换操作生成的RDD -
转换操作，只是转换，并未生成 - 控制操作，进行持久化 -
行动操作，触发spark运行的程序</p>
<p>分区，注意到分区是一个逻辑概念</p>
<p>分区的多少，往往意味着并行计算的粒度
如果是从本地文件创建，则默认值为程序所分配到的CPU数；如果是从hdfs上建立，则为文件的数据块数</p>
<p>RDD首选位置
Spark形成任务有向无环图时，会尽可能地把计算分配到靠近数据的位置，减少数据网络传输</p>
<h2 id="scala">2. scala</h2>
<p>https://learnxinyminutes.com/docs/scala/</p>
<ul>
<li>:help 查看所有的帮助</li>
<li>:type (true, 2.0) &gt; 查看类型</li>
<li>保存和加载 repl文件
<ul>
<li>:save /sites/repl-test.scala</li>
<li>:load /sites/rep1-test.scala</li>
</ul></li>
<li>查看历史 :h? &gt; 怎么使用历史中的文件呢？
<ul>
<li>:history number</li>
</ul></li>
<li>编写长代码
<ul>
<li>:paste &gt; 怎么加载文件中代码还是不会</li>
</ul></li>
<li>退出
<ul>
<li>quit</li>
</ul></li>
</ul>
<h3 id="类型">2.1 类型</h3>
<ul>
<li><p>val z:Type = value &gt; val, var</p>
<ul>
<li>Type: Int, Long, Double</li>
<li>类型继承体系 <img data-src="asserts/scala_type.png" />
<ul>
<li>列表中没有元素了即, Nil = List[Nothing], 它是List[T]的子类</li>
<li>Null类型的唯一实例是null值，可以将null赋值给任何引用但是不能赋值给值类型的变量</li>
<li>与Java基本类型相对应的类，以及Unit类型，都扩展自AnyVal</li>
<li>Any类定义了，A.isInstanceOf[B] 来判断A是否是类别B</li>
<li>A.getClass.getSimpleName</li>
</ul></li>
</ul></li>
<li><p>String &gt; raw" " 不含转义字符</p>
<ul>
<li>基本
<ul>
<li>属性
<ul>
<li>length</li>
</ul></li>
<li>init
<ul>
<li>直接赋值</li>
<li>Char[], copyValueOf(char[], offset, count)</li>
</ul></li>
<li>增
<ul>
<li>尾部增加元素或元组 str = str.concat(str2); str = str+str2</li>
</ul></li>
<li>删
<ul>
<li>转变为替换或者查拼接</li>
</ul></li>
<li>改
<ul>
<li>改特定群组的值 str.replace(regex, "") //前面可以接正则表达式</li>
</ul></li>
<li>查
<ul>
<li>按索引查 str(i) str.charAt(i)</li>
<li>按值查 str.indexof(c1) str.lastindexof(c1)</li>
<li>查范围的值
<ul>
<li>只要求前面 str.take()</li>
<li>只要求后面 str.drop()</li>
<li>同时 str.substring(start_index, end_index) str.slice()</li>
</ul></li>
<li>查是否满足要求
<ul>
<li>str.startsWith() str.endsWith()</li>
</ul></li>
</ul></li>
</ul></li>
<li>高级
<ul>
<li>预处理 trim()</li>
<li>切分 split()</li>
<li>格式化
<ul>
<li>s"${expression}" expression可以为上文的变量之类的 &gt;
对于输出的各种类型的操作为使用变量的toString参数</li>
<li>f"${}%1.0f dada"</li>
<li>raw" "</li>
<li>regr.r内置了正则表达式, 如 <code>"(.*)@(.*)".r</code></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>函数 def fun(x:Int, y:Int=4):Int={}</p>
<ul>
<li>默认参数</li>
<li>可变参数, 由变量直接指定</li>
<li>匿名函数 val sq: Int-&gt;Int = (x:Int)-&gt;x*x</li>
<li>允许多返回值</li>
<li>可以省略参数，可以省略返回值</li>
</ul></li>
<li><p>flow control</p>
<ul>
<li>range(5): (1 to 5 by 1) start to end by steo</li>
<li>循环
<ul>
<li>().foreach{}</li>
<li>while() {}</li>
<li>for(a&lt;-array){}</li>
</ul></li>
<li>条件
<ul>
<li>简单本 val a = if(x==10) "" else " "</li>
</ul></li>
</ul></li>
<li><p>Data Structures</p>
<ul>
<li>物理: 数组、链表</li>
<li>不变的
<ul>
<li>Array() List()
<ul>
<li>sortBy, sortWith{case (a,b)} // 自定义</li>
<li>distince</li>
</ul></li>
<li>Map()
<ul>
<li>sort: Map()没有sort函数，所以需要 用list</li>
<li>获取值
<ul>
<li>apply() 返回默认方法，不知道谁制定的, default()
会进行定义默认值</li>
<li>getOrElse(v,defalut) 返回默认值</li>
</ul></li>
<li>增加，以及更新
<ul>
<li>错误： map(key) = new_value &gt;
注意这条命令只能对于mutable的集合可用</li>
</ul></li>
<li>删除
<ul>
<li>remove(key)</li>
</ul></li>
<li>其他</li>
<li>keys, values</li>
<li>isEmpty</li>
<li>max, min, filter, find</li>
<li>sum,size</li>
<li>++添加一个新的</li>
<li>clear(), clone()</li>
<li>count(): 技术</li>
</ul></li>
<li>Set()
<ul>
<li>操作</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>类 Classes</p>
<ul>
<li>构造函数： 直接在类的开头声明 class Dog(br: String) { var breed:
String = br // 这里即构造函数 }</li>
<li>变量和函数默认的访问控制权限是public &gt; 特别地，可以private def
fun(): Type={} ？？？protect</li>
</ul></li>
<li><p>同名Object,
实际上是该类的一个单例对象，在其他语言中往往对应的是静态方法，静态变量之类的东西。
&gt;
两者的区别感觉上说也就是Class需要new产生，而Object因为是静态的，所以可以直接使用</p></li>
<li><p>case classes &gt; vs Classes, 如何使用？
Classes强调的是封装，多态和行为。这些值在类中通常是私有的，方法是可扩展的。
// 即默认情况下 &gt; 而case
classes的目的是来持有不可变对象，它们往往有很少的方法，而且这些方法基本上没有副作用。
使用起来定义简单，有点像结构体的感觉，pair case class Person(name:
String, phoneNumber:String)</p></li>
<li><p>trait 特征，实际上就是抽象类或者接口的概念； &gt;
只需要定义值或方法的属性或者返回值即可。 由继承它的类来自行扩展 class A
extends Dog with Bark {} // 扩展两个接口</p></li>
<li><p>继承 &gt;
继承利用的也是extends关键字，不过在scala中继承实体类有以下的要求：</p>
<ul>
<li>def只能重写另一个def</li>
<li>val只能重写另一个val或不带参数的def(?,应该不会涉及到)</li>
<li>var只能重写另一个抽象的var &gt; 可以定义自己的方法</li>
</ul></li>
<li><p>Pattern Matching &gt; scala特有的, 利用了case结构;
这样的想法就是使得省去了break语句 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> // Pattern matching might look familiar to the switch statements in the C family</span><br><span class="line">// of languages, but this is much more powerful. In Scala, you can match much</span><br><span class="line">// more:</span><br><span class="line">def matchEverything(obj: Any): String = obj match &#123;</span><br><span class="line">  // You can match values:</span><br><span class="line">  case &quot;Hello world&quot; =&gt; &quot;Got the string Hello world&quot;</span><br><span class="line"></span><br><span class="line">  // You can match by type:</span><br><span class="line">  case x: Double =&gt; &quot;Got a Double: &quot; + x</span><br><span class="line"></span><br><span class="line">  // You can specify conditions:</span><br><span class="line">  case x: Int if x &gt; 10000 =&gt; &quot;Got a pretty big number!&quot;</span><br><span class="line"></span><br><span class="line">  // You can match case classes as before:</span><br><span class="line">  case Person(name, number) =&gt; s&quot;Got contact info for $name!&quot;</span><br><span class="line"></span><br><span class="line">  // You can match regular expressions:</span><br><span class="line">  case email(name, domain) =&gt; s&quot;Got email address $name@$domain&quot;</span><br><span class="line"></span><br><span class="line">  // You can match tuples:</span><br><span class="line">  case (a: Int, b: Double, c: String) =&gt; s&quot;Got a tuple: $a, $b, $c&quot;</span><br><span class="line"></span><br><span class="line">  // You can match data structures:</span><br><span class="line">  case List(1, b, c) =&gt; s&quot;Got a list with three elements and starts with 1: 1, $b, $c&quot;</span><br><span class="line"></span><br><span class="line">  // You can nest patterns:</span><br><span class="line">  case List(List((1, 2, &quot;YAY&quot;))) =&gt; &quot;Got a list of list of tuple&quot;</span><br><span class="line"></span><br><span class="line">  // Match any case (default) if all previous haven&#x27;t matched</span><br><span class="line">  case _ =&gt; &quot;Got unknown object&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>函数式编程</p>
<ul>
<li>map</li>
<li>foreach</li>
<li>filter (1 to 15 by 2).filter(_%2==0)</li>
<li>reduce &gt; 等价于 for{n&lt;-s} yield sq(n) &gt; //
所有scala这门语言本身就支持 惰性求值, 想想真的nb</li>
</ul></li>
<li><p>implicit &gt; commonplace 频繁 &gt; 怎么说呢？
实际上就是一种潜在的标记的感觉。默认的全局的变量。 &gt;
对于方法，如果有一个参数通常是平凡的，但是又可能改变。这是就可以使用implicit作为参数。
&gt; 编译器会自动向前寻找该标记然后进行解析</p>
<ul>
<li>def sendGreetings(toWhom:String)(implicit howMany:Int) = toWhom +
howMany &gt; sendGreetings("wang") // "wang 100"</li>
<li>implicit val myImplicitInt=100 &gt; ? 怎么用，不知道</li>
<li>implicit def myImplicitFucion(breed:String) = new
Dog("Golder"+breed) &gt; "wyp" // "Golder wyp" &gt;
从理解上看，为什么不用默认形参或者指定参数，不会就只为了少点代码吧？？</li>
</ul></li>
<li><p>Misc</p>
<ul>
<li>import scala.collection</li>
<li>import scala.collectin.immutable._</li>
<li>import scala.collection.immutable.{List,Map}</li>
<li>import scala.collection.immutable.{List=&gt;Li} // rename</li>
<li>import scala.collection.immutable.{Map=&gt;<em>, Set=&gt;</em>, _}
// 排序Map,Set</li>
</ul></li>
<li><p>Input / Output</p>
<ul>
<li>读 import scala.io.Source for(line &lt;-
Source.fromFile("myfile").getLines()) println(line)</li>
<li>写 val writer = new PrinterWriter("myfile.txt") writer.write(" " +
util.Properties.lineSeparator) writer.close(</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>spark</category>
        <category>study</category>
      </categories>
      <tags>
        <tag>spark</tag>
        <tag>scala</tag>
      </tags>
  </entry>
  <entry>
    <title>spcipy study</title>
    <url>/2019/spcipy-study-4b76b86cf66d/</url>
    <content><![CDATA[<h2 id="概览">概览</h2>
<p>scipy库依赖于numpy库，它提供了便捷且快速的N维数组操作。构建scipy库的原因是，它能与numpy数组一起工作，并提供许多用户友好和高效的数字实践，例如数值积分和优化的教程
numerical integration, interpolation插值， optimization, linear
algebra线性代数 statistics统计</p>
<ul>
<li>cluster： cluster algorithms
<ul>
<li>vq: 只支持矢量化 vector quantization, k-means algorithms
<ul>
<li>whiten: normalize a group of observations on a per feature
basis</li>
<li>vq: assign codes from a code book to observations</li>
<li>kmeans:</li>
</ul></li>
<li>hierarchy: hierarchical and agglomerative clustering,
支持层次聚类和凝聚聚类; 1. generating hierarchical clusters from
distance matrices 2. calculating statistics on clusters 3. cutting
linkages to generate flat clusters 4. visualizing clusters with
dendrograms</li>
</ul></li>
<li>constants: physcial and mathematical constants
<ul>
<li>math
<ul>
<li>pi</li>
<li>golden</li>
<li>golden_ratio</li>
</ul></li>
<li>physical
<ul>
<li>c: 光速</li>
</ul></li>
<li>quick getting: constants.value(u"elementary charge"), unit,
precision, find</li>
</ul></li>
<li>fftpack: fast fourier transform routines
<ul>
<li>fft: discrete 离散, both real or complex sequence</li>
<li>ifft: inverse相反</li>
<li>fft2, ifft2: 2-d</li>
<li>fftn, ifftn</li>
<li>dct 余弦变换</li>
<li>dst: discrete sine transform</li>
</ul></li>
<li>integrate: integration and orginary differential equation slovers
<ul>
<li>quad: definite integral: 有限积分，三个参数，函数、上下限</li>
<li>dblquad: dobule类型</li>
<li>tplquad: 计算多重积分的表达式, 积分限是函数</li>
<li>nquad: 多重积分，积分限是具体的值</li>
<li>fixed_quad: 计算一个固定的积分使用fixed-order的高斯分布</li>
<li>trapz: 使用复合梯度算法计算, 同理simpz, romb</li>
</ul></li>
<li>interpolate: 插值, interpolation and smoothing splines
<ul>
<li>interp1d</li>
</ul></li>
<li>io: input and output &gt; loadmat, savemat,可以加载matlab文件</li>
<li>linalg: linear algebra
<ul>
<li>basic
<ul>
<li>inv</li>
<li>solve(a,b) a*x=b</li>
<li>solve_banded(): a是带状矩阵</li>
<li>solve_triangular(a,b): 解决三角举证</li>
<li>det 行列式</li>
<li>norm 范数</li>
<li>lstsq() 二乘解</li>
<li>pinv: 矩阵的伪逆</li>
<li>kron: 元素乘积</li>
</ul></li>
<li>eigenvalue problems: 特征值问题
<ul>
<li>eig: 方阵特征值问题</li>
</ul></li>
<li>Decompositions
<ul>
<li>lu: LU分解</li>
<li>svd： 奇异值分解</li>
<li>qr：QR分解</li>
</ul></li>
<li>Matrix Functions
<ul>
<li>expm: 使用近似方法</li>
</ul></li>
<li>Matrix Equation Solvers</li>
</ul></li>
<li>ndimage: n-dimensional image processing
<ul>
<li>convolve(): 多维卷积操作</li>
<li>gaussian_filter(): 高斯过滤</li>
<li>laplace： 拉普拉斯过滤</li>
<li>floutier_ellipsoid: 多维ellipsoid fourier filter</li>
</ul></li>
<li>odr: orthogoal distance regression 正交距离回归问题</li>
<li>optimize: optimization and root-finding routines
<ul>
<li>Optimization
<ul>
<li>scalar function标量函数: minimize_scalar</li>
<li>Local(Multivariate) Optimization: 多元回归</li>
<li>Global Optimization: brute()</li>
<li>Least-squares and Curve Fitting
<ul>
<li>nonlinear</li>
<li>linear</li>
<li>curve fitting</li>
</ul></li>
<li>Root finding</li>
</ul></li>
<li>Linear Programming
<ul>
<li>linprog</li>
</ul></li>
<li>Utilities
<ul>
<li>Finite-Difference Approximation
<ul>
<li>approx_fprime</li>
<li>check_grad</li>
</ul></li>
<li>Line Search</li>
<li>Hessian Approximation</li>
<li>Benchmark Problems</li>
</ul></li>
<li>Legacy Fuctions 遗留功能
<ul>
<li>fmin</li>
</ul></li>
</ul></li>
<li>signal: signal processing
<ul>
<li>convolution
<ul>
<li>convolve</li>
</ul></li>
<li>B-splines
<ul>
<li>bspline, cubic</li>
</ul></li>
<li>Filtering</li>
<li>Filter design</li>
<li>Matlab-style IIR filter design: butter, cheby1</li>
<li>Continuous-Time Linear Systems: lti()</li>
<li>Discrete-Time Linear Systems</li>
<li>LTI Representations</li>
<li>Waveforms</li>
<li>Window functions</li>
<li>Wavelets</li>
<li>Peak finding</li>
<li>Spectral Analysis</li>
</ul></li>
<li>sparse: sparse matrices and associated routines
<ul>
<li>Contents
<ul>
<li>bsr_matrix: block sparse row matrix</li>
<li>coo_matrix: coordinate format</li>
<li>csr_matrix,, csc_matrix: compressed sparse row matrix</li>
<li>dia_matrix: sparse matrix with disgonal storage</li>
<li>dok_matrix: dictionary of keys based sparse matrix</li>
<li>lil_matrix: row-based linked list sparse matrix</li>
<li>spmatrix: 以上的所有类型</li>
</ul></li>
<li>Functions
<ul>
<li>eye(): ones on diagonal</li>
<li>identity()</li>
<li>kron(A,B)</li>
<li>kronsum</li>
<li>diags(), spdiags</li>
<li>block_diag</li>
<li>tril</li>
<li>bmat: build, hstack, vstack</li>
<li>rand: uniformly distributed values. random()</li>
</ul></li>
<li>Save and load sparse matrices</li>
<li>Sparse matrix tools: find(A)</li>
<li>identifying sparse matrices: issparse(x)</li>
</ul></li>
<li>spatial: spatial data structures and algorithms
<ul>
<li>Spatial Transformations</li>
<li>Nearest-neighbor Queries
<ul>
<li>KDTree</li>
<li>ckDTree</li>
<li>Rectangle: Hyperrectangel</li>
</ul></li>
<li>Delaunay Triangulation, Convex Hulls and Voronoi Diagrams</li>
<li>Plotting Helpers</li>
<li>Simplex representation</li>
</ul></li>
<li>special special functions</li>
<li>stats: statistical distributions and function
<ul>
<li>Statistical functions</li>
<li>Continuous distributions</li>
<li>Multivariate distributions</li>
<li>Discrete distributions</li>
<li>Summary statistics: descrube, gmean</li>
<li>Frequency statistics: cumfreq</li>
<li>Correlation functions</li>
<li>Statistical tests</li>
<li>Transformations</li>
</ul></li>
</ul>
<h2 id="常用">常用</h2>
<ul>
<li>bsr_matrix: block sparse row matrix - coo_matrix: coordinate format
- csr_matrix,, csc_matrix: compressed sparse row matrix - dia_matrix:
sparse matrix with disgonal storage - dok_matrix: dictionary of keys
based sparse matrix - lil_matrix: row-based linked list sparse matrix -
spmatrix: 以上的所有类型</li>
</ul>
]]></content>
      <categories>
        <category>machinelearning</category>
        <category>scipy</category>
      </categories>
      <tags>
        <tag>machinelearning</tag>
        <tag>scipy</tag>
      </tags>
  </entry>
  <entry>
    <title>survey-of-gnn-systems</title>
    <url>/2020/survey-of-gnn-systems-253c400cb676/</url>
    <content><![CDATA[<ul>
<li><a href="#aligraph">AliGraph</a>
<ul>
<li><a href="#%e6%95%b0%e6%8d%ae%e6%a8%a1%e5%9e%8b">数据模型</a></li>
<li><a href="#%e7%ae%97%e6%b3%95%e6%a1%86%e6%9e%b6">算法框架</a></li>
<li><a href="#%e7%b3%bb%e7%bb%9f%e6%a1%86%e6%9e%b6">系统框架</a>
<ul>
<li><a href="#%e5%9b%be%e5%ad%98%e5%82%a8">图存储</a></li>
<li><a href="#%e5%9b%be%e9%87%87%e6%a0%b7">图采样</a></li>
<li><a href="#%e8%ae%a1%e7%ae%97">计算</a></li>
</ul></li>
</ul></li>
<li><a href="#neugraph">NeuGraph</a>
<ul>
<li><a href="#%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b">编程模型</a></li>
<li><a href="#%e7%b3%bb%e7%bb%9f%e5%ae%9e%e7%8e%b0">系统实现</a>
<ul>
<li><a href="#graph-aware-dataflow-translation">Graph-Aware Dataflow
Translation</a></li>
<li><a href="#streaming-processing-out-of-gpu-core">Streaming Processing
out of GPU core</a></li>
<li><a href="#parallel-multi-gpu-processing">Parallel Multi-GPU
Processing</a></li>
<li><a href="#propagation-engine">Propagation Engine</a></li>
<li><a href="#%e5%85%b6%e4%bb%96%e6%8a%80%e5%b7%a7">其他技巧</a></li>
</ul></li>
<li><a href="#%e5%ae%9e%e9%aa%8c%e8%af%84%e4%bc%b0">实验评估</a></li>
</ul></li>
<li><a href="#dgl">DGL</a></li>
<li><a
href="#architectural-implications-of-graph-neural-networks">Architectural
Implications of Graph Neural Networks</a></li>
<li><a
href="#characterizing-and-understanding-gcns-on-gpu-yan-2020">Characterizing
and Understanding GCNs on GPU [Yan-2020]</a></li>
<li><a href="#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae">参考文献</a></li>
</ul>
<h1 id="aligraph"><a href="#ref-aligraph">AliGraph</a></h1>
<h2 id="数据模型">数据模型</h2>
<p>AliGraph面向的数据模型为Attributed Heterogeneous Graph (AHG)。</p>
<p><img data-src="AliGraph-Fig2.png" /></p>
<h2 id="算法框架">算法框架</h2>
<p>AliGraph所支持的通用GNN框架。在该框架中，每一层的GNN被拆解为三个基本算子：Sample,
Aggregate和Combine。其中Aggregate进行边计算，而Combine进行点计算。</p>
<p><img data-src="AliGraph-Alg1.png" /></p>
<blockquote>
<p>注意：在该算法框架中，每一层（hop）都采用了相同的Sample/Aggregate/Combine算子，其不允许不同层采用不同的算子进行组合。</p>
</blockquote>
<h2 id="系统框架">系统框架</h2>
<p>AliGraph的系统架构如下。最上面是Aggregate和Combine算子的实现，中间是Sampling方法，最下面是图存储。目前的AliGraph主要运行在CPU环境中。</p>
<p><img data-src="AliGraph-Fig3.png" /></p>
<h3 id="图存储">图存储</h3>
<p>AliGraph采用的是vertex-cut的划分方案，即不同的边被分到不同的机器上。</p>
<p><img data-src="AliGraph-Alg2.png" /></p>
<p>图中顶点和边的属性与图的邻接表<strong>分开存储</strong>，见图<a
href="#fig-AliGraph-Fig4">AliGraph-Fig4</a>。原因有二：</p>
<ol type="1">
<li><p>属性信息更占据存储空间。</p></li>
<li><p>不同顶点/边的属性有很大的重叠。例如大量顶点都具有共同的标签，例如“男性”、“洗漱用品”等。</p></li>
</ol>
<p>通过为顶点属性和边属性建立Index，将图的拓扑信息与图的属性信息建立关联。为了减少对属性信息的访问开销，在每台机器上会对Index中的属性条目建立cache，cache采用LRU替换策略。</p>
<p><img data-src="AliGraph-Fig4.png" /><a name="fig-AliGraph-Fig4"></a></p>
<p>同时，每台机器会<strong>缓存</strong>重要顶点的邻接表。采用如下的公式为每个顶点v，确定其k-重要性（k-th
importance），其中<span
class="math inline">\(D_i^{(k)}(v)\)</span>和<span
class="math inline">\(D_o^{(k)}(v)\)</span>表示顶点v的k跳出/入邻域的大小。每台机器只缓存重要性大于阈值<span
class="math inline">\(\tau_k\)</span>的顶点v的出边邻接表。实际实践表明考虑至多2跳邻域就足够了，阈值<span
class="math inline">\(\tau_k\)</span>设置为0.2就效果很好。 <span
class="math display">\[
Imp^{(k)}(v)=\frac{D_i^{(k)}(v)}{D_o^{(k)}(v)}
\]</span>
与重要性指标相关的一个定理是：如果顶点的度数服从幂率分布，则其k跳邻域的规模也服从幂率分布，从而k-重要性也服从<em>幂率分布</em>。</p>
<blockquote>
<p>对于无向图这个指标无法适用。</p>
</blockquote>
<p><a
href="#fig-AliGraph-Fig8">实验</a>表明因为Importance指标遵从Power-law分布，因此较低的threshold就能够cache足够数量的顶点。同时<a
href="#fig-AliGraph-Fig9">缓存替换策略</a>的实验基于importance指标的cache策略比随机替换和LRU替换都有效，更适合图神经网络。Importance策略和随机替换策略都是静态策略，其会预先cache相应的顶点邻接表。而LRU策略因为其动态特性，会经常剔除、替换已经cache的邻接表，导致额外开销。</p>
<p><a name="fig-AliGraph-Fig8"><img data-src="AliGraph-Fig8.png" /></a></p>
<p><a name="fig-AliGraph-Fig9"><img data-src="AliGraph-Fig9.png" /></a></p>
<blockquote>
<p>如何制定适合图分析的cache策略也是研究方向之一。</p>
</blockquote>
<p>在实现时，将边按照source
vertex划分成不同的组，每一个组绑定到一个core上。对于该组顶点邻接表的访问与更新操作被组织到一个request-flow桶中，该桶由<strong><a
href="#fig-AliGraph-Fig6">lock-free的队列实现</a></strong>。</p>
<p><a name="fig-AliGraph-Fig6"><img data-src="AliGraph-Fig6.png" /></a></p>
<h3 id="图采样">图采样</h3>
<p>AliGraph中支持3种图采样策略，同时也运行以plugin的形式扩展。</p>
<ol type="1">
<li><p>Traverse：从一个图分区中采样一批顶点。可以直接从当前服务器的分区中生成。</p></li>
<li><p>Neighborhood：采样某个顶点的1跳或多跳邻域。如果顶点邻域跨服务器，则分批地从其他图服务器获取邻接表。</p></li>
<li><p>Negative：生成负采样样本，加速收敛。通常可在本地服务器上完成，按需地查询远程服务器以获得邻接表。</p></li>
</ol>
<p>Sampler中的权重也允许根据梯度进行更新。</p>
<p>经过采样，每个顶点的邻域大小被<strong>对齐</strong>，使其可以很容易地被处理。</p>
<p><a href="#fig-aligraph-tab4">实验表明</a>通过分布式采样（Batch
size=512，Cache size=20%），即使是很大的图，也能非常快地采样完毕。</p>
<p>Neighborhood采样因为要涉及服务器之间的通讯，速度会比另外两个采样慢很多。</p>
<p>采样技术的性能对数据规模不敏感，及时图规模增大6倍，采样时间的变化也不大。</p>
<p><a name="fig-aligraph-tab4"><img data-src="AliGraph-Tab4.png" /></a></p>
<h3 id="计算">计算</h3>
<p>编程模型中与计算相关的是Aggregate和Combine。AliGraph也允许以plugin的形式扩展实现这两个算子。需要注意的是，这两个算子需要同时实现其forward计算和backward计算的逻辑。</p>
<p>在计算的过程中，会保存每个顶点v在当前mini-batch中的最新的中间特征向量：<span
class="math inline">\(h_v^{(1)}, \dots, h_v^{(kmax)}\)</span>。</p>
<p><a href="#fig-aligraph-tab5">实验表明</a>cache
mini-batch的中间特征向量对于提升两个算子的计算速度非常重要。</p>
<p><a name="fig-aligraph-tab5"><img data-src="AliGraph-Tab5.png" /></a></p>
<h1 id="neugraph"><a href="#ref-NeuGraph">NeuGraph</a></h1>
<p>NeuGraph是微软亚洲研究院提出的面向单机多GPU环境的并行图神经网络训练框架，该框架基于TensorFlow实现。NeuGraph主要面相transductive的setting，即整个图参与训练，在目前的系统中没有考虑sample，但作者说可以集成sample到框架中。</p>
<h2 id="编程模型">编程模型</h2>
<p>NeuGraph为图神经网络训练提出了SAGA-NN（Scatter-ApplyEdge-Gather-ApplyVertex
with Neural
Networks）编程模型。SAGA-NN模型将图神经网络中每一层的前向计算划分为4个阶段：Scatter、ApplyEdge、Gather和ApplyVertex，如<a
href="#fig-neugraph-fig2">Figure
2</a>所示。其中ApplyEdge和ApplyVertex阶段执行用户提供的基于神经网络的边特征向量和点特征向量的计算。Scatter和Gather是由NeuGraph系统隐式触发的阶段，这两个阶段为ApplyEdge和ApplyVertex阶段准备数据。</p>
<p><a name="fig-neugraph-fig2"><img data-src="neugraph-fig2.png" /></a></p>
<p>在编程时，用户只需利用给定的算子实现ApplyEdge和ApplyVertex函数，并指定Gather方式，即可利用NeuGraph自动地完成GNN的训练。<a
href="#fig-neugraph-fig3">Figure
3</a>展示了利用SAGA-NN编程模型表达Gated-GCN的编程示例。</p>
<p><a name="fig-neugraph-fig3"><img data-src="neugraph-fig3.png" /></a></p>
<h2 id="系统实现">系统实现</h2>
<h3 id="graph-aware-dataflow-translation">Graph-Aware Dataflow
Translation</h3>
<p>NeuGraph采用2D图划分方法，其将顶点集划分为<strong>P</strong>个分区（trunk），边集（邻接矩阵）划分为<span
class="math inline">\(P\times P\)</span>个分区，其中边分区<span
class="math inline">\(E_{ij}\)</span>保存了连接点分区<span
class="math inline">\(V_i\)</span>和<span
class="math inline">\(V_j\)</span>的边。NeuGraph基于chunk构建数据流图，如<a
href="#fig-neugraph-fig5">Figure 5</a>所示。</p>
<p><a name="fig-neugraph-fig5"><img data-src="neugraph-fig5.png" /></a></p>
<p>其中Scatter算子接收1个边分区和2个对应的点分区，将数据整理成[src,
dst,data]的元组形式，该元组形式将传递给ApplyEdge函数进行处理。</p>
<p>在Forward阶段会产生大量中间计算结果（例如ApplyEdge中的矩阵乘法的结果），NeuGraph为了避免中间结果占用大量的GPU显存，其会将中间结果从GPU端显存上传到Host端的内存中，在Backward阶段再传回GPU端。</p>
<p>为了能在Gather阶段中复用数据，NeuGraph在Forward（Backward）阶段中采用列（行）优先的顺序处理边分区。例如为了在Forward阶段持续累加V0点分区中的点特征向量，其依次处理E(0,0),
E(1,0), ..., E(n,0)边分区。</p>
<p>NeuGraph在不超过GPU显存容量限制的情况下选择尽可能小的分区数<span
class="math inline">\(P\)</span>。</p>
<h3 id="streaming-processing-out-of-gpu-core">Streaming Processing out
of GPU core</h3>
<p>为了能让GPU处理超过其显存容量的数据，必须将数据动态地在GPU和Host端进行交换。</p>
<p><strong>Selective
Scheduling技巧</strong>：一个边分区可能只与对应点分区中少量的点发生关联，因此在从CPU端向GPU端发送点分区数据时，可以只传递点分区中的少部分数据。NeuGraph根据CPU端内存拷贝的带宽、CPU-GPU端数据交换的带宽，动态地确定阈值，来确定是向GPU发送整个点分区，还是只发送点分区中的部分数据。</p>
<p><strong>Pipeline
Scheduling技巧</strong>：将一个边分区进一步划分为sub-trunk，流水线地向GPU发送sub-trunk并在GPU端并发地进行sub-trunk的计算。为了使计算和HtoD数据传输充分地重叠，NeuGraph采用一个基于profile的sub-trunk调度方案，其在头几轮迭代中profile各个sub-trunk的计算开销和数据传输开销，并根据开销计算出更优的调度方案，如<a
href="#fig-neugraph-fig6">Figure 6</a>所示。</p>
<p><a name="fig-neugraph-fig6"><img data-src="neugraph-fig6.png" /></a></p>
<h3 id="parallel-multi-gpu-processing">Parallel Multi-GPU
Processing</h3>
<p>在拥有多GPU卡的环境中，可以充分利用各GPU卡之间的高速P2P
PCIe通信来降低Host端PCIe总线带宽压力。NeuGraph将共享PCIe
Switch的GPU卡视作一个虚拟GPU卡组，点分区、边分区的数据从Host
memory中广播到各个虚拟GPU卡的第一个物理GPU中（例如Figure
8中的GPU0和GPU2）。第一个物理GPU在对该点分区进行处理的同时，并发地将数据发送给同一个虚拟GPU中的下一个物理GPU（例如<a
href="#fig-neugraph-fig8">Figure 8</a>中的GPU1和GPU3），并发地从Host
Device载入下一批Vertex Chunk和Edge
Chunk数据。流水线地处理，直到所有点分区和边分区均处理完。</p>
<p><a name="fig-neugraph-fig8"><img data-src="neugraph-fig8.png" /></a></p>
<h3 id="propagation-engine">Propagation Engine</h3>
<p>NeuGraph在GPU上实现Graph Propagation时额外采用了如下优化手段：</p>
<ul>
<li>在ApplyEdge中出现的只与source vertex或destination
vertex相关的计算移动到上一步中的ApplyVertex中进行。这样避免对于每一条边都进行相应的计算。</li>
<li>在GPU上实现高效的Scatter和Gather kernel。</li>
<li>Scatter-ApplyEdge-Gather算子融合：当ApplyEdge算子是element-wise的简单逻辑时，其整个SAG的过程被直接替换为Fused-Gather算子，该算子直接将source
vertex和edge
data读入到kernel的register中，并在register中完成ApplyEdge的计算，计算结果累加如destination
vertex的accumulation向量。通过融合可以避免将中间计算结果保存回GPU显存，节省GPU内存访问开销。</li>
</ul>
<h3 id="其他技巧">其他技巧</h3>
<ul>
<li>模型参数每个GPU一份，通过all-reduce在各GPU之间保持同步。</li>
<li>GPU之间通过P2P通信。</li>
</ul>
<h2 id="实验评估">实验评估</h2>
<ul>
<li>实验在点分类任务上进行，我们可以借鉴论文中的叙述来说明。 <img
src="neugraph-paragraph.png" /></li>
<li>数据集的平均度数影响Graph
Propagation的时间开销，平均度数越高的数据集其Propagation的开销越高。</li>
<li>系统实验中的优化技巧是有效的，能够比单纯在TensorFlow上实现SAGA模型快2.4~4.9倍。</li>
<li>“The results under other models are similar”这句表达可以借鉴。</li>
<li>Selectively scheduling适合sparse graph而graph kernel
optimization适合dense graph。</li>
<li>即使采用了IO（GPU与Host端数据交换）和GPU
kernel互相重叠的优化，IO耗时依然长于GPU kernel计算耗时。 <img
src="neugraph-tab2.png" /></li>
<li>Chain-based mechanism对于多GPU卡的扩展性至关重要。 <img
src="neugraph-fig17.png" /></li>
<li>当GPU卡数量上来时，被多GPU共享的CPU和Memory带宽将成为制约多GPU扩展性的瓶颈。</li>
<li>NeuGraph的speedup曲线虽然是线性的，但距离理想的线性可扩展性还有差距。当其GPU卡数量从1增加到8时，其Speedup的增长远没有到8倍。</li>
</ul>
<h1 id="dgl"><a href="#ref-DGL">DGL</a></h1>
<p>DGL是支持多后端（MXNet、TensorFlow、PyTorch）的一个面向深度图神经网络的计算框架。</p>
<p>DGL也采用基于message-passing的编程模型，用户提供自定义的message
function（边计算）、update function（点计算）和reduce operation
（消息规约操作）。但与PyG不同的是，DGL支持用户提供自定义的reduce
operation，而不局限于sum、mean、max等少数几种。</p>
<p>DGL引用了文献<a
href="#ref-Xu-2018">(Xu-2018)</a>表明aggregator（即reduce）所支持的复杂度与图神经网络的表达能力密切相关。</p>
<p>DGL支持sampling机制，该机制通过指定active vertex/set set实现，以data
loader的形式提供给用户。</p>
<p>用户提供的message function和update
function必须是向量化的，即可以对多个顶点同时操作。</p>
<p>kernel fusion是一个提高计算性能的有效技巧。</p>
<ul>
<li>kernel fusion将message function与update
function合并进行，从而避免生成message的实体中间结果，从而大幅降低计算开销和GPU显存使用量。</li>
<li>kernel fusion要求message function非常简单，不能使用任何参数。</li>
<li>实验表明DGL相比PyG的主要性能提升即来自kernel fusion。</li>
</ul>
<h1 id="architectural-implications-of-graph-neural-networks"><a
href="#ref-Zhang-ICAL-2020">Architectural Implications of Graph Neural
Networks</a></h1>
<p>GNN吸引人的一个优点是end-to-end的训练能力。</p>
<p>作者认为computation-intensive GEMM
kernel不是GNN的性能热点。<strong>这个结论要和我们的实验结果对照一下</strong>。</p>
<p>本文关注<strong>inference</strong>阶段的性能热点。</p>
<p>如<a href="#fig-aignn-fig3">Fig.
3</a>所示，实际GNN中用到的基本算子的种类是有限的，各算子经过组合得到丰富的GNN架构。
<a name="fig-aignn-fig3"><img data-src="AIGNN-Fig3.png" /></a></p>
<p>DGL中允许Gather阶段采用任何的累加函数，包含LSTM，因此作者论文中覆盖了GraphSAGE-LSTM版本。</p>
<p><a href="#fig-aignn-tab2">Tab
2</a>中列出了实验中采用数据集情况。在列图数据集的情况后，可以把Graph
Type也列上，如[Tab 2] (#fig-aignn-tab2)所示。</p>
<p><a name="fig-aignn-tab2"><img data-src="./AIGNN-Tab2.png" /></a></p>
<blockquote>
<p>作者选用的数据集平均度数有些低。
采用sampling技巧后，处理的图的平均度数也可能很低，需要结合实验。
我感觉图的平均度数可能会是影响性能的重要指标。</p>
</blockquote>
<p>GPU硬件资源的利用率与图规模和隐向量的规模密切相关。</p>
<p>作者认为GNN没有固定的性能瓶颈，性能瓶颈会随着数据集和算法的不同而变化，因此各阶段都需要优化，都有优化的价值。</p>
<p>本文在处理GAT时，其ApplyEdge只有简单的矩阵向量乘法，而将耗时的softmax阶段算到Gather里，因此作者的实验结果中GAT的Gather阶段非常耗时，如<a
href="#fig-aignn-fig5">Fig. 5</a>所示。</p>
<p><a name="fig-aignn-fig5"><img data-src="./AIGNN-Fig5.png"
alt="aignn-fig5" /></a></p>
<p>本文确认了Scatter阶段（对应于PyG的collect阶段）中只有数据拷贝，没有计算，并给出了该阶段的实现<a
href="#fig-aignn-fig2">示意图</a>。</p>
<p><a name="fig-aignn-fig2"><img data-src="./AIGNN-Fig2.png"
alt="aignn-fig2" /></a></p>
<p>相比传统的图分析计算PageRank、SCC等，因为GNN中每个顶点和边上都是向量，因此对于硬件cache来说locality比较好。</p>
<p>本文进一步验证了kernel fusion对于性能提升的重要性，如<a
href="#fig-aignn-fig6">Fig.6</a>所示。fused gattern
kernel是由稀疏矩阵乘法实现，因此是可微的。</p>
<p><a name="fig-aignn-fig6"><img data-src="AIGNN-Fig6.png"
alt="aignn-fig6" /></a></p>
<p>GNN相比传统DL的最大特点是引入了Sparse Matrix Operation。</p>
<p>文中<a href="#fig-aignn-tab3">Tab
3</a>中总结了各阶段算子的Kernel和计算特性，这与我们的结论互相对照一下。</p>
<p><a name="fig-aignn-tab3"><img data-src="AIGNN-Tab3.png"
alt="aignn-tab3" /></a></p>
<h1
id="characterizing-and-understanding-gcns-on-gpu-yan-2020">Characterizing
and Understanding GCNs on GPU [<a
href="#ref-Yan-2020">Yan-2020</a>]</h1>
<p>本文分析了GCN类的算法在inference阶段的特性，同时与经典的图分析算法（PageRank）和基于MLP的经典神经网络做了特性对比分析。</p>
<p>GCN顶点和边上的属性值是特征向量（维度至少为几十），而PageRank中顶点和边上的属性是标量。</p>
<ul>
<li>特征向量带来了更加良好的locality（一个顶点的数据被连续的访问）。</li>
<li>特征向量带来了更高的顶点内的并行性。</li>
</ul>
<p>本文利用sgemm实现GCN中特征向量（稀疏）与权重矩阵的乘法。</p>
<p>本文发现在GCN算法中的每一层<span
class="math inline">\(H=AXW\)</span>中，先计算<span
class="math inline">\(X&#39;=XW\)</span>再计算<span
class="math inline">\(H=AX&#39;\)</span>会带来更好的性能，因为<span
class="math inline">\(X\)</span>的纬度一般很高，而<span
class="math inline">\(W\)</span>的维度一般较低。</p>
<blockquote>
<p>但是这样做会带来<span class="math inline">\(X\)</span>也要参与<span
class="math inline">\(W\)</span>的梯度计算的问题，反而可能会得不偿失。</p>
</blockquote>
<p>本文发现实际图中的顶点度数分布符合幂律分布的特性，因此缓存高度数的顶点，有可能可以提升硬件Cache的命中率。</p>
<p>因为aggregation阶段需要并发地、原子地更新顶点的输出特征向量，因此向量化原子访问有可能可以提升aggregation阶段的效率。</p>
<h1 id="参考文献">参考文献</h1>
<ol type="1">
<li><p><a name="ref-aligraph">[AliGraph]</a>ZHU R, ZHAO K, YANG H, 等.
AliGraph: A Comprehensive Graph Neural Network Platform[J]. Proceedings
of the VLDB Endowment, 2019, 12(12): 2094–2105.
DOI:10.14778/3352063.3352127.</p></li>
<li><p><a name="ref-NeuGraph">[NeuGraph]</a>MA L, YANG Z, MIAO Y, 等.
NeuGraph: Parallel Deep Neural Network Computation on Large
Graphs[C/OL]//2019 USENIX Annual Technical Conference (USENIX ATC 19).
Renton, WA: USENIX Association, 2019: 443–458.
https://www.usenix.org/conference/atc19/presentation/ma.</p></li>
<li><p><a name="ref-DGL">[DGL]</a>WANG M, YU L, ZHENG D, 等. Deep Graph
Library: Towards Efficient and Scalable Deep Learning on Graphs[J/OL].
arXiv:1909.01315 [cs, stat], 2019[2020–06–20].
http://arxiv.org/abs/1909.01315.</p></li>
<li><p><a name="ref-Xu-2018">[Xu-2018]</a>XU K, HU W, LESKOVEC J, 等.
How Powerful are Graph Neural Networks?[C/OL]//7th International
Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA,
May 6-9, 2019. . https://openreview.net/forum?id=ryGs6iA5Km.</p></li>
<li><p><a name="ref-Zhang-ICAL-2020">[Zhang-ICAL-2020]</a>Z. ZHANG, J.
LENG, L. MA, 等. Architectural Implications of Graph Neural Networks[J].
IEEE Computer Architecture Letters, 2020, 19(1): 59–62.
DOI:10.1109/LCA.2020.2988991.</p></li>
<li><p><a name="ref-Yan-2020">[Yan-2020]</a>M. YAN, Z. CHEN, L. DENG,
等. Characterizing and Understanding GCNs on GPU[J]. IEEE Computer
Architecture Letters, 2020, 19(1): 22–25.
DOI:10.1109/LCA.2020.2970395.</p></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>target for work</title>
    <url>/2019/target-for-work-e362996f8bd8/</url>
    <content><![CDATA[<p>需要找清楚自己的工作内容</p>
<p>自己必须学那些东西！</p>
<p>注意说一个事情，不要说着说着，想到另一个点，又转移到另一个点。</p>
<p>不要DFS, 要BFS</p>
]]></content>
  </entry>
  <entry>
    <title>tools-latex-MathJax</title>
    <url>/2019/tools-latex-MathJax-b0283ec1aa12/</url>
    <content><![CDATA[<p>https://colobu.com/2014/08/17/MathJax-quick-reference/</p>
<p>MathJax是一个JavaScript引擎，用来显示网络上的数学公式。它支持大部分主流的浏览器，对大部分用户而言它不需要安装，既没有插件需要下载也没有软件需要安装，属于Apache。MathJax使用网络字体去产生高质量的排版，使其在所有分辨率都可缩放和显示，这远比包含公式的图片更有效得多。使用MathJax显示数学公式是基于文本的，而非图片。他可以被搜索引擎使用，这意味着方程式和页面上的文字一样是可以被搜索的。MathJax允许页面作者使用Tex、
LaTex符号和MathML或者AsciiMath去书写公式。
转化为MathML格式你可以赋值粘贴它们到其他程序中。
MathJax是模块化的，所以它仅仅在需要时才加载它的组件，同时也可以被扩展以实现更多功能。MathJax同时也是高度可配置的，允许作者做出更适宜网站自身的定义。</p>
<p><a
href="https://colobu.com/2014/08/17/MathJax-quick-reference/">MathJax中文文档</a></p>
<ol type="1">
<li><p>希腊字母</p>
<ul>
<li>lower <code>\alpha, \beta, \gamma, \delta, \epsilon(\varepsilon),
\zeta, \eta, \theta(\vartheta), \iota, \kappa, \lambda, \mu, \xi, o,
\pi, \rho(\varrho), \sigma, \tau, \upsilon, \phi(\varphi), \chi, \psi,
\omega</code> <span class="math display">\[\alpha, \beta, \gamma,
\delta, \epsilon(\varepsilon), \zeta, \eta, \theta(\vartheta), \iota,
\kappa, \lambda, \mu, \xi, o, \pi, \rho(\varrho), \sigma, \tau,
\upsilon, \phi(\varphi), \chi, \psi, \omega\]</span></li>
<li>upper <code>A, B, \Gamma, \Delta, E, Z, H, \Theta, I, K, \Lambda,
M(N), \Xi, O, \Pi, P, \Sigma, T, \Upsilon, \Phi, X, \Psi, \Omega</code>
<span class="math display">\[A, B, \Gamma, \Delata, E, Z, H, \Theta, I,
K, \Lambda, M(N), \Xi, O, \Pi, P, \Sigma, T, \Upsilon, \Phi, X, \Psi,
\Omega\]</span></li>
</ul></li>
<li><p>字体</p>
<ul>
<li><code>\mathbb, \Bbb</code>黑板体 <span
class="math inline">\(\mathbb{Z}, \Bbb{Z}\)</span></li>
<li><code>\mathbf</code>粗体 <span
class="math inline">\(\mathbf{Z}\)</span></li>
<li><code>\mathtt</code>打印体 <span
class="math inline">\(\mathtt{Z}\)</span></li>
<li><code>\mathrm</code>罗马体 <span
class="math inline">\(\mathrm{Z}\)</span></li>
<li><code>\mathcal</code> <span
class="math inline">\(\mathcal{Z}\)</span></li>
<li><code>\mathscr</code> <span
class="math inline">\(\mathscr{Z}\)</span></li>
<li><code>\mathfrak</code> <span
class="math inline">\(\mathfrak{Z}\)</span></li>
</ul></li>
<li><p>一大堆符号 &gt; https://pic.plover.com/MISC/symbols.pdf</p>
<ul>
<li>常用</li>
</ul></li>
<li><p>中途空格 <code>\quad, \qquad</code></p></li>
<li><p><code>\hat, \widehat, \bar, \overline, \vec, \overrightarrow,
\dot, \ddot</code> &gt; <span class="math inline">\(\hat{x},
\widehat{xy}, \bar{x}, \overline{xyz}, \vec{x}, \overrightarrow{xyz},
\dot{x}, \ddot{x}\)</span></p></li>
<li><p>矩阵 <code>\begin&#123;matrix&#125; ... \end&#123;matrix&#125;</code></p></li>
</ol>
]]></content>
      <categories>
        <category>tools</category>
        <category>latex</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title>tensorflow variable</title>
    <url>/2019/tensorflow-variable-63af8c1f1dbc/</url>
    <content><![CDATA[<p>https://blog.csdn.net/shenxiaolu1984/article/details/52815641 &gt;
tensorflow变量相关</p>
<p>https://blog.csdn.net/huqinweI987/article/details/82771521 &gt;
tensorflow自动训练简介和选择训练</p>
<h2 id="概览">概览</h2>
<p>tf.Optimizer只优化tf.GraphKeys.TRAINABLE_VARIABLES变量</p>
<p>init=tf.initialize_all_variables() sess.run(init) //
初始化之后Variable中的值生成完毕，不再变化</p>
<p>v = tf.all_variables() // 查看所有tf.GraphKeys.VARIABLES v =
tf.get_collection(tf.GraphKeys.VARIABLES)</p>
<h2 id="各类variable">各类Variable</h2>
<ul>
<li>获取训练的变量 方式1
<ul>
<li>tf.all_variables() &gt; 直接在某种状态下进行运行即可</li>
<li>tf.trainable_variables()</li>
</ul></li>
<li>获取训练的变量 方式2
<ul>
<li>tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)</li>
<li>优化特定的变量: optimizer.minimize(cost, var_list)</li>
</ul></li>
</ul>
<p>sess: how to get a default sess</p>
<p>tf.gradients() &gt; 需要注意的是grad_weights这里返回得到的是list</p>
<p>使用一个未知的函数时，请务必详细地查看参数</p>
<p>想想tensorflow, 真的是厉害， 把模型具体给抽象出来</p>
<p>做事之前先想清楚，比如说对这段时间科研进行总结的话</p>
<p>一件事情不要测试过多，过于复杂</p>
<p>首要目标应该是把事情做完。</p>
<p>而且遇到挫折，不要扔，可以暂时转移，应该是想如何解决问题</p>
<p>ctrl+shift+f 全局搜索</p>
<p>一定要精确度到最细</p>
<p>而且要把测试代码单独拿出来，没做一次改变进行一次测试</p>
<p>git 使用中扩展思路总结: 1.
代码在当前版本，然后进行两部分分别测试，那么可以考虑创建两个分支 2.
代码提交的版本最好是能够运行的</p>
]]></content>
      <categories>
        <category>tools</category>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>linux</title>
    <url>/2019/tools-pygraphviz-study-eb13879f68e7/</url>
    <content><![CDATA[<p>参考 1. <a href="http://graphviz.org/doc/info/attrs.html">Node, Edge
and Graph Attributes of Pygraphviz</a> 2. <a
href="https://www.cnblogs.com/liang1101/p/7641984.html">graphviz
程序生成多种类型图表详解</a></p>
<h2 id="i-一个完整的pipline">I 一个完整的pipline</h2>
<ol type="1">
<li>install <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install python-dev graphviz libgraphviz-dev pkg-config</span><br></pre></td></tr></table></figure></li>
<li>初始化
<ul>
<li>.dot文件 <code>dot hello.dot -T png -o hello.png</code>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strict digraph&#123;</span><br><span class="line">    graph [bb=&quot;-64.382, -82.544, 57.743, 78.934&quot;,</span><br><span class="line">        center=True,</span><br><span class="line">        label=wyp_label];</span><br><span class="line">    node [label=&quot;\n&quot;];</span><br><span class="line">    edge [label=&quot;\n&quot;]</span><br><span class="line">    1   [height=0.5,</span><br><span class="line">        pos=&quot;, &quot;]</span><br><span class="line">    2   []</span><br><span class="line">    1 -&gt; 2 [pos=&quot;&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>dict <code>d = &#123;'1': &#123;'2': None&#125;, '2': &#123;'1': None, '3':None&#125;,
'3':&#123;'2': None&#125;&#125;  A=pgv.AGraph(d)</code></li>
<li>图形 &gt; man <cmd>?
<ul>
<li>dot 明确的方向性</li>
<li>neato 缺乏反向性</li>
<li>twopi 放射性</li>
<li>circo 环形布局</li>
</ul></li>
<li>pipline <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pygraphviz as pgv</span><br><span class="line"># 1. init a graph</span><br><span class="line">G = pgv.AGraph(strict=, directed=) # default: strict-True</span><br><span class="line"></span><br><span class="line"># 2. set the global property</span><br><span class="line">G.graph_attr[&#x27;&#x27;] = &#x27;&#x27;</span><br><span class="line">G.node_attr[&#x27;&#x27;]=&#x27;&#x27;</span><br><span class="line">G.edge_attr[&#x27;&#x27;]=&#x27;&#x27;</span><br><span class="line"></span><br><span class="line"># 3. add node and edge</span><br><span class="line">G.add_node_from(list1)</span><br><span class="line">G.add_node(&#x27;a&#x27;, color=&#x27;red&#x27;)</span><br><span class="line">G.add_edge(&#x27;b&#x27;, &#x27;c&#x27;, color=&#x27;blue&#x27;)</span><br><span class="line"></span><br><span class="line"># change node or edge attributes</span><br><span class="line">n = G.get_node(&#x27;f&#x27;)</span><br><span class="line">n.attr[&#x27;shape&#x27;]=&#x27;box&#x27;</span><br><span class="line">e = G.get_edge(&#x27;b&#x27;, &#x27;c&#x27;)</span><br><span class="line">e.attr[&#x27;color&#x27;]=&#x27;green&#x27;</span><br><span class="line"></span><br><span class="line"># 4. set layout: dot(direction), twopi(away), circo(circle)</span><br><span class="line">G.layout(lay)</span><br><span class="line"></span><br><span class="line"># 5. save fig</span><br><span class="line">G.draw(file_path)</span><br></pre></td></tr></table></figure></li>
<li>属性
<ul>
<li>node
<ul>
<li>color</li>
<li>comment: ??</li>
<li>fillcolor</li>
<li>fontname: font family Times-Roman</li>
<li>fontsize: 14</li>
<li>label</li>
<li>shape</li>
</ul></li>
<li>edge
<ul>
<li>arrowhead: normal</li>
<li>arrowsize: 1.0</li>
<li>arrowtail</li>
<li>color</li>
<li>comment</li>
<li>dir: forward, back, both</li>
<li>fontcolor: black; fontname: ; fontsize</li>
<li>headlabel: label near head of edge</li>
<li>label: edge label</li>
<li>labelfontcolor:; labelfontname:;</li>
</ul></li>
<li>graph
<ul>
<li>bgcolor:</li>
<li>center false</li>
<li>comment:</li>
<li>label &gt; 有意思的是支持html语言 &gt;
http://graphviz.org/doc/info/shapes.html#record &gt;
https://www.cnblogs.com/zhishaofei/p/4033175.html</li>
</ul></li>
</ul></li>
<li>其他的
<ul>
<li>转换为pvg <code>h=A.handle;
C=pgv.AGraph(h);A.draw("a.svg");</code></li>
<li>load and save dot file <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">G = pgv.AGraph(dot_file)</span><br><span class="line">G.write(dot_file)</span><br></pre></td></tr></table></figure></li>
<li>string &gt; s = G.string()</li>
</ul></li>
</ul></li>
</ol>
<p>output-format https://graphviz.gitlab.io/_pages/doc/info/output.html
## 待做</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>torch-study</title>
    <url>/2019/torch-study-09a1932c0a22/</url>
    <content><![CDATA[<p>https://blog.csdn.net/qq_31590831/article/details/90764240</p>
<h2 id="pytorch">pytorch</h2>
<p>https://www.cnblogs.com/denny402/p/7520063.html</p>
<p>一个完整的pipeline <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from torch.utils.data import Dataset, DataLoader</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line">class MyDataset(Dataset):</span><br><span class="line">    def __init__(self, txt, transform,):</span><br><span class="line">        self.imgs = </span><br><span class="line">        self.transform =</span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        pass</span><br><span class="line">    def __len__(self):</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">train_data = MyDataset(txt=&quot;.txt&quot;, transform)</span><br><span class="line">train_loader = DataLoader(dataset=, batch_size=, shuffle=True)</span><br><span class="line"></span><br><span class="line">class Net(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Sequential(</span><br><span class="line">            torch.nn.Conv2d(3, 32, 3, 1, 1),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.MaxPool2d(2)</span><br><span class="line">        )</span><br><span class="line">        self.conv2 = torch.nn.Sequential(</span><br><span class="line">            torch.nn.Conv2d(32, 64, 3, 1, 1),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.MaxPool2d(2)</span><br><span class="line">        )</span><br><span class="line">    def forward(self, x):</span><br><span class="line">        conv1_out = self.conv1(x)</span><br><span class="line">        conv2_out = self.conv2(conv1_out)</span><br><span class="line">        conv3_out = self.conv3(conv2_out)</span><br><span class="line">        out = self.dense(conv3_out)</span><br><span class="line">        return out</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">print(model)</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters())</span><br><span class="line">loss_func = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">for epoch in range(10):</span><br><span class="line">    print(&#x27;epoch &#123;&#125;&#x27;.format(epoch + 1))</span><br><span class="line">    # training</span><br><span class="line">    train_loss = 0</span><br><span class="line">    train_acc = 0</span><br><span class="line">    for batch_x, batch_y in train_loader:</span><br><span class="line">        batch_x, batch_y = Variable(batch_x), Variable(batch_y)</span><br><span class="line">        out = model(batch_x)</span><br><span class="line">        loss = loss_func(out, batch_y)</span><br><span class="line">        train_loss += loss.data[0]</span><br><span class="line">        pred = torch.max(out, 1)[1]</span><br><span class="line">        train_correct = (pred == batch_y).sum()</span><br><span class="line">        train_acc += train_correct.data[0]</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    print(&#x27;Train Loss: &#123;:.6f&#125;, Acc: &#123;:.6f&#125;&#x27;.format(train_loss / (len(</span><br><span class="line">        train_data)), train_acc / (len(train_data))))</span><br></pre></td></tr></table></figure></p>
<p>net.zero_grad(): optimizer.zero_grad():
在下一次计算梯度之前清空梯度</p>
<p>optimizer.step(): 进行下一步更新</p>
<p>查看grad
https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#variablehttp://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#variable</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import torch</span><br><span class="line">x = torch.ones(2, 2, requires_grad=True)</span><br><span class="line">y = 2 * x + 2 #y.data, y.grad, y.grad_func</span><br><span class="line">out = y.sum()</span><br><span class="line">out.backward()</span><br><span class="line">x.grad # [[2, 2], [2, 2]]</span><br></pre></td></tr></table></figure>
<p>单看Variable和Tensor没什么区别，个人理解对于Variable可能能保证计算过程一直是grad</p>
]]></content>
  </entry>
  <entry>
    <title>vim</title>
    <url>/2019/vim-03f7c94da709/</url>
    <content><![CDATA[<h1 id="vim">vim</h1>
<h2 id="光标移动">光标移动</h2>
<ol start="0" type="1">
<li><p>整篇文章 gg: 开头 G: 末尾 123+gg: 跳转到指定行</p></li>
<li><p>屏幕 H屏幕顶行，J合并两行 L屏幕底行 M屏幕中间行 ctr+f pagedown
ctrl+b pageup</p></li>
<li><p>行列上下 左、下、上、右 h, j,k,l</p></li>
<li><p>单词 w:开头, 向后 b:开头，向前 e:末尾，向后</p></li>
<li><p>缩进 &gt;&gt; 缩进 &lt;&lt;</p></li>
<li><p>行前，行尾 行前，行尾 ^, $</p></li>
<li><p>段前，段后 {段前 }段后: 跳过开头 ( ): 会经过开头行 ## 选择 v:
行选择 ctrl+v: 列选择</p></li>
</ol>
<h2 id="修改">修改</h2>
<ol type="1">
<li>插入 i: 当前字母前插入 I: 当前行前插入</li>
</ol>
<p>a: 当前字母后插入 A: 当前字母后插入</p>
<p>o: 下一行插入 O: 上一行插入</p>
<ol start="2" type="1">
<li><p>复制 y: 复制选中内容 yy: 复制当前行 123+yy:
向下复制多少行</p></li>
<li><p>剪切 无，=复制+删除</p></li>
<li><p>删除 y: 复制选中内容 yy: 复制当前行 123+yy:
向下复制多少行</p></li>
<li><p>粘贴 y: 复制选中内容 yy: 复制当前行 123+yy:
向下复制多少行</p></li>
</ol>
<h2 id="操作撤销和恢复">操作撤销和恢复</h2>
<p>u: 撤销操作undo ctr+r 重做redo</p>
<h2 id="全局查找替换">全局查找、替换</h2>
<ol type="1">
<li><p>查找 /word 回车<br />
N查看上一处 n查看下一处</p></li>
<li><p>替换 :{作用范围}s/{目标}/{替换}/{替换标志}</p></li>
</ol>
<ul>
<li><p>作用范围 全局范围<code>:%s/</code> 当前行s 选区
<code>:'&lt;,'&gt;/</code>
当前行<code>.</code>与接下来的两行<code>+2</code>:
<code>:.,+2s</code></p></li>
<li><p>替换标志 g: global替换所有的出现 空：从光标位置开始替换 gc:
需要进行确认</p></li>
<li><p>块选择 v 光标移动过的位置直接进行选择。可以操作 ctrl+v 列选择
y复制， p粘贴</p></li>
</ul>
<p>该模式下移动光标的感觉跟查看下一样</p>
<p>参考 https://harttle.land/2016/07/18/intro-to-regexp.html &gt;
正则表达式这篇写得很好！！</p>
]]></content>
      <categories>
        <category>tools</category>
        <category>vim</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vscode using</title>
    <url>/2019/vscode-using-e71ff5fd83de/</url>
    <content><![CDATA[<p>? 关闭终端的快捷键: 暂时未发现</p>
<p>搜索文件: ctrl+p</p>
]]></content>
      <categories>
        <category>tools</category>
        <category>vscode</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title>日记-210524.md</title>
    <url>/2021/%E6%97%A5%E8%AE%B0-210524-md-9d6ef4f3e9c0/</url>
    <content><![CDATA[<h2 id="待思考的地方">待思考的地方</h2>
<p>P38: 结论应该怎么写？</p>
<h2 id="讲稿">讲稿</h2>
<p>各位答辩老师下午好，我是王云攀，我的毕业论文题目是基于GPU的/图神经网络计算性能/优化研究，指导老师是黄宜华教授</p>
<p>我将从5个方面展开</p>
<p>首先来看研究背景/和相关工作</p>
<p>图神经网络是一种基于深度学习/处理图域数据/的方法，广泛应用于多个领域。
众多图神经网络系统，采样技术/和基于采样的训练推理流程被提出。</p>
<p>本文重点研究/面向GPU环境的图神经网络计算性能优化。</p>
<p>现有的性能评估工作对图神经网络训练推理过程计算效率方面的性能瓶颈研究不充分，如未涵盖训练阶段，且未考虑采样方法对性能瓶颈的影响</p>
<p>而目前的采样方法重点关注于优化采样方式，以降低采样对模型精度的影响，对算法流程上的计算效率缺乏关注</p>
<p>现有的分布式系统对GPU支持有限，单机多GPU系统也未关注到基于采样的训练推理流程中的内存开销问题。</p>
<p>本文的工作概述如下：</p>
<p>针对计算效率性能瓶颈不明确、缺乏相关分析工作的问题，研究设计了一系列实验，对基于GPU的图神经网络计算性能瓶颈做了系统性的分析。</p>
<p>性能分析发现，边计算是主要的性能瓶颈。高额的内存使用限制了图神经网络的数据扩展性。采样技术能有效降低内存使用，但基于采样的计算流程存在额外开销占比大导致GPU利用率低、内存波动大导致个别批次可能出现内存溢出两大问题。</p>
<p>针对训练推理流程GPU利用率低的问题，研究提出了基于流水线并行的训练推理流程优化方法。采样流程的流水线并行优化有效解决了采样流程额外开销大的问题。训练与评估步骤的流水线并行优化有效解决了评估步骤耗时长的问题。最终的实验结果证实了该优化方法的有效性。</p>
<p>针对不同批次内存开销波动大以及个别批次可能出现内存溢出风险的问题，研究提出了内存使用可控的训练推理流程优化方法。利用基于线性模型和随机森林的内存开销模型有效识别出可能带来内存风险的采样子图，并针对这些子图采取基于度数和PageRank的超限子图剪枝策略缩减子图规模，确保内存开销不超限。实验结果表明，两种预测模型有着非常高的精度，超限子图剪枝策略能有效限制子图的内存开销，且对模型精度的影响小于随机剪枝策略。</p>
<p>第二章将介绍性能瓶颈分析工作。</p>
<p>本文根据边/点复杂度将主流图神经网络算法划分在了四个象限，并选取了各个象限的代表算法GaAN,
GGNN, GCN, GAT作为评估算法。</p>
<p>选取了七个性能评估中常用的数据集用于实验</p>
<p>以下是具体的实验设置，基于PyG实现了所有算法，并设计了统一的两层网络结构。</p>
<p>接着，我们从时间分解分析、内存使用分析，采样对性能的影响分析三个方面进行了性能瓶颈分析。</p>
<p>通过观察四个算法在图神经网络层的耗时分解，我们可以发现对于大多数情况，边计算占据了主要的耗时。</p>
<p>在PyG中，边计算被分解为了四个步骤，收集、消息传递、聚集和向量更新。</p>
<p>从边计算层耗时分解中可以分析，对于边计算复杂度高的算法（GAT和GaAN），消息传递是主要性能瓶颈。但边计算复杂度低时，收集和聚集步骤也占据了相当比例的耗时。</p>
<p>对于内存使用来说，定义内存膨胀比例为峰值内存与数据加载内存的壁纸，从图中可以看出，图神经网络计算过程存在着高额的内存开销。</p>
<p>基于采样的图神经网络训练推理流程以分批方式进行。单个批次包含了三个步骤：CPU端的采样，CPU端到GPU端的数据传输和GPU端的训练与推理。</p>
<p>通过比较不同批规模与全数据训练的内存使用，我们发现采样技术的确能显著减少内存使用！</p>
<p>在对单个批次训练耗时进行分解后，可以发现基于采样的训练推理存在的一个问题：采样和数据传输步骤占到了相当大的比例，该额外开销直接降低了GPU利用率。</p>
<p>通过内存使用分布箱线图可以发现基于采样的训练推理中的另一个问题：不同批次的内存开销波动很大，其中极个别批次可能导致内存溢出风险。</p>
<p>基于上述分析可以总结如下：
（1）边计算是大多数的图神经网络的性能瓶颈。
（2）高额内存使用限制了图神经网络的数据扩展性，采样技术能显著减少内存使用，将图神经网络扩展到大规模图数据集。但是，采样流程存在两大性能问题。第三章和第四章将分别解决这两大问题。</p>
<p>本部分的完整工作已在CCF-C类期刊上全文发表。</p>
<p>第三章将对基于流水线并行的训练推理流程优化方法进行介绍。</p>
<p>时间方面，对于图神经网络训练推理流程，除了采样流程的额外开销显著外，还存在着训练过程的评估步骤耗时较长的问题。本章将通过流水线的方式解决这两大性能问题。</p>
<p>如图所示，通过理论加速比的分析可以发现，理论加速比与总计算批次、采样、数据传输步骤的耗时占比关。</p>
<p>对于该优化具体实现，本文使用了基于CUDA流实现了采样和数据传输步骤的并发执行。基于数据预取技术，借助双线程和队列实现了采样数据传输步骤和GPU计算步骤的并发执行。</p>
<p>对于训练与评估步骤的流水线并行优化，同理，可以发现理论加速比与训练轮数和评估耗时占比相关。</p>
<p>对于具体实现，基于多进程和本地文件数据共享进行了实现。总共维护了三个进程，主进程负责总控制，训练进程负责模型训练，评估进程负责模型评估。训练进程和评估进程通过本地文件进行数据交换。</p>
<p>由于实际中采样、数据传输、评估耗时占比一直发生变化，实际加速比的代表意义不强。这里将优化效果定义为了实际加速比与理论加速比的比值。</p>
<p>其他设置与第二章保持一致。</p>
<p>从图中可以发现，优化效果只与总耗时相关，随总耗时增加而增加，其他因素通过影响总耗时影响优化效果。这是因为实现本身的额外开销一定，总耗时越多，意味着额外开销占比越少，从而优化效果更好。</p>
<p>在训练与评估步骤的优化效果评估中，同理观察到了类似的结论。</p>
<p>对于叠加优化效果评估，虽然具体的优化比值存在差异，在大多数情况下，优化1+优化2的组合可以取得更好的优化效果。</p>
<p>第四章将介绍内存使用可控的训练推理流程优化方法。</p>
<p>GPU内存有限，如何在有限的条件下安全地实现大规模的图神经网络训练推理变得至关重要。由第二章分析知，基于采样的训练推理流程能大幅降低计算过程中的内存开销。但该流程存在不同批次内存波动大从而个别批次触发内存溢出风险问题。</p>
<p>从内存安全角度，研究内存使用可控的图神经网络训练推理流程变得非常重要。</p>
<p>下图展示了总流程设计。</p>
<p>我们在单个批次的常规训练流程中加入了内存超限处理步骤，负责发现和处理超限采样子图。面对不同的应用场景，我们提出了两种不同的预测模型：线性模型和随机森林。由于推理阶段必须对采样子图推理，推理阶段直接进入剪枝处理机制。为了避免对模型精度的影响，对于训练阶段，会尝试一定次数的重采样，再执行剪枝处理机制。</p>
<p>确定超参数场景指算法的超参数、数据集规模和批规模等所有均确定的场景，常出现于图神经网络应用阶段或开发阶段的某个具体步骤。</p>
<p>基于峰值内存开销与输入图的二元线性关系，在此场景下，可直接基于边数和点数的二元线性模型预测内存开销。</p>
<p>非确定超参数场景指仅图神经网络结构确定（算法确定），其他均可以不确定的场景，常出现与图神经网络的设计阶段。基于多个参数对具体值建模，本质上为回归问题。</p>
<p>通过对多种已有的机器学习方法比较，随机森林综合表现最好，选择其作为了预测模型。</p>
<p>为了获得较为精确的模型，在训练或推理之前会构造一定数量的样本预训练模型。
为了进一步提高模型的精度，在训练或推理过程中，会基于确定阈值对模型进行在线更新。</p>
<p>基于对峰值内存与图的边数的线性关系，可以使用二分搜索作为采样子图规模上界预测方法。</p>
<p>对于采样子图剪枝处理总流程，在通过规模上界预测方法得到剪枝边数后，会基于边的重要性评估所有边并剪枝掉重要性低的边以缩减采样子图。这里设计了基于度数和PageRank信息设计了两种边重要性衡量方法，其基本思想是一条边的两个顶点越重要，那么其边越不重要。</p>
<p>预测模型的评价指标，误差方面选取了MAPE(平均绝对百分比误差)；准确率方面选取了R2决定系数指标。其他设置与第二章保持一致。</p>
<p>从线性模型的测试集上的分析结果可以发现，线性模型表现出来非常好的性能，误差小于0.006，
准确率均在99%以上。（）</p>
<p>如图展示了随机森林与其他机器学习方面对比，可以发现，随着训练集规模的增加，随机森林在两个指标上表现最好。</p>
<p>对于预测模型的额外开销，可以发现，额外开销很稳定，而且值也很小。</p>
<p>同时，我们展示了实际模拟情况下的预测效果，可以发现，两种模型所有批次的内存开销均成功控制在了指定GPU内存限制内。</p>
<p>如图展示了推理阶段使用采样子图规模上界预测方法和随机剪枝策略后的内存分布箱线图，可以看出，所有批次的内存开销均控制在了指定GPU内存限制内</p>
<p>首先，我们评估了不同剪枝比例下的各个算法的精度情况。可以发现，绝大多数情况下，两种剪枝的精度均优于随机剪枝。同时，使用剪枝可能取得更好的模型精度！</p>
<p>对实际情况来说，除了PageRank剪枝在ClusterGCN算法和ogbn-products数据集上的情况外，两种剪枝精度均优于随机剪枝。</p>
<p>由于本文提出了剪枝策略使用了多余的信息，所以两种剪枝策略耗时高于随机剪枝。但由于实际情况中剪枝策略发生的比例非常小（如表所示，实际情况中均小于14%），所以不会带来太多的额外开销！</p>
<p>本文工作总结如下：
第一，研究设计了一系列实验，对基于GPU的图神经网络计算性能进行了系统性的分析。选取了四个代表性算法，从时间、内存和采样对性能的影响三个方面进行了分析</p>
<p>第二，研究了提出了基于流水线并行的训练推理流程优化方法。实现了采样流程的流水线优化和训练与评估步骤的流水线优化，实验证实了该优化方法的有效性。</p>
<p>第三，研究提出了内存使用可控的训练推理流程优化方法。提出了基于线性模型和随机森林的内存开销预测模型；提出了基于二分搜素的采样子图规模上界预测方法和基于度数和PageRank的超限子图剪枝策略。实验证实了该优化方法的有效性。</p>
<p>未来工作考虑从三个方面展开： 1.
多GPU或分布式环境下的训练推理流程性能优化。 2.
面向具有动态拓扑结构的时空图数据集的性能优化 3.
新兴的图神经网络编程模型的性能差异</p>
<p>这是我在研究生期间的主要工作</p>
<p>最后，感谢各位老师和同学，以上就是我的硕士论文答辩</p>
<h2 id="todo">TODO</h2>
<ol type="1">
<li>前面研究背景还存在很大的问题 &gt; 这里需要添加的内容太多了</li>
</ol>
<p>优先级：先完成必须要改的，然后再考虑怎么改</p>
<ol start="2" type="1">
<li>“研究背景与动机”应该怎么写？ &gt; ?</li>
</ol>
<h2 id="安排">安排</h2>
<ol type="1">
<li><p>先第一遍把自己觉得有问题的地方改正</p></li>
<li><p>写一遍稿子，从而来检查自己的通顺程度</p></li>
<li><p>调格式，调字体 &gt; 1,2,3目标为将PPT完成好 &gt;
不能出现不通顺，错别字等问题</p></li>
<li><p>反复修改演讲稿</p></li>
<li><p>背演讲稿（反复累计10遍）</p></li>
<li><p>累计10遍以后</p></li>
<li><p>计时排练（争取在10分钟左右），同时详略得当</p></li>
<li><p>现场放映，并观看PPT的显示是否有问题，是否需要调整PPT的字体。</p></li>
</ol>
<h2 id="纠正自己的作息">纠正自己的作息</h2>
<p>认识自己，坚持做一件事！</p>
]]></content>
  </entry>
  <entry>
    <title>日记-210518</title>
    <url>/2021/%E6%97%A5%E8%AE%B0-210518-10b781ce206c/</url>
    <content><![CDATA[<p>今天被批评了，这些都是由我自己造成的。</p>
<p>很多时候感到自己孤单，但是一细想是能体会到身边人对我的关心的。</p>
<blockquote>
<p>先回复师兄吧</p>
</blockquote>
<p>昨天预答辩表现太差，实属自作自受。一下子浪过了头，PPT也没有做好，</p>
<h2 id="ppt大纲">PPT大纲</h2>
<p>新的PPT的计划:(15分钟)</p>
<h3 id="标题-目录-30s-2页">标题 + 目录 (30s) (2页)</h3>
<h3 id="第一章-研究背景及相关工作2min-7页">第一章
研究背景及相关工作（2min) (7页)</h3>
<p>1.1 研究背景 P1: -
图神经网络作为一种基于深度学习处理图数据的方法，广泛应用与多个领域 -
现实应用中图数据规模迅速增长，图神经网络结构日益增长，但GPU内存受限。许多图神经网络系统和采样技术相继提出。
-
本文重点关注于从系统角度的基于GPU的大规模图神经网络的计算性能优化。</p>
<p>1.2 相关工作（待进一步完善） P2: （1）图神经网络算法
现有图神经网路算法众多，但对基于GPU的大规模图神经网络的计算性能的关注工作却有限。
这些算法主要集中在精度，并且都是case by case P3: （2）图神经网络性能评估
效率方面工作集中于发现 P4:（3）图神经网络系统
目前系统包含了单机环境、分布式环境的系统。 从xx, xxx,
xx角度可以将这些系统划分为 1 2 3
这些系统没有关注到提高采样流程的效率和采样流程的安全性。
P5:（4）采样方法 采样方法专注于采样本身的效率，以及如何提升精度。
这些采样方法为考虑。</p>
<p>1.3 工作概述 P6:
（1）针对性能瓶颈分析工作缺乏的问题，本文对图神经网络计算性能进行了系统的分析。
-
选择了四个代表性算法，对采样技术引入前后的图神经网络的性能瓶颈进行了研究。
（2）针对训练推理过程低效的问题，研究提出了基于流水线并行的图神经网络训练推理流程优化方法。
- 采样流程的流水线并行优化有效解决了采样过程额外开销大的问题。 -
训练与评估步骤的流水线并行优化有效解决了评估步骤耗时长的问题。 -
实验结果表明，该优化方法可以有效加速训练与推理过程。
（3）针对内存开销波动以及个别批次可能出现内存溢出风险的问题，研究提出了内存使用可控的图神经网络训练推理流程优化方法。
-
利用面向确定超参数的线性模型和面向非确定超参数的随机森林，对给定采样子图上的内存开销进行预测。
-
采样基于度数和PageRank的超限子图剪枝策略缩减子图规模，确保内存开销小于GPU内存容量上限。
-
实验结果表明，线性内存开销预测模型准确率达99%以上，随机森林预测准确率高达95%，超限子图剪枝策略能有效限制采样子图的内存开销，且对模型精度的影响低于随机剪枝策略。</p>
<h3 id="第二章-基于gpu的图神经网络计算性能瓶颈-3min-11页">第二章:
基于GPU的图神经网络计算性能瓶颈 3min (11页)</h3>
<p>2.1 实验说明 （1）实验算法 P1:
对于图神经网络来说，主要可以分为三个步骤：a.聚集;
b.更新。聚集操作与领边相关，更新操作与点相关。根据复杂度分析，本文将主流的算法划分在四个象限。选取各个象限的GCN,GGNN,GAT,GaAN作为代表性算法
（2）实验设置 P2: 如图所示，实验数据集和实验设置 -
数据集：精度评估中最常用的数据集 - 选取了两种代表性的采样方法。
（略去参数设置） 2.2 图神经网络的性能瓶颈？ P3: 时间方面
图神经网络层：在大多数情况下，边计算都是主要性能瓶颈。
边计算层：边计算的性能瓶颈在消息步骤，同时聚集和收集步骤也非常重要。</p>
<p>P4: 内存方面
PyTorch本身产生用于后向传播的被缓存的内存产生了高额的膨胀比例，导致了内存很难扩展到。</p>
<p>总结：图神经网络计算的性能瓶颈在边计算时期。
但是，图神经网络存在高额的内存使用，制约了数据扩展性。</p>
<p>2.3 采样对性能的影响</p>
<p>P5:
为了解决GPU内存有限下，大规模图神经网络的训练，采样技术提出。采样技术从大图中采样出小图，来进行图神经网络。相比于全图训练方式，采样技术以分批方式，即一轮训练中将大图拆分为多个小图进行一个批次训练。
采样是基于CPU的，一次参数更新中加入了采样过程和数据传输的耗时。
如图所示，可以发现，与全数据方式相比，明显内存更低。</p>
<p>此外，由于评估部分，需要基于全图评估，发现相比于全图评估。 训练耗时
-&gt; 采样耗时</p>
<p>P6: 采样对精度的影响。</p>
<p>P7:
如图所示，对采样过程BreakDown分析。目前，采样过程的采样和数据传输占据了大部分的耗时。</p>
<p>P8: 采样引入了随机性。如图所示，。推理同样如此。</p>
<p>2.4 总结 P9:
图神经网络计算的性能瓶颈在边计算时期。边计算复杂度高时，重点在消息时期。同时，收集和聚集也值得优化。
GPU内存有限下，由于高内存使用，采样技术是大规模的必要手段。采样并不会带来精度的下降。但采样存在两大性能问题：</p>
<ol type="1">
<li><p>训练推理流程低效问题。训练流程中存在评估步骤耗时大，采样过程存在采样和数据传输额外开销大。</p></li>
<li><p>内存有限下的内存安全问题。内存波动大从而某些个别批次可能触发内存安全问题。</p></li>
</ol>
<h3
id="第四章-基于流水线并行的图神经网络训练推理流程优化5min-13页4912">第四章:
基于流水线并行的图神经网络训练推理流程优化。5min (13页)；4/9=1/2</h3>
<blockquote>
<p>可思考这里是否需要引入问题背景</p>
</blockquote>
<p>P1: 4.1 总设计流程（通用化流程） <img
src="日记-210518/第四章_总体流程设计.png" /></p>
<p>P2&amp;P3: 4.2 采样过程的流水线并行优化</p>
<p>P4&amp;P5: 4.3 训练和评估步骤的流水线并行优化</p>
<p>4.4 实验结果分析（实验数据集与第三章一致） P6: 实验说明 &gt;
思考是否需要加入</p>
<p>P7: 采样过程优化 &gt; 算法、数据集和批规模的影响</p>
<p>P8: 训练与评估步骤优化 &gt; 算法、数据集和训练轮数的影响</p>
<p>P9: 叠加优化结果 &gt; 用来查看哪种优化效果更佳？</p>
<h3
id="第五章-内存使用可控的图神经网络训练推理流程优化-5min-17页-14-5页-81412">第五章:
内存使用可控的图神经网络训练推理流程优化 5min (17页) 1/4, 5页;
8/14=1/2</h3>
<blockquote>
<p>思考问题背景是否引入问题背景</p>
</blockquote>
<p>P1: 5.1 总体流程设计 <img
src="日记-210518/第五章_总体流程设计.png" /></p>
<p>5.2 内存开销预测模型 P2:（1）面向确定超参数的线性预测模型</p>
<p>P3:（2）面向非确定超参数的随机森林预测模型</p>
<p>P4:（3）内存开销预测模型的训练与在线更新</p>
<p>P5: 5.3 采样子图规模上界预测方法。</p>
<p>（1）确定删边 （2）确定使用二分法</p>
<p>5.4 采样子图的剪枝策略</p>
<p>P6：剪枝策略的工作流程（流程图）</p>
<p>P7：边重要性的衡量方法</p>
<p>5.5 性能评估 P8: 实验说明（内存开销预测模型评估指标）
（1）内存开销预测模型 a. 准确率 P9:线性内存开销预测模型
R2准确率均在0.99以上。 P10: 随机森林模型。 R2准确率均在0.95以上。 b.
额外开销</p>
<p>（2）重采样策略评估 P11: &gt; 耗时这里就是重采样一次的耗时</p>
<p>（3）剪枝策略评估 a. 准确率 P12: 不同算法下准确率 P13:
内存受限下对准确率的影响 b. 额外开销 P14:
虽然很耗时，但是剪枝发生比例非常小，所以额外开销有限。</p>
<blockquote>
<p>（4）总的额外开销 总的额外开销由内存开销预测模型 + 重采样处理机制 +
可能的剪枝处理。</p>
</blockquote>
<h3 id="第六章-总结与展望-1min-2页">第六章 总结与展望 1min （2页）</h3>
<p>P1: 本文工作总结</p>
<p>P2: 未来工作</p>
<h3 id="附录-5页">附录 (5页)</h3>
<p>P1: 研究生期间工作</p>
<p>P2: 致谢</p>
<p>P3&amp;P4: 参考文献</p>
<p>P5: 谢谢</p>
]]></content>
  </entry>
  <entry>
    <title>情绪管理的重要性</title>
    <url>/2021/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0-%E6%83%85%E7%BB%AA%E7%AE%A1%E7%90%86-d97e12218af6/</url>
    <content><![CDATA[<h2 id="情绪管理的观念">情绪管理的观念</h2>
<p>概念： 1.
情绪随时可能产生，有正向有负向，然而往往影响我们的是负面的情绪事情 2.
负面情绪如果积累到一定程度，一定会在最意想不到的时候，以最意想不到的强度爆发。
3. 情绪是不嗯呢该被压抑的，只能被标明、了解和疏导。</p>
<p>工作角度：
非常容易失去关系的，好的同事关系和工作氛围可以增加我们的工作的效率
个人角度： 心理垃圾也要及时清理</p>
<p>先处理好心情，才能处理好事情</p>
<h2 id="情绪的定义和产生">情绪的定义和产生</h2>
<ul>
<li><p>人脑的发展顺序： 脑干：主管呼吸、睡眠、心跳、消化系统等
情感的脑：主管情绪和人际关系等
理性的脑：主管逻辑思考、理性分析等</p></li>
<li><p>情绪的脑在激昂的时候会把冲突对方看成是敌人而不是友人。</p></li>
<li><p>情绪的产生：情绪ABC理论 A.情境、时间 -&gt; B.思想、诠释 -&gt;
感受、情绪反应</p></li>
<li><p>情绪感受和思想诠释的区别
诠释：对一件事的价值判断，和行为一样，有好坏之分的。
情绪：一个人对一件事的主管感受，不应该有对错之分，任何一种情绪的产生都是合理的</p></li>
<li><p>当我们可以花时间了解自己的情绪时，找到引发情绪的思想诠释，就可以很好的管理我们的情绪。</p></li>
</ul>
<h2 id="情绪调节五要诀">情绪调节五要诀</h2>
<ol type="1">
<li>描述情境：用“当...”的句式，客观、具体地描述事件
<ol type="1">
<li>客观地描述情景：将自己想象为墙上的录影机</li>
<li>具体地描述情境</li>
</ol></li>
<li>标明情绪：用“我觉得...”的句式，找到可以描述情绪的形容词。根据层次，选择2-3个层次的形容词</li>
<li>寻找诠释：用“我觉得...(情绪)，因为...(诠释)”的句式</li>
<li>探索需求：用“我的需要是...”的句式，找到自己行为层面和心理层面的需要（最难的地方）
<ul>
<li>行为层面的需要：把策划改好，发给Leader</li>
<li>心理层面的需要：努力被看见，工作能力被认可</li>
</ul></li>
<li>行动改进：用“建设性的想法和行动是...”的句式，思考如何借着建设性的想法和行动，帮助他人成功地满足你的需要
<ul>
<li>心理需要：建设性的想法——一个更成熟、更客观地看待这件事情的角度</li>
<li>行为需要：建设性的行动——一些切实可行的行动</li>
</ul></li>
</ol>
<h2 id="提示">提示</h2>
<ol type="1">
<li>情绪疏导是非常私密的事情，可以自己用文字的方式写下来，这样会更清晰</li>
<li>如果需要向别人倾诉，可以选择一个你信赖的、同时和这件事毫不相关的第三方</li>
<li>如果你觉得有必要和发生冲突的对方探讨这件事，请一定在自己疏导完全后再和对方沟通。同时，不要谈及任何第三步“诠释”部分，表达不当很可能会引发新的冲突。</li>
</ol>
<p>每一次情绪来临的时候，都是一个很好的自我探索和成长的机会。
先处理好心情，才能处理好事情</p>
]]></content>
  </entry>
  <entry>
    <title>问题分析与解决</title>
    <url>/2021/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0-%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%E4%B8%8E%E8%A7%A3%E5%86%B3-f111709bda69/</url>
    <content><![CDATA[<h2 id="概述">1. 概述</h2>
<p>几种错误的做法： - 否定状况 - 在错误时机追究责任 -
夸张评价：来源与恐惧，因此想要逃离或者消极面对；危害：对问题置之不理</p>
<p>归因: 认为“问题绝对不会发生”</p>
<p>问题的解决者： 1. 首先具备优异的压力管理能力</p>
<p>问题分析与解决的五大基本步骤： 1. 发现问题并归类 2. 设定具体课题:
SCQA分析法 3. 找出替代方案 4. 评估替代方案: 情境分析法 5. 实施解决策略:
剔除超过容许范围的替代方案，指定详细的行动计划</p>
<h2 id="确定问题">2. 确定问题</h2>
<p>问题: 明天的会议请谁来主持? 怎样才能降低沟通成本?</p>
<h2 id="问题的分类及解决思路">3. 问题的分类及解决思路</h2>
<h2 id="section">4.</h2>
]]></content>
  </entry>
  <entry>
    <title>课程学习_高效能认识的七个习惯</title>
    <url>/2021/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0-%E9%AB%98%E6%95%88%E8%83%BD%E8%AE%A4%E8%AF%86%E7%9A%84%E4%B8%83%E4%B8%AA%E4%B9%A0%E6%83%AF-e8878b26a334/</url>
    <content><![CDATA[<p>https://elearning.kundou.cn/student/course-content/5fc9b77e5ebfdb9c5c6a6bf2?entrance=course_list&amp;lesson=yFQ2eUbYM</p>
<h2 id="高效能人士的习惯概述">1. 高效能人士的习惯概述</h2>
<p>如何使自己变成高效能人士？</p>
<p>第一步，转变思维方式。培养以原则为中心的思维方式。原则是不能动摇的自然法则，如公平、正义、诚信等。有了它就可以培养高效能的习惯。</p>
<p>第二步，培养以下六个习惯。 个人领域： 1 积极主动 2 以终为始。 3
要事第一。</p>
<p>公众领域： 4 双赢思维 5 知彼解己 6 综合统效</p>
<p>总的方面 7 不断更新</p>
<h2 id="积极主动">2. 积极主动</h2>
<p><img
src="课程学习-高效能认识的七个习惯/_sec2_积极主动_小结.png" /></p>
<p>在刺激与回应之间，人有选择的自由</p>
<p>积极主动的含义： 第一，采取积极的态度与行动，面向现实和面向未来
第二，个人的行为是取决于自身选择，而不是外在环境</p>
<p>日常语言： 我可以xxx 我能选择xxx 我选择xxx 我愿意xxx</p>
<p>每个人有自己的关注点，按照是否可以掌控可以分为： 一，影响圈
如何提高自己的影响力 二，关注圈</p>
<p>如何做到积极主动？ 1 专注并扩大“影响圈” -
可直接控制的问题：与自身行为相关，培养正确习惯 -
可间接控制的问题：与他人行为相关，改进影响方法 -
无法控制的问题：与经历&amp;环境有关，改变心态 2 改善语言的使用习惯 3
从小事做起：以28天为一个周期，确立具体的flag</p>
<h2 id="以终为始">3. 以终为始</h2>
<p>纠结与各个问题，并且懊悔为什么没有想清楚</p>
<p>含义： - 以目标为导向，从结果出发（反向思维方式） -
以原则和价值观为基础，走对方向，走好方向</p>
<p>如何培养 1. 明确个人准则 - 基于个人的愿景和价值观——个人宪法 -
因人而异 2. 区分角色 - 排好每个角色的重要性 -
为每个角色设定好目标（三条行为要求） &gt;
如生活：朋友，女儿，摄影师；工作：销售，小白 3.
SMART法则，对每个目标进行分解，明确目标 - S(Specific): 具体的，明确的 -
M(Mesuable): 可衡量的 &gt;
能量化的量化，不能量化的细化，不能细化的流程化；数量、质量、成本、时间、满意度五个维度衡量
- A(Attainable): 可实现的 - R(Relevant): 相关性的 - T(Time-based):
有时限的</p>
<h2 id="要事第一">4 要事第一</h2>
<p>经常感觉时间不够用？重要的事情好像一件也没干好？</p>
<p>时间管理，本质是自我管理</p>
<p>“要事”的特征 1. 与目标有关 工作中，与关键OKR有关
生活中，与人生目标有关 2. 具有价值：附加价值和长远价值 3.
因人而异：个人角色与原则</p>
<p>“时间管理四象限法则” 1. 危机：重要且紧急 -
消耗大量时间和精力，持续性感到压力，成为消防员 -
不要拖延、提高效率、做好第二象限的工作（减少第一象限事情的发生） 2.
要事：重要且不紧急（七个习惯） - 制定预防性措施 - 团队梯度培养 -
锻炼身体 - 学习英语 - 复盘 3. 琐事：不重要且紧急 - TODO List -
勇于说no，分清主次 4. 杂事,消遣：不重要且不紧急 - 整理办公桌，娱乐 -
请勿沉迷</p>
<p>如何坚持做“要事”？ - 提高要事的优先级（优先将要事安排在日程表中） -
留出整块时间集中做 - 按计划逐步推进（不需要非常精细） -
将要事拆分小目标，逐步推进 - 留出弹性时间 - 摆正心态，不要急躁</p>
<h2 id="双赢思维">5 双赢思维</h2>
<p>含义？ 双赢!=妥协让步 在双方均认可下，达到均获利的方式</p>
<p>人际交往的六种模式： - 赢/输 （损人利己） - 输/赢 （舍己为人） - 赢
（独善其身） - 输/输（两败俱伤） - 赢/赢（利人利己） -
无交易（好聚好散）</p>
<p>重要性： - 是在相互依赖的环境中唯一可行的交往模式 -
是在敢作敢为与善解人意之间的平衡状态</p>
<p>如何培养？ 1. 向情感账户存款 - 理解他人 - 注意小节 - 信守承诺 -
明确目标和期望 - 正直诚信 - 勇于道歉 - 无条件的关爱 &gt;
针对不同的人，存取款行为各不相同，不要试图速战速决； &gt; 存款: &gt;
取款： 2. 识别立场，预设善意；提高ROI &gt;
不要纠结与立场，不指责不评价，以解决问题为目的 3.
无法双赢，不如好聚好散</p>
<h2 id="知彼解己">6 知彼解己</h2>
<p>先理解对方，再正确对方理解自己 倾听 + 表达</p>
<p>自传式倾听 vs 移情倾听 ? - 自传式倾听:
以自我为中心；把让别人理解自己放在首位；用自己的经历理解别人
沟通状态：频繁打断，没有眼神和肢体的交流，记不住讲述内容
表现：评价（对或不对），探究（还有其他原因），建议（好为人事），诠释（肯定是因为xx原因）</p>
<ul>
<li>移情倾听：以理解对方为目的；把先理解对方放在首位；在情感和理智上充分理解对方
沟通状态：鼓励讲话者叙述更多，眼神、表情和肢体都有互动，能记住讲述的重点</li>
</ul>
<p>步骤：
第一步，全神贯注的听。以眼神、手势和语气词配合即可。对方与你讲述内容在7:3或8:2以上。
第二步，表现出兴趣，引导对方继续讲述。对方在期待你的回应。还有呢，还有哪些呢，再多跟我说说等等
第三步，扼要总结复述，捕捉确定关键词。复述时不掺入过多的个人情感。最主要关注的是哪一点呢？
第四步，聚焦关注点，引导更深层次的沟通。你关注A是有哪些原因呢？</p>
<p>注意： 1. 节奏慢下来 2. 注意语音、语调和肢体动作 3.
把理解对方放在首位</p>
<p>知彼解己是实现有效人际沟通的关键</p>
<h2 id="统合综效">6 统合综效</h2>
<p>含义 - 整体大于部分之和 - 各部分之间的“关系”也是整体的一部分 -
有差异才有收获</p>
<p>前提条件： - 余额充足的情感账户； - 双赢模式； - 先理解他人。</p>
<p>区别： - 有开放的心态 - 充满正能量 - 以不同的视角看世界 -
寻求理解他人 - 积极寻找第三条道路</p>
<p>根本原则：尊重差异、取长补短 1. 了解你与他人的差异
第一步，写下他的特质 - 才智/能力 - 成长环境&amp;教育背景 - 人际关系能力
- 性格特征 第二步，写下你与TA的显著差别
第三步，写下这些差异可以怎样帮助你们实现共同的目标 2.
坦诚开放，尊重差异（珍视、肯定） 3. 设定共同目标</p>
<h2 id="不断更新">7 不断更新</h2>
<p>提高个人产能，保护并优化自己</p>
<ul>
<li>兼顾人生的四个层面：身体、精神、智力、社会/情感</li>
</ul>
<p>第一步，身体
第二步，精神（非常私人，因人而异），冥想，亲近大自然，找良师益友沟通，回忆小时候
第三步，智力（自我教育）。定期阅读优秀著作，写作
第三步，社会/情感（时刻自我激励，不断训练和累计）</p>
<p>如何做？ 1. 低调开始：从小事+有吸引力的事情做起 2.
留出空闲时间，不要急于求成 3. 不断调整</p>
<p>学习，坚持，实践 （坚持原则）</p>
]]></content>
  </entry>
</search>
