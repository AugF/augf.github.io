<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"ypwang.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Life&#39;s Notes">
<meta property="og:url" content="https://ypwang.github.io/page/4/index.html">
<meta property="og:site_name" content="Life&#39;s Notes">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Yun-Pan Wang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://ypwang.github.io/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Life's Notes</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Life's Notes</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">岁月数载，愿不负韶华</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/deeplearning-tensorflow-study-c596b3b82490/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/deeplearning-tensorflow-study-c596b3b82490/" class="post-title-link" itemprop="url">deeplearning tensorflow study</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 13:22:41" itemprop="dateCreated datePublished" datetime="2019-09-19T13:22:41+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/" itemprop="url" rel="index"><span itemprop="name">tools</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="一个pipeline">一个pipeline</h1>
<blockquote>
<p>一层封装，但还是仍然比较繁琐
https://blog.csdn.net/u012896627/article/details/72874678</p>
</blockquote>
<ol type="1">
<li>建立一个sess=tf.Session &gt; 交互式会话跟全局会话有什么区别 &gt;
tf.Session.init()
<ul>
<li>tf.Session vs tf.InteractiveSession &gt;
原本每个张量的计算，以及最后的取值都需要在默认的Session中，而且最终的运行也离不开Session.run();
采用InteractiveSession后， 本身就为默认的session,
此时距直接tensor.eval() 即可运行， vai.init.run()即可运行</li>
</ul></li>
<li>中间涉及到的张量Tensor, 主要相关的其实就是矩阵运算
<ul>
<li>tensor类型
<ul>
<li>tf.placeholder() // 通常用于小数据集的输入, 在后面的feed_back={}
将进行制定</li>
<li>tf.Variable(name=, intilizer=) // 可用于梯度 更新的内容</li>
<li>tf.constant(name= , shape=)</li>
</ul></li>
<li>tensor初始化
<ul>
<li>获取指定分布的值
<ul>
<li>random_normal 正态分布 random_uniform 聚云分布 truncated_normal</li>
</ul></li>
</ul></li>
<li>区分不同作用域的变量
<ul>
<li>with tf.variable_scope(scope_name, resue=): v1=""</li>
</ul></li>
<li>小技巧
<ul>
<li>tensor.eval() // 查看tensor的numpy矩阵</li>
<li>tensor.shape // 查看形状</li>
<li>v.assign() assign( )</li>
<li>tf.get_variable(name): 获取指定名称的var</li>
</ul></li>
</ul></li>
<li>Tensor之间的运算, 即边 &gt;
https://blog.csdn.net/u012896627/article/details/72874678
<ul>
<li>矩阵变换, 这个本身可以用numpy来做？
<ul>
<li>tf.expands_dims(arr, 1), 在指定的轴，
比如axis=1，增加一维，原数据不变？ 如其名，</li>
<li>tf.concat(arr1, arr2, axis=1) 在某一维上将两个向量合并。
(2,3)-&gt;(2,6), (4,3) 发现对于0来说是倒着来的</li>
<li>tf.sparse_to_dense()</li>
<li>tf.random_shuffle() 按照axis=0, 进行制定shuffle</li>
<li>tf.argmax/ arg.min 找到最大最小所对应的的位置</li>
<li>tf.equal 判断两个tensor是否每个元素都相等，返回bool的tensor</li>
<li>tf.cast 将x的数据格式转化为dtype</li>
<li>tf.matul 用来做举证乘法</li>
</ul></li>
<li>神经网络
<ul>
<li>tf.nn.embedding_lookup
将一个数字序列转化为embedding序列表示？举证</li>
<li>tf.trainable_variables 返回多个有训练的变量</li>
<li>tf.gradients 用来计算导数</li>
<li>tf.nn.dropout 防止过拟合</li>
</ul></li>
<li>普通操作
<ul>
<li>tf.linrange() tf.range()</li>
</ul></li>
<li>规范化
<ul>
<li>tf.variable_scope</li>
<li>tf.getvariale_scope</li>
</ul></li>
<li></li>
</ul></li>
<li>变量的初始化操作
<ul>
<li>Session.run(vari.initilizer) // 进行变量的初始化</li>
<li>tf.initialize_all_variables().run()</li>
</ul></li>
<li>损失函数和梯度下降
<ul>
<li>损失函数为图的最后一个tensor</li>
<li>优化器. optimizer = tf.train.GradientDesecentOptimizer(0.5)</li>
<li>train = ptimizer.minimize(cross_entropy)</li>
</ul></li>
<li>tensorflow运行
<ul>
<li>sess.run(fetches, feed_dict, options) //
<ul>
<li>fetches: tensor_node</li>
<li>feed_dict</li>
<li>return: fetches中的值</li>
</ul></li>
</ul></li>
<li>预测
<ul>
<li>tf.equal(tf.argmax(a, 1), tf.argmax(g,1))</li>
<li>accuary = tf.reduce_mean()</li>
</ul></li>
<li>tensor.close()</li>
</ol>
<blockquote>
<p>另外，所谓的tf.Graph; 每个tensor都可以产生一个graph;
或者定义一个graph, 之后都在该作用域下进行声明tensor</p>
</blockquote>
<p>tf快捷配置命令行参数 &gt; 并不是技术，用在了很多方面
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 声明</span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line">tf.app.flags.DEFINE_string(props_str, default_str) // DEFINE_TYPE</span><br><span class="line"></span><br><span class="line">// 使用</span><br><span class="line">FLAGS.props</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>查看GPU nvidia-smi</p></li>
<li><p>以后计划任务，务必注意查看需要花费的时间</p></li>
</ul>
<p>什么是skip-gram算法？
skip-gram算法是什么，在给出目标单词的情况下，预测它的上下文单词，这里会给定指定窗口大小。
思想：https://zhuanlan.zhihu.com/p/29305464 &gt;
没看懂，还是没明白第一个矩阵W是V*d,
是当前矩阵的什么。还有就是用到邻接矩阵的向量？？</p>
<p>https://zhuanlan.zhihu.com/p/27234078</p>
<p>扩展，一点想法，代理是什么？ 代理服务，代理协议，代理端口
首先代理服务，有邮件 代理协议就是像常见的http/https协议等等
代理端口也就是所用的代理端口的感觉</p>
<p>两个问题：现在已经测试了可以开启代理服务器的方式允许各种方式的网络配置。
已经测试了同局域网下可以访问，如何允许私网段以及不同局域网访问呢？按理说是能做到的</p>
<p>ssh连接远程访问也可以通过代理服务器来做，也就是说如果解决了不同局域网的访问，那么就可以访问到集群</p>
<p>很多配置相关的文件都在~/.ssh下</p>
<p>现在所配置的代理不过都是私网地址，即局域网内允许使用的地址
另外有一种情况就是NAT，地址映射协议，由某一地址统一管理。如果其他计算机需要访问的话，需要首先在主节点上进行说明。</p>
<ul>
<li>docker是什么？有什么用？ 相关概念：虚拟机，操作系统
http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html
虚拟机是在一个操作系统之上再嵌套一个操作系统。</li>
</ul>
<p>对于虚拟机来说，它管理很多方面，有着很多方面的高效性。就是一个操作系统，并且能够提供各种服务，比如文件服务、网络</p>
<p>而docker是进行进程的模拟，所以提供的服务会很快。启动快，占用资源少
有什么用？ 提供一次性的环境， 提供弹性的云服务， 组件微服务架</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/spark-study-ee540432fb17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/spark-study-ee540432fb17/" class="post-title-link" itemprop="url">spark study</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 13:18:49" itemprop="dateCreated datePublished" datetime="2019-09-19T13:18:49+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index"><span itemprop="name">spark</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>sc.textFile(,numpartition)</p>
<p>如果numpartition参数比实际划分的SplitSize小的化，则按照SplitSize的数目在每个executor上执行；否则就按照numpartition参数进行执行；</p>
<p>一定要区分资源调度和任务执行</p>
<p>在任务执行阶段，每个executor只会按照其对应的InputSize单位来执行数据。如果有多个executor,
则按照多个的executor来进行执行</p>
<h1 id="写代码要考虑的事">写代码要考虑的事</h1>
<p>代码之前——环境，环境如何配置？ 代码载体——IDE, 有哪些特点？
代码语言——常用操作和模板进行总结，语法特性要能表达出来，用语言能够实现出任意自己想实现的犯方法
- 角度1 - 数据结构 &gt; 1. 对基本数据结构操作的了解 &gt; 2.
这些操作的输入、输出参数是什么？如何实现的？快慢如何 &gt; 3.
如何自己定义？ - 算法 &gt;
设计算法，算法正确性，算法的时间空间复杂度，算法的实现，代码复杂度 -
角度2 基本数据结构，字符串，数组，元祖，列表，字典这些抽象的数据结构；
对象，多态，操作符重载， 异常， debug</p>
<p>代码调试——如何测试自己的代码是否正确 &gt; 测试语句，继承测试
代码维护——Git, 版本控制 代码执行——编译器执行的角度（一般不用去考虑）
代码上线——命令行设置</p>
<blockquote>
<p>非设计算法，主要调用接口，那么关注代码的含义，代码对应着实际上有哪些操作
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import spark</span><br><span class="line">// 前面一系列的环境配置先耍开</span><br><span class="line"></span><br><span class="line">def main()&#123;</span><br><span class="line">    </span><br><span class="line">    val conf = new SparkConf().setAppName().setMaster</span><br><span class="line">    conf.set()  // 这里可以配置哪些项？这些项又表示着什么？</span><br><span class="line"></span><br><span class="line">    val sc = new SparkContext()   // 2.3之后spark是怎么执行的</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>计算模式中节点故障和慢节点容错处理 特别是在流和交互式SQL查询中</p>
<p>RDD能够保存世系图，而且提供保存到各个部分的功能。
所以RDD能够很好地处理并行计算中的数据共享</p>
<p>spark编程中开发者需要编写一个驱动程序来链接到工作进程，驱动程序定义一个或者多个RDD以及相关行动操作，驱动程序同时记录RDD的继承关系。
工作进程是一直运行的进程</p>
<p>操作 -
定义操作，创建RDD，来自于内存集合和外部存储系统，转换操作生成的RDD -
转换操作，只是转换，并未生成 - 控制操作，进行持久化 -
行动操作，触发spark运行的程序</p>
<p>分区，注意到分区是一个逻辑概念</p>
<p>分区的多少，往往意味着并行计算的粒度
如果是从本地文件创建，则默认值为程序所分配到的CPU数；如果是从hdfs上建立，则为文件的数据块数</p>
<p>RDD首选位置
Spark形成任务有向无环图时，会尽可能地把计算分配到靠近数据的位置，减少数据网络传输</p>
<h2 id="scala">2. scala</h2>
<p>https://learnxinyminutes.com/docs/scala/</p>
<ul>
<li>:help 查看所有的帮助</li>
<li>:type (true, 2.0) &gt; 查看类型</li>
<li>保存和加载 repl文件
<ul>
<li>:save /sites/repl-test.scala</li>
<li>:load /sites/rep1-test.scala</li>
</ul></li>
<li>查看历史 :h? &gt; 怎么使用历史中的文件呢？
<ul>
<li>:history number</li>
</ul></li>
<li>编写长代码
<ul>
<li>:paste &gt; 怎么加载文件中代码还是不会</li>
</ul></li>
<li>退出
<ul>
<li>quit</li>
</ul></li>
</ul>
<h3 id="类型">2.1 类型</h3>
<ul>
<li><p>val z:Type = value &gt; val, var</p>
<ul>
<li>Type: Int, Long, Double</li>
<li>类型继承体系 <img data-src="asserts/scala_type.png" />
<ul>
<li>列表中没有元素了即, Nil = List[Nothing], 它是List[T]的子类</li>
<li>Null类型的唯一实例是null值，可以将null赋值给任何引用但是不能赋值给值类型的变量</li>
<li>与Java基本类型相对应的类，以及Unit类型，都扩展自AnyVal</li>
<li>Any类定义了，A.isInstanceOf[B] 来判断A是否是类别B</li>
<li>A.getClass.getSimpleName</li>
</ul></li>
</ul></li>
<li><p>String &gt; raw" " 不含转义字符</p>
<ul>
<li>基本
<ul>
<li>属性
<ul>
<li>length</li>
</ul></li>
<li>init
<ul>
<li>直接赋值</li>
<li>Char[], copyValueOf(char[], offset, count)</li>
</ul></li>
<li>增
<ul>
<li>尾部增加元素或元组 str = str.concat(str2); str = str+str2</li>
</ul></li>
<li>删
<ul>
<li>转变为替换或者查拼接</li>
</ul></li>
<li>改
<ul>
<li>改特定群组的值 str.replace(regex, "") //前面可以接正则表达式</li>
</ul></li>
<li>查
<ul>
<li>按索引查 str(i) str.charAt(i)</li>
<li>按值查 str.indexof(c1) str.lastindexof(c1)</li>
<li>查范围的值
<ul>
<li>只要求前面 str.take()</li>
<li>只要求后面 str.drop()</li>
<li>同时 str.substring(start_index, end_index) str.slice()</li>
</ul></li>
<li>查是否满足要求
<ul>
<li>str.startsWith() str.endsWith()</li>
</ul></li>
</ul></li>
</ul></li>
<li>高级
<ul>
<li>预处理 trim()</li>
<li>切分 split()</li>
<li>格式化
<ul>
<li>s"${expression}" expression可以为上文的变量之类的 &gt;
对于输出的各种类型的操作为使用变量的toString参数</li>
<li>f"${}%1.0f dada"</li>
<li>raw" "</li>
<li>regr.r内置了正则表达式, 如 <code>"(.*)@(.*)".r</code></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>函数 def fun(x:Int, y:Int=4):Int={}</p>
<ul>
<li>默认参数</li>
<li>可变参数, 由变量直接指定</li>
<li>匿名函数 val sq: Int-&gt;Int = (x:Int)-&gt;x*x</li>
<li>允许多返回值</li>
<li>可以省略参数，可以省略返回值</li>
</ul></li>
<li><p>flow control</p>
<ul>
<li>range(5): (1 to 5 by 1) start to end by steo</li>
<li>循环
<ul>
<li>().foreach{}</li>
<li>while() {}</li>
<li>for(a&lt;-array){}</li>
</ul></li>
<li>条件
<ul>
<li>简单本 val a = if(x==10) "" else " "</li>
</ul></li>
</ul></li>
<li><p>Data Structures</p>
<ul>
<li>物理: 数组、链表</li>
<li>不变的
<ul>
<li>Array() List()
<ul>
<li>sortBy, sortWith{case (a,b)} // 自定义</li>
<li>distince</li>
</ul></li>
<li>Map()
<ul>
<li>sort: Map()没有sort函数，所以需要 用list</li>
<li>获取值
<ul>
<li>apply() 返回默认方法，不知道谁制定的, default()
会进行定义默认值</li>
<li>getOrElse(v,defalut) 返回默认值</li>
</ul></li>
<li>增加，以及更新
<ul>
<li>错误： map(key) = new_value &gt;
注意这条命令只能对于mutable的集合可用</li>
</ul></li>
<li>删除
<ul>
<li>remove(key)</li>
</ul></li>
<li>其他</li>
<li>keys, values</li>
<li>isEmpty</li>
<li>max, min, filter, find</li>
<li>sum,size</li>
<li>++添加一个新的</li>
<li>clear(), clone()</li>
<li>count(): 技术</li>
</ul></li>
<li>Set()
<ul>
<li>操作</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>类 Classes</p>
<ul>
<li>构造函数： 直接在类的开头声明 class Dog(br: String) { var breed:
String = br // 这里即构造函数 }</li>
<li>变量和函数默认的访问控制权限是public &gt; 特别地，可以private def
fun(): Type={} ？？？protect</li>
</ul></li>
<li><p>同名Object,
实际上是该类的一个单例对象，在其他语言中往往对应的是静态方法，静态变量之类的东西。
&gt;
两者的区别感觉上说也就是Class需要new产生，而Object因为是静态的，所以可以直接使用</p></li>
<li><p>case classes &gt; vs Classes, 如何使用？
Classes强调的是封装，多态和行为。这些值在类中通常是私有的，方法是可扩展的。
// 即默认情况下 &gt; 而case
classes的目的是来持有不可变对象，它们往往有很少的方法，而且这些方法基本上没有副作用。
使用起来定义简单，有点像结构体的感觉，pair case class Person(name:
String, phoneNumber:String)</p></li>
<li><p>trait 特征，实际上就是抽象类或者接口的概念； &gt;
只需要定义值或方法的属性或者返回值即可。 由继承它的类来自行扩展 class A
extends Dog with Bark {} // 扩展两个接口</p></li>
<li><p>继承 &gt;
继承利用的也是extends关键字，不过在scala中继承实体类有以下的要求：</p>
<ul>
<li>def只能重写另一个def</li>
<li>val只能重写另一个val或不带参数的def(?,应该不会涉及到)</li>
<li>var只能重写另一个抽象的var &gt; 可以定义自己的方法</li>
</ul></li>
<li><p>Pattern Matching &gt; scala特有的, 利用了case结构;
这样的想法就是使得省去了break语句 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"> // Pattern matching might look familiar to the switch statements in the C family</span><br><span class="line">// of languages, but this is much more powerful. In Scala, you can match much</span><br><span class="line">// more:</span><br><span class="line">def matchEverything(obj: Any): String = obj match &#123;</span><br><span class="line">  // You can match values:</span><br><span class="line">  case &quot;Hello world&quot; =&gt; &quot;Got the string Hello world&quot;</span><br><span class="line"></span><br><span class="line">  // You can match by type:</span><br><span class="line">  case x: Double =&gt; &quot;Got a Double: &quot; + x</span><br><span class="line"></span><br><span class="line">  // You can specify conditions:</span><br><span class="line">  case x: Int if x &gt; 10000 =&gt; &quot;Got a pretty big number!&quot;</span><br><span class="line"></span><br><span class="line">  // You can match case classes as before:</span><br><span class="line">  case Person(name, number) =&gt; s&quot;Got contact info for $name!&quot;</span><br><span class="line"></span><br><span class="line">  // You can match regular expressions:</span><br><span class="line">  case email(name, domain) =&gt; s&quot;Got email address $name@$domain&quot;</span><br><span class="line"></span><br><span class="line">  // You can match tuples:</span><br><span class="line">  case (a: Int, b: Double, c: String) =&gt; s&quot;Got a tuple: $a, $b, $c&quot;</span><br><span class="line"></span><br><span class="line">  // You can match data structures:</span><br><span class="line">  case List(1, b, c) =&gt; s&quot;Got a list with three elements and starts with 1: 1, $b, $c&quot;</span><br><span class="line"></span><br><span class="line">  // You can nest patterns:</span><br><span class="line">  case List(List((1, 2, &quot;YAY&quot;))) =&gt; &quot;Got a list of list of tuple&quot;</span><br><span class="line"></span><br><span class="line">  // Match any case (default) if all previous haven&#x27;t matched</span><br><span class="line">  case _ =&gt; &quot;Got unknown object&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>函数式编程</p>
<ul>
<li>map</li>
<li>foreach</li>
<li>filter (1 to 15 by 2).filter(_%2==0)</li>
<li>reduce &gt; 等价于 for{n&lt;-s} yield sq(n) &gt; //
所有scala这门语言本身就支持 惰性求值, 想想真的nb</li>
</ul></li>
<li><p>implicit &gt; commonplace 频繁 &gt; 怎么说呢？
实际上就是一种潜在的标记的感觉。默认的全局的变量。 &gt;
对于方法，如果有一个参数通常是平凡的，但是又可能改变。这是就可以使用implicit作为参数。
&gt; 编译器会自动向前寻找该标记然后进行解析</p>
<ul>
<li>def sendGreetings(toWhom:String)(implicit howMany:Int) = toWhom +
howMany &gt; sendGreetings("wang") // "wang 100"</li>
<li>implicit val myImplicitInt=100 &gt; ? 怎么用，不知道</li>
<li>implicit def myImplicitFucion(breed:String) = new
Dog("Golder"+breed) &gt; "wyp" // "Golder wyp" &gt;
从理解上看，为什么不用默认形参或者指定参数，不会就只为了少点代码吧？？</li>
</ul></li>
<li><p>Misc</p>
<ul>
<li>import scala.collection</li>
<li>import scala.collectin.immutable._</li>
<li>import scala.collection.immutable.{List,Map}</li>
<li>import scala.collection.immutable.{List=&gt;Li} // rename</li>
<li>import scala.collection.immutable.{Map=&gt;<em>, Set=&gt;</em>, _}
// 排序Map,Set</li>
</ul></li>
<li><p>Input / Output</p>
<ul>
<li>读 import scala.io.Source for(line &lt;-
Source.fromFile("myfile").getLines()) println(line)</li>
<li>写 val writer = new PrinterWriter("myfile.txt") writer.write(" " +
util.Properties.lineSeparator) writer.close(</li>
</ul></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/python-study-764325c9e34f/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/python-study-764325c9e34f/" class="post-title-link" itemprop="url">python-study</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 13:17:33" itemprop="dateCreated datePublished" datetime="2019-09-19T13:17:33+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/study/" itemprop="url" rel="index"><span itemprop="name">study</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>8.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="vscode的好处">1. vscode的好处</h2>
<ol type="1">
<li>显示思路过程</li>
<li>实时性显示</li>
<li>块编程</li>
<li>批处理</li>
</ol>
<h2 id="机器学习常用的库">2. 机器学习常用的库</h2>
<ul>
<li><p>核心库与统计：Numpy、Scipy、Pandas、StatsModels。</p></li>
<li><p>可视化：Matplotlib、Seaborn、Plotly、Bokeh、Pydot、Scikit-learn、XGBoost/LightGBM/CatBoost、Eli5。</p></li>
<li><p>深度学习：Tensorflow、PyTorch、Keras。</p></li>
<li><p>分布式深度学习：Dist-keras/elephas/spark-deep-learning。</p></li>
</ul>
<p>自然语言处理：NLTK、SpaCy、Gensim。</p>
<p>数据抓取：Scrapy。</p>
<h2 id="python使用总结">3. python使用总结</h2>
<p>jupyter - b? 查看文档 - b?? 查看源码 - %shell命令 - qucikref
快捷查看</p>
<h3 id="基本类型">3.1 基本类型</h3>
<h4 id="null类型">3.1.1 null类型</h4>
<p>注意一个想法，python中万物均可对象化，这么说的意思就是所有东西都有它的类型和值。
&gt;
特别需要注意的是，哪些时候使用引用即可，哪些使用必须使用一个新的对象</p>
<blockquote>
<p>dir() 查看参数的方法, type() 查看类型, id()=hashCode, - ==: value
equality - is: reference equality is是==加上两个对象的位置是一样 ==
isinstance(some_object, (int, float)) &amp;&amp; value</p>
</blockquote>
<p>None表示不是对象？什么时候会碰到？？ &gt;
比如函数参数时，什么都没有传递过来，都是有默认值的情况！！！ &gt;
表示空对象, 类型是NoneType, 值是为空 &gt; if(None) =False //
一般是None的话，最好事先说出。 &gt;
True和Flase类型也跟None不一样，他们是bool类型</p>
<p>NULL: 表示空字符，str</p>
<p>"": 0: False: True:</p>
<h4 id="值和引用">3.1.2 值和引用</h4>
<ul>
<li><p>值类型: 数值、字符串、元组(注意这里是元组) &gt;
即只能自己改自己，不能因为赋值就改变自己，因为赋值它始终是产生了一个新的内存地址</p></li>
<li><p>引用类型： 列表、集合、字典 &gt; 本身允许被改变</p></li>
</ul>
<h4
id="and-or替代了-依然是按位操作-它的优先级始终是小于比较大于赋值的">3.1.3
and, or替代了&amp;&amp;, ||; &amp;,|依然是按位操作，
它的优先级始终是小于比较，大于赋值的</h4>
<blockquote>
<p>python中int之间的and, or;
始终是按照先将其转化为bool类型，然后按照实际的and,or判断逻辑，不行则返回即返回值</p>
</blockquote>
<h4 id="section">3.1.4</h4>
<ul>
<li>可执行的伪代码</li>
<li>使用缩进而不是括号</li>
<li>万物皆可对象</li>
<li>动态引用，强类型</li>
<li>鸭子类型，不关注具体类型，而是关注能做什么</li>
<li>属性和方法
<ul>
<li>getattr(a, attr)(x): 反射，属于强类型</li>
</ul></li>
<li>可变 vs 不可变</li>
<li>单值，即标量类型
<ul>
<li>None</li>
<li>str</li>
<li>bytes</li>
<li>float</li>
<li>bool</li>
<li>int</li>
</ul></li>
<li>数值类型
<ul>
<li>**, 平方</li>
<li>7.2324</li>
<li>6.78e-5</li>
<li>3 / 2: 实际的除法</li>
<li>3 // 2: 整除</li>
</ul></li>
<li>字符串
<ul>
<li>', ", """</li>
<li>r' ', "\" 字面值和转义</li>
<li>不可变的，即s[1]=2是错误的。
<ul>
<li>hash(): 可行；</li>
<li>=：产生一个新的对象</li>
</ul></li>
<li>基本操作
<ul>
<li>长度 len()</li>
<li>清空 str=""</li>
<li>判断某种属性
<ul>
<li>isalnum() // 数字和单词</li>
<li>isalpha() // 单词</li>
<li>isdecimal() // 数字 byte</li>
<li>islower() // 小写</li>
</ul></li>
<li>字母相关操作
<ul>
<li>lower()</li>
<li>captialize()</li>
<li>upper()</li>
</ul></li>
<li>常见操作
<ul>
<li>查找
<ul>
<li>次数， count(substr,start, end)</li>
<li>位置
<ul>
<li>index(str, ) rindex // 异常</li>
<li>find(str, ) rfind // lower, -1</li>
<li>endswith, startswith</li>
</ul></li>
</ul></li>
<li>去空格
<ul>
<li>strip(), rstrip()</li>
</ul></li>
<li>划分为列表： split, rsplit</li>
<li>替换， replace(A, B)</li>
<li>合并两个字符串
<ul>
<li>join</li>
</ul></li>
<li>格式化
<ul>
<li>{0:.2f}, {0:s}, {2:d}</li>
</ul></li>
<li>encode, decode</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="元组-集合-列表-字典">3.2. 元组(), 集合{}, 列表[], 字典</h3>
<h4 id="list">3.2.1 list []</h4>
<ul>
<li>长度 &gt;
特别地，长度一般是有多种方法，具体哪种一般来说看源代码怎么定义的，对于Tree结构，习惯性地包括定义size,那么使用size方法绝对是最优秀的
<ul>
<li>__len__方法</li>
</ul></li>
<li>插入
<ul>
<li>尾部， apppend</li>
<li>任意， insert(index, value)</li>
</ul></li>
<li>删除
<ul>
<li>尾部， pop()</li>
<li>任意， del li[index]</li>
<li>值， remove(value)</li>
</ul></li>
<li>查找
<ul>
<li>单点查找
<ul>
<li>是否存在 in</li>
<li>index: li.index(value)</li>
<li>value: li[index]</li>
</ul></li>
<li>范围查找
<ul>
<li>d[start:end:step] // 可为负</li>
</ul></li>
</ul></li>
<li>合并list
<ul>
<li>+性能低</li>
<li>extend(list2)</li>
</ul></li>
<li>其他
<ul>
<li>li.sort(key=) // 原地排序</li>
<li>sorted(li) // 返回副本</li>
<li>reversed</li>
</ul></li>
</ul>
<blockquote>
<p>允许范围查找，赋值，删除，即切片</p>
</blockquote>
<h4 id="dict">3.2.2 dict</h4>
<blockquote>
<p>key必须是可以hashtable的数据，即唯一性, 可以通过hash来检验;
一般来说只有值类型可哈希 <strong>doc</strong> ,
查看文档中的使用说明，输入与输出 isinstance(1, set)
查看是否是需要的类型</p>
</blockquote>
<ul>
<li>插入
<ul>
<li>set(key, defalut) // 存在不改变值 &gt; 可加后续操作 set(key,
default).appende(key)</li>
<li>di[key]=value // 存在改变值</li>
</ul></li>
<li>删除
<ul>
<li>del d[key]</li>
<li>di.pop(key) // 返回当前元素</li>
</ul></li>
<li>查看
<ul>
<li>存在： in di // 默认在keys()中查看</li>
<li>di[key] // KeyError 异常</li>
<li>do.get(key, default_value) // 不存在返回特定的值</li>
</ul></li>
<li>合并dict
<ul>
<li>update(di2) // 完全舍弃旧值</li>
</ul></li>
<li>输出
<ul>
<li>di.keys() // Iterable类型</li>
<li>di.values()</li>
</ul></li>
<li>由两个列表创建
<ul>
<li>di = {k:v for k,v in zip(list1, list2)} // 会吞并重复元素</li>
<li>di = dict(zip(list1, list2)) &gt; li = list(zip(list1, list2)) // [(
), ( )] 此时内部为元组</li>
</ul></li>
<li>分解为两个列表
<ul>
<li>list1, list2 = dict.keys(), dict.values() // python3是对应的顺序
&gt; list1, list2 = zip(*li) // li为列表时</li>
</ul></li>
<li>一些进一步简化的操作
<ul>
<li>defaultdict // 可设置value默认值 &gt; from collections import
defaultdict &gt; by_letter=defaultdict(list) // 中间传入的为类型</li>
</ul></li>
</ul>
<blockquote>
<p>一个很神奇的现象, di = {1:2, 2:5} ci=di 1. di = {} , ci =&gt; {1:2,
2:5} 2. di[1]=5 ci[1]=&gt;5</p>
</blockquote>
<p><font color="red">defaultdict</font> &gt; 可以用来指定value的类型</p>
<h4 id="集合-set">3.2.3 集合 set</h4>
<blockquote>
<p>特殊的字典，只有健没有值; 同样不可重复. 没有特定的位置性.
像元组则是序列数据，即可重复出现</p>
</blockquote>
<ul>
<li>插入： add(x)</li>
<li>删除： remove(x)</li>
<li>清空： clear()</li>
<li>合并集合： a.update({1,2})</li>
<li>清楚首元素： a.pop() // 默认最小元素， 可以做堆</li>
<li>两个集合的运算
<ul>
<li>A是B的子集： A.issubset(B)</li>
<li>A是B的父集： A.issuperset(B)</li>
<li>并集
<ul>
<li><div class="line-block"></div></li>
<li>union</li>
</ul></li>
<li>交集
<ul>
<li>&amp;</li>
<li>intersection</li>
</ul></li>
<li>差集， -, 不够减为空</li>
<li>异或 ^</li>
<li>支持 &amp;=</li>
</ul></li>
</ul>
<h4 id="推导式">3.2.4 推导式</h4>
<ul>
<li><p>list</p></li>
<li><p>tuple: !!! 有个特别好的特性就是generator, 即满足惰性求值;
而且是值类型 &gt;
所以这里得到的结果不是tuple类型，而是generator</p></li>
<li><p>{} 结果两种</p>
<ul>
<li>dict</li>
<li>set</li>
</ul></li>
</ul>
<h4 id="复制">3.2.5 复制</h4>
<ul>
<li>copy只复制一层</li>
<li>深度复制 &gt; import copy &gt; di = copy.deepcopy(my_dict)</li>
</ul>
<h4 id="一些好的方法">3.2.6 一些好的方法</h4>
<ul>
<li><strong>mro</strong>_ ：动态类型， 判断属于哪些类型</li>
<li>isinstance(A, type): 判断是否属于某个类型</li>
<li>if, <strong>len</strong>, 查看是否为0,
and都是转变为bool类型来做</li>
<li><strong>doc</strong>: 查看基本的函数输入，输出文档</li>
<li>dir(): 查看所拥有的方法</li>
</ul>
<h3 id="语句">3.3 语句</h3>
<ul>
<li>if A: pass elif: pass else: pass</li>
<li>while A: pass</li>
<li>for i in range(2):</li>
<li>try: except Exception: finally ### 3.4 函数</li>
</ul>
<h4 id="基本">3.4.1 基本</h4>
<ul>
<li>参数
<ul>
<li>顺序性， 有默认值的放在最后</li>
<li>*args, **kwargs 默认为None</li>
<li>可为函数</li>
<li>字典式指定值 &gt; 无参数时，为None</li>
</ul></li>
<li>变量： 严格作用域</li>
<li>返回值：
<ul>
<li>多值</li>
<li>字典</li>
</ul></li>
</ul>
<h4 id="匿名函数">3.4.2 匿名函数</h4>
<p><code>lambda paras: return_value</code> <code>lambda x,y : x+y</code>
&gt; 可以引用在任何需要使用函数作为参数的情况中 如 map, reduce, sort
&gt; reduce 还是不大好理解</p>
<h4 id="柯里化">3.4.3 柯里化</h4>
<p>部分参数应用 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">add_number = lambda x,y: x+y</span><br><span class="line">from functools import partial</span><br><span class="line">add_five = partial(add_numbers, 5)  // 相比于默认参数，是动态默认参数</span><br></pre></td></tr></table></figure></p>
<p>#### 3.4.4 生成器 generaotr 惰性求值 - return =&gt; yeild - gen = (
)</p>
<p>#### 3.4.5 itertools模块 &gt; 用于许多常见数据算法的生成器</p>
<p>https://www.liaoxuefeng.com/wiki/1016959663602400/1017783145987360</p>
<ul>
<li>combinations(, k): 产生组合数</li>
<li>permutations(): 产生排列数</li>
<li>groupby, 将相同的字符串给弄出来 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; for key, group in itertools.groupby(&#x27;AAABBBCCAAA&#x27;):</span><br><span class="line">...     print(key, list(group))</span><br><span class="line">...</span><br><span class="line">A [&#x27;A&#x27;, &#x27;A&#x27;, &#x27;A&#x27;]</span><br><span class="line">B [&#x27;B&#x27;, &#x27;B&#x27;, &#x27;B&#x27;]</span><br><span class="line">C [&#x27;C&#x27;, &#x27;C&#x27;]</span><br><span class="line">A [&#x27;A&#x27;, &#x27;A&#x27;, &#x27;A&#x27;]</span><br></pre></td></tr></table></figure></li>
<li>chain(iter1, iter2[,..]): 串联多个iter</li>
<li>repeat('A',n): 重复n次</li>
<li>cycle("ABC"): 循环，直到ctrl+c退出 #### 3.4.6 字节、位运算 (n &amp;
0x3f3f3) &gt;&gt;1: 人可用</li>
</ul>
<h3 id="类">3.5 类</h3>
<ul>
<li>命名特点
<ul>
<li>属性: 名词</li>
<li>方法：动词, 注意要加括号</li>
<li></li>
</ul></li>
</ul>
<h3 id="其他模块">3.6 其他模块</h3>
<h4 id="正则表达式">3.6.1 正则表达式</h4>
<ul>
<li>模式: r" "
<ul>
<li>替换：str = re.sub(origin_str, res_str, str)</li>
<li>匹配首个结果 re.match(, test) None(False)</li>
<li>划分 li = re.split(r' ',str)</li>
<li>分组 li = re.group(r' ', str) //group(0)为原始, 1-k为分组结果</li>
</ul></li>
<li>方法
<ul>
<li>单个字母匹配
<ul>
<li>字</li>
<li>空格</li>
<li>字母或数字</li>
<li>. 任意</li>
<li>0<sub>9,a</sub>z 特别</li>
<li>. 转义， 匹配原字符</li>
</ul></li>
<li>次数
<ul>
<li>a 1次</li>
<li>a+ &gt;=1</li>
<li>a* &gt;=0</li>
<li>a{n} n次</li>
<li>a{n,m} n~m次</li>
</ul></li>
<li>特别
<ul>
<li>^ 指定必须从数字开头</li>
<li>$: 指定必须数字结尾</li>
</ul></li>
<li>范围
<ul>
<li></li>
<li>(A|B)： 两个可选 &gt; ()
子表达式的开始和结束，在分组时起到特别的作用，一个括号表示一个group</li>
</ul></li>
</ul></li>
<li>特别说明：正则表达式匹配为贪婪模式</li>
</ul>
<h4 id="文件模块">3.6.2 文件模块</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in open(path): // i默认有行结束符，记住用rstrip()</span><br></pre></td></tr></table></figure>
<ul>
<li><p>f.read(121)</p></li>
<li><p>f.tell()</p></li>
<li><p>f.seek(3): 移动指针到指定字节</p></li>
<li><p>模式： r, w, a, r+, b, U</p></li>
</ul>
<h4 id="collections">3.6.3 collections</h4>
<ul>
<li><p>namedtuple &gt; 为tuple的每一项起名字 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from collections import namedtuple</span><br><span class="line">Point = namedtuple(&#x27;Point&#x27;,[&#x27;x&#x27;,&#x27;y&#x27;])</span><br><span class="line">p = Point(1,2)</span><br><span class="line">p.x  # 1</span><br><span class="line">p.y # 2</span><br></pre></td></tr></table></figure></p></li>
<li><p>deque &gt; list支持的太过分,
deque缩小限制，只允许两端插入和删除</p>
<ul>
<li>append, appendleft</li>
<li>pop , popleft</li>
</ul></li>
<li><p>defaultdict &gt; 设置默认的值 dd = defaultdict(lambda:
"N/A")</p></li>
<li><p>OrderedDict &gt; 保证先进先出的顺序，可以当做队列用</p></li>
<li><p>ChainMap &gt; 将多个dict, 合为一个逻辑dict ## 4. 优化</p></li>
</ul>
<p>https://python-web-guide.readthedocs.io/zh/latest/idiom/idiom.html#true-false-none</p>
<h3 id="a.-链式1a7">a. 链式：1&lt;a&lt;7</h3>
<h3 id="b.-ba-if-ab-else-b">b. b=a if a&gt;b else b</h3>
<h3 id="c.-xyyx">c. x,y=y,x</h3>
<h3 id="d.-strmyname-my-age-.formatname-age">d. str="myname:{} my age
{}".format(name, age)</h3>
<h3 id="e.-list-dict使用">e. list, dict使用[],</h3>
<p>odd_list=[e for e in mulist if e%2==1]</p>
<p>user_list = [{'name': 'lucy', 'email': 'lucy@g.com'}, {'name':
'lily', 'email': 'lily@g.com'}] user_email = {user['name']:user['email']
for user in user_list if 'email' in user}</p>
<h3 id="f.-if-none-特别说明">f. if None 特别说明</h3>
<p>if() : pass 实际调用的是l.__len__()==0</p>
<p>if something is None: // None是单例对象 // 注意</p>
<h3 id="g.-index变量访问-enumerate">g. index变量访问, enumerate;</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for index,  element int enumerate(my_container)</span><br></pre></td></tr></table></figure>
<h3 id="h.-避免使用可变变量作为函数参数的默认初始化值-none">h.
避免使用可变变量作为函数参数的默认初始化值, None</h3>
<p>// 可以使用None作为可变对象的占位符</p>
<h3 id="i.-函数参数即函数">i. 函数参数即函数</h3>
<p>// 一切都可对象，可以把参数作为函数使用 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import operator as op</span><br><span class="line">def print_table(operator):</span><br><span class="line">    for x in range(1, 3):</span><br><span class="line">        for y in range(1, 3):</span><br><span class="line">            print(str(operator(x, y)) + &#x27;\n&#x27;)</span><br><span class="line"></span><br><span class="line">for operator in (op.add, op.sub, op.mul, op.div):</span><br><span class="line">    print_table(operator)</span><br><span class="line"></span><br></pre></td></tr></table></figure> ### j.
防御式编程, 不断检查参数</p>
<h3 id="k.-dict实现switch..case..">k. dict实现switch..case..</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># bad</span><br><span class="line">def apply_operation(left_operand, right_operand, operator):</span><br><span class="line">    if operator == &#x27;+&#x27;:</span><br><span class="line">        return left_operand + right_operand</span><br><span class="line">    elif operator == &#x27;-&#x27;:</span><br><span class="line">        return left_operand - right_operand</span><br><span class="line">    elif operator == &#x27;*&#x27;:</span><br><span class="line">        return left_operand * right_operand</span><br><span class="line">    elif operator == &#x27;/&#x27;:</span><br><span class="line">        return left_operand / right_operand</span><br><span class="line"># good</span><br><span class="line">def apply_operation(left_operand, right_operand, operator):</span><br><span class="line">    import operator as op</span><br><span class="line">    operator_mapper = &#123;&#x27;+&#x27;: op.add, &#x27;-&#x27;: op.sub, &#x27;*&#x27;: op.mul, &#x27;/&#x27;: op.truediv&#125;</span><br><span class="line">    return operator_mapper[operator](left_operand, right_operand)</span><br></pre></td></tr></table></figure>
<h3 id="l.-namedtuple">l. namedtuple ?</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># bad</span><br><span class="line">rows = [(&#x27;lily&#x27;, 20, 2000), (&#x27;lucy&#x27;, 19, 2500)]</span><br><span class="line">for row in rows:</span><br><span class="line">    print &#x27;&#123;&#125;`age is &#123;&#125;, salary is &#123;&#125; &#x27;.format(row[0], row[1], row[2])</span><br><span class="line"></span><br><span class="line"># good</span><br><span class="line">from collections import  namedtuple</span><br><span class="line">Employee = namedtuple(&#x27;Employee&#x27;, &#x27;name, age, salary&#x27;)</span><br><span class="line">for row in rows:</span><br><span class="line">    employee = Employee._make(row)</span><br><span class="line">    print &#x27;&#123;&#125;`age is &#123;&#125;, salary is &#123;&#125; &#x27;.format(employee.name, employee.age, employee.salary)</span><br></pre></td></tr></table></figure>
<h3 id="m.-isinstance">m. isinstance</h3>
<h3 id="n.-with">n. with</h3>
<h3 id="o.-yeild关键字-惰性求值">o. yeild关键字, 惰性求值</h3>
<p>([ expression ]) // 本身就是惰性求值 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># bad</span><br><span class="line">def f():</span><br><span class="line">    # ...</span><br><span class="line">    return biglist</span><br><span class="line"></span><br><span class="line"># good</span><br><span class="line">def f():</span><br><span class="line">    # ...</span><br><span class="line">    for i in biglist:</span><br><span class="line">        yield i</span><br></pre></td></tr></table></figure></p>
<h3 id="p.-wraper">p. Wraper</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from functools import wraps</span><br><span class="line"></span><br><span class="line">ef beg(target_function):</span><br><span class="line">    @wraps(target_function)</span><br><span class="line">    def wrapper(*args, **kwargs):</span><br><span class="line">        msg, say_please = target_function(*args, **kwargs)</span><br><span class="line">        if say_please:</span><br><span class="line">            return &quot;&#123;&#125; &#123;&#125;&quot;.format(msg, &quot;Please! I am poor :(&quot;)</span><br><span class="line">        return msg</span><br><span class="line"></span><br><span class="line">    return wrapper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@beg</span><br><span class="line">def say(say_please=False):</span><br><span class="line">    msg = &quot;Can you buy me a beer?&quot;</span><br><span class="line">    return msg, say_please</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="好用的工具">5. 好用的工具</h2>
<p>https://blog.csdn.net/moqsien/article/details/79544876</p>
<h2 id="一些其他">6. 一些其他</h2>
<h3 id="二分搜索和维护已排序的列表">6.1 二分搜索和维护已排序的列表</h3>
<p>bitsect: 二分搜索</p>
<p>bitsect.bitsect(c, 2) // 搜索插入的位置 bitsect.insort(c,5) //
插入元素</p>
<h3 id="排序">6.2 排序</h3>
<p>a.sort(key=len) sorted(a)</p>
<h3
id="zip-将多个列表元组或其它序列成对组合为一个元组列表-ziplist-解压">6.3
zip: 将多个列表、元组或其它序列成对组合为一个元组列表; zip(*list),
解压</h3>
<p>seq1 = ['foo', 'bar', 'baz'] seq2 = ['a', 'b', 'c'] zip(seq1, seq2)
&gt; type zip</p>
<p>a = list(zip(seq1,seq2))</p>
<p>解压 seq1, seq2 = zip(*a)</p>
<h3 id="reversed翻转">6.4 reversed翻转</h3>
<p>另外，注意range也是一种类型</p>
<p>关于relu的倒数可以直接用</p>
<h2 id="关于python解释器">7. 关于Python解释器</h2>
<ol type="1">
<li>脚本语言 vs 编译语言</li>
</ol>
<p>首先，脚本语言需要能够实时运行，与编译语言来说有何不同？
脚本语言需要进行保存上下文变量</p>
<blockquote>
<p>特别地， C vs Python 1. 没有类型：
在实现阶段，那么需要进行多层的类型匹配。这会花费大量的时间 2. 函数参数？
python中对参数是如何进行解释的？ 如果按照python来参数是进行怎么解释的 3.
？</p>
</blockquote>
<ol start="2" type="1">
<li>解释器 ？ 解释器是如何实现的</li>
</ol>
<ul>
<li>CPython: 使用C语言对python进行解释</li>
<li>IPython: 在CPython的基础上向上封装了一些高级接口 &gt;
另外，还有一些其他的接口，比如JPython, 用jav来做</li>
</ul>
<p>## 8. 关于其他 当显示Microsoft Visual C++ 14.0 is
required.时，可到以下网站进行安装
https://www.lfd.uci.edu/~gohlke/pythonlibs/#pygraphviz</p>
<p>查看某个属性或者方法是否可以调用？ hasattr(obj, attr)</p>
<p>callable(getattr(obj, funcName))</p>
<p>numpy注意使用浮点数</p>
<p>列表解析 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">list_c = [item if item &gt; 5 else 1 for item in list_a]</span><br><span class="line"></span><br><span class="line">list_c = []</span><br><span class="line">for item in list_a:</span><br><span class="line">    if item &gt; 5:</span><br><span class="line">        list_c.append(item)</span><br><span class="line">    else:</span><br><span class="line">        list_c.append(1)</span><br></pre></td></tr></table></figure></p>
<h4 id="python-远程分享目录">python 远程分享目录</h4>
<p>ifconfig -&gt; eno1 -&gt; 114.212.86.85</p>
<p>python2 -m SimpleHTTPServer &gt; 本地下localhost:
8000可以查看目录</p>
<p>专注于当前的事，不要老是去做一些有的没的东西</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/daily-cplus-thinking-f792bd59e5ea/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/daily-cplus-thinking-f792bd59e5ea/" class="post-title-link" itemprop="url">daily cplus thinking</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 13:13:45" itemprop="dateCreated datePublished" datetime="2019-09-19T13:13:45+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/daily/" itemprop="url" rel="index"><span itemprop="name">daily</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/daily/thinking/" itemprop="url" rel="index"><span itemprop="name">thinking</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="c-多文件组织">C++ 多文件组织</h2>
<h3 id="问题">1. 问题</h3>
<p>之前大学学习的时候也是这个问题一直在困扰自己没有得到解决。
主要想思考着将计算机系统基础所学知识联系起来思考。 首先，两个问题： 1.
多个cpp中调用同一个.cpp, 或者重复调用一个.h, 或者变量重复怎么办 2.
头文件中有那个#ifdef定义的怎么用</p>
<blockquote>
<p>现在已经知道的就是c++在编译的过程中是先将cpp文件进行编译（有时间再复习计算机基础的知识，结合起来进行思考）。</p>
</blockquote>
<h3 id="想法">2. 想法</h3>
<p>gcc编译过程有静态链接和动态链接的过程。对于动态链接就是增加已经预先编译好的东西。</p>
<p>一般来说，编译器会做以下几个过程： 1. 预处理阶段 2.
词法与语法分析阶段 3.
编译阶段，首先编译成纯汇编语句，再将之汇编成跟CPU相关的二进制码，生成各个目标文件(obj文件)
4.
连接阶段，将各个目标文件中的各段代码进行绝对地址定位，生成跟特定平台相关的可执行文件</p>
<p>注意，1主要是处理源文件中的宏、变量、函数声明、嵌套的头文件包含等东西，然后重新生成C文件。
2和3通常为一起，此时已经产生了符号表。已经将全局符号和局部变量分开了。而且在操作系统中，建立了对应的符号表以及将定义位置和引用都联系好了。同时，已将将全局变量还有程序转入了对应的程序的位置区段。</p>
<p>哪些已经编译好的内容是指直接只差操作系统指定将代码放在哪里了，只要操作系统指定位置，那么就可以指定按行行动，然后产生文件了？
&gt;
刚刚看了维基百科，其实这里所表述的链接也很正常，易于理解。实际上就是所想的那样的。dll提出的初衷也就是为了复用，比如window窗口部件。直接复用就可以调用同样的功能。</p>
<h4 id="静态编译">2.1 静态编译</h4>
<p>首先，不管是IDE还是命令行，IDE不过是命令行的一个集成，帮你把什么东西都设置快捷了，让你来进行操作。
gcc .cpp .cpp
它会把每个cpp进行编译成.o文件，再由.o文件一起生成可执行文件。
main.cpp一定是在最后。 ##### 为什么有.h和.cpp文件？
.h文件一般是放说明的，而.cpp一般是对应的实现；（同名警告！？
是会给编译过程带来好处吗？）</p>
<p>如果一个.h中声明太多，需要两个.cpp来书写可以吗，如果允许，这样感觉同名潜规则没必要。不允许，编译器规定死了，相关声明只能从相关同名文件中去找。然后，如果其他.cpp声明要用到该环境直接用即可。</p>
<p>所以一般来说，那我们再构建其他文件时，只需要include
.h文件就可以了啊，没有必要引入其他文件。</p>
<p>对啊，因为你生成的是cpp文件，所以这里每个cpp对应的是.o，
它会在对应的表上记录。
那么对应的cpp与源文件存在依赖关系，所以这里就涉及到依赖关系。 &gt;
依赖关系，这里就是图的拓扑排序。还有一个问题，记得计算机系统基础中有讲过gcc
后面的参数对表的构建其实也是有影响的</p>
<p>同时，又可以回答一个问题，在cpp中引用stdio.h也是没有问题的啊。因为这些不过是标志着它会去找文件，所以完全就没有关系。最终不过是生成.o文件是，它会把对应的库中的文件进行替换而已。</p>
<h5 id="一些关键字作用的思考">一些关键字作用的思考</h5>
<ol type="1">
<li><p>incline ？incline声明的会先一步静态编译到程序中。
extern感觉上更多的用法是在一个cpp文件中使用的是另一个文件中的，然后却并不会指出是在哪个文件中定义又初始化的，不安全，不建议使用该关键字。</p></li>
<li><p>define #
define关键字的使用也相当明了了。我们的目的是什么，就是每个.h文件应该管理自己特有的变量和函数声明这样我们就能使程序避免变得杂乱无章。而且像<code>#define
FILE_H</code>这种操作，只能在file.h中做啊，其他情况你为什么要这么做。而加
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#ifndef CPLUS_LAB1_STACK_H</span><br><span class="line">#define CPLUS_LAB1_STACK_H</span><br><span class="line">stack.h特有的</span><br><span class="line">#endif //CPLUS_LAB1_STACK_H</span><br></pre></td></tr></table></figure> 不过是避免犯错，编译特有的。</p>
<p>思考define的第二种用法，首先在命令行或者某个场合环境下，你需要说明你现在是什么环境，或者代码里定义环境。然后，在代码里使用对应的条件判断语句也就很轻易的判断出是哪个了。
##### 多文件组织
多个.h之间的依赖，有什么例子吗？如果是结构体，比如有个queue的操作，现在我又要新建一个优先级queue的操作，所以可以用到queue的操作。那么就涉及到进阶的知识即抽象为类，以及类之间的关系表示。</p></li>
</ol>
<p>一般来说书写.h文件的话没有必要那么多和复杂。而且一般是直接引用两个相对独立的.h,
共同使用它们的函数。然后其实一个cpp也可以调用多个.h的，那么这样的话，按前面的想就明了。
有反常情况吗？</p>
<p>还有一个问题可以创建文件的问题，至少在clion中，因为MakeFile是自己书写，所以只用把文件路径点名即可，照样可以操作，对。</p>
<h4 id="动态链接">2.2 动态链接</h4>
<p>.dll未明朗解决</p>
<h3 id="进一步思考和建议">3. 进一步思考和建议</h3>
<p>MakeFile相关的东西 整理以及实践的结果</p>
<p>一点额外的东西：
一般情况下，程序并不关心栈的具体分配情况，但进行混合语言编程时，则要考虑不同语言在栈使用上的差别。
&gt; 1. 还需要考虑哪些？</p>
<h3 id="再理解的内容">4. 再理解的内容</h3>
<ul>
<li><a
target="_blank" rel="noopener" href="https://blog.csdn.net/u010167037/article/details/19680877">关于如何将多个Cpp组织起来
-jamesheros</a></li>
<li><a
target="_blank" rel="noopener" href="https://blog.csdn.net/candcplusplus/article/details/53326368">菜鸟攻略-C语言多文件编程初探
-流沙的刺客</a></li>
<li><a
target="_blank" rel="noopener" href="https://blog.csdn.net/lee244868149/article/details/39341751">头文件与同名源文件的关系-奔跑的路</a></li>
<li><a
target="_blank" rel="noopener" href="https://blog.csdn.net/xhbxhbsq/article/details/78955216">C语言中，头文件和源文件的关系</a></li>
<li>计算机系统基础, 袁春风</li>
<li>程序员的自我修养-链接、装载与库 &gt; 只是被推荐，未读</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/machinelearning-gradient-descent-cdac096ff45e/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/machinelearning-gradient-descent-cdac096ff45e/" class="post-title-link" itemprop="url">machinelearning gradient descent</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 13:11:31" itemprop="dateCreated datePublished" datetime="2019-09-19T13:11:31+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machinelearning/" itemprop="url" rel="index"><span itemprop="name">machinelearning</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machinelearning/gradient-descent/" itemprop="url" rel="index"><span itemprop="name">gradient-descent</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>SGD ? 是只是针对一个样本做的吗？ 难道不是学习了随机</p>
<p>无偏估计：不考虑系统误差，只有随机误差，在大数情况下有效。
也就是估计式的期望等于估计值</p>
<p>SGD Challenges: 1. 收敛速度跟学习速率关系很大，大容易震荡，小收敛很慢
2.
学习速率对所有特征都是一样的。事实上，应该某些特征下降慢，有些快，没有考虑稀疏性
3. 容易陷入不太好局部最小或鞍点。</p>
<p>误差曲面，权重为多维的 梯度与等高线的关系 梯度是等高线上的法向量
梯度是数字较低的等高线指向数值较高的等高线，梯度的模是函数在这个法线方向的方向导数
常见的有两种误差曲线：
一种一维的，一种等高线的，实际上就是反映在图像上多维的等高线
动量使得收敛过程更快地通过SGD来回震荡的峡谷</p>
<p>改进 1. 动量：
模拟物体运动的惯性，更新时一定程度上保留之前更新的方向，同时利用当前的batch的梯度微雕最终的更新方向。增加了一定程度上的稳定性，有一定的摆脱局部最优的能力
- 传统：首先计算当前位置的梯度，然后再更新累加的梯度方向移动 - NAG:
先在之前累加的梯度方向上移动，然后再计算当前位置的梯度？ &gt;
利用了物理中动量的思想，保持总的下降方向减小震荡，也比较容易跳出不太好的局部最小
2. 自动调节学习速率 - Adagrad:
Adagrad利用以前的梯度信息Gt判断对应的特征是否经常被更新，
平滑项用于防止分母为0 &gt;
考虑了之前的梯度的累加的信息，Gt是一个对角矩阵，每个对角线(i,i)的值为累加到t次迭代的对应参数wt梯度平方和，越到后面学习率会变得越来越小
- Rmsprop:
Adagrad的改进：解决Adagrad算法中学习率单调下降趋向于0的问题，把历史梯度累积窗口限定到固定的窗口
- Adadelta:
使用均方根来估计步长，使用临近时间窗口的步长来估计当前的步长；避免了手动调借参数
- Adam： 使用一阶和二阶矩估计 &gt; Adam = Rmsprop + Bias-crrection +
Momentum &gt;
初始化gradient较大，导致基于速度的算法NAG发生偏离又修正过来；具有自适应学习率的算法效果想加速版的SGD,能更加稳定地解决large
initial gradient问题</p>
<p>二阶优化方法</p>
<p>现实世界中所遇到的Hessian矩阵都是实对称的，实对称矩阵都能分解为实特征向量和实特征值
梯度下降无法利用含在Hessian矩阵的曲率信息。对于正曲率，梯度下降会下降得很慢；对于负曲率，梯度下降会下降得很快。当迭代点越靠近X，其搜索步长就越小，因而收敛速度越慢</p>
<p>牛顿法，寻找收敛速度快的无约束最优化方法，在每次迭代时，用适当的二次函数去近似目标函数f
&gt; 更新公式，二阶和一阶的内积和？ 二阶矩阵计算内容包含太多。</p>
<p>牛顿法考虑走了一步后，坡度是否会变得更大。要求二阶矩阵的逆，计算量巨大k^3</p>
<p>改进 - 共轭梯度 &gt; 避免求逆运算 &gt;
向量共轭是正交的推广，共轭方向法最多经过N步迭代，就可以到达极小值点，二次收敛性。沿共轭方向集的每个方向顺序做line
search的时候，在每个方向上都不需要做重复搜索。每个方向的移动都不会影响到在另一方向上已经找到的极小值？
CG:线性搜索并不严重依赖于线性搜索寻找该方向上和真正极小值很近的一点。 -
拟牛顿法 &gt; 不用二阶偏导数而构造正定对称阵 &gt; BFGS,
需要存储Hessian逆矩阵M, 空间复杂度O(n), 花费更少的时间改进每个线性搜索
line search: 搜索方向d_k
已经是确定的，目标是如何在一个确定的d_k上，找到一个合适的a_k</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/spark-study-thinking-1-649b108ce6d3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/spark-study-thinking-1-649b108ce6d3/" class="post-title-link" itemprop="url">spark study thinking</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 13:09:17" itemprop="dateCreated datePublished" datetime="2019-09-19T13:09:17+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index"><span itemprop="name">spark</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/thinking/" itemprop="url" rel="index"><span itemprop="name">thinking</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>spark中map就是把数据集分配到各个节点上，然后各个节点执行 &gt;
思考Partioner的过程是什么</p>
<p>Partitioner感觉上是全局变量 &gt;
HashPartitioner就是把Hash桶做成了</p>
<p>inputSplit, 一定要比它大，这样就可以使得每一部分执行的数据少</p>
<p>flatMap并没有那么简单，也就是说 flatMap = map + flatten &gt;
flatMap(t=&gt;f(t)) f返回的是什么类型，最终结果就是什么类型</p>
<p>reduce(x+y=&gt;x) reduceByKey(x+y=&gt;x)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mapPartitions(iter =&gt; &#123;    // mapPartitions即 Mapper端的数据进行了Combine计数</span><br><span class="line">      val pair = mutable.Map.empty[WrapArray, Long]</span><br><span class="line">      while (iter.hasNext) &#123;</span><br><span class="line">        val arr = new WrapArray(iter.next())</span><br><span class="line">        val value = pair.get(arr)</span><br><span class="line">        if (value == None) &#123;</span><br><span class="line">          pair(arr) = 1L</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          pair(arr) = value.get + 1L</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      pair.iterator   // 这种写法很精妙，进行学习</span><br><span class="line">    &#125;)</span><br><span class="line">    // 每次返回一个迭代器，下次还可以考虑继续使用这个迭代器</span><br></pre></td></tr></table></figure>
<p>基本类型的迭代器可以定义</p>
<p>自定义迭代器
https://blog.csdn.net/XiaoHeiBlack/article/details/77014626</p>
<p>groupByKey(): RDD, Iterable[V] reduceByKey(): U+U=&gt;U</p>
<blockquote>
<p>思考迭代器</p>
</blockquote>
<p>FPGrowth思路整理</p>
<p>MLlib做法： 1. 产生每个分区的数据集 &gt; val part =
partitioner.getPartition(item), 这一步依然感觉很懵逼? &gt;
mapreduce中map的过程实际上就不过是map的数据集的个体变大的。所以按照自己想的就是
&gt; 代码这里的感觉就是用的默认集群的？？？ 2.
将每个分区的数据集合并为一棵子树 3. 将所有分区合并为一个大的子树 4.
从这个大的子树中提取对应的频繁项集</p>
<p>defaultParallelism(): cluster default trait: 相当于接口</p>
<p>sc.text(): 这里默认的也是这个参数</p>
<p>FPNewDef做法 1. 产生对应分区的数据集 2. 对每个分区进行相同合并 3.
数据重新写为(key, value) 4. 映射到对应的分区 &gt;
所以就要用分区内的排序来做 repartitionAndSortWithinPartitions
https://www.jianshu.com/p/5906ddb5bfcd 5.
分区内根据顺序收集，从而形成条件树 &gt;
这里可以直接根据收集结果来产生频繁项集啊</p>
<p>NewIdea 1. 产生分区的数据集 2. 可选，Combine(需要开销) 3.
数据重新分为(key, value) 4. reduceByKey &gt;
收集对应的key，然后直接产生条件树</p>
<blockquote>
<p>因为类没有实现迭代器的特性，所以不能这样用？
居然可以用排序就可以了，牛逼，牛逼
如果是对所有的元素做某种运算，但不需要产生最后的结果，只需要foreach</p>
</blockquote>
<blockquote>
<p>第一个想法，一个是将每个(key,value)的value映射为一个FPNewNode,
然后添加，需要重新改写数据结构
第二个想法，reduceByKey，先收集到一个集合，然后再对该集合进行下一步做法</p>
</blockquote>
<p>? spark任务调用顺序</p>
<p>spark-shell --master spark://slave033:7077</p>
<p>例子： 1 2 3 4 1 2 4 2 3 2 4</p>
<p>partion: 2</p>
<p>1: 1 2 3 4 -&gt;<br />
1 2 4</p>
<p>2: 2 3 2 4</p>
<p>总结：
FPTree中的extract是对所有的项都要来直接求解，试着不需要。只需要对某一个地方进行求解即可。
然后这里的 extract又是个递归</p>
<p>summries中包含所有元素</p>
<blockquote>
<p>怎么生成数据？关于大数据集的
slave033上的文件和hdfs上的文件有什么区别？ &gt;
这个问题实际上是想问这里用到的是啥？</p>
</blockquote>
<p>本地进行模拟运行 ## 学到的知识</p>
<h3 id="spark.default.parallelism">1. spark.default.parallelism</h3>
<blockquote>
<p>如果不进行设置，默认值是底层HDFS的block数量（HDFS中有设置）;
一般这是个特别需要设置；
在默认情况下，非常小，如果不调节它就起不到分布式的效果了。通常来说也不会只调节到num_executors*executor-cores，因为相当于只给每个节点分配了对应很少的值，所以实际上的话，是在2~3倍。为什么呢，因为有的task运行速度快，有的慢，为了避免快的执行完等慢的，所以可以考虑多加进行设置，这样的话就能充分利用到集群了。
? hdfs block的数量？？ https://www.iteblog.com/archives/1659.html</p>
</blockquote>
<h3 id="scala语法">2. scala语法</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class FPTree</span><br><span class="line">  def merge(other: FPTree[T]): this.type = &#123;</span><br><span class="line">    other.transactions.foreach &#123; case (t, c) =&gt;</span><br><span class="line">      add(t, c)  // 这里就默认的是this.add()</span><br><span class="line">    &#125;</span><br><span class="line">    this</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="spark参数配置优先级">3. Spark参数配置优先级</h3>
<ol type="1">
<li>SparkConf</li>
<li>spark-submit spark-shell</li>
<li>spark-defaults.conf &gt; 在文件中进行配置 ### 4. 零散知识点</li>
</ol>
<h4 id="提交">4.1 提交</h4>
<ol type="1">
<li>spark-shell</li>
</ol>
<ul>
<li>--master spark://host:port本身的运行模式</li>
<li>--deploy-mode: driver端位于哪里</li>
<li>dirver-memory, dirver-cores &gt; driver-memory,
driver-cores指的是driver端执行的情况</li>
</ul>
<ol start="2" type="1">
<li>运行模式</li>
</ol>
<ul>
<li>standalone模式</li>
<li>spark on yarn, dirver在本地</li>
<li>spark on yarn, dirver在集群 &gt;
其实standalone和其他没有什么区别吧，主要就在于standalone是主模式，而yarn各个节点都相同</li>
</ul>
<ol start="3" type="1">
<li>yarn</li>
</ol>
<p>yarn: 整个资源管理在一个资源池中，想要获取资源通过在资源池中进行获取
&gt;
这里yarn把整个集群集合在了一起，具体yarn是怎么执行的需要看居然的yarn的东西。</p>
<p>然后，关于yarn的就有几个特别的参数：</p>
<p>worker是资源分配单位 executor是任务执行单位</p>
<p>executor的内存主要分为几块 1. 执行自己的代码所需要的内存,默认值20% 2.
shuffle所需要的内存，默认20% 3. 持久化的内存,默认60%</p>
<p>资源参数调优: 1. num-executors: 总的executor数 &gt;
总共的任务执行单元</p>
<ol start="2" type="1">
<li>executor-cores</li>
</ol>
<h3 id="inputpath">inputPath</h3>
<blockquote>
<p>在哪里？ hdfs://master:port/根路径</p>
</blockquote>
<blockquote>
<p>默认情况下为master节点上的9000端口</p>
</blockquote>
<p>注意到一个问题： aggreateByKey一直都是根据key来处理
reduceByKey(partioner, <em>+</em>) 可以使结果放在对应的位置上</p>
<p>学长的代码，想法依然是那样的。感觉上还是最终落在了收集fpTree上，而且并没有什么优化啊。</p>
<p>前面汇聚相同的什么用?</p>
<p>在倒数第二个的时候依然是形成fpTree,然后提取</p>
<h2 id="scala编程">scala编程</h2>
<p>注意区分Iterator和</p>
<h2 id="师兄代码的想法">师兄代码的想法</h2>
<p>建树开销，即考虑的是</p>
<p>spark-submit 默认参数在 spark-defaults.conf中 ？
master是否进行资源的分配</p>
<p>--dirver-memory https://www.cnblogs.com/weiweifeng/p/8073553.html</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/spark-study-thinking-a261c8159f04/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/spark-study-thinking-a261c8159f04/" class="post-title-link" itemprop="url">spark study thinking</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 13:06:59" itemprop="dateCreated datePublished" datetime="2019-09-19T13:06:59+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index"><span itemprop="name">spark</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/thinking/" itemprop="url" rel="index"><span itemprop="name">thinking</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">val file_split = args(2).toInt  // 文件的切分，将文件划分为多少个mapper</span><br><span class="line">val numPartition = args(3).toInt // mapper后，形成多少个reducer</span><br><span class="line"></span><br><span class="line">// 还有其他建议参数</span><br><span class="line">// driver-memory, driver-cores 内存主要是启动内存，存储启动的数据，</span><br><span class="line">// ? driver所使用的数据，首先数据本身是可以放在多个位置吧，然后，其次，数据来源是本地文件的话，应该也可以在worker节点上，因为这样本身就可以做，在task执行时，直接就近选取接地那执行即可</span><br><span class="line">// 其而，是当执行collect()时， 数据将被拉回driver端？？？</span><br><span class="line"></span><br><span class="line">// executor-memory, executor-cores:</span><br><span class="line"></span><br><span class="line">// spark-default-parrallism: 如果一直从头默认，尽管是reduceByKey, 它有个参数partitioner也使用的是默认，那么这样看来也就是说基本上都是这个参数，除非中间设置repartitiones; 这里官方的建议是总cores的2-4倍</span><br><span class="line"></span><br><span class="line">// 然后 executor和worker,driver的对应, 首先系统会计算driver,worker剩下的内存，然后按照某种策略（一个worker装满再装下一个，还是一个一个worker地装）, 于是就形成了执行单元。</span><br><span class="line"></span><br><span class="line">// 对于每个executor, 在执行时必然需要用到数据，会采用就近原则，比如使用的是hdfs架构时，会优先从某个就近的地方读取</span><br><span class="line"></span><br><span class="line">// 分给每个executor的内存，有几个用途：1. 运行，包括代码执行, 所以有堆外内存，用于调节GC; </span><br><span class="line"></span><br><span class="line">// executor:  executor-cores， 按系统能给的最大程度在每个worker上给予的方式来分配executor. 然后executor, 然后，关于executor启动以及后面的执行又是怎么折腾的呢？怎么看出负载均衡这些东西的？ spark-ui</span><br><span class="line">https://blog.csdn.net/dandykang/article/details/48525467</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>所以整个并行化，spark需要关注的点</p>
<ol type="1">
<li><p>mapper前的预处理操作</p></li>
<li><p>数据传送到mapper的开销</p></li>
<li><p>mapper的个数 &gt; task执行完后的负载均衡,
有小任务和大任务，有的先执行完，有的后执行完</p></li>
<li><p>mapper数据汇集的通信开销 &gt; 这个过程又名shuffle, shuffle read:
抓取数据, 这里涉及到将mapper的结果抓取过来，然后进一步考虑怎么搞;
shuffle write: 将数据按key值分发到各个reducer上 &gt;
感觉上处理shuffle的是保存一个类似hash的东西来做的</p></li>
<li><p>reducer的个数 &gt; reducer再将结果汇聚到driver端</p></li>
</ol>
<p>关于一些默认的东西一般在spark安装的文件里，进行spark安装环境的解析</p>
<p>然后具体怎么做的，就主要的想法是参照源码</p>
<p>然后，涉及到整个系统的：</p>
<ol type="1">
<li><p>环境准备，怎么将所有东西给放在一起</p></li>
<li><p>代码执行</p>
<ul>
<li>集群初始化：面向对象的思想，首选一个外部消息导致整个事件触发，然后如此直到达到某个结束标志
<ul>
<li>调度单位，将事情作为不同方面进行调度；比如，掌管通信的，掌管DAG的，然后，再起对应的名字；最终再进行来做</li>
</ul></li>
<li>Dirver端执行代码，分配到mapper端，惰性求值，当在mapper端遇到需要收集数据，即需要将这个数据分离时，即认为该stage结束，则开始进行运算。
这里会进行DAG世袭图的计算。 &gt; DAG世袭图的提出 &gt; 查看sparkUI</li>
<li>如何保证容错 &gt;
这里的想法就是在整个Driver端维持？，还是？。不对！应该是会维持计算图，首先进行思考，优先从就近的前一步抓取未计算完的数据。所以，这就意味着把某一步的RDD计算结果放在某一个位置上于是就显得很重要了！</li>
<li>这里的checkpoint，已然忘记是不是说的也就是这个感觉</li>
</ul></li>
<li><p>数据库操作，SQL层抽象，存储，hdfs存储到每个节点</p></li>
</ol>
<p>SparkUI的几个东西： 18080; 系统： 8080 - jobs
job的概念，其实也就是一次map/reduce过程，当然也可以看作是action操作结束后。唯一需要特别注意的是，job最终即action的结果又会回到Driver端，由系统再次分配job.
一个SparkContext中一个任务，一个任务多个job. &gt; 物理时，Master, Slaves
&gt; 工作时，Driver, Worker
Dirver不等于Master，因为Dirver根据不同的执行方式，可以分布在不同的位置，比如
各种部署模式 &gt; &gt; 本地模型 local[4], 用来模拟线程;
Client提交任务，所以我们很多时候一般都是上环境进行提交任务Driver;
在Standalone, 这里指的是master单独的意思，即spark defalut，
此时Master=Driver;
其余有两种，一种是本地为Dirver端，与集群进行交互，但是本地机器不是集群机器，当运行大量任务时，会带来很严重的开销';一种是本地把代码提交到集群，集群再选择一个节点做Driver，注意此时每个节点的地位相同
- event timeline: executor的执行状态
<font color="red">可以分析出来是否负载均衡</font> - DAG visualization:
整个的stage图，就是按宽stage和窄stage来进行划分 - Skipped Stages, Failed
Stages - stages 对于每个stages由着以下的指标： - 任务延迟 - 持续时间 -
GC Time - Shuffle Red Blocked Time - Shuffle Read Size</p>
<pre><code>- 每个executor的状态数据
- 每个tasks的执行状况</code></pre>
<ul>
<li>storage 存储，关于在每个点或者其他点上存储的东西</li>
<li>environment
<ul>
<li>runtime information</li>
<li>spark properties</li>
<li>classpath entries</li>
</ul></li>
<li>Executors: 每个executors的执行状态</li>
</ul>
<p>整个Spark技术内幕主要包括以下几个方面： - RDD的实现</p>
<ul>
<li><p>Scheduler模块 &gt; 关于调度如何实现的</p></li>
<li><p>Deplo模块 &gt; 消息传递，容错，运行模式</p></li>
<li><p>Executor模块 &gt; 分配， task的执行</p></li>
<li><p>Shuffle模块 &gt; Hash Based Read/ Shuffle Write</p></li>
<li><p>Storge &gt; 存储模块</p></li>
</ul>
<p>Spark编程需要的内容 - scala常用数据类型的了解 - spark编程环境的问题 -
RDD编程 &gt; 创建RDD， RDD的各种操作，常见转化和行动操作， 持久化 -
键值对操作<em> &gt; 主要说的是PairRDD, 目前来说，并没遇到 -
数据读取和保存 &gt; 本地和hdfs://master:9000<br />
- 进阶</em> &gt;
累加器，广播变量，基于分区操作，与外部程序间的管道，数值RDD的操作 -
运行spark-submit, 打包和依赖 - 关键性能度量 - 并行度 - 序列化格式：
这里好像只涉及到使用 kryo工具 - 内存管理 - 硬件供给 - Spark Sql* &gt;
未涉及到，好像后面可以通过sql语句直接得到，所以超级简单</p>
<p>一些实战 &gt; 进行数据分析，从而来提高熟练度</p>
<h2 id="语言编程">2. 语言编程</h2>
<p>数据结构 1. 变量，常量 2. 物理上不同的类型 - 基本类型，Int,String -
静态数据结构，长度不可变，比如List, Array, - 变长 vector, ArrayBuffer; -
hash结构， - tree结构， 堆 - 抽象结构，栈、队列 - (key, value)对 &gt;
注意思考，一般这种的内部实现是什么样的; 比如说平衡二叉树 3. 访问特性来看
- 迭代器，只支持iterator - travesac: 支持随机访问 -
支持从前或者从后访问</p>
<ol start="3" type="1">
<li><p>基本操作符： +, -, ==, equals, &gt;=, ., -&gt;</p></li>
<li><p>扩展操作符： ++= --</p></li>
<li><p>常见操作</p>
<ul>
<li>合并两个集合</li>
<li>插入某个元素，某个元素不存在</li>
<li>删除某个元素，元素不存在</li>
<li>查看某个元素是否存在</li>
<li>判断是否为空</li>
<li>初始化</li>
<li>是否为满</li>
<li>清空</li>
<li>转换为其他集合 &gt; 默认hashCode, ==, euqals的实现,
&gt;小于比较的实现</li>
</ul></li>
<li><p>泛型</p>
<ul>
<li>支持所有类型 &gt; 迭代器</li>
<li>抽象的算法</li>
</ul></li>
<li><p>类</p>
<ul>
<li>抽象类， 接口</li>
<li>抽象抽象类， traits</li>
<li>类的继承，派生； 可以互用的方法</li>
</ul></li>
<li><p>其他编程范式</p>
<ul>
<li>map(), reduce()等以及扩展的操作，还有变量在里面或者变量在外面</li>
</ul></li>
<li><p>基本常见语句的操作：循环，条件；特殊的语句</p></li>
<li><p>其他类别：</p>
<ul>
<li>文件操作，交互</li>
<li>异常处理，捕捉 &gt; try, catch; assert(); 宏语句来一件更改是否执行,
继承测试</li>
</ul></li>
<li><p>多文件</p>
<ul>
<li><p>整个项目，组；</p>
<ul>
<li>资源文件</li>
<li>配置文件</li>
<li>测试文件</li>
<li>源代码
<ul>
<li>包的概念， 包这里的概念与C中不同可以理解为物理上的文件组织转换为了包
&gt; 更进一步从文件上分割了各个包，使得文件的组织更加合理
<ul>
<li>功能划分： 实体，数据库访问层，网页层，逻辑层 &gt;
按照功能，或者考虑用其他的方式进行划分</li>
</ul></li>
<li>类的概念</li>
</ul></li>
</ul></li>
<li><p>引用已有代码： 这里是人类的精华，使用依赖的概念。</p>
<ul>
<li>如何进行管理这些依赖的东西？ jar(java), .net(C++类库)</li>
<li>在自己的工程中引用: mvn管理， pom文件配置，自动化处理包 &gt;
将资源放在云端，maven， 需要地则通过网络拉取在编译时进行整合到程序中
&gt; 这里是在一般机器所有层上进行扩展的。 &gt; 比如如果是java,
首先机器上是具备有jvm虚拟机的。C++, MinGW,
所以之后的包的所有东西都是基于这些基本的接口进行调用的。所以是更上一层的抽象.</li>
</ul></li>
<li><p>因为涉及到各种功能，所以需要考虑计算机的基本功能进行支持，比如</p>
<ul>
<li>计算机网络：联网与其他计算机进行交互</li>
<li>计算机文件系统： linux相关命令</li>
<li>安全：
设置网络访问权限，网络防火墙，从小到大网络的权限的设置。从网络向下到各层文件，所以又涉及到各层文件的私密网络。
外加网络通信</li>
<li>接口，与外部显示器，音箱，键盘等各种输入输出设备的兼容</li>
</ul></li>
<li><p>再向下，计算机上层功能的实现，全都可以抽象为一台具有CPU计算，存储和输入输出的机器。输入则认为是代码，输出则认为是结果。
&gt;
不管是图像显示还是声音，可以看作是输出在特定物理设备上的反映。它遵从一定的物理表现形式就可以表现为某个点。声音是频率，图像是光的变化，即像素点
&gt;
对于文件系统的功能，可以看作是有超大的一块内存，然后按某种特别地形式对文件进行组织管理，于是乎就可以抽象出各类文件。这块地方其实先划分为块，然后再划分为其他。也可以分为系统区，文件节点区，具体文件区，其他所有的不过是层抽象。
&gt;
对于安全，不过是对输入输出进行处理。计算机网络，对输入进行处理</p></li>
<li><p>再向下，CPU可以抽象为一个累加器？，或者其他什么，这一层可以放在上层。根据图灵机知道这是可行的；然后，实际上可以由累加器来看出由0,1的基本的与，或，非，对应于各类的逻辑电路，最终然后得到各种功能的叠加</p></li>
<li><p>最向下，于是就到了逻辑管层</p></li>
<li><p>往上，编译原理，当一段抽象代码出来时机器是怎么做的呢，首先，将所有依赖的东西加进来然后构成源代码。接着，将源代码进行词法、语法分析，接着进行会形成一些底层一点的东西，进行符号表解析，最简单的理解就是把所有文件，都不歧义地翻译为一个文件的内容。当然，中间因为是对多文件进行翻译，所以需要一些基本的辅助数据结构，如符号表。因为从某种意义上来说，最终结果为汇编语言，而汇编语言并没有什么特别的语言结构，所以需要把变量和函数都给简单地组织为需要进行访问几次内存，等来做。
最终代码执行阶段，所谓代码执行，也就是将静态转换为动态，根据代码中初始化的东西进行分配资源，根据算法进行代码运行，然后最终出结果
&gt;
编译器一定都是有shell终端的，所以很多时候远远可以考虑使用shell终端来进行机器</p></li>
</ul></li>
<li><p>如果共享网络</p></li>
</ol>
<p>new 1. 算法 - 并行化算法 - 串行化算</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/deeplearning-learn-dc64da181b72/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/deeplearning-learn-dc64da181b72/" class="post-title-link" itemprop="url">deeplearning learn</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 13:03:19" itemprop="dateCreated datePublished" datetime="2019-09-19T13:03:19+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>参考: 吴恩达深度学习视频和网上教程</p>
</blockquote>
<p>https://www.zybuluo.com/hanbingtao/note/433855</p>
<p>隐藏层大于2的神经网路叫做深度神经网络</p>
<p>一个仅有隐藏层的神经网络可以拟合热河一个函数，但是它需要很多很多的神经元。
而深度网络就是考虑用少得多的神经元就能拟合同样的函数。</p>
<p>为了拟合一个函数，要么使用浅而宽的网络，要么使用深而窄的网络。 &gt;
后者给节约资源</p>
<h2 id="感知器">1. 感知器</h2>
<p><img data-src="ganzhiqi.png" /></p>
<h2 id="组成">1.1 组成</h2>
<ul>
<li>输入权值 <span class="math inline">\(w_i\)</span></li>
<li>激活函数, 比如阶跃函数，<span class="math inline">\(f(x) =
z&gt;0?1:0\)</span></li>
<li>输出，整个感知器的公式 <span class="math display">\[f(w \cdot x +
b)\]</span></li>
</ul>
<p>如此，表示的就是一元函数。因为权值的不同取值，由此可以表达出不同的函数</p>
<h2 id="表示能力">1.2 表示能力</h2>
<ul>
<li><p>and函数: <span class="math inline">\(w_1 = 0.5, w_2=0.5,
b=-0.8\)</span> <img data-src="and.png" alt="and function" /> <span
class="math display">\[y = 0.5x_1 + 0.5x_2 -0.8\]</span></p></li>
<li><p>or函数： <span
class="math display">\[y=0.5x_1+0.5x_2-0.3\]</span></p></li>
<li><p>线性分类 &gt; 因为它的数学表示实际上就是一条直线
<font color="red">不能表示一维以上的，比如异或运算</font> ## 1.3
训练</p></li>
</ul>
<blockquote>
<p>训练的主要想法就是进行更新权值</p>
</blockquote>
<blockquote>
<p>更新 <span class="math inline">\(w_i, w_0=b\)</span></p>
</blockquote>
<p>深度学习： 反向传播是否可以保证收敛？？ 强化学习：探索和利用</p>
<p>budget: 总共评估多少个节点 随机深林</p>
<p>算法</p>
<p>Q-learning &gt; 蒙特卡罗 + 动态规划</p>
<h2 id="深度学习应用总结">1. 深度学习应用总结</h2>
<p>分类 - Standard NN - CNN - RNN - Customl / Hybrid</p>
<ol type="1">
<li>structured vs unstructured
<ul>
<li>结构化数据： 组织为表格形式，每个维度都在人类的意义下具有解释性</li>
<li>非结构化数据：例如图像或者音频，每个细小的单位是像素点。 &gt;
从历史的角度来看，计算机很难解释非结构化数据。但是深度学习引入后，对非结构化数据也能解释的很好</li>
</ul></li>
<li>why 深度学习现在火起来？
<ul>
<li>大量数据的产生</li>
<li>越来越深的神经网络的规模的上限会表现得越来越好 &gt;
在小规模数据上，算法的优劣性不好比较。但是在大规模数据上，深度学习是远远领先的</li>
</ul></li>
<li>发展
<ul>
<li>Data</li>
<li>Computation</li>
<li>Algorithms:
<ul>
<li>特别地，从sigmoid函数到ReLu函数的改变，因为sigmoid函数在最低端和最上端点的梯度变化非常缓慢，不利于学习。可以是梯度下降得更快</li>
</ul></li>
</ul></li>
</ol>
<p>神经网络类比于人的大脑有点过度了，没有必要，因为从某种深度学习只是人的大脑一个非常简化的近似</p>
<h3 id="神经网络与深度学习">1.1 神经网络与深度学习</h3>
<ul>
<li>二分类</li>
<li>Logistic Regression &gt; 目标改变了，是从概率上来约束，即希望<span
class="math inline">\(P(y=1|x)\)</span>最大，此时认为该算法是最优的</li>
</ul>
<h3 id="序列模型-sequence">1.5 序列模型 Sequence</h3>
<p>https://mooc.study.163.com/learn/2001280005?tid=2001391038&amp;<em>trace_c_p_k2</em>=a561339e0cbf45b491dd9e12104a8641#/learn/content?type=detail&amp;id=2001771052</p>
<blockquote>
<p>序列模型是什么？
其实，从某种意义上说，定义很简单。就是输入和输出的是序列。
从某种意义上感觉，就是原本的数据是输入有很多维特征，而现在是这些维特征从另一个角度进行解释。即比如自然语言处理，输入为一个句子。
每个单词作为输入的特征，但是这些特征并不是相互独立的。
机器学习中好像有要求特征必须相互独立把</p>
</blockquote>
<blockquote>
<p>在这里好像又从新起了一个名字？</p>
</blockquote>
<blockquote>
<p>在这里看来，每维特征姑且叫做特征吧。
这些是相关联的，有点像层次分析法，所以必须要使用神经网络来做。
这些是序列的
序列意味着什么？意味着之间的关系性，前后具有联系，不能割开看。
如何做标记？ 这里认为<span
class="math inline">\(x^{(i)}\)</span>表示第i个样本，<span
class="math inline">\(x^{(i)&lt;t&gt;}\)</span>表示第i个样本的第t个特征，y同理。<span
class="math inline">\(T_x^{(i)}\)</span>表示<span
class="math inline">\(x^{i}\)</span>的长度？？？ -
于是意味着x的输入还可以处理为不一样？？</p>
</blockquote>
<pre><code>&gt; 所以后面有说到，可以填充或者零填充使得每个输入语句达到同样的长度</code></pre>
<p>如何来表示这些词？
这里的一个想法是用字典(这里通常是最常见的词，不在其中的词使用UNK来表示)，使用One-hot编码来做</p>
<h4 id="rnn在nlp中的应用">1.1.1 RNN在NLP中的应用</h4>
<ul>
<li>任务： 输入一个句子，对句子做情感分析，比如评分。
比如：输入的x是一个句子，那么怎么感觉学习过程的有效性呢？
首先必须思考神经网络结构是基于什么做的？比如在图中，是基于图的整个结构做的。
而在NLP中这里针对的就是一个句子。</li>
</ul>
<p>那么，在自然中，多个句子之间是会存在相同的单词。
所以，当对上一个单词训练结束后，再使用下一个单词进行训练就可。此时模型</p>
<blockquote>
<p>特别注意，深度学习是分领域的，等于说如果这里没有给定在哪个领域内是很难的。像在这里，邻域实际上决定了学习目标是什么。
而这里的学习目标，以及输入，输出是什么，神经网络模型需要学习的是什么就显得非常重要了。所以这里需要特别思考</p>
</blockquote>
<ul>
<li>RNN &gt; 这里理解的角度和自己的想象方式，从某种角度上还是出现了偏差
&gt;
这里的时间步，说的是上一个x训练的模型的参数，然后再影响到下一个x输入的模型的参数。
？ 合理循环之说呢？ 不对！错误，这里看错了标记<span
class="math inline">\(x^{&lt;t&gt;}\)</span>只的是第t步的特征，所以这里网络结构的输入依然是一个x。不可网络结构变得非常不一样，不再是每一维特征都有复杂的到最终的关系。</li>
</ul>
<p><span class="math display">\[a^{&lt;1&gt;} = g(W_{aa} a^{&lt;00&gt;}
+ W_{ax} x_{&lt;1&gt;} + b_a\]</span></p>
<p><span class="math display">\[y^{&lt;1&gt;} = g(W_{ya} a^{&lt;1&gt;} +
b_y\]</span> &gt; 其中<span
class="math inline">\(a^{&lt;0&gt;}\)</span>是初始化的，<span
class="math inline">\(a^{&lt;1&gt;}\)</span>是循环神经网络<span
class="math inline">\(x^{&lt;1&gt;}\)</span>到<span
class="math inline">\(x^{&lt;2&gt;}\)</span>传递的参数</p>
<p>假设输入向量的维度为x，循环体的全连接层神经网络的输入大小为h+x.</p>
<blockquote>
<p>做深度学习时，最重要的想法就是能够转换为矩阵运算，然后记得通过检查维度来确定正确性</p>
</blockquote>
<blockquote>
<p>RNN只用到了之前的信息。即只使用了序列前面的信息，未使用序列后面的信息</p>
</blockquote>
<h4 id="section">1.2</h4>
<p>梯度下降优化</p>
<blockquote>
<p>如果对于凸函数，是具有全局最优解的 为什么凸函数具有全局最优解？ <span
class="math inline">\(f(y)-f(x) \leq f&#39;(x) (y-x)\)</span>
注意最凸优化中，把权重矩阵看成是x的参数，目标是看何时x能够降到最低点；直观上看就是，梯度下降的方向就是去往最低点的地方。因为全局只有一个最低点。</p>
</blockquote>
<ul>
<li>凸函数的快速判断
<ol type="1">
<li>判断的性质 &gt; 一阶条件，即满足一阶不等式的公式，即证明不等式 &gt;
二阶条件，直接对二阶求导公式需要大于等于0.
对于矩阵来说，探究的就是矩阵的二阶导矩阵，此时称为Hessian矩阵。</li>
<li>常见的1维凸函数
<ul>
<li>放射函数 <span class="math inline">\(ax+b, a,b \in R\)</span></li>
<li>指数函数</li>
<li>对数函数 <span class="math inline">\(logx\)</span></li>
<li>幂函数 <span class="math inline">\(x^a\)</span>，绝对值幂函数</li>
<li>负熵 xlogx</li>
</ul></li>
<li>常见的d维凸函数有：
<ul>
<li>仿射函数</li>
<li>范数</li>
</ul></li>
<li>凸函数运算
<ul>
<li>非负加权求和: 所以这一点在神经网络中不能保证，所以就不是最优解</li>
<li>与放射函数复合</li>
<li>最大值或者上确界</li>
</ul></li>
</ol></li>
</ul>
<h2 id="各种优化器">2. 各种优化器</h2>
<p>二阶Hessian矩阵：各个的偏导数</p>
<p>一阶倒数刻画切线的斜率，二阶倒数刻画的是切线的斜率的变化率。</p>
<p>二阶函数能刻画函数的凹凸性</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/gnn-gnn-parallel-gnn-overview-paper-summary-163378634a76/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/gnn-gnn-parallel-gnn-overview-paper-summary-163378634a76/" class="post-title-link" itemprop="url">gnn-parallel-gnn-overview-paper-summary</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 12:59:16" itemprop="dateCreated datePublished" datetime="2019-09-19T12:59:16+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/gnn-parallel/" itemprop="url" rel="index"><span itemprop="name">gnn-parallel</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/gnn-parallel/gnn/" itemprop="url" rel="index"><span itemprop="name">gnn</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC] # 1. 序言 图有着复杂的关系和交互依赖</p>
<p>2D卷积: 邻居的决定由filter size w = 平均，
邻居有序，可以按照一定的序列来看且有固定的尺寸</p>
<p>Graph卷积： 邻居无序，价值等同，数量不一</p>
<p>Random Walk??? 随机游走，有概率计算方法还有要理解？</p>
<p>图网络表示： 1. 编码 2. 随机游走 3. 矩阵因式分解</p>
<h1 id="框架">2. 框架</h1>
<p>Node-level: MLP+softmax: 见pooling结构 Edge-level:
额外的函数将两个节点的表示作为边 Graph-level: 就是pooling</p>
<p>半监督: 只能适用于node-level 监督学习: 适用于graph-level 无监督：
graph-embedding &gt; 编码器+译码器 负采样</p>
<h1 id="正文">3. 正文</h1>
<h2 id="gcn">3.1 GCN:</h2>
<p>? stack多层可以学到更多的东西. 对！注意这里的输入是整个图
如果堆叠多层的话，实际上就可以不断的获得更远的信息</p>
<p>basic &gt; 这里每个的输出应该不会只是一个值吧？？ Relu修正线性函数：
当大于x时为本身，小于x时为0</p>
<p><font color="red">ReLU</font>
ReLU可以将模型实现稀疏话更好地挖掘相关特征
就激活函数而言，在深度网络中，由于非负区间的梯度为常数，所以不存在梯度消失问题，使得模型的收敛速度维持在一个稳定状态。
https://blog.csdn.net/cherrylvlei/article/details/53149381</p>
<p>pooling</p>
<p>一个图经过GCN加pooling得到一个子图，然后给下一个模型。如此最后不断地得到更高级别的表示，最后一层是MLP
+ softmax</p>
<p><font color="red">MLP</font> MLP: 多层感知机 vs 支持向量机 SVM &gt;
多层感知机其实就是多层网络结构，但是一般是向前的，不会有后退的，然后关键就是设定一个偏差评价函数，以及某种策略，当出现错误时可以向后调节参数</p>
<p><font color="red">softmax</font>
softmax函数：逻辑函数的推广，归一化指数函数。</p>
<p><span class="math display">\[\delta(z)_j = \frac
{e^{z_j}}{\sum_{k=1}^K e^{z_k}}\]</span></p>
<blockquote>
<p>将任何一个元素都压缩到了指数域，并满足归一化,并且保证了归一化结果在[0,1]之间
将原数压缩为指数来做有什么感觉</p>
</blockquote>
<p><font color="red">sigmoid</font> sigmoid函数，数学表达式 <span
class="math display">\[f(x) = \frac {1}{1 + e^{-x}}\]</span>
优点：可以把任何值映射到[0,1]之间；导数的计算公式方便<span
class="math inline">\(f&#39;(x) = f(x) (1-f(x))\)</span>
https://blog.csdn.net/saltriver/article/details/57531963</p>
<p>扩展：<a
target="_blank" rel="noopener" href="https://blog.csdn.net/saltriver/article/details/55105285">指数分布族</a>
### 3.1.1 spectral-based</p>
<p>spectral CNN: 直接将filter设置为了参数 ChebySheve:
重新改进了公式，定义了filter的计算，并使得公式的更新的复杂度降低，而且只需要用到空间中的局部信息
1阶：沟通两类, 在batch-learning时会指数级增加开销 AGCN:
扩展了Laplacian矩阵的适用范围，为每个图重定义了一个剩余矩阵，即完成有向图到无向图的转换</p>
<blockquote>
<p>所以这里的黑盒实际上就是数学表达式计算</p>
</blockquote>
<p>原本2D卷积是filter设置的是尺寸，而这里的filter有什么含义呢？ &gt;
就是从信号的角度，过滤得程度吧？？</p>
<p>所以说这里的GCN是有很多参数，然后反馈参数修正是当end时再来修正参数，对吗?</p>
<p>filter为什么是domin dependent,
比如两个不同的domin,人和物品，显然感觉不能吧</p>
<h3 id="spatial-based">3.1.2 spatial-based</h3>
<p>GNNs,GRU, SSE MMNN, GraphSage</p>
<p>recurrent GCN全一样 composition GCN全不一样</p>
<h4 id="recurrent">1) recurrent</h4>
<p>GNNs:
每个GCN考虑当前节点的属性，相关边的属性，邻居在上一步的表示，邻居的属性
GRU: 每个GCN将上一步的状态和邻居节点当前的状态放在GNU中进行考虑 SSE：
每个GCN,
随机地选取t个节点，进行更新表示然后随机第选取P个已经更新？的节点来更新梯度</p>
<ol type="1">
<li>GNNs
全是用的一个把所有因素都进行考虑的函数，唯一的点就是要保证这个函数收敛
循环神经网络</li>
<li>GRU 门控神经网络：
循环神经网络在时间步数较大或时间步数较小时，循环神经网络的梯度会衰减和爆炸</li>
</ol>
<p><font color="red">RNN</font> 循环神经网络 RNN
神经网络可以看作任意函数的黑盒子，目的是为了解决时序数据中存在的对应关系。
中间因为出现循环，所以某个状态会对应T步，但是还是基本的权重更新公式 &gt;
这里待推导！！！ &gt; 所以这里有个时间t原来是这么回事 &gt;
这里的时间步数就是关联程度的感觉
https://zhuanlan.zhihu.com/p/30844905</p>
<p>https://zybuluo.com/hanbingtao/note/541458</p>
<p><font color="red">GRU</font>
实际上的感觉就是认为RNN那样直接进行步长来更新（因为该步也要考自己来设置），这样可能导致问题，衰减或爆炸，所以这里的想法就是加入了门控，即在中间可以根据隐藏状态和当前出现的值来决定是否进一步计算还是改变当前值进行另一种计算。
https://zh.d2l.ai/chapter_recurrent-neural-networks/gru.html</p>
<ol start="3" type="1">
<li>SSE</li>
</ol>
<p>随机异步更新节点的表示，考虑历史状态和所有新状态 &gt; 神奇？
暂未涉猎， 直觉上会收敛</p>
<blockquote>
<p>这里统一的<span
class="math inline">\(h_v^t\)</span>是指v在第t个GCN所得到的值，注意这里的t是全局所设置的网络结构</p>
</blockquote>
<h4 id="composition-based">2) Composition Based</h4>
<p>MPNN： 每一步的GCN综合上一步的信息和邻居节点的更新操作集合的信息
GraphSage: one
batch在线学习的特点，根据域，聚集当前的邻居信息，使一个点成为最终状态；然后，为每个邻居进行更新；最后，知道所有的节点都成为了最终状态</p>
<ul>
<li>MPNN</li>
</ul>
<p>message passing: 信息函数，信息更新函数
这里的信息函数考虑到了上一步的信息，和关于邻居节点的所有更新操作
更新函数考虑到了自己的上一步的表示，邻居节点的表示和边的权重 readout
关于最后的值的读取函数</p>
<ul>
<li>GraphSage
看公式的话是每个位置有个权重，并且将上一次的点的状态和邻居节点的状态进行了考虑。</li>
</ul>
<p>过程？？ 不是很清楚？ 一种观点：</p>
<p>这里的节点是怎么选取的？ &gt;
它说的是保证各种聚集参数是对的，但是并未说其他的啊？？</p>
<p>首先对一个节点进行更新，然后根据邻居节点产生该节点的状态，然后使用中间节点的最终状态来预测和反馈错误。</p>
<p>也就是说先考虑一个点，然后传递错误到其他点，但是我会进行标记这个点已经不可再取。
而且当新的数据来临时，也可以采用直接训练的想法</p>
<h4 id="杂项">3) 杂项</h4>
<p>DCNN(缩小图的转移举证) PATCHY-SAN(先全局排序，CNN)
LGCN(得到邻接节点的特征矩阵处理排序后，CNN+子图搜索)
MMN(建议考虑边的权重，使用高斯核来学习)</p>
<ul>
<li>DCNN
模拟压缩图的扩散过程，所以这里除了权重，函数f应该具有缩小尺寸的功能
但是需要存储转移矩阵，耗费内存</li>
<li>PATCHY-SAN
先将节点排序，然后后面的所有做法就是选取特定的值，然后使用标准的CNN来做</li>
<li>LGCN * node level
在每次做的时候，对特征矩阵进行分析，选取特征矩阵的前多少行来做。
子图训练</li>
<li>MMN
*考虑了空间位置关系，即便的权重，建议使用标准的高斯核来学习参数调节边的权重
&gt; 绝大部分采用CNN,也有用GCN的</li>
</ul>
<h3 id="总结">3.1.3 总结</h3>
<p>recurrent 节点的稳定状态 composition 可能获得高级别的信息</p>
<p>但是要放隐藏状态，内存</p>
<p>子图训练： GraphSage确定一个的最终状态先,SSE完全随机的思想</p>
<p>复杂的网络结构取得成果 1. 增加深度和宽度 2. 多图维护信息 3.
超参数学习接收域的大小</p>
<h3 id="池化">3.1.4 池化</h3>
<p>chebNet首先进行池化，使得一开始的结构得到了改进，进一步取得了更好的效果
DGCNN 池化进行预处理排序 DIFFPOOL 使用两个GCN, 一个embed, 一个pool,
用来整合异质的GCN。</p>
<p>基于空间的在效率上可以使用batch和smapling提高效率，在泛化性上可以共享权重;在灵活性上，可以处理多源输入
## 3.2 GAN</p>
<ul>
<li><p>GAT 就是考虑所有邻居节点的表示和考虑邻居节点的权重 &gt;
不同的子空间是指的，随着当前所处的不同位置，可能得到的数据不同，所以就把所有子空间的邻居节点的位置堆叠吗。感觉是这样的
&gt; 这里的子空间也可以看做是某个模型</p></li>
<li><p>GAAN 在聚集不同子空间中的信息时，考虑不同的权重</p></li>
<li><p>GAM
不考虑所有的情况，考虑其中一段一段的状态，因为LSTM非常好用，就用它</p></li>
<li><p>AW 目标是node embedding,
即为了学习转移矩阵。操作的想法是，构造转移矩阵，并且当前的共现矩阵为所有转移矩阵之和的某种表示
&gt; ? 如何体现，应该是转移矩阵的参数体现吧</p></li>
</ul>
<p><strong>总结</strong></p>
<ul>
<li>注意力为邻居赋予权重</li>
<li>整合多个模型</li>
<li>指导random walks</li>
</ul>
<p>GCN每个聚集时，直接按照某种特定的属性进行聚集 GAN:
首先会通过一个神经网络结构来获得权重指派，等于说多加了一层网络结构</p>
<h2 id="gae">3.3 GAE</h2>
<p>编码：得到最终的编码结果</p>
<p>GAE: GCNs, 评价调节 AGRA: GCN产生，GAN训练 NetRA: 序列到序列，random
walks DNGR: 堆叠矩阵+噪声，基于统计数据 SDNE:
使用指标，评价邻居，评价结果，正则化项 DRNE: 重建节点，LSTM聚集函数</p>
<ul>
<li><p>GAE GCNs, 然后定义评价函数</p></li>
<li><p>AGRA GCN产生，GAN评价,
产生时服从某一先验分布，评价时选出服从分布的</p></li>
<li><p>混合变体</p>
<ul>
<li>NetRA: 通过序列到序列结构的random walks来重建序列</li>
<li>DNGR:
用堆叠的降噪的自动编码器来重建矩阵。具体做法是通过统计同时出现的数量与单独出现数量的比值的最大值来决定最终的共现矩阵的值。因为是直接根据数据特性来统计，所以所学得的东西应该是非线性的。另外一点就是，在做的时候随机增加了噪声</li>
<li>SDNE:
使用了两个指标，一个是隐藏节点表示与邻居节点隐藏表示之间的距离；一个是节点的输入与重新构造之间的距离（这里考虑了惩罚项）；最后，优化目标即为三个项+正则化项</li>
<li>DRNE:
直接考虑重建节点，设置损失函数，定义为所有邻居节点表示值与聚集函数(LSTM)的差</li>
</ul></li>
</ul>
<p>DNGR+SDNE：仅考虑拓扑结构 邻接矩阵的稀疏性： GAE: 重新赋予权重；
NetRA线性化；DNGR密集矩阵; SDNE: 惩罚</p>
<p>A+X经过Encoder, 再经过GCN,
得到一种简单的表示，然后经过非线性激活函数？
就可以由decoder重构出邻接举证吗？ &gt;
这前后是不是应该有严格的数学来做？加一层GCN，训练得到的参数是否还满足性质</p>
<h2 id="ggn">3.4 GGN</h2>
<p>重新生成图</p>
<ul>
<li><p>MolGAN
分布-&gt;Generator-&gt;密集邻接矩阵tensor(张量)-&gt;sample产生Graph-&gt;
GCN-&gt; Disciminator产生反馈和进行调节 &gt;
需要预知分布，共同产生边和节点</p></li>
<li><p>DGMG
采用加点和边的方式，有一个停止的标准；当decision为假时，加边；为真时，评估将加入的节点连接到已存在的节点的可能分布，然后随机选择一个点。当一个新的节点和它的连接都被加入图中，更新图的表示。
&gt; 需要预知分布，采用序列化的方式来做 &gt;
图的表示用来计算前面的decision,
所以该方法又称为根据图的表示产生图的节点和边</p></li>
<li><p>杂项</p>
<ul>
<li>GraphRNN
两个RNN，对于graph和level，操作在二进制序列上。如何添加根据假设分布来做。对于graph为了训练，用BFS线性化为序列
&gt; 采用序列化的方式来做，利用了统计数据？</li>
<li>NetGAN 产生器LSTM产生合理的random walks,
测试器GAN挑选，最后获得共现矩阵 &gt; 利用统计数据？
同时产生节点和边</li>
</ul></li>
</ul>
<p>序列化的方式在于，长序列会带来问题？？ 其他方式维护全局属性难
最近的采用变化的自动编码器做，增加输出空间
没有方法有很好的大规模可扩展性</p>
<p>产生+训练</p>
<h2 id="gsn">3.5 GSN</h2>
<p>DCRNN能处理长时间 CNN-GCN有效取决于1DCNN
ST-CNN考虑瞬时流作为节点的边，导致邻接矩阵平方增长，会导致计算图卷积层的开销增大，但是要堆叠很多次
Strutural-RNN需要先验知识来分割语义组</p>
<p>空间+瞬时</p>
<h1 id="其他">4. 其他</h1>
<h2 id="建议">4.1 建议</h2>
<p>go deep 感受野 扩展性： 什么时候具有扩展性？？
快采样（在线算法）和子图训练。不够
动力学和异质性：图的结构固定，节点和边不一定来源相同 ## 4.2 batch
learning vs stochastic learning</p>
<p>batch learning: 批量学习，是一种离线的学习方法 &gt;
离线学习，输入数据时不处理数据；训练数据时才处理数据 &gt;
总是全局最优的，但是耗时</p>
<p>stochastic learning: 随机学习，在线学习 &gt;
每输入一种数据都进行修正，这里默认的单位为1，即有一个样本时就进行修正
&gt;
那么问题的关键就在于这个样本是否有问题，即该模型就容易搜到噪声的影响，有问题的数据称为噪声；
但也有好处，能够节省时间。 &gt; 易陷入局部最优</p>
<p>深度网络的实现中都采用了两种方法的结合，即每次训练使用10个或者别的合适数目的样本，即可以稍微消除噪声的影响，又可以进行在线学习</p>
<p>https://blog.csdn.net/Buyi_Shizi/article/details/51454549</p>
<h2 id="无结构化数据-vs-结构化数据">4.3 无结构化数据 vs 结构化数据</h2>
<p>结构化数据即数据能够用二维表结构来逻辑表达实现的数据，通常每行和每列都有具体的含义</p>
<p>无结构数据即不能用数据二维逻辑来表现的数据，比如所有格式的办公文档、文本、图片、HTML等等</p>
<p>无结构化数据更难被计算机理解</p>
<p>https://zhuanlan.zhihu.com/p/29856645</p>
<h2 id="dropout">4.4 dropout</h2>
<p>为了解决过拟合现象，也就是用小数据集训练过于复杂的网络
训练深度神经网络，总会遇到两大问题：过拟合+费时，一定程度可以达到正则化的效果。</p>
<p>dropout就是在训练深度神经网络中，每次训练中，忽略一半的特征检测器（让一半的隐层节点值为0），这样可以明显地减少过拟合现象。</p>
<p>简单地说就是让某个神经元以一定的概率停止工作
https://zhuanlan.zhihu.com/p/38200980</p>
<h2 id="cross-entropy-loss">4.5 cross entropy loss</h2>
<p>回归问题常用的损失函数是均方误差MSE 分类问题常用的损失函数是交叉熵
&gt; 描述了两个概率分布之间的距离 &gt;
预测函数得出的结果应该是分为每一类的概率</p>
<p>在得到概率之前，softmax函数经常在交叉熵前面，用于把结果处理为[0,1]之间的概率</p>
<p>首先，如果用实际分类错误率来做，太粗略 为什么不用MSE？因为softmax +
MSE会产生非凸函数，不具有好的性质。 &gt; 这里自己可以进行分析</p>
<p>所以最终用的是交叉熵，softmax+交叉熵会产生凸函数，结果具有凸函数的性质。
&gt; 损失函数也会参与反馈传递误差的过程吗？</p>
<p><span class="math display">\[H_y(y) = - \sum_i y&#39;_i
log(y_i)\]</span> 为什么回归问题不用交叉熵?
因为<code>log-1.5</code>没有意义。 &gt;
MSE是在欧式距离为误差度量的情况下，由系数矩阵所张成的向量空间内对于观测向量的最佳逼近点</p>
<p>结论： traning中需要用最反映实际情况的，即分类问题用交叉熵 &gt;
交叉熵用在training这里是体现训练误差的，损失函数的设置是用来指导如何进行梯度下降的。</p>
<p>validation/testing中，关注的就是分类的错误率，所以用分类错误率即可。</p>
<p>https://blog.csdn.net/xg123321123/article/details/80781611</p>
<p>https://www.cnblogs.com/pinard/p/5970503.html</p>
<h1 id="简要">5. 简要</h1>
<h2 id="gcns">5.1. GCNS</h2>
<h3 id="spectral-based">5.1.1 spectral-based</h3>
<p>spectral CNN: 直接将filter设置为了参数 ChebySheve:
重新改进了公式，定义了filter的计算，并使得公式的更新的复杂度降低，而且只需要用到空间中的局部信息
1阶：沟通两类, 在batch-learning时会指数级增加开销 AGCN:
扩展了Laplacian矩阵的适用范围，为每个图重定义了一个剩余矩阵，即完成有向图到无向图的转换</p>
<h3 id="spatial-based-1">5.1.2 spatial-based</h3>
<ul>
<li><p>recurrent GNNs:
每个GCN考虑当前节点的属性，相关边的属性，邻居在上一步的表示，邻居的属性
GRU: 每个GCN将上一步的状态和邻居节点当前的状态放在GNU中进行考虑 SSE：
每个GCN,
随机地选取t个节点，进行更新表示然后随机地选取P个已经更新？的节点来更新梯度</p></li>
<li><p>Composition Based MPNN：
每一步的GCN综合上一步的信息和邻居节点的更新操作集合的信息 GraphSage: one
batch在线学习的特点，根据域，聚集当前的邻居信息，使一个点成为最终状态；然后，为每个邻居进行更新；最后，知道所有的节点都成为了最终状态</p></li>
<li><p>杂项 DCNN(缩小图的转移举证) PATCHY-SAN(先全局排序，CNN)
LGCN(得到邻接节点的特征矩阵处理排序后，CNN+子图搜索)
MMN(建议考虑边的权重，使用高斯核来学习)</p></li>
</ul>
<h3 id="池化-1">5.1.3 池化</h3>
<p>chebNet首先进行池化，使得一开始的结构得到了改进，进一步取得了更好的效果
DGCNN 池化进行预处理排序 DIFFPOOL 使用两个GCN, 一个embed, 一个pool,
用来整合异质的GCN。</p>
<h2 id="gan">5.2. GAN</h2>
<p>GAT:
考虑邻居及诶点的表示和邻居节点的权重。并且考虑子空间，不过每个子空间都是相同的权重
GAAN: 不同的权重 GAM: 考虑用的因素不再全部，而是一段一段 AM: 目标是node
embedding, 直接学习转移矩阵，由注意力指导random walks</p>
<h2 id="gae-1">5.3. GAE</h2>
<p>GAE: GCNs, 评价调节 AGRA: GCN产生，GAN训练 NetRA: 序列到序列，random
walks DNGR: 堆叠矩阵+噪声，基于统计数据, 统计出来的结果 SDNE:
使用指标，评价邻居，评价结果，正则化项 DRNE: 重建节点，LSTM聚集函数</p>
<h2 id="ggn-1">5.4. GGN</h2>
<p>MolGAN: 基于分布 ，产生图和点，然后产生Graph,GCN,再调节 DGMG:
获得一个图的表示后，做一个决定，根据决定来加边，或从分布中加点,操作在序列上
GraphRNN: 两个RNN, 一个graph训练，一个edge由分布来做 NetGAN:
LSTM产生合理的random walks, 测试器筛选，最终获得共现矩阵</p>
<h2 id="gsn-1">5.5. GSN</h2>
<p>DCRNN: 出度入度-空， DCGRU-瞬时 CNN-GNN: GCN空间，1DCNN-瞬时 ST-CNN:
瞬时流作为边，同时考虑。用邻接举证距离的和作为最终接地那的值
Strutual-RNN: 语义组，GCN瞬时；nodeRNN接edgeRNN输出空间</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ypwang.github.io/2019/gnn-parallel-gnn-semi-gnn-paper-read-1c84427ec79e/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/default-avatar.png">
      <meta itemprop="name" content="Yun-Pan Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life's Notes">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/gnn-parallel-gnn-semi-gnn-paper-read-1c84427ec79e/" class="post-title-link" itemprop="url">gnn-parallel gnn semi-gnn paper read</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-19 12:56:18" itemprop="dateCreated datePublished" datetime="2019-09-19T12:56:18+08:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-27 09:05:35" itemprop="dateModified" datetime="2021-05-27T09:05:35+08:00">2021-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/gnn-parallel/" itemprop="url" rel="index"><span itemprop="name">gnn-parallel</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/gnn-parallel/gnn/" itemprop="url" rel="index"><span itemprop="name">gnn</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="introduction">1. Introduction</h2>
<p>半监督学习步骤： 1. 选取标记数据，划分为训练集、验证集和测试集 2.
根据数据进行学习、训练模型</p>
<ul>
<li><p>模型目标函数 <span class="math display">\[\mathcal{L} =
\mathcal{L}_0 + \lambda \mathcal{L}_{reg}\]</span> 这里， <span
class="math inline">\(\mathcal{L}_0 = \sum_{(\vec{x}, y)} H(\vec{x},
y)\)</span> <span class="math inline">\(\mathcal{L}_{reg}=\sum_{i,j}
A_{ij} ||f(x_i)-f(x,j) ||^2 = f(X)^T (D - A) f(X)\)</span> &gt; 这里
<span class="math inline">\(D_{ii}=\sum_j A_{ij}\)</span>为对角矩阵,
该正则化项是二范数，所以<span
class="math inline">\(\lambda\)</span>为L2参数</p>
<p>其中 <span class="math inline">\(H(\vec{x}, y) = - \sum_i y&#39;_i
log y_i\)</span>， 表示交叉熵损失函数 &gt;
使用交叉熵损失函数式，上一步为softmax函数，即指数标准化函数; <span
class="math inline">\(y&#39;_i\)</span>是即真实类别，<span
class="math inline">\(y_i\)</span>是对应节点最终得出来的关于某个类别的概率</p>
<p>进一步， <span class="math display">\[y = softmax(\hat{A}\
ReLU(\hat{A}XW^{(0)})\ W^{(1)})\]</span> &gt;
y是深度神经网络预测出来的每个类别的概率的矩阵, 这里是三层的公式</p>
<p>多层的公式即为，<span class="math inline">\(y = softmax(\tilde{A}\
ReLU(\tilde{A}\ ReLU(...)\ W^{(n-1)})\ W^{(n)})\)</span></p>
<p>在这里层与层之间的更新公式有两种：</p>
<ul>
<li><span class="math inline">\(X^{(l+1)} = \delta
(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} X^{(l)}
W^{(l)})\)</span>
<ul>
<li><span class="math inline">\(\tilde{A}=A+I_N\)</span>:
这里增加考虑了自己的因素;</li>
<li><span class="math inline">\(\tilde{D}_{ii}=\sum_j
\tilde{A}_{ij}\)</span></li>
<li><span class="math inline">\(W_{(l)}\)</span>是每层的权重</li>
<li><span class="math inline">\(\delta\)</span>是激活函数，比如<span
class="math inline">\(ReLU(\cdot)=max(\cdot, 0)\)</span></li>
<li><span class="math inline">\(X^{(0)}= X\)</span>,
表示每一层表示得到的表示 <img data-src="asserts/paper2/fig1.png" /> &gt;
这里C是输入的channel, F是倒数第二层的输出channel</li>
</ul></li>
<li><span class="math inline">\(X^{(l+1)} = \delta
(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} X^{(l)}
W^{(l)}) + X^{(l)}\)</span> &gt; 又称为+残差 Residual</li>
</ul></li>
</ul>
<p><span class="math display">\[ \mathbf{\hat{A}} =
\mathbf{\tilde{D}^{-\frac{1}{2}}} \mathbf{\tilde{A}}
\mathbf{\tilde{D}^{-\frac{1}{2}}} \]</span> <span
class="math display">\[ \hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A}
\tilde{D}^{-\frac{1}{2}}\]</span> - 模型更新 &gt;
Adam优化器，自适应梯度下降优化器
https://www.jianshu.com/p/aebcaf8af76e</p>
<h2 id="公式的由来">3. 公式的由来</h2>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1211.0053.pdf">spectual based</a></p>
<p><a target="_blank" rel="noopener" href="https://hal.inria.fr/inria-00541855/document">Hammond.</a>
&gt; 近似方法推导的来源</p>
<p><a
target="_blank" rel="noopener" href="https://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering.pdf">Cheby方法</a></p>
<h2 id="相关工作">4. 相关工作</h2>
<ol type="1">
<li>内存扩展</li>
<li>使用mini batch 随机梯度下降</li>
</ol>
<h3 id="基于图的半监督学习">4.1 基于图的半监督学习</h3>
<p>拉普拉斯矩阵： 标签传播、多种正则化、深度半监督表示</p>
<p>注意力机制： DeepWalk, &gt; skim-gram model,
简单来说就是，当要看当前单词时，向前或向后看几个单词 &gt;
通常这些做法有种更多的步骤或者宽度优先模式，所以需要考虑用哪一步进行优化才是最恰当的</p>
<h3 id="关于图的神经网络">4.1 关于图的神经网络</h3>
<p>2009的框架重复利用了收缩的想法进行传播误差直到最终节点的表示到达一个稳定的状态</p>
<p>2015年的做法介绍了一种类似卷积的传播规则作用在图上，并且针对于图级别的分类。但是可以发现，因为卷积要求有着固定的邻居。所以这种做法是不符合当节点的度有着很广的分布的情况。
&gt; 这篇文章会重新考虑计算邻接矩阵，所以不会担心有这种因素的出现</p>
<p>2016,1-DNN, 引入了排序的想法 本文的方法，2014,简单，可扩展</p>
<h2 id="实验">5. 实验</h2>
<h3 id="数据集">5.1 数据集</h3>
<p><strong>类别</strong> 1. 引用网络 Citeseer, Cora, Pubmed 2. 知识图
NELL, 本身属于二部图</p>
<p><strong>内容</strong> 数据： 数据类别， 节点， 边（这里会进行定义），
classes:节点的类别， features:输入的channels， Label rate:
用作训练的数据集</p>
<p><img data-src="asserts/paper2/dataset.png" /></p>
<p><strong>预处理</strong> - 引用网络
无向图，不用处理，二进制邻接举证；每个类只使用了20个标记，使用了全部的特征
&gt; 1. 是如何筛选出训练集和测试集的？ &gt; &gt; 2.
是否保证了训练集中各个标记的样本的比例相同？</p>
<ul>
<li><p>NELL 有向图，预处理同2016. 做法将(e1, r, e2)拆分为(e1,r1), (e2,
r2) <code>也就是将节点拆分成了很多片,
这样从某种程度就可以使得一条边可以被两个点同时共用</code>
所以也就使得得到的节点表示是稀疏向量，one-hot作为特征，所以产生了61278维，<code>这里可以注意到，one-hot每一个特征所拥有的取值即其位数</code>，如果两个节点中存在边的话，则说明边是存在的，则对应邻接矩阵中置为1</p></li>
<li><p>Random graphs
我们模拟各种尺寸的随机图数据集，并在每轮中测试训练时间。
一般的做法时，随机地为N个节点赋予2N条边。对于每个节点的特征初始化为<span
class="math inline">\(I_N\)</span>,
表示每个节点并没有什么特征。并为每个节点置一个假标记<span
class="math inline">\(Y_i = 1\)</span> &gt; 目的是为了什么？
有什么用？</p></li>
</ul>
<h3 id="实验部分">5.2 实验部分</h3>
<p>首先是3层的网络，附录B中有10层的网络。 data split技术 <a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.08861.pdf">Yang, 2016</a> &gt; ？
这里是1000个样本做测试，500个样本做交叉验证的意思吗？</p>
<p>3层的网络，超参数： - dropout - L2 - number of units - optimizer &gt;
优化器，就是采用什么样的梯度下降方式</p>
<blockquote>
<p>这里不使用验证集作为训练，那还是用的交叉验证的方法吗？？</p>
</blockquote>
<p>在Cora上优化得到的超参数直接用到Citeseer, Pumbed。
训练中优化器使用的是Adam， 学习率为0.01 &gt;
Adam优化器，自适应梯度下降优化器
https://www.jianshu.com/p/aebcaf8af76e</p>
<p>停止条件：最大训练轮数200轮，如果交叉验证集误差连续10次不下降则停止训练。
权重初始化和特征向量标准化方法：<a
target="_blank" rel="noopener" href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Glorot
&amp; Bengio 2010</a> 隐藏层单元：32个 忽略正则化项 &gt;
隐藏层单元的设置除了对业务的理解，还有什么其他的建议点？ &gt;
否则一般有经验公式</p>
<h3 id="baselines">5.3 baselines</h3>
<blockquote>
<p>注意到这里baselines比较了前面提到的基于图的半监督学习中所有目前有的论文的模型。并且可以忽略其中不适合的模型</p>
</blockquote>
<p>忽略了TSVM, 不适用于大规模分类</p>
<p>进一步与Lu提出的迭代分类算法ICA进行了比较，结合两个逻辑回归分类器，一个用于本地接地那特征，一个用于使用局部特征和聚合算子的关系进行分类。首先，使用所欲标记的训练集训练本地分类器并使用它用于引导为未标记节点的类标记。然后，运行迭代分类器，随机节点排序，对所有未标记的节点进行10次迭代。<code>这里是为了做什么</code>
L2交叉验证和聚集函数的选择都是基于每个数据集的验证集的性能分别进行选择
选择了Planetoid，选择了它们模型最好的变体</p>
<h2 id="结果">6. 结果</h2>
<p>ICA随机选择100论随机节点排序运行的平均准确率</p>
<h2 id="贡献">7. 贡献</h2>
<p>主要有两个贡献： 1. 提出了一种新的梯度计算公式 2.
这个模型可以快速用于大规模的半监督的节点分类中</p>
<h2 id="一些超参数">一些超参数</h2>
<pre><code>- dropout
&gt; 每层都可以设置，[0,1], 表示以多大的概率使当前节点停止工作，避免过拟合
- L2 正则化系数
&gt; ?为啥有第一层， 这里的理解不应该是$\lambda$吗
- number of units for each hidden layer 隐藏层节点个数
&gt; 隐藏层表示的特征数？ 对吗？
- 学习率
&gt; $\eta$: 梯度下降的步长</code></pre>
<h2 id="很神奇的地方">很神奇的地方</h2>
<pre><code>- filter公式的推出
- Tk的近似
- K=1, $\lambda_&#123;max&#125;$的取值</code></pre>
<h2 id="一些定义">一些定义</h2>
<p><span class="math inline">\(G = (\mathcal{V}, \mathcal{E})\)</span>
顶点数和边数</p>
<p>F-- output layer的channel个数 C-- input layer的channel个数 H-- input
layer的输出，channel, hidden layer的输入 ## 一些不懂的点</p>
<p>训练集 &gt;
由损失函数，特定的评价指标；一般看的训练误差也就是损失函数的误差。</p>
<p>交叉验证集：用于评价泛化性如何，是否产生了过拟合现象，然后交叉验证的准确率可以进行反应
&gt;
如果表现得很低，那么有可以在训练集上进行重新训练；再次交叉验证，唯一注意的是不能混用。
&gt;
然后，一般来说采用的是K交叉验证，即将数据集分为K份，最终的做法是取这些值的平均值来做</p>
<blockquote>
<p>???
K交叉取平均会不会混淆，因为在用的时候，实际是在多次训练时，虽然本次没有用到数据集，但是在下一次肯定用到了，那么是不是有问题</p>
</blockquote>
<blockquote>
<p>如果是独立的训练，那么又是取哪个值来做呢？ 注意关注一下交叉验证.
https://blog.csdn.net/lhx878619717/article/details/49079785
按这里的说法，就是分为k份，然后每次训练集是独立的，最终选取的目标其实就是测试误差最小的模型为最优模型。该模型的参数就是最终的参数
突然想起，之前的学习也说明了这里的问题</p>
</blockquote>
<p>测试集：最终的真实结果，未知 &gt;
从某种意义上讲，交叉验证的实际结果应该和测试集上表现尽量相同，也就是说性能度量指标基本上就是在这里用的。
&gt; 一般来说实验的精确率就是用交叉验证集和测试集的交过来反映来看 &gt;
但是这里不一定相等，因为存在训练集过小等因素</p>
<blockquote>
<p>比如，查准率，查全率，F1</p>
</blockquote>
<p>https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89</p>
<p>学习率：反向传播中的步长 L2正则化参数：L2的系数</p>
<p>矩阵 &gt;
一般来说，把向量定义为列向量；为什么？因为人们就作用来说，还是习惯左作用。
&gt; 比如A对应的线性映射为Ax https://www.zhihu.com/question/26304877</p>
<h2 id="不懂的地方">不懂的地方</h2>
<p>表达式不懂</p>
<p>hidden层的激活函数是怎么用的？</p>
<p>交叉熵和MSE最小平方法都是用来做损失函数的</p>
<p>几个概念： - 损失函数：单个样本 - 代价函数：针对总体 -
目标函数：通常会考虑正则化项</p>
<p>所以这里正则化项系数就是目标函数中使用的是哪种正则化项，然后就对应于哪个参数</p>
<p>其实，本身一般来说是把问题经过抽象变成最优化问题的，这里的最优化问题可以分为有约束最优化问题，无约束最优化问题以及其他；
然后，本身最优化问题有多种解的，比如模拟退火算法、遗传算法、蚁群算法、图割算法。
但是，在机器学习中，一直长学的求导占了主要的位置，所以考虑的就是使用求导法，也就是所谓的梯度下降，然后所以每次在考虑很多的问题都想要保证凸函数，因为这样才能保证取得全局最优解</p>
<p>https://blog.csdn.net/liujiboy/article/details/78078042</p>
<p>然后，又怎么转化到学习上去了呢？就是为什么是大量的样本上去了呢。其实，本身不管是什么事情，除非是固定的数学问题，都是一个学习的过程。那么，就永远不会到达最理想的状态，所以就是学习本身，那么引入正则化项也合理了，就是为了避免进行过拟合。</p>
<blockquote>
<p>更深入地从KL散度了解交叉熵
https://blog.csdn.net/tsyccnh/article/details/79163834</p>
</blockquote>
<p>sigmoid函数，1/(1+e^(-x)) 将R映射到了[0,1]</p>
<p>https://zhuanlan.zhihu.com/p/3824176</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yun-Pan Wang"
      src="/images/default-avatar.png">
  <p class="site-author-name" itemprop="name">Yun-Pan Wang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">115</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">72</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">69</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/AugF" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;AugF" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wangyp@smail.nju.edu.cn" title="E-Mail → mailto:wangyp@smail.nju.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/Joswxe" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;Joswxe" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.google.com/" title="https:&#x2F;&#x2F;www.google.com" rel="noopener" target="_blank">Google</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://cn.bing.com/" title="https:&#x2F;&#x2F;cn.bing.com" rel="noopener" target="_blank">Bing</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.baidu.com/" title="https:&#x2F;&#x2F;www.baidu.com" rel="noopener" target="_blank">Baidu</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">[object Object]</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">466k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">7:04</span>
</div>!

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://ypwang.github.io/page/4/',]
      });
      });
  </script>



</body>
</html>
